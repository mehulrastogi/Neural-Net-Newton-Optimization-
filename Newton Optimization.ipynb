{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has an example of Neton Optimization tecnique on a Multilayer Perceptron using NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but first wee need to undestand what is a Newton Optimization Technique and how is it dfferent from the Gradient Descent Tecnique gernally used for optimizing a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.seterr('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am building a normal forward propogation for a single perceptron\n",
    "# and the various function i would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #this is the non-linear activation function\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Declaring Traing Data        ############\n",
    "#############################################\n",
    "X_train = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_train = np.array([[1],[0],[0],[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    '''\n",
    "    Class containing loss functions\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def sq_loss(self , pred ,Y):\n",
    "        loss = Y - pred\n",
    "        loss_dash = -1 * loss\n",
    "        loss = 1/2 * np.sum(loss * loss)\n",
    "        loss_dash_dash = -1\n",
    "        \n",
    "        \n",
    "        return loss,loss_dash,loss_dash_dash\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Layer:\n",
    "    '''\n",
    "    This is a very specefic Neuron class that uses sigmoid activation\n",
    "    and square loss.\n",
    "    '''\n",
    "    def __init__(self,l0,l1):\n",
    "        self.W = np.random.randn(l0 ,l1).astype(np.float128) * np.sqrt(2.0 /l0 )\n",
    "        self.b = np.zeros((l1)).astype(np.float128)\n",
    "        print(self.W.shape , self.b.shape)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        #print(X.shape , self.W.shape , self.b.shape)\n",
    "        h_x = X.dot(self.W) + self.b\n",
    "        h_x = sigmoid(h_x)\n",
    "        return h_x\n",
    "    \n",
    "    def update_newton(self,X,h_x,d_back , d_back_dash):\n",
    "        #f_x = self.forward(X)\n",
    "        f_x = h_x\n",
    "        \n",
    "        #Derivating w.r.t W\n",
    "        temp = f_x * (1 - f_x) #this value was computed again and again\n",
    "        f_x_dash_W = X.T.dot(temp * d_back)\n",
    "        \n",
    "        first_term = X.T.dot(h_x * (1-h_x) * d_back_dash) * X.T.dot(h_x * (1-h_x))\n",
    "        second_term = (X*X).T.dot(d_back * (h_x * (1 - h_x) * (1 - 2 * h_x)))\n",
    "        f_x_dash_dash_W =  first_term + second_term\n",
    "        \n",
    "        #Derivating w.r.t b\n",
    "        f_x_dash_b = temp * d_back\n",
    "        \n",
    "        first_term = d_back_dash * np.square(temp)\n",
    "        second_term = d_back * temp * (1 - 2 * h_x)\n",
    "        f_x_dash_dash_b = first_term + second_term\n",
    "        \n",
    "        #Derivating w.r.t x(to return to previous layers)\n",
    "        f_x_dash_x = (temp * d_back).dot(self.W.T)\n",
    "        \n",
    "        first_term = (d_back_dash * temp).dot(self.W.T) * temp.dot(self.W.T)\n",
    "        second_term = (d_back * h_x * (1 - h_x ) * (1 - 2 * h_x)).dot(np.square(self.W).T)\n",
    "        f_x_dash_dash_x = first_term + second_term\n",
    "        \n",
    "        delta_W = -1 * (f_x_dash_W / f_x_dash_dash_W)\n",
    "        self.W = self.W + delta_W\n",
    "        \n",
    "        delta_b = -1 * np.sum(f_x_dash_b / f_x_dash_dash_b , axis = 0)\n",
    "        self.b = self.b + delta_b\n",
    "        \n",
    "        d_back = f_x_dash_x\n",
    "        d_back_dash = f_x_dash_dash_x\n",
    "        \n",
    "        return d_back,d_back_dash\n",
    "        \n",
    "    def update_batch_gradient_descent(self , X , h_x , d_back,alpha = 0.01):\n",
    "        \n",
    "        f_x = h_x\n",
    "        \n",
    "        temp = f_x * (1 - f_x) * d_back\n",
    "        #Derivating w.r.t W\n",
    "        f_x_dash_W = X.T.dot(temp)\n",
    "        \n",
    "        #Derivatng w.r.t b\n",
    "        f_x_dash_b = temp\n",
    "        \n",
    "        #Derivating w.r.t x(to return to previous layers)\n",
    "        f_x_dash_x = temp.dot(self.W.T)\n",
    "        \n",
    "        #Update W\n",
    "        delta_W = f_x_dash_W\n",
    "        self.W = self.W - alpha * delta_W\n",
    "        \n",
    "        #Update b\n",
    "        delta_b = np.sum(f_x_dash_b , axis =0)\n",
    "        self.b = self.b - alpha * delta_b\n",
    "        \n",
    "        d_back = f_x_dash_x\n",
    "        return d_back\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model , X , Y):\n",
    "    pred = model.forward(X)\n",
    "    pred =pred > 0.5\n",
    "    acc = np.sum(pred == Y)\n",
    "    acc = acc / Y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "# Declare a neuron with shape of weights as [shape_of_input,1]\n",
    "model = Neural_Layer(2,1)\n",
    "loss_m = Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       ],\n",
       "       [0.41036746],\n",
       "       [0.54326179],\n",
       "       [0.45289868]], dtype=float128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model outputs\n",
    "model.forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 0th epoch : 0.5064273411256793  Training Accuracy:0.25\n",
      "The training loss at 1th epoch : 0.516434484138249  Training Accuracy:0.75\n"
     ]
    }
   ],
   "source": [
    "# Now we can train the model by training on a batch.As our batch is equal to the raing data.1 iter = 1 epoch\n",
    "\n",
    "\n",
    "def train_newton_update(model ,loss_m,X_train , Y_train,epochs):\n",
    "    for i in range(epochs):\n",
    "        h_x = model.forward(X_train)\n",
    "        loss,d_loss,d_loss_dash = loss_m.sq_loss(h_x,Y_train)\n",
    "        acc = accuracy(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        \n",
    "        model.update_newton(X_train,h_x , d_loss,d_loss_dash)        \n",
    "\n",
    "train_newton_update(model , loss_m , X_train,Y_train , 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can predict the values for unseen data or trained data also\n",
    "# We can also calculate the accuracy of the model we have trained\n",
    "accuracy(model , X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (1,)\n",
      "The training loss at 0th epoch : 0.5035487222282764  Training Accuracy:0.5\n",
      "The training loss at 1th epoch : 0.5035441470201979  Training Accuracy:0.5\n",
      "The training loss at 2th epoch : 0.5035395796637846  Training Accuracy:0.5\n",
      "The training loss at 3th epoch : 0.503535020130299  Training Accuracy:0.5\n",
      "The training loss at 4th epoch : 0.5035304683911919  Training Accuracy:0.5\n",
      "The training loss at 5th epoch : 0.5035259244180997  Training Accuracy:0.5\n",
      "The training loss at 6th epoch : 0.5035213881828448  Training Accuracy:0.5\n",
      "The training loss at 7th epoch : 0.5035168596574321  Training Accuracy:0.5\n",
      "The training loss at 8th epoch : 0.5035123388140494  Training Accuracy:0.5\n",
      "The training loss at 9th epoch : 0.5035078256250654  Training Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "model = Neural_Layer(2,1)\n",
    "loss_m = Loss()\n",
    "\n",
    "def train_gradient_update(model ,loss_m,X_train , Y_train,epochs):\n",
    "    for i in range(epochs):\n",
    "        h_x = model.forward(X_train)\n",
    "        loss,d_loss,_ = loss_m.sq_loss(h_x,Y_train)\n",
    "        acc = accuracy(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        \n",
    "        model.update_batch_gradient_descent(X_train,h_x , d_loss , 0.01)        \n",
    "\n",
    "train_gradient_update(model , loss_m , X_train,Y_train , 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can predict the values for unseen data or trained data also\n",
    "# We can also calculate the accuracy of the model we have trained\n",
    "accuracy(model , X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built a single perceptron layer we can scale it to make a neural net(A deep Neral Net would just be adding more layers on it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to make a Neural Network that is scalable from scratch.That is it can be directly used as a library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    \n",
    "    def __init__(self , layer_list):\n",
    "        \n",
    "        \n",
    "        self.hidden_layers = len(layer_list) - 1\n",
    "        \n",
    "        self.layers = {}\n",
    "        \n",
    "        for i in range(self.hidden_layers):            \n",
    "            self.layers[i+1] = Neural_Layer(layer_list[i] , layer_list[i+1])\n",
    "            \n",
    "            \n",
    "    def forward(self , X_train):\n",
    "        t = X_train\n",
    "        cache = []\n",
    "        cache.append(t)        \n",
    "        for i in range(self.hidden_layers):\n",
    "            t = self.layers[i+1].forward(t)\n",
    "            cache.append(t)\n",
    "            \n",
    "        return t,cache\n",
    "    \n",
    "    def update_newton(self , cache, d_back,d_back_dash):\n",
    "        #list of activations--cache\n",
    "        \n",
    "        for i in range(self.hidden_layers , 0 , -1):\n",
    "            d_back,d_back_dash = self.layers[i].update_newton(cache[i-1],cache[i],d_back,d_back_dash)\n",
    "            \n",
    "        return d_back,d_back_dash \n",
    "    \n",
    "    def update_gradient(self , cache, d_back , alpha=0.01):\n",
    "        for i in range(self.hidden_layers , 0 , -1):\n",
    "            d_back = self.layers[i].update_batch_gradient_descent(cache[i-1],cache[i],d_back,alpha)\n",
    "            \n",
    "        return d_back \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_neural_net(model , X , Y):\n",
    "    pred,_ = model.forward(X)\n",
    "    pred =pred > 0.5\n",
    "    acc = np.sum(pred == Y)\n",
    "    acc = acc / Y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (3,)\n",
      "(3, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "# Lets make a neural net as follows\n",
    "# visible_layer-->3 neurons-->1 neuron\n",
    "layer_list = [2 , 3, 1]\n",
    "model = Neural_Net(layer_list)\n",
    "loss_m = Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28102243],\n",
       "       [0.38233196],\n",
       "       [0.27124511],\n",
       "       [0.35378332]], dtype=float128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,_ = model.forward(X_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 0th epoch : 0.5771381906037006  Training Accuracy:0.5\n",
      "The training loss at 1th epoch : 0.632520062156091  Training Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "def train_newton_update(model ,loss_m,X_train , Y_train,epochs):\n",
    "    for i in range(epochs):\n",
    "        act , cache = model.forward(X_train)\n",
    "        loss,d_back,d_back_dash = loss_m.sq_loss(act,Y_train)\n",
    "        acc = accuracy_neural_net(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        model.update_newton(cache,d_back,d_back_dash)        \n",
    "\n",
    "train_newton_update(model , loss_m , X_train,Y_train , 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_neural_net(model,X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (3,)\n",
      "(3, 1) (1,)\n",
      "The training loss at 0th epoch : 0.8528249546211842  Training Accuracy:0.5\n",
      "The training loss at 1th epoch : 0.8492732557401613  Training Accuracy:0.5\n",
      "The training loss at 2th epoch : 0.8455912896380257  Training Accuracy:0.5\n",
      "The training loss at 3th epoch : 0.841773865269743  Training Accuracy:0.5\n",
      "The training loss at 4th epoch : 0.8378156820199799  Training Accuracy:0.5\n",
      "The training loss at 5th epoch : 0.8337113496857546  Training Accuracy:0.5\n",
      "The training loss at 6th epoch : 0.8294554133471445  Training Accuracy:0.5\n",
      "The training loss at 7th epoch : 0.8250423838438584  Training Accuracy:0.5\n",
      "The training loss at 8th epoch : 0.8204667746378649  Training Accuracy:0.5\n",
      "The training loss at 9th epoch : 0.8157231458989778  Training Accuracy:0.5\n",
      "The training loss at 10th epoch : 0.810806156696766  Training Accuracy:0.5\n",
      "The training loss at 11th epoch : 0.8057106262125071  Training Accuracy:0.5\n",
      "The training loss at 12th epoch : 0.800431604891752  Training Accuracy:0.5\n",
      "The training loss at 13th epoch : 0.7949644564322533  Training Accuracy:0.5\n",
      "The training loss at 14th epoch : 0.7893049514325622  Training Accuracy:0.5\n",
      "The training loss at 15th epoch : 0.783449373400623  Training Accuracy:0.5\n",
      "The training loss at 16th epoch : 0.7773946376245371  Training Accuracy:0.5\n",
      "The training loss at 17th epoch : 0.7711384231232739  Training Accuracy:0.5\n",
      "The training loss at 18th epoch : 0.7646793175067048  Training Accuracy:0.5\n",
      "The training loss at 19th epoch : 0.75801697406559  Training Accuracy:0.5\n",
      "The training loss at 20th epoch : 0.7511522797688469  Training Accuracy:0.5\n",
      "The training loss at 21th epoch : 0.7440875320578239  Training Accuracy:0.5\n",
      "The training loss at 22th epoch : 0.7368266213931595  Training Accuracy:0.5\n",
      "The training loss at 23th epoch : 0.729375215438149  Training Accuracy:0.5\n",
      "The training loss at 24th epoch : 0.7217409395779028  Training Accuracy:0.5\n",
      "The training loss at 25th epoch : 0.7139335472205041  Training Accuracy:0.5\n",
      "The training loss at 26th epoch : 0.705965072073459  Training Accuracy:0.5\n",
      "The training loss at 27th epoch : 0.6978499534315231  Training Accuracy:0.5\n",
      "The training loss at 28th epoch : 0.6896051245734126  Training Accuracy:0.5\n",
      "The training loss at 29th epoch : 0.6812500537921043  Training Accuracy:0.5\n",
      "The training loss at 30th epoch : 0.6728067275394143  Training Accuracy:0.5\n",
      "The training loss at 31th epoch : 0.6642995658149642  Training Accuracy:0.5\n",
      "The training loss at 32th epoch : 0.6557552614179099  Training Accuracy:0.5\n",
      "The training loss at 33th epoch : 0.6472025371069162  Training Accuracy:0.5\n",
      "The training loss at 34th epoch : 0.6386718181050267  Training Accuracy:0.5\n",
      "The training loss at 35th epoch : 0.6301948216639208  Training Accuracy:0.5\n",
      "The training loss at 36th epoch : 0.6218040703660528  Training Accuracy:0.5\n",
      "The training loss at 37th epoch : 0.6135323411633878  Training Accuracy:0.5\n",
      "The training loss at 38th epoch : 0.6054120673825183  Training Accuracy:0.5\n",
      "The training loss at 39th epoch : 0.5974747155447558  Training Accuracy:0.5\n",
      "The training loss at 40th epoch : 0.5897501623160074  Training Accuracy:0.5\n",
      "The training loss at 41th epoch : 0.5822660987336059  Training Accuracy:0.5\n",
      "The training loss at 42th epoch : 0.5750474887136997  Training Accuracy:0.5\n",
      "The training loss at 43th epoch : 0.5681161065881905  Training Accuracy:0.5\n",
      "The training loss at 44th epoch : 0.5614901741662651  Training Accuracy:0.5\n",
      "The training loss at 45th epoch : 0.5551841119212442  Training Accuracy:0.5\n",
      "The training loss at 46th epoch : 0.5492084119325308  Training Accuracy:0.5\n",
      "The training loss at 47th epoch : 0.5435696328546842  Training Accuracy:0.5\n",
      "The training loss at 48th epoch : 0.5382705101566114  Training Accuracy:0.5\n",
      "The training loss at 49th epoch : 0.5333101688133939  Training Accuracy:0.5\n",
      "The training loss at 50th epoch : 0.528684421022038  Training Accuracy:0.5\n",
      "The training loss at 51th epoch : 0.5243861286216379  Training Accuracy:0.5\n",
      "The training loss at 52th epoch : 0.5204056087778889  Training Accuracy:0.5\n",
      "The training loss at 53th epoch : 0.5167310619942969  Training Accuracy:0.5\n",
      "The training loss at 54th epoch : 0.5133490033435089  Training Accuracy:0.5\n",
      "The training loss at 55th epoch : 0.510244680593523  Training Accuracy:0.5\n",
      "The training loss at 56th epoch : 0.5074024662348173  Training Accuracy:0.5\n",
      "The training loss at 57th epoch : 0.5048062139252217  Training Accuracy:0.5\n",
      "The training loss at 58th epoch : 0.5024395732543308  Training Accuracy:0.5\n",
      "The training loss at 59th epoch : 0.5002862597661553  Training Accuracy:0.5\n",
      "The training loss at 60th epoch : 0.4983302797306869  Training Accuracy:0.5\n",
      "The training loss at 61th epoch : 0.49655611116192744  Training Accuracy:0.75\n",
      "The training loss at 62th epoch : 0.4949488440427361  Training Accuracy:0.75\n",
      "The training loss at 63th epoch : 0.4934942836800236  Training Accuracy:0.75\n",
      "The training loss at 64th epoch : 0.49217902164811045  Training Accuracy:0.75\n",
      "The training loss at 65th epoch : 0.49099047896603704  Training Accuracy:0.75\n",
      "The training loss at 66th epoch : 0.4899169260797705  Training Accuracy:0.75\n",
      "The training loss at 67th epoch : 0.48894748395960325  Training Accuracy:0.75\n",
      "The training loss at 68th epoch : 0.4880721102429382  Training Accuracy:0.75\n",
      "The training loss at 69th epoch : 0.48728157390699395  Training Accuracy:0.75\n",
      "The training loss at 70th epoch : 0.4865674214861824  Training Accuracy:0.75\n",
      "The training loss at 71th epoch : 0.48592193738506956  Training Accuracy:0.75\n",
      "The training loss at 72th epoch : 0.48533810040027775  Training Accuracy:0.75\n",
      "The training loss at 73th epoch : 0.48480953816592043  Training Accuracy:0.75\n",
      "The training loss at 74th epoch : 0.4843304808836286  Training Accuracy:0.75\n",
      "The training loss at 75th epoch : 0.483895715391983  Training Accuracy:0.75\n",
      "The training loss at 76th epoch : 0.4835005403701897  Training Accuracy:0.75\n",
      "The training loss at 77th epoch : 0.48314072325415497  Training Accuracy:0.75\n",
      "The training loss at 78th epoch : 0.4828124592656297  Training Accuracy:0.75\n",
      "The training loss at 79th epoch : 0.4825123328121665  Training Accuracy:0.75\n",
      "The training loss at 80th epoch : 0.48223728140254946  Training Accuracy:0.75\n",
      "The training loss at 81th epoch : 0.48198456213456226  Training Accuracy:0.75\n",
      "The training loss at 82th epoch : 0.4817517207452634  Training Accuracy:0.75\n",
      "The training loss at 83th epoch : 0.48153656316457555  Training Accuracy:0.75\n",
      "The training loss at 84th epoch : 0.4813371294776847  Training Accuracy:0.75\n",
      "The training loss at 85th epoch : 0.48115167017765464  Training Accuracy:0.75\n",
      "The training loss at 86th epoch : 0.48097862457441787  Training Accuracy:0.75\n",
      "The training loss at 87th epoch : 0.48081660121791686  Training Accuracy:0.75\n",
      "The training loss at 88th epoch : 0.48066436019001085  Training Accuracy:0.75\n",
      "The training loss at 89th epoch : 0.48052079712050727  Training Accuracy:0.75\n",
      "The training loss at 90th epoch : 0.480384928786263  Training Accuracy:0.75\n",
      "The training loss at 91th epoch : 0.4802558801578828  Training Accuracy:0.75\n",
      "The training loss at 92th epoch : 0.48013287276545663  Training Accuracy:0.75\n",
      "The training loss at 93th epoch : 0.4800152142625159  Training Accuracy:0.75\n",
      "The training loss at 94th epoch : 0.4799022890755537  Training Accuracy:0.75\n",
      "The training loss at 95th epoch : 0.4797935500347576  Training Accuracy:0.75\n",
      "The training loss at 96th epoch : 0.4796885108898229  Training Accuracy:0.75\n",
      "The training loss at 97th epoch : 0.47958673962270115  Training Accuracy:0.75\n",
      "The training loss at 98th epoch : 0.4794878524767807  Training Accuracy:0.75\n",
      "The training loss at 99th epoch : 0.47939150862922836  Training Accuracy:0.75\n",
      "The training loss at 100th epoch : 0.47929740543999905  Training Accuracy:0.75\n",
      "The training loss at 101th epoch : 0.47920527421732684  Training Accuracy:0.75\n",
      "The training loss at 102th epoch : 0.47911487644533934  Training Accuracy:0.75\n",
      "The training loss at 103th epoch : 0.4790260004247985  Training Accuracy:0.75\n",
      "The training loss at 104th epoch : 0.4789384582828789  Training Accuracy:0.75\n",
      "The training loss at 105th epoch : 0.4788520833123699  Training Accuracy:0.75\n",
      "The training loss at 106th epoch : 0.4787667276047578  Training Accuracy:0.75\n",
      "The training loss at 107th epoch : 0.4786822599453324  Training Accuracy:0.75\n",
      "The training loss at 108th epoch : 0.47859856394179856  Training Accuracy:0.75\n",
      "The training loss at 109th epoch : 0.4785155363608827  Training Accuracy:0.75\n",
      "The training loss at 110th epoch : 0.47843308565013687  Training Accuracy:0.75\n",
      "The training loss at 111th epoch : 0.47835113062458  Training Accuracy:0.75\n",
      "The training loss at 112th epoch : 0.4782695993000067  Training Accuracy:0.75\n",
      "The training loss at 113th epoch : 0.47818842785675564  Training Accuracy:0.75\n",
      "The training loss at 114th epoch : 0.4781075597194921  Training Accuracy:0.75\n",
      "The training loss at 115th epoch : 0.4780269447401291  Training Accuracy:0.75\n",
      "The training loss at 116th epoch : 0.4779465384724231  Training Accuracy:0.75\n",
      "The training loss at 117th epoch : 0.47786630152803655  Training Accuracy:0.75\n",
      "The training loss at 118th epoch : 0.47778619900498115  Training Accuracy:0.75\n",
      "The training loss at 119th epoch : 0.47770619998036046  Training Accuracy:0.75\n",
      "The training loss at 120th epoch : 0.47762627706022154  Training Accuracy:0.75\n",
      "The training loss at 121th epoch : 0.4775464059801229  Training Accuracy:0.75\n",
      "The training loss at 122th epoch : 0.4774665652507356  Training Accuracy:0.75\n",
      "The training loss at 123th epoch : 0.4773867358434261  Training Accuracy:0.75\n",
      "The training loss at 124th epoch : 0.477306900911331  Training Accuracy:0.75\n",
      "The training loss at 125th epoch : 0.4772270455419366  Training Accuracy:0.75\n",
      "The training loss at 126th epoch : 0.4771471565376195  Training Accuracy:0.75\n",
      "The training loss at 127th epoch : 0.4770672222210011  Training Accuracy:0.75\n",
      "The training loss at 128th epoch : 0.4769872322623222  Training Accuracy:0.75\n",
      "The training loss at 129th epoch : 0.4769071775263553  Training Accuracy:0.75\n",
      "The training loss at 130th epoch : 0.47682704993665215  Training Accuracy:0.75\n",
      "The training loss at 131th epoch : 0.47674684235516984  Training Accuracy:0.75\n",
      "The training loss at 132th epoch : 0.4766665484755396  Training Accuracy:0.75\n",
      "The training loss at 133th epoch : 0.4765861627284374  Training Accuracy:0.75\n",
      "The training loss at 134th epoch : 0.47650568019768885  Training Accuracy:0.75\n",
      "The training loss at 135th epoch : 0.4764250965458939  Training Accuracy:0.75\n",
      "The training loss at 136th epoch : 0.4763444079484955  Training Accuracy:0.75\n",
      "The training loss at 137th epoch : 0.476263611035336  Training Accuracy:0.75\n",
      "The training loss at 138th epoch : 0.4761827028388539  Training Accuracy:0.75\n",
      "The training loss at 139th epoch : 0.47610168074816805  Training Accuracy:0.75\n",
      "The training loss at 140th epoch : 0.4760205424683835  Training Accuracy:0.75\n",
      "The training loss at 141th epoch : 0.4759392859845258  Training Accuracy:0.75\n",
      "The training loss at 142th epoch : 0.4758579095295797  Training Accuracy:0.75\n",
      "The training loss at 143th epoch : 0.47577641155616585  Training Accuracy:0.75\n",
      "The training loss at 144th epoch : 0.47569479071144394  Training Accuracy:0.75\n",
      "The training loss at 145th epoch : 0.4756130458148742  Training Accuracy:0.75\n",
      "The training loss at 146th epoch : 0.475531175838514  Training Accuracy:0.75\n",
      "The training loss at 147th epoch : 0.4754491798895612  Training Accuracy:0.75\n",
      "The training loss at 148th epoch : 0.47536705719488825  Training Accuracy:0.75\n",
      "The training loss at 149th epoch : 0.47528480708734155  Training Accuracy:0.75\n",
      "The training loss at 150th epoch : 0.4752024289936049  Training Accuracy:0.75\n",
      "The training loss at 151th epoch : 0.4751199224234487  Training Accuracy:0.75\n",
      "The training loss at 152th epoch : 0.47503728696020797  Training Accuracy:0.75\n",
      "The training loss at 153th epoch : 0.4749545222523484  Training Accuracy:0.75\n",
      "The training loss at 154th epoch : 0.47487162800599725  Training Accuracy:0.75\n",
      "The training loss at 155th epoch : 0.4747886039783284  Training Accuracy:0.75\n",
      "The training loss at 156th epoch : 0.47470544997170466  Training Accuracy:0.75\n",
      "The training loss at 157th epoch : 0.4746221658284912  Training Accuracy:0.75\n",
      "The training loss at 158th epoch : 0.47453875142646246  Training Accuracy:0.75\n",
      "The training loss at 159th epoch : 0.474455206674736  Training Accuracy:0.75\n",
      "The training loss at 160th epoch : 0.4743715315101726  Training Accuracy:0.75\n",
      "The training loss at 161th epoch : 0.4742877258941889  Training Accuracy:0.75\n",
      "The training loss at 162th epoch : 0.4742037898099365  Training Accuracy:0.75\n",
      "The training loss at 163th epoch : 0.4741197232598042  Training Accuracy:0.75\n",
      "The training loss at 164th epoch : 0.4740355262632081  Training Accuracy:0.75\n",
      "The training loss at 165th epoch : 0.47395119885463455  Training Accuracy:0.75\n",
      "The training loss at 166th epoch : 0.4738667410819091  Training Accuracy:0.75\n",
      "The training loss at 167th epoch : 0.47378215300466414  Training Accuracy:0.75\n",
      "The training loss at 168th epoch : 0.4736974346929827  Training Accuracy:0.75\n",
      "The training loss at 169th epoch : 0.4736125862261988  Training Accuracy:0.75\n",
      "The training loss at 170th epoch : 0.4735276076918355  Training Accuracy:0.75\n",
      "The training loss at 171th epoch : 0.4734424991846655  Training Accuracy:0.75\n",
      "The training loss at 172th epoch : 0.4733572608058802  Training Accuracy:0.75\n",
      "The training loss at 173th epoch : 0.4732718926623538  Training Accuracy:0.75\n",
      "The training loss at 174th epoch : 0.47318639486599323  Training Accuracy:0.75\n",
      "The training loss at 175th epoch : 0.4731007675331621  Training Accuracy:0.75\n",
      "The training loss at 176th epoch : 0.4730150107841715  Training Accuracy:0.75\n",
      "The training loss at 177th epoch : 0.4729291247428296  Training Accuracy:0.75\n",
      "The training loss at 178th epoch : 0.47284310953604275  Training Accuracy:0.75\n",
      "The training loss at 179th epoch : 0.47275696529346295  Training Accuracy:0.75\n",
      "The training loss at 180th epoch : 0.4726706921471756  Training Accuracy:0.75\n",
      "The training loss at 181th epoch : 0.47258429023142334  Training Accuracy:0.75\n",
      "The training loss at 182th epoch : 0.4724977596823617  Training Accuracy:0.75\n",
      "The training loss at 183th epoch : 0.4724111006378425  Training Accuracy:0.75\n",
      "The training loss at 184th epoch : 0.4723243132372225  Training Accuracy:0.75\n",
      "The training loss at 185th epoch : 0.47223739762119377  Training Accuracy:0.75\n",
      "The training loss at 186th epoch : 0.47215035393163335  Training Accuracy:0.75\n",
      "The training loss at 187th epoch : 0.47206318231147015  Training Accuracy:0.75\n",
      "The training loss at 188th epoch : 0.471975882904567  Training Accuracy:0.75\n",
      "The training loss at 189th epoch : 0.471888455855616  Training Accuracy:0.75\n",
      "The training loss at 190th epoch : 0.4718009013100459  Training Accuracy:0.75\n",
      "The training loss at 191th epoch : 0.47171321941393934  Training Accuracy:0.75\n",
      "The training loss at 192th epoch : 0.47162541031396016  Training Accuracy:0.75\n",
      "The training loss at 193th epoch : 0.47153747415728803  Training Accuracy:0.75\n",
      "The training loss at 194th epoch : 0.4714494110915607  Training Accuracy:0.75\n",
      "The training loss at 195th epoch : 0.47136122126482255  Training Accuracy:0.75\n",
      "The training loss at 196th epoch : 0.47127290482547857  Training Accuracy:0.75\n",
      "The training loss at 197th epoch : 0.4711844619222535  Training Accuracy:0.75\n",
      "The training loss at 198th epoch : 0.47109589270415514  Training Accuracy:0.75\n",
      "The training loss at 199th epoch : 0.47100719732044155  Training Accuracy:0.75\n",
      "The training loss at 200th epoch : 0.4709183759205918  Training Accuracy:0.75\n",
      "The training loss at 201th epoch : 0.4708294286542797  Training Accuracy:0.75\n",
      "The training loss at 202th epoch : 0.4707403556713495  Training Accuracy:0.75\n",
      "The training loss at 203th epoch : 0.47065115712179534  Training Accuracy:0.75\n",
      "The training loss at 204th epoch : 0.47056183315574135  Training Accuracy:0.75\n",
      "The training loss at 205th epoch : 0.4704723839234244  Training Accuracy:0.75\n",
      "The training loss at 206th epoch : 0.470382809575178  Training Accuracy:0.75\n",
      "The training loss at 207th epoch : 0.4702931102614182  Training Accuracy:0.75\n",
      "The training loss at 208th epoch : 0.47020328613263  Training Accuracy:0.75\n",
      "The training loss at 209th epoch : 0.4701133373393556  Training Accuracy:0.75\n",
      "The training loss at 210th epoch : 0.47002326403218314  Training Accuracy:0.75\n",
      "The training loss at 211th epoch : 0.4699330663617365  Training Accuracy:0.75\n",
      "The training loss at 212th epoch : 0.46984274447866586  Training Accuracy:0.75\n",
      "The training loss at 213th epoch : 0.4697522985336391  Training Accuracy:0.75\n",
      "The training loss at 214th epoch : 0.4696617286773334  Training Accuracy:0.75\n",
      "The training loss at 215th epoch : 0.469571035060428  Training Accuracy:0.75\n",
      "The training loss at 216th epoch : 0.469480217833597  Training Accuracy:0.75\n",
      "The training loss at 217th epoch : 0.46938927714750256  Training Accuracy:0.75\n",
      "The training loss at 218th epoch : 0.4692982131527888  Training Accuracy:0.75\n",
      "The training loss at 219th epoch : 0.46920702600007613  Training Accuracy:0.75\n",
      "The training loss at 220th epoch : 0.46911571583995537  Training Accuracy:0.75\n",
      "The training loss at 221th epoch : 0.4690242828229826  Training Accuracy:0.75\n",
      "The training loss at 222th epoch : 0.46893272709967426  Training Accuracy:0.75\n",
      "The training loss at 223th epoch : 0.4688410488205025  Training Accuracy:0.75\n",
      "The training loss at 224th epoch : 0.46874924813589036  Training Accuracy:0.75\n",
      "The training loss at 225th epoch : 0.46865732519620773  Training Accuracy:0.75\n",
      "The training loss at 226th epoch : 0.4685652801517673  Training Accuracy:0.75\n",
      "The training loss at 227th epoch : 0.4684731131528205  Training Accuracy:0.75\n",
      "The training loss at 228th epoch : 0.46838082434955364  Training Accuracy:0.75\n",
      "The training loss at 229th epoch : 0.4682884138920848  Training Accuracy:0.75\n",
      "The training loss at 230th epoch : 0.46819588193046  Training Accuracy:0.75\n",
      "The training loss at 231th epoch : 0.46810322861465004  Training Accuracy:0.75\n",
      "The training loss at 232th epoch : 0.46801045409454745  Training Accuracy:0.75\n",
      "The training loss at 233th epoch : 0.46791755851996353  Training Accuracy:0.75\n",
      "The training loss at 234th epoch : 0.4678245420406253  Training Accuracy:0.75\n",
      "The training loss at 235th epoch : 0.46773140480617303  Training Accuracy:0.75\n",
      "The training loss at 236th epoch : 0.46763814696615763  Training Accuracy:0.75\n",
      "The training loss at 237th epoch : 0.467544768670038  Training Accuracy:0.75\n",
      "The training loss at 238th epoch : 0.46745127006717885  Training Accuracy:0.75\n",
      "The training loss at 239th epoch : 0.4673576513068485  Training Accuracy:0.75\n",
      "The training loss at 240th epoch : 0.4672639125382166  Training Accuracy:0.75\n",
      "The training loss at 241th epoch : 0.4671700539103525  Training Accuracy:0.75\n",
      "The training loss at 242th epoch : 0.46707607557222297  Training Accuracy:0.75\n",
      "The training loss at 243th epoch : 0.4669819776726909  Training Accuracy:0.75\n",
      "The training loss at 244th epoch : 0.46688776036051327  Training Accuracy:0.75\n",
      "The training loss at 245th epoch : 0.46679342378433997  Training Accuracy:0.75\n",
      "The training loss at 246th epoch : 0.4666989680927123  Training Accuracy:0.75\n",
      "The training loss at 247th epoch : 0.46660439343406146  Training Accuracy:0.75\n",
      "The training loss at 248th epoch : 0.46650969995670793  Training Accuracy:0.75\n",
      "The training loss at 249th epoch : 0.46641488780886  Training Accuracy:0.75\n",
      "The training loss at 250th epoch : 0.4663199571386128  Training Accuracy:0.75\n",
      "The training loss at 251th epoch : 0.46622490809394795  Training Accuracy:0.75\n",
      "The training loss at 252th epoch : 0.46612974082273245  Training Accuracy:0.75\n",
      "The training loss at 253th epoch : 0.4660344554727182  Training Accuracy:0.75\n",
      "The training loss at 254th epoch : 0.46593905219154164  Training Accuracy:0.75\n",
      "The training loss at 255th epoch : 0.4658435311267234  Training Accuracy:0.75\n",
      "The training loss at 256th epoch : 0.4657478924256679  Training Accuracy:0.75\n",
      "The training loss at 257th epoch : 0.4656521362356634  Training Accuracy:0.75\n",
      "The training loss at 258th epoch : 0.4655562627038822  Training Accuracy:0.75\n",
      "The training loss at 259th epoch : 0.46546027197738005  Training Accuracy:0.75\n",
      "The training loss at 260th epoch : 0.4653641642030973  Training Accuracy:0.75\n",
      "The training loss at 261th epoch : 0.4652679395278586  Training Accuracy:0.75\n",
      "The training loss at 262th epoch : 0.4651715980983736  Training Accuracy:0.75\n",
      "The training loss at 263th epoch : 0.46507514006123757  Training Accuracy:0.75\n",
      "The training loss at 264th epoch : 0.46497856556293193  Training Accuracy:0.75\n",
      "The training loss at 265th epoch : 0.4648818747498253  Training Accuracy:0.75\n",
      "The training loss at 266th epoch : 0.4647850677681741  Training Accuracy:0.75\n",
      "The training loss at 267th epoch : 0.4646881447641239  Training Accuracy:0.75\n",
      "The training loss at 268th epoch : 0.4645911058837105  Training Accuracy:0.75\n",
      "The training loss at 269th epoch : 0.4644939512728609  Training Accuracy:0.75\n",
      "The training loss at 270th epoch : 0.46439668107739523  Training Accuracy:0.75\n",
      "The training loss at 271th epoch : 0.46429929544302767  Training Accuracy:0.75\n",
      "The training loss at 272th epoch : 0.4642017945153684  Training Accuracy:0.75\n",
      "The training loss at 273th epoch : 0.46410417843992524  Training Accuracy:0.75\n",
      "The training loss at 274th epoch : 0.46400644736210533  Training Accuracy:0.75\n",
      "The training loss at 275th epoch : 0.4639086014272174  Training Accuracy:0.75\n",
      "The training loss at 276th epoch : 0.46381064078047335  Training Accuracy:0.75\n",
      "The training loss at 277th epoch : 0.46371256556699086  Training Accuracy:0.75\n",
      "The training loss at 278th epoch : 0.46361437593179533  Training Accuracy:0.75\n",
      "The training loss at 279th epoch : 0.4635160720198224  Training Accuracy:0.75\n",
      "The training loss at 280th epoch : 0.4634176539759204  Training Accuracy:0.75\n",
      "The training loss at 281th epoch : 0.46331912194485286  Training Accuracy:0.75\n",
      "The training loss at 282th epoch : 0.46322047607130135  Training Accuracy:0.75\n",
      "The training loss at 283th epoch : 0.4631217164998682  Training Accuracy:0.75\n",
      "The training loss at 284th epoch : 0.46302284337507926  Training Accuracy:0.75\n",
      "The training loss at 285th epoch : 0.46292385684138726  Training Accuracy:0.75\n",
      "The training loss at 286th epoch : 0.4628247570431744  Training Accuracy:0.75\n",
      "The training loss at 287th epoch : 0.46272554412475614  Training Accuracy:0.75\n",
      "The training loss at 288th epoch : 0.462626218230384  Training Accuracy:0.75\n",
      "The training loss at 289th epoch : 0.46252677950424936  Training Accuracy:0.75\n",
      "The training loss at 290th epoch : 0.46242722809048664  Training Accuracy:0.75\n",
      "The training loss at 291th epoch : 0.46232756413317727  Training Accuracy:0.75\n",
      "The training loss at 292th epoch : 0.4622277877763529  Training Accuracy:0.75\n",
      "The training loss at 293th epoch : 0.4621278991639999  Training Accuracy:0.75\n",
      "The training loss at 294th epoch : 0.4620278984400625  Training Accuracy:0.75\n",
      "The training loss at 295th epoch : 0.46192778574844723  Training Accuracy:0.75\n",
      "The training loss at 296th epoch : 0.46182756123302704  Training Accuracy:0.75\n",
      "The training loss at 297th epoch : 0.4617272250376453  Training Accuracy:0.75\n",
      "The training loss at 298th epoch : 0.46162677730612006  Training Accuracy:0.75\n",
      "The training loss at 299th epoch : 0.4615262181822486  Training Accuracy:0.75\n",
      "The training loss at 300th epoch : 0.4614255478098116  Training Accuracy:0.75\n",
      "The training loss at 301th epoch : 0.4613247663325781  Training Accuracy:0.75\n",
      "The training loss at 302th epoch : 0.4612238738943095  Training Accuracy:0.75\n",
      "The training loss at 303th epoch : 0.4611228706387651  Training Accuracy:0.75\n",
      "The training loss at 304th epoch : 0.46102175670970613  Training Accuracy:0.75\n",
      "The training loss at 305th epoch : 0.460920532250901  Training Accuracy:0.75\n",
      "The training loss at 306th epoch : 0.46081919740613037  Training Accuracy:0.75\n",
      "The training loss at 307th epoch : 0.4607177523191919  Training Accuracy:0.75\n",
      "The training loss at 308th epoch : 0.46061619713390556  Training Accuracy:0.75\n",
      "The training loss at 309th epoch : 0.4605145319941189  Training Accuracy:0.75\n",
      "The training loss at 310th epoch : 0.4604127570437122  Training Accuracy:0.75\n",
      "The training loss at 311th epoch : 0.4603108724266039  Training Accuracy:0.75\n",
      "The training loss at 312th epoch : 0.460208878286756  Training Accuracy:0.75\n",
      "The training loss at 313th epoch : 0.46010677476817957  Training Accuracy:0.75\n",
      "The training loss at 314th epoch : 0.46000456201494044  Training Accuracy:0.75\n",
      "The training loss at 315th epoch : 0.4599022401711649  Training Accuracy:0.75\n",
      "The training loss at 316th epoch : 0.4597998093810451  Training Accuracy:0.75\n",
      "The training loss at 317th epoch : 0.4596972697888453  Training Accuracy:0.75\n",
      "The training loss at 318th epoch : 0.4595946215389074  Training Accuracy:0.75\n",
      "The training loss at 319th epoch : 0.45949186477565707  Training Accuracy:0.75\n",
      "The training loss at 320th epoch : 0.4593889996436097  Training Accuracy:0.75\n",
      "The training loss at 321th epoch : 0.4592860262873764  Training Accuracy:0.75\n",
      "The training loss at 322th epoch : 0.4591829448516703  Training Accuracy:0.75\n",
      "The training loss at 323th epoch : 0.4590797554813127  Training Accuracy:0.75\n",
      "The training loss at 324th epoch : 0.458976458321239  Training Accuracy:0.75\n",
      "The training loss at 325th epoch : 0.45887305351650565  Training Accuracy:0.75\n",
      "The training loss at 326th epoch : 0.4587695412122959  Training Accuracy:0.75\n",
      "The training loss at 327th epoch : 0.4586659215539267  Training Accuracy:0.75\n",
      "The training loss at 328th epoch : 0.4585621946868548  Training Accuracy:0.75\n",
      "The training loss at 329th epoch : 0.45845836075668367  Training Accuracy:0.75\n",
      "The training loss at 330th epoch : 0.45835441990916975  Training Accuracy:0.75\n",
      "The training loss at 331th epoch : 0.4582503722902294  Training Accuracy:0.75\n",
      "The training loss at 332th epoch : 0.45814621804594546  Training Accuracy:0.75\n",
      "The training loss at 333th epoch : 0.45804195732257386  Training Accuracy:0.75\n",
      "The training loss at 334th epoch : 0.4579375902665506  Training Accuracy:0.75\n",
      "The training loss at 335th epoch : 0.4578331170244987  Training Accuracy:0.75\n",
      "The training loss at 336th epoch : 0.4577285377432347  Training Accuracy:0.75\n",
      "The training loss at 337th epoch : 0.457623852569776  Training Accuracy:0.75\n",
      "The training loss at 338th epoch : 0.45751906165134754  Training Accuracy:0.75\n",
      "The training loss at 339th epoch : 0.457414165135389  Training Accuracy:0.75\n",
      "The training loss at 340th epoch : 0.45730916316956177  Training Accuracy:0.75\n",
      "The training loss at 341th epoch : 0.45720405590175606  Training Accuracy:0.75\n",
      "The training loss at 342th epoch : 0.4570988434800979  Training Accuracy:0.75\n",
      "The training loss at 343th epoch : 0.45699352605295657  Training Accuracy:0.75\n",
      "The training loss at 344th epoch : 0.4568881037689516  Training Accuracy:0.75\n",
      "The training loss at 345th epoch : 0.4567825767769601  Training Accuracy:0.75\n",
      "The training loss at 346th epoch : 0.45667694522612384  Training Accuracy:0.75\n",
      "The training loss at 347th epoch : 0.4565712092658569  Training Accuracy:0.75\n",
      "The training loss at 348th epoch : 0.45646536904585255  Training Accuracy:0.75\n",
      "The training loss at 349th epoch : 0.4563594247160909  Training Accuracy:0.75\n",
      "The training loss at 350th epoch : 0.4562533764268462  Training Accuracy:0.75\n",
      "The training loss at 351th epoch : 0.4561472243286943  Training Accuracy:0.75\n",
      "The training loss at 352th epoch : 0.45604096857251986  Training Accuracy:0.75\n",
      "The training loss at 353th epoch : 0.45593460930952395  Training Accuracy:0.75\n",
      "The training loss at 354th epoch : 0.45582814669123156  Training Accuracy:0.75\n",
      "The training loss at 355th epoch : 0.45572158086949904  Training Accuracy:0.75\n",
      "The training loss at 356th epoch : 0.45561491199652154  Training Accuracy:0.75\n",
      "The training loss at 357th epoch : 0.45550814022484054  Training Accuracy:0.75\n",
      "The training loss at 358th epoch : 0.45540126570735145  Training Accuracy:0.75\n",
      "The training loss at 359th epoch : 0.455294288597311  Training Accuracy:0.75\n",
      "The training loss at 360th epoch : 0.45518720904834514  Training Accuracy:0.75\n",
      "The training loss at 361th epoch : 0.45508002721445623  Training Accuracy:0.75\n",
      "The training loss at 362th epoch : 0.4549727432500307  Training Accuracy:0.75\n",
      "The training loss at 363th epoch : 0.4548653573098468  Training Accuracy:0.75\n",
      "The training loss at 364th epoch : 0.45475786954908204  Training Accuracy:0.75\n",
      "The training loss at 365th epoch : 0.454650280123321  Training Accuracy:0.75\n",
      "The training loss at 366th epoch : 0.45454258918856255  Training Accuracy:0.75\n",
      "The training loss at 367th epoch : 0.4544347969012278  Training Accuracy:0.75\n",
      "The training loss at 368th epoch : 0.4543269034181676  Training Accuracy:0.75\n",
      "The training loss at 369th epoch : 0.45421890889667005  Training Accuracy:0.75\n",
      "The training loss at 370th epoch : 0.4541108134944683  Training Accuracy:0.75\n",
      "The training loss at 371th epoch : 0.4540026173697479  Training Accuracy:0.75\n",
      "The training loss at 372th epoch : 0.4538943206811547  Training Accuracy:0.75\n",
      "The training loss at 373th epoch : 0.4537859235878022  Training Accuracy:0.75\n",
      "The training loss at 374th epoch : 0.4536774262492791  Training Accuracy:0.75\n",
      "The training loss at 375th epoch : 0.45356882882565724  Training Accuracy:0.75\n",
      "The training loss at 376th epoch : 0.45346013147749875  Training Accuracy:0.75\n",
      "The training loss at 377th epoch : 0.4533513343658639  Training Accuracy:0.75\n",
      "The training loss at 378th epoch : 0.4532424376523185  Training Accuracy:0.75\n",
      "The training loss at 379th epoch : 0.45313344149894136  Training Accuracy:0.75\n",
      "The training loss at 380th epoch : 0.4530243460683321  Training Accuracy:0.75\n",
      "The training loss at 381th epoch : 0.4529151515236184  Training Accuracy:0.75\n",
      "The training loss at 382th epoch : 0.45280585802846357  Training Accuracy:0.75\n",
      "The training loss at 383th epoch : 0.45269646574707406  Training Accuracy:0.75\n",
      "The training loss at 384th epoch : 0.45258697484420674  Training Accuracy:0.75\n",
      "The training loss at 385th epoch : 0.45247738548517663  Training Accuracy:0.75\n",
      "The training loss at 386th epoch : 0.45236769783586406  Training Accuracy:0.75\n",
      "The training loss at 387th epoch : 0.45225791206272214  Training Accuracy:0.75\n",
      "The training loss at 388th epoch : 0.45214802833278406  Training Accuracy:0.75\n",
      "The training loss at 389th epoch : 0.45203804681367055  Training Accuracy:0.75\n",
      "The training loss at 390th epoch : 0.4519279676735972  Training Accuracy:0.75\n",
      "The training loss at 391th epoch : 0.4518177910813815  Training Accuracy:0.75\n",
      "The training loss at 392th epoch : 0.45170751720645036  Training Accuracy:0.75\n",
      "The training loss at 393th epoch : 0.4515971462188472  Training Accuracy:0.75\n",
      "The training loss at 394th epoch : 0.4514866782892392  Training Accuracy:0.75\n",
      "The training loss at 395th epoch : 0.45137611358892443  Training Accuracy:0.75\n",
      "The training loss at 396th epoch : 0.4512654522898389  Training Accuracy:0.75\n",
      "The training loss at 397th epoch : 0.4511546945645638  Training Accuracy:0.75\n",
      "The training loss at 398th epoch : 0.45104384058633246  Training Accuracy:0.75\n",
      "The training loss at 399th epoch : 0.45093289052903734  Training Accuracy:0.75\n",
      "The training loss at 400th epoch : 0.4508218445672371  Training Accuracy:0.75\n",
      "The training loss at 401th epoch : 0.45071070287616355  Training Accuracy:0.75\n",
      "The training loss at 402th epoch : 0.45059946563172837  Training Accuracy:0.75\n",
      "The training loss at 403th epoch : 0.4504881330105301  Training Accuracy:0.75\n",
      "The training loss at 404th epoch : 0.45037670518986095  Training Accuracy:0.75\n",
      "The training loss at 405th epoch : 0.4502651823477136  Training Accuracy:0.75\n",
      "The training loss at 406th epoch : 0.45015356466278794  Training Accuracy:0.75\n",
      "The training loss at 407th epoch : 0.4500418523144975  Training Accuracy:0.75\n",
      "The training loss at 408th epoch : 0.4499300454829763  Training Accuracy:0.75\n",
      "The training loss at 409th epoch : 0.4498181443490857  Training Accuracy:0.75\n",
      "The training loss at 410th epoch : 0.44970614909442014  Training Accuracy:0.75\n",
      "The training loss at 411th epoch : 0.44959405990131457  Training Accuracy:0.75\n",
      "The training loss at 412th epoch : 0.44948187695285025  Training Accuracy:0.75\n",
      "The training loss at 413th epoch : 0.44936960043286117  Training Accuracy:0.75\n",
      "The training loss at 414th epoch : 0.4492572305259408  Training Accuracy:0.75\n",
      "The training loss at 415th epoch : 0.4491447674174479  Training Accuracy:0.75\n",
      "The training loss at 416th epoch : 0.44903221129351295  Training Accuracy:0.75\n",
      "The training loss at 417th epoch : 0.4489195623410443  Training Accuracy:0.75\n",
      "The training loss at 418th epoch : 0.44880682074773426  Training Accuracy:0.75\n",
      "The training loss at 419th epoch : 0.4486939867020651  Training Accuracy:0.75\n",
      "The training loss at 420th epoch : 0.44858106039331513  Training Accuracy:0.75\n",
      "The training loss at 421th epoch : 0.44846804201156454  Training Accuracy:0.75\n",
      "The training loss at 422th epoch : 0.44835493174770125  Training Accuracy:0.75\n",
      "The training loss at 423th epoch : 0.4482417297934269  Training Accuracy:0.75\n",
      "The training loss at 424th epoch : 0.4481284363412623  Training Accuracy:0.75\n",
      "The training loss at 425th epoch : 0.44801505158455335  Training Accuracy:0.75\n",
      "The training loss at 426th epoch : 0.4479015757174766  Training Accuracy:0.75\n",
      "The training loss at 427th epoch : 0.4477880089350446  Training Accuracy:0.75\n",
      "The training loss at 428th epoch : 0.4476743514331117  Training Accuracy:0.75\n",
      "The training loss at 429th epoch : 0.4475606034083793  Training Accuracy:0.75\n",
      "The training loss at 430th epoch : 0.44744676505840103  Training Accuracy:0.75\n",
      "The training loss at 431th epoch : 0.44733283658158846  Training Accuracy:0.75\n",
      "The training loss at 432th epoch : 0.4472188181772158  Training Accuracy:0.75\n",
      "The training loss at 433th epoch : 0.44710471004542557  Training Accuracy:0.75\n",
      "The training loss at 434th epoch : 0.4469905123872331  Training Accuracy:0.75\n",
      "The training loss at 435th epoch : 0.446876225404532  Training Accuracy:0.75\n",
      "The training loss at 436th epoch : 0.4467618493000987  Training Accuracy:0.75\n",
      "The training loss at 437th epoch : 0.44664738427759776  Training Accuracy:0.75\n",
      "The training loss at 438th epoch : 0.44653283054158616  Training Accuracy:0.75\n",
      "The training loss at 439th epoch : 0.44641818829751834  Training Accuracy:0.75\n",
      "The training loss at 440th epoch : 0.44630345775175057  Training Accuracy:0.75\n",
      "The training loss at 441th epoch : 0.44618863911154577  Training Accuracy:0.75\n",
      "The training loss at 442th epoch : 0.44607373258507776  Training Accuracy:0.75\n",
      "The training loss at 443th epoch : 0.4459587383814358  Training Accuracy:0.75\n",
      "The training loss at 444th epoch : 0.4458436567106287  Training Accuracy:0.75\n",
      "The training loss at 445th epoch : 0.4457284877835893  Training Accuracy:0.75\n",
      "The training loss at 446th epoch : 0.4456132318121786  Training Accuracy:0.75\n",
      "The training loss at 447th epoch : 0.4454978890091896  Training Accuracy:0.75\n",
      "The training loss at 448th epoch : 0.44538245958835143  Training Accuracy:0.75\n",
      "The training loss at 449th epoch : 0.44526694376433357  Training Accuracy:0.75\n",
      "The training loss at 450th epoch : 0.44515134175274906  Training Accuracy:0.75\n",
      "The training loss at 451th epoch : 0.4450356537701588  Training Accuracy:0.75\n",
      "The training loss at 452th epoch : 0.4449198800340749  Training Accuracy:0.75\n",
      "The training loss at 453th epoch : 0.4448040207629644  Training Accuracy:0.75\n",
      "The training loss at 454th epoch : 0.4446880761762528  Training Accuracy:0.75\n",
      "The training loss at 455th epoch : 0.4445720464943273  Training Accuracy:0.75\n",
      "The training loss at 456th epoch : 0.4444559319385403  Training Accuracy:0.75\n",
      "The training loss at 457th epoch : 0.4443397327312126  Training Accuracy:0.75\n",
      "The training loss at 458th epoch : 0.4442234490956364  Training Accuracy:0.75\n",
      "The training loss at 459th epoch : 0.4441070812560787  Training Accuracy:0.75\n",
      "The training loss at 460th epoch : 0.4439906294377839  Training Accuracy:0.75\n",
      "The training loss at 461th epoch : 0.44387409386697696  Training Accuracy:0.75\n",
      "The training loss at 462th epoch : 0.44375747477086613  Training Accuracy:0.75\n",
      "The training loss at 463th epoch : 0.4436407723776457  Training Accuracy:0.75\n",
      "The training loss at 464th epoch : 0.4435239869164984  Training Accuracy:0.75\n",
      "The training loss at 465th epoch : 0.44340711861759835  Training Accuracy:0.75\n",
      "The training loss at 466th epoch : 0.44329016771211316  Training Accuracy:0.75\n",
      "The training loss at 467th epoch : 0.4431731344322063  Training Accuracy:0.75\n",
      "The training loss at 468th epoch : 0.4430560190110397  Training Accuracy:0.75\n",
      "The training loss at 469th epoch : 0.44293882168277554  Training Accuracy:0.75\n",
      "The training loss at 470th epoch : 0.44282154268257856  Training Accuracy:0.75\n",
      "The training loss at 471th epoch : 0.44270418224661795  Training Accuracy:0.75\n",
      "The training loss at 472th epoch : 0.44258674061206926  Training Accuracy:0.75\n",
      "The training loss at 473th epoch : 0.44246921801711625  Training Accuracy:0.75\n",
      "The training loss at 474th epoch : 0.44235161470095263  Training Accuracy:0.75\n",
      "The training loss at 475th epoch : 0.4422339309037836  Training Accuracy:0.75\n",
      "The training loss at 476th epoch : 0.4421161668668274  Training Accuracy:0.75\n",
      "The training loss at 477th epoch : 0.4419983228323168  Training Accuracy:0.75\n",
      "The training loss at 478th epoch : 0.44188039904350035  Training Accuracy:0.75\n",
      "The training loss at 479th epoch : 0.4417623957446437  Training Accuracy:0.75\n",
      "The training loss at 480th epoch : 0.44164431318103076  Training Accuracy:0.75\n",
      "The training loss at 481th epoch : 0.4415261515989647  Training Accuracy:0.75\n",
      "The training loss at 482th epoch : 0.4414079112457689  Training Accuracy:0.75\n",
      "The training loss at 483th epoch : 0.441289592369788  Training Accuracy:0.75\n",
      "The training loss at 484th epoch : 0.4411711952203884  Training Accuracy:0.75\n",
      "The training loss at 485th epoch : 0.4410527200479591  Training Accuracy:0.75\n",
      "The training loss at 486th epoch : 0.4409341671039123  Training Accuracy:0.75\n",
      "The training loss at 487th epoch : 0.44081553664068385  Training Accuracy:0.75\n",
      "The training loss at 488th epoch : 0.4406968289117336  Training Accuracy:0.75\n",
      "The training loss at 489th epoch : 0.4405780441715457  Training Accuracy:0.75\n",
      "The training loss at 490th epoch : 0.440459182675629  Training Accuracy:0.75\n",
      "The training loss at 491th epoch : 0.44034024468051675  Training Accuracy:0.75\n",
      "The training loss at 492th epoch : 0.44022123044376693  Training Accuracy:0.75\n",
      "The training loss at 493th epoch : 0.44010214022396227  Training Accuracy:0.75\n",
      "The training loss at 494th epoch : 0.43998297428070954  Training Accuracy:0.75\n",
      "The training loss at 495th epoch : 0.43986373287463987  Training Accuracy:0.75\n",
      "The training loss at 496th epoch : 0.439744416267408  Training Accuracy:0.75\n",
      "The training loss at 497th epoch : 0.43962502472169196  Training Accuracy:0.75\n",
      "The training loss at 498th epoch : 0.43950555850119244  Training Accuracy:0.75\n",
      "The training loss at 499th epoch : 0.43938601787063203  Training Accuracy:0.75\n",
      "The training loss at 500th epoch : 0.4392664030957547  Training Accuracy:0.75\n",
      "The training loss at 501th epoch : 0.43914671444332487  Training Accuracy:0.75\n",
      "The training loss at 502th epoch : 0.4390269521811262  Training Accuracy:0.75\n",
      "The training loss at 503th epoch : 0.43890711657796083  Training Accuracy:0.75\n",
      "The training loss at 504th epoch : 0.4387872079036482  Training Accuracy:0.75\n",
      "The training loss at 505th epoch : 0.4386672264290237  Training Accuracy:0.75\n",
      "The training loss at 506th epoch : 0.4385471724259373  Training Accuracy:0.75\n",
      "The training loss at 507th epoch : 0.4384270461672524  Training Accuracy:0.75\n",
      "The training loss at 508th epoch : 0.4383068479268438  Training Accuracy:0.75\n",
      "The training loss at 509th epoch : 0.4381865779795967  Training Accuracy:0.75\n",
      "The training loss at 510th epoch : 0.4380662366014043  Training Accuracy:0.75\n",
      "The training loss at 511th epoch : 0.43794582406916666  Training Accuracy:0.75\n",
      "The training loss at 512th epoch : 0.4378253406607882  Training Accuracy:0.75\n",
      "The training loss at 513th epoch : 0.43770478665517615  Training Accuracy:0.75\n",
      "The training loss at 514th epoch : 0.43758416233223807  Training Accuracy:0.75\n",
      "The training loss at 515th epoch : 0.43746346797288  Training Accuracy:0.75\n",
      "The training loss at 516th epoch : 0.4373427038590038  Training Accuracy:0.75\n",
      "The training loss at 517th epoch : 0.43722187027350523  Training Accuracy:0.75\n",
      "The training loss at 518th epoch : 0.437100967500271  Training Accuracy:0.75\n",
      "The training loss at 519th epoch : 0.43697999582417646  Training Accuracy:0.75\n",
      "The training loss at 520th epoch : 0.4368589555310829  Training Accuracy:0.75\n",
      "The training loss at 521th epoch : 0.4367378469078348  Training Accuracy:0.75\n",
      "The training loss at 522th epoch : 0.4366166702422568  Training Accuracy:0.75\n",
      "The training loss at 523th epoch : 0.43649542582315104  Training Accuracy:0.75\n",
      "The training loss at 524th epoch : 0.4363741139402939  Training Accuracy:0.75\n",
      "The training loss at 525th epoch : 0.43625273488443306  Training Accuracy:0.75\n",
      "The training loss at 526th epoch : 0.436131288947284  Training Accuracy:0.75\n",
      "The training loss at 527th epoch : 0.43600977642152683  Training Accuracy:0.75\n",
      "The training loss at 528th epoch : 0.43588819760080316  Training Accuracy:0.75\n",
      "The training loss at 529th epoch : 0.43576655277971205  Training Accuracy:0.75\n",
      "The training loss at 530th epoch : 0.43564484225380684  Training Accuracy:0.75\n",
      "The training loss at 531th epoch : 0.4355230663195914  Training Accuracy:0.75\n",
      "The training loss at 532th epoch : 0.4354012252745162  Training Accuracy:0.75\n",
      "The training loss at 533th epoch : 0.4352793194169746  Training Accuracy:0.75\n",
      "The training loss at 534th epoch : 0.4351573490462989  Training Accuracy:0.75\n",
      "The training loss at 535th epoch : 0.4350353144627561  Training Accuracy:0.75\n",
      "The training loss at 536th epoch : 0.4349132159675442  Training Accuracy:0.75\n",
      "The training loss at 537th epoch : 0.43479105386278744  Training Accuracy:0.75\n",
      "The training loss at 538th epoch : 0.43466882845153254  Training Accuracy:0.75\n",
      "The training loss at 539th epoch : 0.43454654003774384  Training Accuracy:0.75\n",
      "The training loss at 540th epoch : 0.43442418892629925  Training Accuracy:0.75\n",
      "The training loss at 541th epoch : 0.4343017754229853  Training Accuracy:0.75\n",
      "The training loss at 542th epoch : 0.4341792998344927  Training Accuracy:0.75\n",
      "The training loss at 543th epoch : 0.4340567624684117  Training Accuracy:0.75\n",
      "The training loss at 544th epoch : 0.43393416363322695  Training Accuracy:0.75\n",
      "The training loss at 545th epoch : 0.433811503638313  Training Accuracy:0.75\n",
      "The training loss at 546th epoch : 0.43368878279392903  Training Accuracy:0.75\n",
      "The training loss at 547th epoch : 0.43356600141121376  Training Accuracy:0.75\n",
      "The training loss at 548th epoch : 0.43344315980218057  Training Accuracy:0.75\n",
      "The training loss at 549th epoch : 0.43332025827971193  Training Accuracy:0.75\n",
      "The training loss at 550th epoch : 0.4331972971575544  Training Accuracy:0.75\n",
      "The training loss at 551th epoch : 0.43307427675031296  Training Accuracy:0.75\n",
      "The training loss at 552th epoch : 0.43295119737344573  Training Accuracy:0.75\n",
      "The training loss at 553th epoch : 0.4328280593432582  Training Accuracy:0.75\n",
      "The training loss at 554th epoch : 0.4327048629768978  Training Accuracy:0.75\n",
      "The training loss at 555th epoch : 0.4325816085923482  Training Accuracy:0.75\n",
      "The training loss at 556th epoch : 0.4324582965084231  Training Accuracy:0.75\n",
      "The training loss at 557th epoch : 0.432334927044761  Training Accuracy:0.75\n",
      "The training loss at 558th epoch : 0.43221150052181867  Training Accuracy:0.75\n",
      "The training loss at 559th epoch : 0.4320880172608655  Training Accuracy:0.75\n",
      "The training loss at 560th epoch : 0.4319644775839771  Training Accuracy:0.75\n",
      "The training loss at 561th epoch : 0.4318408818140294  Training Accuracy:0.75\n",
      "The training loss at 562th epoch : 0.43171723027469217  Training Accuracy:0.75\n",
      "The training loss at 563th epoch : 0.43159352329042283  Training Accuracy:0.75\n",
      "The training loss at 564th epoch : 0.43146976118645985  Training Accuracy:0.75\n",
      "The training loss at 565th epoch : 0.43134594428881656  Training Accuracy:0.75\n",
      "The training loss at 566th epoch : 0.4312220729242744  Training Accuracy:0.75\n",
      "The training loss at 567th epoch : 0.4310981474203763  Training Accuracy:0.75\n",
      "The training loss at 568th epoch : 0.4309741681054199  Training Accuracy:0.75\n",
      "The training loss at 569th epoch : 0.4308501353084511  Training Accuracy:0.75\n",
      "The training loss at 570th epoch : 0.43072604935925707  Training Accuracy:0.75\n",
      "The training loss at 571th epoch : 0.43060191058835895  Training Accuracy:0.75\n",
      "The training loss at 572th epoch : 0.4304777193270055  Training Accuracy:0.75\n",
      "The training loss at 573th epoch : 0.43035347590716583  Training Accuracy:0.75\n",
      "The training loss at 574th epoch : 0.4302291806615219  Training Accuracy:0.75\n",
      "The training loss at 575th epoch : 0.430104833923462  Training Accuracy:0.75\n",
      "The training loss at 576th epoch : 0.42998043602707303  Training Accuracy:0.75\n",
      "The training loss at 577th epoch : 0.4298559873071334  Training Accuracy:0.75\n",
      "The training loss at 578th epoch : 0.42973148809910555  Training Accuracy:0.75\n",
      "The training loss at 579th epoch : 0.42960693873912853  Training Accuracy:0.75\n",
      "The training loss at 580th epoch : 0.4294823395640106  Training Accuracy:0.75\n",
      "The training loss at 581th epoch : 0.42935769091122167  Training Accuracy:0.75\n",
      "The training loss at 582th epoch : 0.42923299311888535  Training Accuracy:0.75\n",
      "The training loss at 583th epoch : 0.42910824652577173  Training Accuracy:0.75\n",
      "The training loss at 584th epoch : 0.42898345147128936  Training Accuracy:0.75\n",
      "The training loss at 585th epoch : 0.42885860829547745  Training Accuracy:0.75\n",
      "The training loss at 586th epoch : 0.4287337173389982  Training Accuracy:0.75\n",
      "The training loss at 587th epoch : 0.4286087789431285  Training Accuracy:0.75\n",
      "The training loss at 588th epoch : 0.42848379344975246  Training Accuracy:0.75\n",
      "The training loss at 589th epoch : 0.42835876120135286  Training Accuracy:0.75\n",
      "The training loss at 590th epoch : 0.42823368254100347  Training Accuracy:0.75\n",
      "The training loss at 591th epoch : 0.4281085578123606  Training Accuracy:0.75\n",
      "The training loss at 592th epoch : 0.4279833873596552  Training Accuracy:0.75\n",
      "The training loss at 593th epoch : 0.42785817152768424  Training Accuracy:0.75\n",
      "The training loss at 594th epoch : 0.42773291066180275  Training Accuracy:0.75\n",
      "The training loss at 595th epoch : 0.4276076051079151  Training Accuracy:0.75\n",
      "The training loss at 596th epoch : 0.4274822552124672  Training Accuracy:0.75\n",
      "The training loss at 597th epoch : 0.42735686132243716  Training Accuracy:0.75\n",
      "The training loss at 598th epoch : 0.42723142378532764  Training Accuracy:0.75\n",
      "The training loss at 599th epoch : 0.4271059429491567  Training Accuracy:0.75\n",
      "The training loss at 600th epoch : 0.4269804191624495  Training Accuracy:0.75\n",
      "The training loss at 601th epoch : 0.4268548527742295  Training Accuracy:0.75\n",
      "The training loss at 602th epoch : 0.4267292441340099  Training Accuracy:0.75\n",
      "The training loss at 603th epoch : 0.4266035935917847  Training Accuracy:0.75\n",
      "The training loss at 604th epoch : 0.42647790149802006  Training Accuracy:0.75\n",
      "The training loss at 605th epoch : 0.4263521682036455  Training Accuracy:0.75\n",
      "The training loss at 606th epoch : 0.42622639406004487  Training Accuracy:0.75\n",
      "The training loss at 607th epoch : 0.42610057941904755  Training Accuracy:0.75\n",
      "The training loss at 608th epoch : 0.42597472463291935  Training Accuracy:0.75\n",
      "The training loss at 609th epoch : 0.42584883005435387  Training Accuracy:0.75\n",
      "The training loss at 610th epoch : 0.42572289603646285  Training Accuracy:0.75\n",
      "The training loss at 611th epoch : 0.42559692293276774  Training Accuracy:0.75\n",
      "The training loss at 612th epoch : 0.42547091109719015  Training Accuracy:0.75\n",
      "The training loss at 613th epoch : 0.4253448608840429  Training Accuracy:0.75\n",
      "The training loss at 614th epoch : 0.4252187726480206  Training Accuracy:0.75\n",
      "The training loss at 615th epoch : 0.42509264674419084  Training Accuracy:0.75\n",
      "The training loss at 616th epoch : 0.42496648352798444  Training Accuracy:0.75\n",
      "The training loss at 617th epoch : 0.42484028335518653  Training Accuracy:0.75\n",
      "The training loss at 618th epoch : 0.424714046581927  Training Accuracy:0.75\n",
      "The training loss at 619th epoch : 0.4245877735646713  Training Accuracy:0.75\n",
      "The training loss at 620th epoch : 0.42446146466021095  Training Accuracy:0.75\n",
      "The training loss at 621th epoch : 0.424335120225654  Training Accuracy:0.75\n",
      "The training loss at 622th epoch : 0.42420874061841596  Training Accuracy:0.75\n",
      "The training loss at 623th epoch : 0.42408232619620984  Training Accuracy:0.75\n",
      "The training loss at 624th epoch : 0.42395587731703704  Training Accuracy:0.75\n",
      "The training loss at 625th epoch : 0.4238293943391775  Training Accuracy:0.75\n",
      "The training loss at 626th epoch : 0.4237028776211804  Training Accuracy:0.75\n",
      "The training loss at 627th epoch : 0.4235763275218544  Training Accuracy:0.75\n",
      "The training loss at 628th epoch : 0.4234497444002582  Training Accuracy:0.75\n",
      "The training loss at 629th epoch : 0.4233231286156905  Training Accuracy:0.75\n",
      "The training loss at 630th epoch : 0.42319648052768094  Training Accuracy:0.75\n",
      "The training loss at 631th epoch : 0.4230698004959799  Training Accuracy:0.75\n",
      "The training loss at 632th epoch : 0.42294308888054916  Training Accuracy:0.75\n",
      "The training loss at 633th epoch : 0.4228163460415518  Training Accuracy:0.75\n",
      "The training loss at 634th epoch : 0.42268957233934296  Training Accuracy:0.75\n",
      "The training loss at 635th epoch : 0.4225627681344594  Training Accuracy:0.75\n",
      "The training loss at 636th epoch : 0.42243593378761046  Training Accuracy:0.75\n",
      "The training loss at 637th epoch : 0.4223090696596678  Training Accuracy:0.75\n",
      "The training loss at 638th epoch : 0.4221821761116556  Training Accuracy:0.75\n",
      "The training loss at 639th epoch : 0.4220552535047409  Training Accuracy:0.75\n",
      "The training loss at 640th epoch : 0.42192830220022365  Training Accuracy:0.75\n",
      "The training loss at 641th epoch : 0.42180132255952696  Training Accuracy:0.75\n",
      "The training loss at 642th epoch : 0.421674314944187  Training Accuracy:0.75\n",
      "The training loss at 643th epoch : 0.42154727971584344  Training Accuracy:0.75\n",
      "The training loss at 644th epoch : 0.4214202172362292  Training Accuracy:0.75\n",
      "The training loss at 645th epoch : 0.42129312786716083  Training Accuracy:0.75\n",
      "The training loss at 646th epoch : 0.42116601197052844  Training Accuracy:0.75\n",
      "The training loss at 647th epoch : 0.42103886990828593  Training Accuracy:0.75\n",
      "The training loss at 648th epoch : 0.42091170204244077  Training Accuracy:0.75\n",
      "The training loss at 649th epoch : 0.4207845087350443  Training Accuracy:0.75\n",
      "The training loss at 650th epoch : 0.42065729034818183  Training Accuracy:0.75\n",
      "The training loss at 651th epoch : 0.4205300472439624  Training Accuracy:0.75\n",
      "The training loss at 652th epoch : 0.4204027797845092  Training Accuracy:0.75\n",
      "The training loss at 653th epoch : 0.42027548833194917  Training Accuracy:0.75\n",
      "The training loss at 654th epoch : 0.4201481732484035  Training Accuracy:0.75\n",
      "The training loss at 655th epoch : 0.4200208348959772  Training Accuracy:0.75\n",
      "The training loss at 656th epoch : 0.4198934736367496  Training Accuracy:0.75\n",
      "The training loss at 657th epoch : 0.41976608983276403  Training Accuracy:0.75\n",
      "The training loss at 658th epoch : 0.41963868384601793  Training Accuracy:0.75\n",
      "The training loss at 659th epoch : 0.41951125603845296  Training Accuracy:0.75\n",
      "The training loss at 660th epoch : 0.419383806771945  Training Accuracy:0.75\n",
      "The training loss at 661th epoch : 0.41925633640829413  Training Accuracy:0.75\n",
      "The training loss at 662th epoch : 0.4191288453092147  Training Accuracy:0.75\n",
      "The training loss at 663th epoch : 0.41900133383632543  Training Accuracy:0.75\n",
      "The training loss at 664th epoch : 0.41887380235113936  Training Accuracy:0.75\n",
      "The training loss at 665th epoch : 0.41874625121505393  Training Accuracy:0.75\n",
      "The training loss at 666th epoch : 0.41861868078934106  Training Accuracy:0.75\n",
      "The training loss at 667th epoch : 0.4184910914351372  Training Accuracy:0.75\n",
      "The training loss at 668th epoch : 0.41836348351343344  Training Accuracy:0.75\n",
      "The training loss at 669th epoch : 0.41823585738506547  Training Accuracy:0.75\n",
      "The training loss at 670th epoch : 0.41810821341070376  Training Accuracy:0.75\n",
      "The training loss at 671th epoch : 0.4179805519508437  Training Accuracy:0.75\n",
      "The training loss at 672th epoch : 0.4178528733657957  Training Accuracy:0.75\n",
      "The training loss at 673th epoch : 0.417725178015675  Training Accuracy:0.75\n",
      "The training loss at 674th epoch : 0.4175974662603924  Training Accuracy:0.75\n",
      "The training loss at 675th epoch : 0.41746973845964386  Training Accuracy:0.75\n",
      "The training loss at 676th epoch : 0.41734199497290086  Training Accuracy:0.75\n",
      "The training loss at 677th epoch : 0.41721423615940073  Training Accuracy:0.75\n",
      "The training loss at 678th epoch : 0.4170864623781365  Training Accuracy:0.75\n",
      "The training loss at 679th epoch : 0.4169586739878474  Training Accuracy:0.75\n",
      "The training loss at 680th epoch : 0.4168308713470089  Training Accuracy:0.75\n",
      "The training loss at 681th epoch : 0.41670305481382314  Training Accuracy:0.75\n",
      "The training loss at 682th epoch : 0.4165752247462088  Training Accuracy:0.75\n",
      "The training loss at 683th epoch : 0.41644738150179184  Training Accuracy:0.75\n",
      "The training loss at 684th epoch : 0.4163195254378955  Training Accuracy:0.75\n",
      "The training loss at 685th epoch : 0.4161916569115307  Training Accuracy:0.75\n",
      "The training loss at 686th epoch : 0.41606377627938634  Training Accuracy:0.75\n",
      "The training loss at 687th epoch : 0.4159358838978196  Training Accuracy:0.75\n",
      "The training loss at 688th epoch : 0.41580798012284653  Training Accuracy:0.75\n",
      "The training loss at 689th epoch : 0.41568006531013213  Training Accuracy:0.75\n",
      "The training loss at 690th epoch : 0.41555213981498107  Training Accuracy:0.75\n",
      "The training loss at 691th epoch : 0.4154242039923279  Training Accuracy:0.75\n",
      "The training loss at 692th epoch : 0.41529625819672755  Training Accuracy:0.75\n",
      "The training loss at 693th epoch : 0.4151683027823461  Training Accuracy:0.75\n",
      "The training loss at 694th epoch : 0.415040338102951  Training Accuracy:0.75\n",
      "The training loss at 695th epoch : 0.4149123645119015  Training Accuracy:0.75\n",
      "The training loss at 696th epoch : 0.4147843823621396  Training Accuracy:0.75\n",
      "The training loss at 697th epoch : 0.41465639200618054  Training Accuracy:0.75\n",
      "The training loss at 698th epoch : 0.41452839379610307  Training Accuracy:0.75\n",
      "The training loss at 699th epoch : 0.4144003880835407  Training Accuracy:0.75\n",
      "The training loss at 700th epoch : 0.41427237521967175  Training Accuracy:0.75\n",
      "The training loss at 701th epoch : 0.4141443555552107  Training Accuracy:0.75\n",
      "The training loss at 702th epoch : 0.4140163294403983  Training Accuracy:0.75\n",
      "The training loss at 703th epoch : 0.41388829722499293  Training Accuracy:0.75\n",
      "The training loss at 704th epoch : 0.413760259258261  Training Accuracy:0.75\n",
      "The training loss at 705th epoch : 0.41363221588896787  Training Accuracy:0.75\n",
      "The training loss at 706th epoch : 0.41350416746536894  Training Accuracy:0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 707th epoch : 0.4133761143352003  Training Accuracy:0.75\n",
      "The training loss at 708th epoch : 0.4132480568456696  Training Accuracy:0.75\n",
      "The training loss at 709th epoch : 0.4131199953434475  Training Accuracy:0.75\n",
      "The training loss at 710th epoch : 0.4129919301746582  Training Accuracy:0.75\n",
      "The training loss at 711th epoch : 0.4128638616848706  Training Accuracy:0.75\n",
      "The training loss at 712th epoch : 0.41273579021908946  Training Accuracy:0.75\n",
      "The training loss at 713th epoch : 0.4126077161217465  Training Accuracy:0.75\n",
      "The training loss at 714th epoch : 0.41247963973669155  Training Accuracy:0.75\n",
      "The training loss at 715th epoch : 0.41235156140718365  Training Accuracy:0.75\n",
      "The training loss at 716th epoch : 0.4122234814758825  Training Accuracy:0.75\n",
      "The training loss at 717th epoch : 0.4120954002848394  Training Accuracy:0.75\n",
      "The training loss at 718th epoch : 0.41196731817548876  Training Accuracy:0.75\n",
      "The training loss at 719th epoch : 0.41183923548863954  Training Accuracy:0.75\n",
      "The training loss at 720th epoch : 0.41171115256446644  Training Accuracy:0.75\n",
      "The training loss at 721th epoch : 0.4115830697425015  Training Accuracy:0.75\n",
      "The training loss at 722th epoch : 0.4114549873616252  Training Accuracy:0.75\n",
      "The training loss at 723th epoch : 0.41132690576005865  Training Accuracy:0.75\n",
      "The training loss at 724th epoch : 0.4111988252753543  Training Accuracy:0.75\n",
      "The training loss at 725th epoch : 0.4110707462443882  Training Accuracy:0.75\n",
      "The training loss at 726th epoch : 0.41094266900335147  Training Accuracy:0.75\n",
      "The training loss at 727th epoch : 0.41081459388774166  Training Accuracy:0.75\n",
      "The training loss at 728th epoch : 0.41068652123235494  Training Accuracy:0.75\n",
      "The training loss at 729th epoch : 0.41055845137127744  Training Accuracy:0.75\n",
      "The training loss at 730th epoch : 0.4104303846378774  Training Accuracy:0.75\n",
      "The training loss at 731th epoch : 0.4103023213647969  Training Accuracy:0.75\n",
      "The training loss at 732th epoch : 0.4101742618839436  Training Accuracy:0.75\n",
      "The training loss at 733th epoch : 0.4100462065264831  Training Accuracy:0.75\n",
      "The training loss at 734th epoch : 0.4099181556228303  Training Accuracy:0.75\n",
      "The training loss at 735th epoch : 0.409790109502642  Training Accuracy:0.75\n",
      "The training loss at 736th epoch : 0.4096620684948089  Training Accuracy:0.75\n",
      "The training loss at 737th epoch : 0.4095340329274474  Training Accuracy:0.75\n",
      "The training loss at 738th epoch : 0.40940600312789205  Training Accuracy:0.75\n",
      "The training loss at 739th epoch : 0.4092779794226878  Training Accuracy:0.75\n",
      "The training loss at 740th epoch : 0.40914996213758215  Training Accuracy:0.75\n",
      "The training loss at 741th epoch : 0.4090219515975175  Training Accuracy:0.75\n",
      "The training loss at 742th epoch : 0.40889394812662355  Training Accuracy:0.75\n",
      "The training loss at 743th epoch : 0.40876595204820976  Training Accuracy:0.75\n",
      "The training loss at 744th epoch : 0.4086379636847577  Training Accuracy:0.75\n",
      "The training loss at 745th epoch : 0.4085099833579137  Training Accuracy:0.75\n",
      "The training loss at 746th epoch : 0.40838201138848135  Training Accuracy:0.75\n",
      "The training loss at 747th epoch : 0.408254048096414  Training Accuracy:0.75\n",
      "The training loss at 748th epoch : 0.4081260938008079  Training Accuracy:0.75\n",
      "The training loss at 749th epoch : 0.40799814881989427  Training Accuracy:0.75\n",
      "The training loss at 750th epoch : 0.4078702134710324  Training Accuracy:0.75\n",
      "The training loss at 751th epoch : 0.4077422880707028  Training Accuracy:0.75\n",
      "The training loss at 752th epoch : 0.40761437293449926  Training Accuracy:0.75\n",
      "The training loss at 753th epoch : 0.40748646837712266  Training Accuracy:0.75\n",
      "The training loss at 754th epoch : 0.4073585747123733  Training Accuracy:0.75\n",
      "The training loss at 755th epoch : 0.4072306922531444  Training Accuracy:0.75\n",
      "The training loss at 756th epoch : 0.4071028213114148  Training Accuracy:0.75\n",
      "The training loss at 757th epoch : 0.40697496219824225  Training Accuracy:0.75\n",
      "The training loss at 758th epoch : 0.4068471152237568  Training Accuracy:0.75\n",
      "The training loss at 759th epoch : 0.4067192806971537  Training Accuracy:0.75\n",
      "The training loss at 760th epoch : 0.40659145892668697  Training Accuracy:0.75\n",
      "The training loss at 761th epoch : 0.4064636502196626  Training Accuracy:0.75\n",
      "The training loss at 762th epoch : 0.40633585488243196  Training Accuracy:0.75\n",
      "The training loss at 763th epoch : 0.4062080732203854  Training Accuracy:0.75\n",
      "The training loss at 764th epoch : 0.4060803055379456  Training Accuracy:0.75\n",
      "The training loss at 765th epoch : 0.4059525521385613  Training Accuracy:0.75\n",
      "The training loss at 766th epoch : 0.4058248133247008  Training Accuracy:0.75\n",
      "The training loss at 767th epoch : 0.40569708939784555  Training Accuracy:0.75\n",
      "The training loss at 768th epoch : 0.40556938065848425  Training Accuracy:0.75\n",
      "The training loss at 769th epoch : 0.40544168740610614  Training Accuracy:0.75\n",
      "The training loss at 770th epoch : 0.40531400993919536  Training Accuracy:0.75\n",
      "The training loss at 771th epoch : 0.4051863485552244  Training Accuracy:0.75\n",
      "The training loss at 772th epoch : 0.4050587035506484  Training Accuracy:0.75\n",
      "The training loss at 773th epoch : 0.40493107522089883  Training Accuracy:0.75\n",
      "The training loss at 774th epoch : 0.40480346386037797  Training Accuracy:0.75\n",
      "The training loss at 775th epoch : 0.4046758697624527  Training Accuracy:0.75\n",
      "The training loss at 776th epoch : 0.40454829321944874  Training Accuracy:0.75\n",
      "The training loss at 777th epoch : 0.40442073452264504  Training Accuracy:0.75\n",
      "The training loss at 778th epoch : 0.4042931939622679  Training Accuracy:0.75\n",
      "The training loss at 779th epoch : 0.4041656718274854  Training Accuracy:0.75\n",
      "The training loss at 780th epoch : 0.40403816840640183  Training Accuracy:0.75\n",
      "The training loss at 781th epoch : 0.40391068398605207  Training Accuracy:0.75\n",
      "The training loss at 782th epoch : 0.4037832188523962  Training Accuracy:0.75\n",
      "The training loss at 783th epoch : 0.403655773290314  Training Accuracy:0.75\n",
      "The training loss at 784th epoch : 0.4035283475835996  Training Accuracy:0.75\n",
      "The training loss at 785th epoch : 0.4034009420149563  Training Accuracy:0.75\n",
      "The training loss at 786th epoch : 0.40327355686599103  Training Accuracy:0.75\n",
      "The training loss at 787th epoch : 0.4031461924172094  Training Accuracy:0.75\n",
      "The training loss at 788th epoch : 0.4030188489480106  Training Accuracy:0.75\n",
      "The training loss at 789th epoch : 0.402891526736682  Training Accuracy:0.75\n",
      "The training loss at 790th epoch : 0.40276422606039447  Training Accuracy:0.75\n",
      "The training loss at 791th epoch : 0.4026369471951972  Training Accuracy:0.75\n",
      "The training loss at 792th epoch : 0.4025096904160129  Training Accuracy:0.75\n",
      "The training loss at 793th epoch : 0.40238245599663297  Training Accuracy:0.75\n",
      "The training loss at 794th epoch : 0.4022552442097125  Training Accuracy:0.75\n",
      "The training loss at 795th epoch : 0.4021280553267657  Training Accuracy:0.75\n",
      "The training loss at 796th epoch : 0.4020008896181612  Training Accuracy:0.75\n",
      "The training loss at 797th epoch : 0.40187374735311754  Training Accuracy:0.75\n",
      "The training loss at 798th epoch : 0.4017466287996983  Training Accuracy:0.75\n",
      "The training loss at 799th epoch : 0.4016195342248078  Training Accuracy:0.75\n",
      "The training loss at 800th epoch : 0.4014924638941866  Training Accuracy:0.75\n",
      "The training loss at 801th epoch : 0.4013654180724072  Training Accuracy:0.75\n",
      "The training loss at 802th epoch : 0.4012383970228695  Training Accuracy:0.75\n",
      "The training loss at 803th epoch : 0.4011114010077967  Training Accuracy:0.75\n",
      "The training loss at 804th epoch : 0.40098443028823094  Training Accuracy:0.75\n",
      "The training loss at 805th epoch : 0.40085748512402924  Training Accuracy:0.75\n",
      "The training loss at 806th epoch : 0.4007305657738593  Training Accuracy:0.75\n",
      "The training loss at 807th epoch : 0.40060367249519546  Training Accuracy:0.75\n",
      "The training loss at 808th epoch : 0.40047680554431486  Training Accuracy:0.75\n",
      "The training loss at 809th epoch : 0.4003499651762932  Training Accuracy:0.75\n",
      "The training loss at 810th epoch : 0.40022315164500094  Training Accuracy:0.75\n",
      "The training loss at 811th epoch : 0.4000963652030999  Training Accuracy:0.75\n",
      "The training loss at 812th epoch : 0.39996960610203874  Training Accuracy:0.75\n",
      "The training loss at 813th epoch : 0.3998428745920498  Training Accuracy:0.75\n",
      "The training loss at 814th epoch : 0.39971617092214534  Training Accuracy:0.75\n",
      "The training loss at 815th epoch : 0.39958949534011373  Training Accuracy:0.75\n",
      "The training loss at 816th epoch : 0.3994628480925161  Training Accuracy:0.75\n",
      "The training loss at 817th epoch : 0.3993362294246827  Training Accuracy:0.75\n",
      "The training loss at 818th epoch : 0.39920963958070976  Training Accuracy:0.75\n",
      "The training loss at 819th epoch : 0.3990830788034556  Training Accuracy:0.75\n",
      "The training loss at 820th epoch : 0.3989565473345379  Training Accuracy:0.75\n",
      "The training loss at 821th epoch : 0.39883004541432987  Training Accuracy:0.75\n",
      "The training loss at 822th epoch : 0.39870357328195744  Training Accuracy:0.75\n",
      "The training loss at 823th epoch : 0.39857713117529586  Training Accuracy:0.75\n",
      "The training loss at 824th epoch : 0.3984507193309667  Training Accuracy:0.75\n",
      "The training loss at 825th epoch : 0.3983243379843349  Training Accuracy:0.75\n",
      "The training loss at 826th epoch : 0.3981979873695055  Training Accuracy:0.75\n",
      "The training loss at 827th epoch : 0.39807166771932095  Training Accuracy:0.75\n",
      "The training loss at 828th epoch : 0.39794537926535806  Training Accuracy:0.75\n",
      "The training loss at 829th epoch : 0.3978191222379253  Training Accuracy:0.75\n",
      "The training loss at 830th epoch : 0.39769289686605985  Training Accuracy:0.75\n",
      "The training loss at 831th epoch : 0.39756670337752514  Training Accuracy:0.75\n",
      "The training loss at 832th epoch : 0.39744054199880785  Training Accuracy:0.75\n",
      "The training loss at 833th epoch : 0.3973144129551156  Training Accuracy:0.75\n",
      "The training loss at 834th epoch : 0.3971883164703741  Training Accuracy:0.75\n",
      "The training loss at 835th epoch : 0.3970622527672249  Training Accuracy:0.75\n",
      "The training loss at 836th epoch : 0.3969362220670228  Training Accuracy:0.75\n",
      "The training loss at 837th epoch : 0.39681022458983334  Training Accuracy:0.75\n",
      "The training loss at 838th epoch : 0.39668426055443073  Training Accuracy:0.75\n",
      "The training loss at 839th epoch : 0.3965583301782953  Training Accuracy:0.75\n",
      "The training loss at 840th epoch : 0.3964324336776113  Training Accuracy:0.75\n",
      "The training loss at 841th epoch : 0.3963065712672647  Training Accuracy:0.75\n",
      "The training loss at 842th epoch : 0.39618074316084134  Training Accuracy:0.75\n",
      "The training loss at 843th epoch : 0.39605494957062426  Training Accuracy:0.75\n",
      "The training loss at 844th epoch : 0.39592919070759214  Training Accuracy:0.75\n",
      "The training loss at 845th epoch : 0.3958034667814171  Training Accuracy:0.75\n",
      "The training loss at 846th epoch : 0.39567777800046283  Training Accuracy:0.75\n",
      "The training loss at 847th epoch : 0.3955521245717826  Training Accuracy:0.75\n",
      "The training loss at 848th epoch : 0.39542650670111773  Training Accuracy:0.75\n",
      "The training loss at 849th epoch : 0.39530092459289523  Training Accuracy:0.75\n",
      "The training loss at 850th epoch : 0.39517537845022666  Training Accuracy:0.75\n",
      "The training loss at 851th epoch : 0.39504986847490603  Training Accuracy:0.75\n",
      "The training loss at 852th epoch : 0.3949243948674083  Training Accuracy:0.75\n",
      "The training loss at 853th epoch : 0.39479895782688806  Training Accuracy:0.75\n",
      "The training loss at 854th epoch : 0.39467355755117733  Training Accuracy:0.75\n",
      "The training loss at 855th epoch : 0.3945481942367848  Training Accuracy:0.75\n",
      "The training loss at 856th epoch : 0.3944228680788938  Training Accuracy:0.75\n",
      "The training loss at 857th epoch : 0.39429757927136144  Training Accuracy:0.75\n",
      "The training loss at 858th epoch : 0.39417232800671664  Training Accuracy:0.75\n",
      "The training loss at 859th epoch : 0.3940471144761595  Training Accuracy:0.75\n",
      "The training loss at 860th epoch : 0.39392193886955945  Training Accuracy:0.75\n",
      "The training loss at 861th epoch : 0.3937968013754545  Training Accuracy:0.75\n",
      "The training loss at 862th epoch : 0.3936717021810497  Training Accuracy:0.75\n",
      "The training loss at 863th epoch : 0.3935466414722165  Training Accuracy:0.75\n",
      "The training loss at 864th epoch : 0.3934216194334912  Training Accuracy:0.75\n",
      "The training loss at 865th epoch : 0.39329663624807415  Training Accuracy:0.75\n",
      "The training loss at 866th epoch : 0.3931716920978288  Training Accuracy:0.75\n",
      "The training loss at 867th epoch : 0.39304678716328084  Training Accuracy:0.75\n",
      "The training loss at 868th epoch : 0.39292192162361705  Training Accuracy:0.75\n",
      "The training loss at 869th epoch : 0.39279709565668475  Training Accuracy:0.75\n",
      "The training loss at 870th epoch : 0.3926723094389909  Training Accuracy:0.75\n",
      "The training loss at 871th epoch : 0.39254756314570116  Training Accuracy:0.75\n",
      "The training loss at 872th epoch : 0.3924228569506396  Training Accuracy:0.75\n",
      "The training loss at 873th epoch : 0.39229819102628777  Training Accuracy:0.75\n",
      "The training loss at 874th epoch : 0.392173565543784  Training Accuracy:0.75\n",
      "The training loss at 875th epoch : 0.39204898067292304  Training Accuracy:0.75\n",
      "The training loss at 876th epoch : 0.3919244365821555  Training Accuracy:0.75\n",
      "The training loss at 877th epoch : 0.39179993343858716  Training Accuracy:0.75\n",
      "The training loss at 878th epoch : 0.3916754714079788  Training Accuracy:0.75\n",
      "The training loss at 879th epoch : 0.3915510506547457  Training Accuracy:0.75\n",
      "The training loss at 880th epoch : 0.39142667134195713  Training Accuracy:0.75\n",
      "The training loss at 881th epoch : 0.3913023336313363  Training Accuracy:0.75\n",
      "The training loss at 882th epoch : 0.3911780376832598  Training Accuracy:0.75\n",
      "The training loss at 883th epoch : 0.39105378365675764  Training Accuracy:0.75\n",
      "The training loss at 884th epoch : 0.3909295717095128  Training Accuracy:0.75\n",
      "The training loss at 885th epoch : 0.3908054019978613  Training Accuracy:0.75\n",
      "The training loss at 886th epoch : 0.3906812746767919  Training Accuracy:0.75\n",
      "The training loss at 887th epoch : 0.3905571898999462  Training Accuracy:0.75\n",
      "The training loss at 888th epoch : 0.39043314781961846  Training Accuracy:0.75\n",
      "The training loss at 889th epoch : 0.3903091485867557  Training Accuracy:0.75\n",
      "The training loss at 890th epoch : 0.39018519235095755  Training Accuracy:0.75\n",
      "The training loss at 891th epoch : 0.39006127926047673  Training Accuracy:0.75\n",
      "The training loss at 892th epoch : 0.3899374094622188  Training Accuracy:0.75\n",
      "The training loss at 893th epoch : 0.3898135831017423  Training Accuracy:0.75\n",
      "The training loss at 894th epoch : 0.38968980032325934  Training Accuracy:0.75\n",
      "The training loss at 895th epoch : 0.38956606126963544  Training Accuracy:0.75\n",
      "The training loss at 896th epoch : 0.38944236608238997  Training Accuracy:0.75\n",
      "The training loss at 897th epoch : 0.3893187149016964  Training Accuracy:0.75\n",
      "The training loss at 898th epoch : 0.38919510786638273  Training Accuracy:0.75\n",
      "The training loss at 899th epoch : 0.3890715451139317  Training Accuracy:0.75\n",
      "The training loss at 900th epoch : 0.38894802678048146  Training Accuracy:0.75\n",
      "The training loss at 901th epoch : 0.38882455300082575  Training Accuracy:0.75\n",
      "The training loss at 902th epoch : 0.38870112390841455  Training Accuracy:0.75\n",
      "The training loss at 903th epoch : 0.3885777396353546  Training Accuracy:0.75\n",
      "The training loss at 904th epoch : 0.38845440031240974  Training Accuracy:0.75\n",
      "The training loss at 905th epoch : 0.3883311060690019  Training Accuracy:0.75\n",
      "The training loss at 906th epoch : 0.38820785703321137  Training Accuracy:0.75\n",
      "The training loss at 907th epoch : 0.38808465333177755  Training Accuracy:0.75\n",
      "The training loss at 908th epoch : 0.3879614950900998  Training Accuracy:0.75\n",
      "The training loss at 909th epoch : 0.38783838243223784  Training Accuracy:0.75\n",
      "The training loss at 910th epoch : 0.38771531548091276  Training Accuracy:0.75\n",
      "The training loss at 911th epoch : 0.38759229435750786  Training Accuracy:0.75\n",
      "The training loss at 912th epoch : 0.38746931918206917  Training Accuracy:0.75\n",
      "The training loss at 913th epoch : 0.38734639007330657  Training Accuracy:0.75\n",
      "The training loss at 914th epoch : 0.38722350714859455  Training Accuracy:0.75\n",
      "The training loss at 915th epoch : 0.3871006705239731  Training Accuracy:0.75\n",
      "The training loss at 916th epoch : 0.3869778803141488  Training Accuracy:0.75\n",
      "The training loss at 917th epoch : 0.3868551366324956  Training Accuracy:0.75\n",
      "The training loss at 918th epoch : 0.38673243959105597  Training Accuracy:0.75\n",
      "The training loss at 919th epoch : 0.3866097893005418  Training Accuracy:0.75\n",
      "The training loss at 920th epoch : 0.3864871858703356  Training Accuracy:0.75\n",
      "The training loss at 921th epoch : 0.3863646294084915  Training Accuracy:0.75\n",
      "The training loss at 922th epoch : 0.38624212002173636  Training Accuracy:0.75\n",
      "The training loss at 923th epoch : 0.38611965781547103  Training Accuracy:0.75\n",
      "The training loss at 924th epoch : 0.3859972428937714  Training Accuracy:0.75\n",
      "The training loss at 925th epoch : 0.38587487535938964  Training Accuracy:0.75\n",
      "The training loss at 926th epoch : 0.3857525553137554  Training Accuracy:0.75\n",
      "The training loss at 927th epoch : 0.3856302828569772  Training Accuracy:0.75\n",
      "The training loss at 928th epoch : 0.3855080580878435  Training Accuracy:0.75\n",
      "The training loss at 929th epoch : 0.38538588110382416  Training Accuracy:0.75\n",
      "The training loss at 930th epoch : 0.3852637520010718  Training Accuracy:0.75\n",
      "The training loss at 931th epoch : 0.3851416708744231  Training Accuracy:0.75\n",
      "The training loss at 932th epoch : 0.3850196378174  Training Accuracy:0.75\n",
      "The training loss at 933th epoch : 0.38489765292221156  Training Accuracy:0.75\n",
      "The training loss at 934th epoch : 0.384775716279755  Training Accuracy:0.75\n",
      "The training loss at 935th epoch : 0.3846538279796173  Training Accuracy:0.75\n",
      "The training loss at 936th epoch : 0.38453198811007666  Training Accuracy:0.75\n",
      "The training loss at 937th epoch : 0.38441019675810406  Training Accuracy:0.75\n",
      "The training loss at 938th epoch : 0.38428845400936484  Training Accuracy:0.75\n",
      "The training loss at 939th epoch : 0.38416675994821997  Training Accuracy:0.75\n",
      "The training loss at 940th epoch : 0.38404511465772806  Training Accuracy:0.75\n",
      "The training loss at 941th epoch : 0.3839235182196466  Training Accuracy:0.75\n",
      "The training loss at 942th epoch : 0.38380197071443367  Training Accuracy:0.75\n",
      "The training loss at 943th epoch : 0.3836804722212498  Training Accuracy:0.75\n",
      "The training loss at 944th epoch : 0.38355902281795934  Training Accuracy:0.75\n",
      "The training loss at 945th epoch : 0.38343762258113223  Training Accuracy:0.75\n",
      "The training loss at 946th epoch : 0.3833162715860459  Training Accuracy:0.75\n",
      "The training loss at 947th epoch : 0.3831949699066868  Training Accuracy:0.75\n",
      "The training loss at 948th epoch : 0.383073717615752  Training Accuracy:0.75\n",
      "The training loss at 949th epoch : 0.3829525147846514  Training Accuracy:0.75\n",
      "The training loss at 950th epoch : 0.3828313614835092  Training Accuracy:0.75\n",
      "The training loss at 951th epoch : 0.3827102577811658  Training Accuracy:0.75\n",
      "The training loss at 952th epoch : 0.3825892037451795  Training Accuracy:0.75\n",
      "The training loss at 953th epoch : 0.38246819944182864  Training Accuracy:0.75\n",
      "The training loss at 954th epoch : 0.382347244936113  Training Accuracy:0.75\n",
      "The training loss at 955th epoch : 0.38222634029175623  Training Accuracy:0.75\n",
      "The training loss at 956th epoch : 0.3821054855712073  Training Accuracy:0.75\n",
      "The training loss at 957th epoch : 0.3819846808356428  Training Accuracy:0.75\n",
      "The training loss at 958th epoch : 0.38186392614496834  Training Accuracy:0.75\n",
      "The training loss at 959th epoch : 0.38174322155782114  Training Accuracy:0.75\n",
      "The training loss at 960th epoch : 0.38162256713157156  Training Accuracy:0.75\n",
      "The training loss at 961th epoch : 0.38150196292232513  Training Accuracy:0.75\n",
      "The training loss at 962th epoch : 0.3813814089849248  Training Accuracy:0.75\n",
      "The training loss at 963th epoch : 0.3812609053729527  Training Accuracy:0.75\n",
      "The training loss at 964th epoch : 0.3811404521387322  Training Accuracy:0.75\n",
      "The training loss at 965th epoch : 0.38102004933333017  Training Accuracy:0.75\n",
      "The training loss at 966th epoch : 0.38089969700655874  Training Accuracy:0.75\n",
      "The training loss at 967th epoch : 0.3807793952069775  Training Accuracy:0.75\n",
      "The training loss at 968th epoch : 0.38065914398189576  Training Accuracy:0.75\n",
      "The training loss at 969th epoch : 0.38053894337737443  Training Accuracy:0.75\n",
      "The training loss at 970th epoch : 0.38041879343822815  Training Accuracy:0.75\n",
      "The training loss at 971th epoch : 0.38029869420802753  Training Accuracy:0.75\n",
      "The training loss at 972th epoch : 0.3801786457291013  Training Accuracy:0.75\n",
      "The training loss at 973th epoch : 0.3800586480425383  Training Accuracy:0.75\n",
      "The training loss at 974th epoch : 0.37993870118818984  Training Accuracy:0.75\n",
      "The training loss at 975th epoch : 0.3798188052046717  Training Accuracy:0.75\n",
      "The training loss at 976th epoch : 0.3796989601293666  Training Accuracy:0.75\n",
      "The training loss at 977th epoch : 0.37957916599842606  Training Accuracy:0.75\n",
      "The training loss at 978th epoch : 0.3794594228467728  Training Accuracy:0.75\n",
      "The training loss at 979th epoch : 0.37933973070810306  Training Accuracy:0.75\n",
      "The training loss at 980th epoch : 0.3792200896148886  Training Accuracy:0.75\n",
      "The training loss at 981th epoch : 0.3791004995983792  Training Accuracy:0.75\n",
      "The training loss at 982th epoch : 0.37898096068860465  Training Accuracy:0.75\n",
      "The training loss at 983th epoch : 0.3788614729143772  Training Accuracy:0.75\n",
      "The training loss at 984th epoch : 0.3787420363032939  Training Accuracy:0.75\n",
      "The training loss at 985th epoch : 0.3786226508817387  Training Accuracy:0.75\n",
      "The training loss at 986th epoch : 0.3785033166748848  Training Accuracy:0.75\n",
      "The training loss at 987th epoch : 0.37838403370669704  Training Accuracy:0.75\n",
      "The training loss at 988th epoch : 0.3782648019999341  Training Accuracy:0.75\n",
      "The training loss at 989th epoch : 0.37814562157615106  Training Accuracy:0.75\n",
      "The training loss at 990th epoch : 0.37802649245570136  Training Accuracy:0.75\n",
      "The training loss at 991th epoch : 0.3779074146577393  Training Accuracy:0.75\n",
      "The training loss at 992th epoch : 0.37778838820022265  Training Accuracy:0.75\n",
      "The training loss at 993th epoch : 0.37766941309991453  Training Accuracy:0.75\n",
      "The training loss at 994th epoch : 0.37755048937238617  Training Accuracy:0.75\n",
      "The training loss at 995th epoch : 0.37743161703201894  Training Accuracy:0.75\n",
      "The training loss at 996th epoch : 0.37731279609200713  Training Accuracy:0.75\n",
      "The training loss at 997th epoch : 0.3771940265643599  Training Accuracy:0.75\n",
      "The training loss at 998th epoch : 0.37707530845990395  Training Accuracy:0.75\n",
      "The training loss at 999th epoch : 0.37695664178828575  Training Accuracy:0.75\n",
      "The training loss at 1000th epoch : 0.37683802655797416  Training Accuracy:0.75\n",
      "The training loss at 1001th epoch : 0.37671946277626256  Training Accuracy:0.75\n",
      "The training loss at 1002th epoch : 0.37660095044927133  Training Accuracy:0.75\n",
      "The training loss at 1003th epoch : 0.37648248958195046  Training Accuracy:0.75\n",
      "The training loss at 1004th epoch : 0.37636408017808165  Training Accuracy:0.75\n",
      "The training loss at 1005th epoch : 0.3762457222402811  Training Accuracy:0.75\n",
      "The training loss at 1006th epoch : 0.3761274157700015  Training Accuracy:0.75\n",
      "The training loss at 1007th epoch : 0.3760091607675349  Training Accuracy:0.75\n",
      "The training loss at 1008th epoch : 0.37589095723201466  Training Accuracy:0.75\n",
      "The training loss at 1009th epoch : 0.3757728051614184  Training Accuracy:0.75\n",
      "The training loss at 1010th epoch : 0.3756547045525702  Training Accuracy:0.75\n",
      "The training loss at 1011th epoch : 0.3755366554011428  Training Accuracy:0.75\n",
      "The training loss at 1012th epoch : 0.37541865770166044  Training Accuracy:0.75\n",
      "The training loss at 1013th epoch : 0.37530071144750116  Training Accuracy:0.75\n",
      "The training loss at 1014th epoch : 0.3751828166308991  Training Accuracy:0.75\n",
      "The training loss at 1015th epoch : 0.3750649732429472  Training Accuracy:0.75\n",
      "The training loss at 1016th epoch : 0.3749471812735994  Training Accuracy:0.75\n",
      "The training loss at 1017th epoch : 0.3748294407116734  Training Accuracy:0.75\n",
      "The training loss at 1018th epoch : 0.3747117515448528  Training Accuracy:0.75\n",
      "The training loss at 1019th epoch : 0.3745941137596897  Training Accuracy:0.75\n",
      "The training loss at 1020th epoch : 0.3744765273416072  Training Accuracy:0.75\n",
      "The training loss at 1021th epoch : 0.3743589922749017  Training Accuracy:0.75\n",
      "The training loss at 1022th epoch : 0.3742415085427456  Training Accuracy:0.75\n",
      "The training loss at 1023th epoch : 0.3741240761271895  Training Accuracy:0.75\n",
      "The training loss at 1024th epoch : 0.3740066950091648  Training Accuracy:0.75\n",
      "The training loss at 1025th epoch : 0.37388936516848614  Training Accuracy:0.75\n",
      "The training loss at 1026th epoch : 0.3737720865838538  Training Accuracy:0.75\n",
      "The training loss at 1027th epoch : 0.3736548592328563  Training Accuracy:0.75\n",
      "The training loss at 1028th epoch : 0.37353768309197266  Training Accuracy:0.75\n",
      "The training loss at 1029th epoch : 0.37342055813657493  Training Accuracy:0.75\n",
      "The training loss at 1030th epoch : 0.3733034843409307  Training Accuracy:0.75\n",
      "The training loss at 1031th epoch : 0.3731864616782055  Training Accuracy:0.75\n",
      "The training loss at 1032th epoch : 0.3730694901204653  Training Accuracy:0.75\n",
      "The training loss at 1033th epoch : 0.3729525696386788  Training Accuracy:0.75\n",
      "The training loss at 1034th epoch : 0.37283570020272006  Training Accuracy:0.75\n",
      "The training loss at 1035th epoch : 0.37271888178137086  Training Accuracy:0.75\n",
      "The training loss at 1036th epoch : 0.37260211434232315  Training Accuracy:0.75\n",
      "The training loss at 1037th epoch : 0.37248539785218143  Training Accuracy:0.75\n",
      "The training loss at 1038th epoch : 0.3723687322764653  Training Accuracy:0.75\n",
      "The training loss at 1039th epoch : 0.37225211757961174  Training Accuracy:0.75\n",
      "The training loss at 1040th epoch : 0.3721355537249777  Training Accuracy:0.75\n",
      "The training loss at 1041th epoch : 0.3720190406748425  Training Accuracy:0.75\n",
      "The training loss at 1042th epoch : 0.37190257839040997  Training Accuracy:0.75\n",
      "The training loss at 1043th epoch : 0.37178616683181137  Training Accuracy:0.75\n",
      "The training loss at 1044th epoch : 0.37166980595810734  Training Accuracy:0.75\n",
      "The training loss at 1045th epoch : 0.3715534957272906  Training Accuracy:0.75\n",
      "The training loss at 1046th epoch : 0.37143723609628804  Training Accuracy:0.75\n",
      "The training loss at 1047th epoch : 0.3713210270209636  Training Accuracy:0.75\n",
      "The training loss at 1048th epoch : 0.3712048684561202  Training Accuracy:0.75\n",
      "The training loss at 1049th epoch : 0.3710887603555024  Training Accuracy:0.75\n",
      "The training loss at 1050th epoch : 0.37097270267179866  Training Accuracy:0.75\n",
      "The training loss at 1051th epoch : 0.37085669535664373  Training Accuracy:0.75\n",
      "The training loss at 1052th epoch : 0.37074073836062116  Training Accuracy:0.75\n",
      "The training loss at 1053th epoch : 0.3706248316332654  Training Accuracy:0.75\n",
      "The training loss at 1054th epoch : 0.37050897512306435  Training Accuracy:0.75\n",
      "The training loss at 1055th epoch : 0.3703931687774619  Training Accuracy:0.75\n",
      "The training loss at 1056th epoch : 0.3702774125428598  Training Accuracy:0.75\n",
      "The training loss at 1057th epoch : 0.3701617063646203  Training Accuracy:0.75\n",
      "The training loss at 1058th epoch : 0.3700460501870686  Training Accuracy:0.75\n",
      "The training loss at 1059th epoch : 0.3699304439534949  Training Accuracy:0.75\n",
      "The training loss at 1060th epoch : 0.3698148876061569  Training Accuracy:0.75\n",
      "The training loss at 1061th epoch : 0.3696993810862821  Training Accuracy:0.75\n",
      "The training loss at 1062th epoch : 0.36958392433406995  Training Accuracy:0.75\n",
      "The training loss at 1063th epoch : 0.36946851728869445  Training Accuracy:0.75\n",
      "The training loss at 1064th epoch : 0.3693531598883062  Training Accuracy:0.75\n",
      "The training loss at 1065th epoch : 0.3692378520700347  Training Accuracy:0.75\n",
      "The training loss at 1066th epoch : 0.3691225937699908  Training Accuracy:0.75\n",
      "The training loss at 1067th epoch : 0.36900738492326873  Training Accuracy:0.75\n",
      "The training loss at 1068th epoch : 0.3688922254639486  Training Accuracy:0.75\n",
      "The training loss at 1069th epoch : 0.36877711532509855  Training Accuracy:0.75\n",
      "The training loss at 1070th epoch : 0.36866205443877686  Training Accuracy:0.75\n",
      "The training loss at 1071th epoch : 0.3685470427360345  Training Accuracy:0.75\n",
      "The training loss at 1072th epoch : 0.36843208014691703  Training Accuracy:0.75\n",
      "The training loss at 1073th epoch : 0.36831716660046704  Training Accuracy:0.75\n",
      "The training loss at 1074th epoch : 0.36820230202472626  Training Accuracy:0.75\n",
      "The training loss at 1075th epoch : 0.3680874863467378  Training Accuracy:0.75\n",
      "The training loss at 1076th epoch : 0.36797271949254845  Training Accuracy:0.75\n",
      "The training loss at 1077th epoch : 0.3678580013872105  Training Accuracy:0.75\n",
      "The training loss at 1078th epoch : 0.3677433319547843  Training Accuracy:0.75\n",
      "The training loss at 1079th epoch : 0.3676287111183404  Training Accuracy:0.75\n",
      "The training loss at 1080th epoch : 0.36751413879996137  Training Accuracy:0.75\n",
      "The training loss at 1081th epoch : 0.36739961492074436  Training Accuracy:0.75\n",
      "The training loss at 1082th epoch : 0.3672851394008028  Training Accuracy:0.75\n",
      "The training loss at 1083th epoch : 0.3671707121592691  Training Accuracy:0.75\n",
      "The training loss at 1084th epoch : 0.3670563331142961  Training Accuracy:0.75\n",
      "The training loss at 1085th epoch : 0.3669420021830597  Training Accuracy:0.75\n",
      "The training loss at 1086th epoch : 0.3668277192817607  Training Accuracy:0.75\n",
      "The training loss at 1087th epoch : 0.366713484325627  Training Accuracy:0.75\n",
      "The training loss at 1088th epoch : 0.3665992972289155  Training Accuracy:0.75\n",
      "The training loss at 1089th epoch : 0.36648515790491426  Training Accuracy:0.75\n",
      "The training loss at 1090th epoch : 0.36637106626594473  Training Accuracy:0.75\n",
      "The training loss at 1091th epoch : 0.3662570222233635  Training Accuracy:0.75\n",
      "The training loss at 1092th epoch : 0.3661430256875644  Training Accuracy:0.75\n",
      "The training loss at 1093th epoch : 0.3660290765679807  Training Accuracy:0.75\n",
      "The training loss at 1094th epoch : 0.3659151747730869  Training Accuracy:0.75\n",
      "The training loss at 1095th epoch : 0.3658013202104008  Training Accuracy:0.75\n",
      "The training loss at 1096th epoch : 0.36568751278648554  Training Accuracy:0.75\n",
      "The training loss at 1097th epoch : 0.3655737524069514  Training Accuracy:0.75\n",
      "The training loss at 1098th epoch : 0.36546003897645796  Training Accuracy:0.75\n",
      "The training loss at 1099th epoch : 0.36534637239871603  Training Accuracy:0.75\n",
      "The training loss at 1100th epoch : 0.3652327525764893  Training Accuracy:0.75\n",
      "The training loss at 1101th epoch : 0.3651191794115967  Training Accuracy:0.75\n",
      "The training loss at 1102th epoch : 0.3650056528049139  Training Accuracy:0.75\n",
      "The training loss at 1103th epoch : 0.3648921726563756  Training Accuracy:0.75\n",
      "The training loss at 1104th epoch : 0.3647787388649769  Training Accuracy:0.75\n",
      "The training loss at 1105th epoch : 0.3646653513287757  Training Accuracy:0.75\n",
      "The training loss at 1106th epoch : 0.36455200994489434  Training Accuracy:0.75\n",
      "The training loss at 1107th epoch : 0.3644387146095213  Training Accuracy:0.75\n",
      "The training loss at 1108th epoch : 0.36432546521791326  Training Accuracy:0.75\n",
      "The training loss at 1109th epoch : 0.36421226166439685  Training Accuracy:0.75\n",
      "The training loss at 1110th epoch : 0.3640991038423703  Training Accuracy:0.75\n",
      "The training loss at 1111th epoch : 0.36398599164430556  Training Accuracy:0.75\n",
      "The training loss at 1112th epoch : 0.3638729249617498  Training Accuracy:0.75\n",
      "The training loss at 1113th epoch : 0.3637599036853271  Training Accuracy:0.75\n",
      "The training loss at 1114th epoch : 0.3636469277047407  Training Accuracy:0.75\n",
      "The training loss at 1115th epoch : 0.3635339969087742  Training Accuracy:0.75\n",
      "The training loss at 1116th epoch : 0.36342111118529347  Training Accuracy:0.75\n",
      "The training loss at 1117th epoch : 0.36330827042124847  Training Accuracy:0.75\n",
      "The training loss at 1118th epoch : 0.3631954745026748  Training Accuracy:0.75\n",
      "The training loss at 1119th epoch : 0.3630827233146955  Training Accuracy:0.75\n",
      "The training loss at 1120th epoch : 0.3629700167415226  Training Accuracy:0.75\n",
      "The training loss at 1121th epoch : 0.36285735466645896  Training Accuracy:0.75\n",
      "The training loss at 1122th epoch : 0.36274473697189963  Training Accuracy:0.75\n",
      "The training loss at 1123th epoch : 0.36263216353933375  Training Accuracy:0.75\n",
      "The training loss at 1124th epoch : 0.362519634249346  Training Accuracy:0.75\n",
      "The training loss at 1125th epoch : 0.3624071489816183  Training Accuracy:0.75\n",
      "The training loss at 1126th epoch : 0.36229470761493127  Training Accuracy:0.75\n",
      "The training loss at 1127th epoch : 0.36218231002716594  Training Accuracy:0.75\n",
      "The training loss at 1128th epoch : 0.3620699560953052  Training Accuracy:0.75\n",
      "The training loss at 1129th epoch : 0.3619576456954353  Training Accuracy:0.75\n",
      "The training loss at 1130th epoch : 0.3618453787027476  Training Accuracy:0.75\n",
      "The training loss at 1131th epoch : 0.36173315499153985  Training Accuracy:0.75\n",
      "The training loss at 1132th epoch : 0.36162097443521773  Training Accuracy:0.75\n",
      "The training loss at 1133th epoch : 0.36150883690629637  Training Accuracy:0.75\n",
      "The training loss at 1134th epoch : 0.36139674227640195  Training Accuracy:0.75\n",
      "The training loss at 1135th epoch : 0.36128469041627276  Training Accuracy:0.75\n",
      "The training loss at 1136th epoch : 0.36117268119576107  Training Accuracy:0.75\n",
      "The training loss at 1137th epoch : 0.3610607144838342  Training Accuracy:0.75\n",
      "The training loss at 1138th epoch : 0.3609487901485763  Training Accuracy:0.75\n",
      "The training loss at 1139th epoch : 0.36083690805718927  Training Accuracy:0.75\n",
      "The training loss at 1140th epoch : 0.3607250680759945  Training Accuracy:0.75\n",
      "The training loss at 1141th epoch : 0.3606132700704342  Training Accuracy:0.75\n",
      "The training loss at 1142th epoch : 0.3605015139050724  Training Accuracy:0.75\n",
      "The training loss at 1143th epoch : 0.3603897994435967  Training Accuracy:0.75\n",
      "The training loss at 1144th epoch : 0.3602781265488194  Training Accuracy:0.75\n",
      "The training loss at 1145th epoch : 0.36016649508267873  Training Accuracy:0.75\n",
      "The training loss at 1146th epoch : 0.36005490490624015  Training Accuracy:0.75\n",
      "The training loss at 1147th epoch : 0.35994335587969767  Training Accuracy:0.75\n",
      "The training loss at 1148th epoch : 0.3598318478623752  Training Accuracy:0.75\n",
      "The training loss at 1149th epoch : 0.35972038071272744  Training Accuracy:0.75\n",
      "The training loss at 1150th epoch : 0.3596089542883415  Training Accuracy:0.75\n",
      "The training loss at 1151th epoch : 0.3594975684459378  Training Accuracy:0.75\n",
      "The training loss at 1152th epoch : 0.35938622304137124  Training Accuracy:0.75\n",
      "The training loss at 1153th epoch : 0.3592749179296328  Training Accuracy:0.75\n",
      "The training loss at 1154th epoch : 0.35916365296485  Training Accuracy:0.75\n",
      "The training loss at 1155th epoch : 0.3590524280002885  Training Accuracy:0.75\n",
      "The training loss at 1156th epoch : 0.35894124288835333  Training Accuracy:0.75\n",
      "The training loss at 1157th epoch : 0.3588300974805894  Training Accuracy:0.75\n",
      "The training loss at 1158th epoch : 0.3587189916276832  Training Accuracy:0.75\n",
      "The training loss at 1159th epoch : 0.3586079251794636  Training Accuracy:0.75\n",
      "The training loss at 1160th epoch : 0.35849689798490275  Training Accuracy:0.75\n",
      "The training loss at 1161th epoch : 0.3583859098921174  Training Accuracy:0.75\n",
      "The training loss at 1162th epoch : 0.3582749607483696  Training Accuracy:0.75\n",
      "The training loss at 1163th epoch : 0.35816405040006816  Training Accuracy:0.75\n",
      "The training loss at 1164th epoch : 0.35805317869276915  Training Accuracy:0.75\n",
      "The training loss at 1165th epoch : 0.3579423454711771  Training Accuracy:0.75\n",
      "The training loss at 1166th epoch : 0.35783155057914595  Training Accuracy:0.75\n",
      "The training loss at 1167th epoch : 0.3577207938596798  Training Accuracy:0.75\n",
      "The training loss at 1168th epoch : 0.35761007515493415  Training Accuracy:0.75\n",
      "The training loss at 1169th epoch : 0.35749939430621647  Training Accuracy:0.75\n",
      "The training loss at 1170th epoch : 0.35738875115398727  Training Accuracy:0.75\n",
      "The training loss at 1171th epoch : 0.35727814553786086  Training Accuracy:0.75\n",
      "The training loss at 1172th epoch : 0.35716757729660625  Training Accuracy:0.75\n",
      "The training loss at 1173th epoch : 0.35705704626814805  Training Accuracy:0.75\n",
      "The training loss at 1174th epoch : 0.35694655228956707  Training Accuracy:0.75\n",
      "The training loss at 1175th epoch : 0.35683609519710124  Training Accuracy:0.75\n",
      "The training loss at 1176th epoch : 0.3567256748261464  Training Accuracy:0.75\n",
      "The training loss at 1177th epoch : 0.3566152910112571  Training Accuracy:0.75\n",
      "The training loss at 1178th epoch : 0.35650494358614726  Training Accuracy:0.75\n",
      "The training loss at 1179th epoch : 0.35639463238369073  Training Accuracy:0.75\n",
      "The training loss at 1180th epoch : 0.3562843572359224  Training Accuracy:0.75\n",
      "The training loss at 1181th epoch : 0.35617411797403853  Training Accuracy:0.75\n",
      "The training loss at 1182th epoch : 0.3560639144283975  Training Accuracy:0.75\n",
      "The training loss at 1183th epoch : 0.3559537464285207  Training Accuracy:0.75\n",
      "The training loss at 1184th epoch : 0.3558436138030927  Training Accuracy:0.75\n",
      "The training loss at 1185th epoch : 0.3557335163799624  Training Accuracy:0.75\n",
      "The training loss at 1186th epoch : 0.3556234539861432  Training Accuracy:0.75\n",
      "The training loss at 1187th epoch : 0.3555134264478138  Training Accuracy:0.75\n",
      "The training loss at 1188th epoch : 0.3554034335903187  Training Accuracy:0.75\n",
      "The training loss at 1189th epoch : 0.3552934752381687  Training Accuracy:0.75\n",
      "The training loss at 1190th epoch : 0.3551835512150415  Training Accuracy:0.75\n",
      "The training loss at 1191th epoch : 0.3550736613437823  Training Accuracy:0.75\n",
      "The training loss at 1192th epoch : 0.3549638054464041  Training Accuracy:0.75\n",
      "The training loss at 1193th epoch : 0.35485398334408824  Training Accuracy:0.75\n",
      "The training loss at 1194th epoch : 0.3547441948571848  Training Accuracy:0.75\n",
      "The training loss at 1195th epoch : 0.3546344398052133  Training Accuracy:0.75\n",
      "The training loss at 1196th epoch : 0.35452471800686275  Training Accuracy:0.75\n",
      "The training loss at 1197th epoch : 0.35441502927999236  Training Accuracy:0.75\n",
      "The training loss at 1198th epoch : 0.3543053734416316  Training Accuracy:0.75\n",
      "The training loss at 1199th epoch : 0.35419575030798106  Training Accuracy:0.75\n",
      "The training loss at 1200th epoch : 0.3540861596944122  Training Accuracy:0.75\n",
      "The training loss at 1201th epoch : 0.3539766014154682  Training Accuracy:0.75\n",
      "The training loss at 1202th epoch : 0.3538670752848639  Training Accuracy:0.75\n",
      "The training loss at 1203th epoch : 0.3537575811154862  Training Accuracy:0.75\n",
      "The training loss at 1204th epoch : 0.35364811871939467  Training Accuracy:0.75\n",
      "The training loss at 1205th epoch : 0.3535386879078211  Training Accuracy:0.75\n",
      "The training loss at 1206th epoch : 0.35342928849117056  Training Accuracy:0.75\n",
      "The training loss at 1207th epoch : 0.35331992027902087  Training Accuracy:0.75\n",
      "The training loss at 1208th epoch : 0.3532105830801233  Training Accuracy:0.75\n",
      "The training loss at 1209th epoch : 0.3531012767024027  Training Accuracy:0.75\n",
      "The training loss at 1210th epoch : 0.35299200095295735  Training Accuracy:0.75\n",
      "The training loss at 1211th epoch : 0.35288275563805954  Training Accuracy:0.75\n",
      "The training loss at 1212th epoch : 0.3527735405631553  Training Accuracy:0.75\n",
      "The training loss at 1213th epoch : 0.35266435553286474  Training Accuracy:0.75\n",
      "The training loss at 1214th epoch : 0.3525552003509822  Training Accuracy:0.75\n",
      "The training loss at 1215th epoch : 0.3524460748204762  Training Accuracy:0.75\n",
      "The training loss at 1216th epoch : 0.3523369787434893  Training Accuracy:0.75\n",
      "The training loss at 1217th epoch : 0.3522279119213387  Training Accuracy:0.75\n",
      "The training loss at 1218th epoch : 0.35211887415451565  Training Accuracy:0.75\n",
      "The training loss at 1219th epoch : 0.3520098652426859  Training Accuracy:0.75\n",
      "The training loss at 1220th epoch : 0.35190088498468935  Training Accuracy:0.75\n",
      "The training loss at 1221th epoch : 0.35179193317854024  Training Accuracy:0.75\n",
      "The training loss at 1222th epoch : 0.35168300962142707  Training Accuracy:0.75\n",
      "The training loss at 1223th epoch : 0.3515741141097124  Training Accuracy:0.75\n",
      "The training loss at 1224th epoch : 0.3514652464389329  Training Accuracy:0.75\n",
      "The training loss at 1225th epoch : 0.3513564064037991  Training Accuracy:0.75\n",
      "The training loss at 1226th epoch : 0.3512475937981955  Training Accuracy:0.75\n",
      "The training loss at 1227th epoch : 0.3511388084151801  Training Accuracy:0.75\n",
      "The training loss at 1228th epoch : 0.3510300500469845  Training Accuracy:0.75\n",
      "The training loss at 1229th epoch : 0.3509213184850137  Training Accuracy:0.75\n",
      "The training loss at 1230th epoch : 0.3508126135198456  Training Accuracy:0.75\n",
      "The training loss at 1231th epoch : 0.3507039349412312  Training Accuracy:0.75\n",
      "The training loss at 1232th epoch : 0.3505952825380942  Training Accuracy:0.75\n",
      "The training loss at 1233th epoch : 0.35048665609853047  Training Accuracy:0.75\n",
      "The training loss at 1234th epoch : 0.3503780554098083  Training Accuracy:0.75\n",
      "The training loss at 1235th epoch : 0.3502694802583677  Training Accuracy:0.75\n",
      "The training loss at 1236th epoch : 0.35016093042982016  Training Accuracy:0.75\n",
      "The training loss at 1237th epoch : 0.35005240570894847  Training Accuracy:0.75\n",
      "The training loss at 1238th epoch : 0.3499439058797063  Training Accuracy:0.75\n",
      "The training loss at 1239th epoch : 0.3498354307252177  Training Accuracy:0.75\n",
      "The training loss at 1240th epoch : 0.349726980027777  Training Accuracy:0.75\n",
      "The training loss at 1241th epoch : 0.3496185535688481  Training Accuracy:0.75\n",
      "The training loss at 1242th epoch : 0.3495101511290642  Training Accuracy:0.75\n",
      "The training loss at 1243th epoch : 0.3494017724882274  Training Accuracy:0.75\n",
      "The training loss at 1244th epoch : 0.3492934174253082  Training Accuracy:0.75\n",
      "The training loss at 1245th epoch : 0.3491850857184449  Training Accuracy:0.75\n",
      "The training loss at 1246th epoch : 0.3490767771449435  Training Accuracy:0.75\n",
      "The training loss at 1247th epoch : 0.34896849148127657  Training Accuracy:0.75\n",
      "The training loss at 1248th epoch : 0.34886022850308324  Training Accuracy:0.75\n",
      "The training loss at 1249th epoch : 0.3487519879851685  Training Accuracy:0.75\n",
      "The training loss at 1250th epoch : 0.3486437697015025  Training Accuracy:0.75\n",
      "The training loss at 1251th epoch : 0.3485355734252201  Training Accuracy:0.75\n",
      "The training loss at 1252th epoch : 0.34842739892862035  Training Accuracy:0.75\n",
      "The training loss at 1253th epoch : 0.34831924598316555  Training Accuracy:0.75\n",
      "The training loss at 1254th epoch : 0.34821111435948093  Training Accuracy:0.75\n",
      "The training loss at 1255th epoch : 0.34810300382735393  Training Accuracy:0.75\n",
      "The training loss at 1256th epoch : 0.34799491415573336  Training Accuracy:0.75\n",
      "The training loss at 1257th epoch : 0.3478868451127288  Training Accuracy:0.75\n",
      "The training loss at 1258th epoch : 0.34777879646561005  Training Accuracy:0.75\n",
      "The training loss at 1259th epoch : 0.3476707679808061  Training Accuracy:0.75\n",
      "The training loss at 1260th epoch : 0.3475627594239046  Training Accuracy:0.75\n",
      "The training loss at 1261th epoch : 0.3474547705596509  Training Accuracy:0.75\n",
      "The training loss at 1262th epoch : 0.3473468011519476  Training Accuracy:0.75\n",
      "The training loss at 1263th epoch : 0.34723885096385343  Training Accuracy:0.75\n",
      "The training loss at 1264th epoch : 0.3471309197575824  Training Accuracy:0.75\n",
      "The training loss at 1265th epoch : 0.3470230072945034  Training Accuracy:0.75\n",
      "The training loss at 1266th epoch : 0.3469151133351387  Training Accuracy:0.75\n",
      "The training loss at 1267th epoch : 0.34680723763916366  Training Accuracy:0.75\n",
      "The training loss at 1268th epoch : 0.34669937996540534  Training Accuracy:0.75\n",
      "The training loss at 1269th epoch : 0.3465915400718422  Training Accuracy:0.75\n",
      "The training loss at 1270th epoch : 0.3464837177156023  Training Accuracy:0.75\n",
      "The training loss at 1271th epoch : 0.3463759126529634  Training Accuracy:0.75\n",
      "The training loss at 1272th epoch : 0.346268124639351  Training Accuracy:0.75\n",
      "The training loss at 1273th epoch : 0.34616035342933815  Training Accuracy:0.75\n",
      "The training loss at 1274th epoch : 0.3460525987766439  Training Accuracy:0.75\n",
      "The training loss at 1275th epoch : 0.34594486043413253  Training Accuracy:0.75\n",
      "The training loss at 1276th epoch : 0.34583713815381245  Training Accuracy:0.75\n",
      "The training loss at 1277th epoch : 0.3457294316868353  Training Accuracy:0.75\n",
      "The training loss at 1278th epoch : 0.34562174078349456  Training Accuracy:0.75\n",
      "The training loss at 1279th epoch : 0.3455140651932248  Training Accuracy:0.75\n",
      "The training loss at 1280th epoch : 0.3454064046646004  Training Accuracy:0.75\n",
      "The training loss at 1281th epoch : 0.34529875894533424  Training Accuracy:0.75\n",
      "The training loss at 1282th epoch : 0.3451911277822771  Training Accuracy:0.75\n",
      "The training loss at 1283th epoch : 0.345083510921416  Training Accuracy:0.75\n",
      "The training loss at 1284th epoch : 0.344975908107873  Training Accuracy:0.75\n",
      "The training loss at 1285th epoch : 0.34486831908590454  Training Accuracy:0.75\n",
      "The training loss at 1286th epoch : 0.34476074359889963  Training Accuracy:0.75\n",
      "The training loss at 1287th epoch : 0.34465318138937895  Training Accuracy:0.75\n",
      "The training loss at 1288th epoch : 0.3445456321989935  Training Accuracy:0.75\n",
      "The training loss at 1289th epoch : 0.34443809576852336  Training Accuracy:0.75\n",
      "The training loss at 1290th epoch : 0.34433057183787646  Training Accuracy:0.75\n",
      "The training loss at 1291th epoch : 0.34422306014608717  Training Accuracy:0.75\n",
      "The training loss at 1292th epoch : 0.344115560431315  Training Accuracy:0.75\n",
      "The training loss at 1293th epoch : 0.34400807243084347  Training Accuracy:0.75\n",
      "The training loss at 1294th epoch : 0.34390059588107835  Training Accuracy:0.75\n",
      "The training loss at 1295th epoch : 0.34379313051754673  Training Accuracy:0.75\n",
      "The training loss at 1296th epoch : 0.34368567607489536  Training Accuracy:0.75\n",
      "The training loss at 1297th epoch : 0.3435782322868894  Training Accuracy:0.75\n",
      "The training loss at 1298th epoch : 0.34347079888641086  Training Accuracy:0.75\n",
      "The training loss at 1299th epoch : 0.34336337560545727  Training Accuracy:0.75\n",
      "The training loss at 1300th epoch : 0.34325596217514015  Training Accuracy:0.75\n",
      "The training loss at 1301th epoch : 0.3431485583256837  Training Accuracy:0.75\n",
      "The training loss at 1302th epoch : 0.3430411637864231  Training Accuracy:0.75\n",
      "The training loss at 1303th epoch : 0.34293377828580307  Training Accuracy:0.75\n",
      "The training loss at 1304th epoch : 0.34282640155137656  Training Accuracy:0.75\n",
      "The training loss at 1305th epoch : 0.3427190333098029  Training Accuracy:0.75\n",
      "The training loss at 1306th epoch : 0.34261167328684644  Training Accuracy:0.75\n",
      "The training loss at 1307th epoch : 0.3425043212073749  Training Accuracy:0.75\n",
      "The training loss at 1308th epoch : 0.34239697679535785  Training Accuracy:0.75\n",
      "The training loss at 1309th epoch : 0.34228963977386506  Training Accuracy:0.75\n",
      "The training loss at 1310th epoch : 0.34218230986506487  Training Accuracy:0.75\n",
      "The training loss at 1311th epoch : 0.3420749867902227  Training Accuracy:0.75\n",
      "The training loss at 1312th epoch : 0.3419676702696991  Training Accuracy:0.75\n",
      "The training loss at 1313th epoch : 0.34186036002294845  Training Accuracy:0.75\n",
      "The training loss at 1314th epoch : 0.34175305576851694  Training Accuracy:0.75\n",
      "The training loss at 1315th epoch : 0.34164575722404117  Training Accuracy:0.75\n",
      "The training loss at 1316th epoch : 0.3415384641062461  Training Accuracy:0.75\n",
      "The training loss at 1317th epoch : 0.34143117613094376  Training Accuracy:0.75\n",
      "The training loss at 1318th epoch : 0.34132389301303095  Training Accuracy:0.75\n",
      "The training loss at 1319th epoch : 0.3412166144664881  Training Accuracy:0.75\n",
      "The training loss at 1320th epoch : 0.34110934020437694  Training Accuracy:0.75\n",
      "The training loss at 1321th epoch : 0.3410020699388391  Training Accuracy:0.75\n",
      "The training loss at 1322th epoch : 0.3408948033810939  Training Accuracy:0.75\n",
      "The training loss at 1323th epoch : 0.3407875402414371  Training Accuracy:0.75\n",
      "The training loss at 1324th epoch : 0.34068028022923846  Training Accuracy:0.75\n",
      "The training loss at 1325th epoch : 0.34057302305294035  Training Accuracy:0.75\n",
      "The training loss at 1326th epoch : 0.34046576842005544  Training Accuracy:0.75\n",
      "The training loss at 1327th epoch : 0.3403585160371653  Training Accuracy:0.75\n",
      "The training loss at 1328th epoch : 0.34025126560991814  Training Accuracy:0.75\n",
      "The training loss at 1329th epoch : 0.340144016843027  Training Accuracy:0.75\n",
      "The training loss at 1330th epoch : 0.3400367694402679  Training Accuracy:0.75\n",
      "The training loss at 1331th epoch : 0.33992952310447766  Training Accuracy:0.75\n",
      "The training loss at 1332th epoch : 0.3398222775375524  Training Accuracy:0.75\n",
      "The training loss at 1333th epoch : 0.33971503244044493  Training Accuracy:0.75\n",
      "The training loss at 1334th epoch : 0.33960778751316334  Training Accuracy:0.75\n",
      "The training loss at 1335th epoch : 0.3395005424547687  Training Accuracy:0.75\n",
      "The training loss at 1336th epoch : 0.33939329696337295  Training Accuracy:0.75\n",
      "The training loss at 1337th epoch : 0.33928605073613727  Training Accuracy:0.75\n",
      "The training loss at 1338th epoch : 0.33917880346926954  Training Accuracy:0.75\n",
      "The training loss at 1339th epoch : 0.33907155485802265  Training Accuracy:0.75\n",
      "The training loss at 1340th epoch : 0.3389643045966923  Training Accuracy:0.75\n",
      "The training loss at 1341th epoch : 0.3388570523786148  Training Accuracy:0.75\n",
      "The training loss at 1342th epoch : 0.3387497978961651  Training Accuracy:0.75\n",
      "The training loss at 1343th epoch : 0.33864254084075474  Training Accuracy:0.75\n",
      "The training loss at 1344th epoch : 0.33853528090282947  Training Accuracy:0.75\n",
      "The training loss at 1345th epoch : 0.3384280177718674  Training Accuracy:0.75\n",
      "The training loss at 1346th epoch : 0.3383207511363765  Training Accuracy:0.75\n",
      "The training loss at 1347th epoch : 0.33821348068389284  Training Accuracy:0.75\n",
      "The training loss at 1348th epoch : 0.3381062061009781  Training Accuracy:0.75\n",
      "The training loss at 1349th epoch : 0.3379989270732174  Training Accuracy:0.75\n",
      "The training loss at 1350th epoch : 0.33789164328521726  Training Accuracy:0.75\n",
      "The training loss at 1351th epoch : 0.3377843544206032  Training Accuracy:0.75\n",
      "The training loss at 1352th epoch : 0.3376770601620176  Training Accuracy:0.75\n",
      "The training loss at 1353th epoch : 0.33756976019111745  Training Accuracy:0.75\n",
      "The training loss at 1354th epoch : 0.33746245418857196  Training Accuracy:0.75\n",
      "The training loss at 1355th epoch : 0.3373551418340605  Training Accuracy:0.75\n",
      "The training loss at 1356th epoch : 0.3372478228062702  Training Accuracy:0.75\n",
      "The training loss at 1357th epoch : 0.3371404967828935  Training Accuracy:0.75\n",
      "The training loss at 1358th epoch : 0.3370331634406261  Training Accuracy:0.75\n",
      "The training loss at 1359th epoch : 0.3369258224551646  Training Accuracy:0.75\n",
      "The training loss at 1360th epoch : 0.336818473501204  Training Accuracy:0.75\n",
      "The training loss at 1361th epoch : 0.3367111162524353  Training Accuracy:0.75\n",
      "The training loss at 1362th epoch : 0.33660375038154366  Training Accuracy:0.75\n",
      "The training loss at 1363th epoch : 0.3364963755602053  Training Accuracy:0.75\n",
      "The training loss at 1364th epoch : 0.33638899145908563  Training Accuracy:0.75\n",
      "The training loss at 1365th epoch : 0.3362815977478366  Training Accuracy:0.75\n",
      "The training loss at 1366th epoch : 0.3361741940950946  Training Accuracy:0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1367th epoch : 0.33606678016847763  Training Accuracy:0.75\n",
      "The training loss at 1368th epoch : 0.3359593556345831  Training Accuracy:0.75\n",
      "The training loss at 1369th epoch : 0.33585192015898563  Training Accuracy:0.75\n",
      "The training loss at 1370th epoch : 0.335744473406234  Training Accuracy:0.75\n",
      "The training loss at 1371th epoch : 0.3356370150398493  Training Accuracy:0.75\n",
      "The training loss at 1372th epoch : 0.335529544722322  Training Accuracy:0.75\n",
      "The training loss at 1373th epoch : 0.3354220621151099  Training Accuracy:0.75\n",
      "The training loss at 1374th epoch : 0.33531456687863526  Training Accuracy:0.75\n",
      "The training loss at 1375th epoch : 0.3352070586722825  Training Accuracy:0.75\n",
      "The training loss at 1376th epoch : 0.3350995371543957  Training Accuracy:0.75\n",
      "The training loss at 1377th epoch : 0.3349920019822761  Training Accuracy:0.75\n",
      "The training loss at 1378th epoch : 0.3348844528121792  Training Accuracy:0.75\n",
      "The training loss at 1379th epoch : 0.3347768892993129  Training Accuracy:0.75\n",
      "The training loss at 1380th epoch : 0.3346693110978344  Training Accuracy:0.75\n",
      "The training loss at 1381th epoch : 0.3345617178608479  Training Accuracy:0.75\n",
      "The training loss at 1382th epoch : 0.33445410924040186  Training Accuracy:0.75\n",
      "The training loss at 1383th epoch : 0.3343464848874868  Training Accuracy:0.75\n",
      "The training loss at 1384th epoch : 0.33423884445203217  Training Accuracy:0.75\n",
      "The training loss at 1385th epoch : 0.3341311875829043  Training Accuracy:0.75\n",
      "The training loss at 1386th epoch : 0.33402351392790336  Training Accuracy:0.75\n",
      "The training loss at 1387th epoch : 0.3339158231337611  Training Accuracy:0.75\n",
      "The training loss at 1388th epoch : 0.33380811484613804  Training Accuracy:0.75\n",
      "The training loss at 1389th epoch : 0.333700388709621  Training Accuracy:0.75\n",
      "The training loss at 1390th epoch : 0.3335926443677201  Training Accuracy:0.75\n",
      "The training loss at 1391th epoch : 0.3334848814628669  Training Accuracy:0.75\n",
      "The training loss at 1392th epoch : 0.3333770996364108  Training Accuracy:0.75\n",
      "The training loss at 1393th epoch : 0.33326929852861714  Training Accuracy:0.75\n",
      "The training loss at 1394th epoch : 0.3331614777786642  Training Accuracy:0.75\n",
      "The training loss at 1395th epoch : 0.33305363702464047  Training Accuracy:0.75\n",
      "The training loss at 1396th epoch : 0.33294577590354246  Training Accuracy:0.75\n",
      "The training loss at 1397th epoch : 0.3328378940512714  Training Accuracy:0.75\n",
      "The training loss at 1398th epoch : 0.33272999110263096  Training Accuracy:0.75\n",
      "The training loss at 1399th epoch : 0.33262206669132455  Training Accuracy:0.75\n",
      "The training loss at 1400th epoch : 0.33251412044995243  Training Accuracy:0.75\n",
      "The training loss at 1401th epoch : 0.33240615201000917  Training Accuracy:0.75\n",
      "The training loss at 1402th epoch : 0.3322981610018809  Training Accuracy:0.75\n",
      "The training loss at 1403th epoch : 0.3321901470548428  Training Accuracy:0.75\n",
      "The training loss at 1404th epoch : 0.33208210979705594  Training Accuracy:0.75\n",
      "The training loss at 1405th epoch : 0.33197404885556503  Training Accuracy:0.75\n",
      "The training loss at 1406th epoch : 0.3318659638562955  Training Accuracy:0.75\n",
      "The training loss at 1407th epoch : 0.33175785442405087  Training Accuracy:0.75\n",
      "The training loss at 1408th epoch : 0.33164972018250977  Training Accuracy:0.75\n",
      "The training loss at 1409th epoch : 0.3315415607542236  Training Accuracy:0.75\n",
      "The training loss at 1410th epoch : 0.33143337576061355  Training Accuracy:0.75\n",
      "The training loss at 1411th epoch : 0.3313251648219679  Training Accuracy:0.75\n",
      "The training loss at 1412th epoch : 0.3312169275574393  Training Accuracy:0.75\n",
      "The training loss at 1413th epoch : 0.33110866358504215  Training Accuracy:0.75\n",
      "The training loss at 1414th epoch : 0.3310003725216497  Training Accuracy:0.75\n",
      "The training loss at 1415th epoch : 0.3308920539829913  Training Accuracy:0.75\n",
      "The training loss at 1416th epoch : 0.3307837075836499  Training Accuracy:0.75\n",
      "The training loss at 1417th epoch : 0.330675332937059  Training Accuracy:0.75\n",
      "The training loss at 1418th epoch : 0.33056692965550005  Training Accuracy:0.75\n",
      "The training loss at 1419th epoch : 0.3304584973500998  Training Accuracy:0.75\n",
      "The training loss at 1420th epoch : 0.3303500356308273  Training Accuracy:0.75\n",
      "The training loss at 1421th epoch : 0.33024154410649154  Training Accuracy:0.75\n",
      "The training loss at 1422th epoch : 0.33013302238473824  Training Accuracy:0.75\n",
      "The training loss at 1423th epoch : 0.33002447007204744  Training Accuracy:0.75\n",
      "The training loss at 1424th epoch : 0.3299158867737307  Training Accuracy:0.75\n",
      "The training loss at 1425th epoch : 0.32980727209392824  Training Accuracy:0.75\n",
      "The training loss at 1426th epoch : 0.32969862563560626  Training Accuracy:0.75\n",
      "The training loss at 1427th epoch : 0.32958994700055433  Training Accuracy:0.75\n",
      "The training loss at 1428th epoch : 0.32948123578938243  Training Accuracy:0.75\n",
      "The training loss at 1429th epoch : 0.3293724916015184  Training Accuracy:0.75\n",
      "The training loss at 1430th epoch : 0.32926371403520494  Training Accuracy:0.75\n",
      "The training loss at 1431th epoch : 0.3291549026874973  Training Accuracy:0.75\n",
      "The training loss at 1432th epoch : 0.32904605715426016  Training Accuracy:0.75\n",
      "The training loss at 1433th epoch : 0.3289371770301652  Training Accuracy:0.75\n",
      "The training loss at 1434th epoch : 0.32882826190868797  Training Accuracy:0.75\n",
      "The training loss at 1435th epoch : 0.3287193113821058  Training Accuracy:0.75\n",
      "The training loss at 1436th epoch : 0.32861032504149446  Training Accuracy:0.75\n",
      "The training loss at 1437th epoch : 0.3285013024767258  Training Accuracy:0.75\n",
      "The training loss at 1438th epoch : 0.3283922432764651  Training Accuracy:0.75\n",
      "The training loss at 1439th epoch : 0.3282831470281681  Training Accuracy:0.75\n",
      "The training loss at 1440th epoch : 0.32817401331807833  Training Accuracy:0.75\n",
      "The training loss at 1441th epoch : 0.3280648417312249  Training Accuracy:0.75\n",
      "The training loss at 1442th epoch : 0.3279556318514191  Training Accuracy:0.75\n",
      "The training loss at 1443th epoch : 0.3278463832612524  Training Accuracy:0.75\n",
      "The training loss at 1444th epoch : 0.3277370955420933  Training Accuracy:0.75\n",
      "The training loss at 1445th epoch : 0.32762776827408485  Training Accuracy:0.75\n",
      "The training loss at 1446th epoch : 0.3275184010361421  Training Accuracy:0.75\n",
      "The training loss at 1447th epoch : 0.32740899340594926  Training Accuracy:0.75\n",
      "The training loss at 1448th epoch : 0.3272995449599572  Training Accuracy:0.75\n",
      "The training loss at 1449th epoch : 0.3271900552733809  Training Accuracy:0.75\n",
      "The training loss at 1450th epoch : 0.32708052392019654  Training Accuracy:0.75\n",
      "The training loss at 1451th epoch : 0.3269709504731393  Training Accuracy:0.75\n",
      "The training loss at 1452th epoch : 0.3268613345037003  Training Accuracy:0.75\n",
      "The training loss at 1453th epoch : 0.32675167558212453  Training Accuracy:0.75\n",
      "The training loss at 1454th epoch : 0.3266419732774078  Training Accuracy:0.75\n",
      "The training loss at 1455th epoch : 0.32653222715729446  Training Accuracy:0.75\n",
      "The training loss at 1456th epoch : 0.32642243678827493  Training Accuracy:0.75\n",
      "The training loss at 1457th epoch : 0.3263126017355828  Training Accuracy:0.75\n",
      "The training loss at 1458th epoch : 0.32620272156319263  Training Accuracy:0.75\n",
      "The training loss at 1459th epoch : 0.32609279583381734  Training Accuracy:0.75\n",
      "The training loss at 1460th epoch : 0.3259828241089056  Training Accuracy:0.75\n",
      "The training loss at 1461th epoch : 0.3258728059486396  Training Accuracy:0.75\n",
      "The training loss at 1462th epoch : 0.32576274091193236  Training Accuracy:0.75\n",
      "The training loss at 1463th epoch : 0.32565262855642524  Training Accuracy:0.75\n",
      "The training loss at 1464th epoch : 0.32554246843848583  Training Accuracy:0.75\n",
      "The training loss at 1465th epoch : 0.3254322601132051  Training Accuracy:0.75\n",
      "The training loss at 1466th epoch : 0.32532200313439524  Training Accuracy:0.75\n",
      "The training loss at 1467th epoch : 0.3252116970545873  Training Accuracy:0.75\n",
      "The training loss at 1468th epoch : 0.32510134142502867  Training Accuracy:0.75\n",
      "The training loss at 1469th epoch : 0.32499093579568084  Training Accuracy:0.75\n",
      "The training loss at 1470th epoch : 0.32488047971521694  Training Accuracy:0.75\n",
      "The training loss at 1471th epoch : 0.3247699727310196  Training Accuracy:0.75\n",
      "The training loss at 1472th epoch : 0.3246594143891785  Training Accuracy:0.75\n",
      "The training loss at 1473th epoch : 0.3245488042344881  Training Accuracy:0.75\n",
      "The training loss at 1474th epoch : 0.3244381418104455  Training Accuracy:0.75\n",
      "The training loss at 1475th epoch : 0.324327426659248  Training Accuracy:0.75\n",
      "The training loss at 1476th epoch : 0.3242166583217912  Training Accuracy:0.75\n",
      "The training loss at 1477th epoch : 0.3241058363376664  Training Accuracy:0.75\n",
      "The training loss at 1478th epoch : 0.32399496024515867  Training Accuracy:0.75\n",
      "The training loss at 1479th epoch : 0.3238840295812448  Training Accuracy:0.75\n",
      "The training loss at 1480th epoch : 0.32377304388159084  Training Accuracy:0.75\n",
      "The training loss at 1481th epoch : 0.3236620026805504  Training Accuracy:0.75\n",
      "The training loss at 1482th epoch : 0.32355090551116217  Training Accuracy:0.75\n",
      "The training loss at 1483th epoch : 0.3234397519051482  Training Accuracy:0.75\n",
      "The training loss at 1484th epoch : 0.3233285413929115  Training Accuracy:0.75\n",
      "The training loss at 1485th epoch : 0.32321727350353463  Training Accuracy:0.75\n",
      "The training loss at 1486th epoch : 0.32310594776477697  Training Accuracy:0.75\n",
      "The training loss at 1487th epoch : 0.32299456370307345  Training Accuracy:0.75\n",
      "The training loss at 1488th epoch : 0.3228831208435322  Training Accuracy:0.75\n",
      "The training loss at 1489th epoch : 0.32277161870993276  Training Accuracy:0.75\n",
      "The training loss at 1490th epoch : 0.3226600568247244  Training Accuracy:0.75\n",
      "The training loss at 1491th epoch : 0.322548434709024  Training Accuracy:0.75\n",
      "The training loss at 1492th epoch : 0.3224367518826144  Training Accuracy:0.75\n",
      "The training loss at 1493th epoch : 0.3223250078639427  Training Accuracy:0.75\n",
      "The training loss at 1494th epoch : 0.3222132021701184  Training Accuracy:0.75\n",
      "The training loss at 1495th epoch : 0.3221013343169116  Training Accuracy:0.75\n",
      "The training loss at 1496th epoch : 0.3219894038187517  Training Accuracy:0.75\n",
      "The training loss at 1497th epoch : 0.32187741018872523  Training Accuracy:0.75\n",
      "The training loss at 1498th epoch : 0.3217653529385747  Training Accuracy:0.75\n",
      "The training loss at 1499th epoch : 0.3216532315786968  Training Accuracy:0.75\n",
      "The training loss at 1500th epoch : 0.3215410456181409  Training Accuracy:0.75\n",
      "The training loss at 1501th epoch : 0.3214287945646075  Training Accuracy:0.75\n",
      "The training loss at 1502th epoch : 0.3213164779244469  Training Accuracy:0.75\n",
      "The training loss at 1503th epoch : 0.3212040952026577  Training Accuracy:0.75\n",
      "The training loss at 1504th epoch : 0.3210916459028853  Training Accuracy:0.75\n",
      "The training loss at 1505th epoch : 0.3209791295274208  Training Accuracy:0.75\n",
      "The training loss at 1506th epoch : 0.32086654557719946  Training Accuracy:0.75\n",
      "The training loss at 1507th epoch : 0.32075389355179945  Training Accuracy:0.75\n",
      "The training loss at 1508th epoch : 0.3206411729494408  Training Accuracy:0.75\n",
      "The training loss at 1509th epoch : 0.320528383266984  Training Accuracy:0.75\n",
      "The training loss at 1510th epoch : 0.32041552399992906  Training Accuracy:0.75\n",
      "The training loss at 1511th epoch : 0.3203025946424143  Training Accuracy:0.75\n",
      "The training loss at 1512th epoch : 0.3201895946872151  Training Accuracy:0.75\n",
      "The training loss at 1513th epoch : 0.32007652362574324  Training Accuracy:0.75\n",
      "The training loss at 1514th epoch : 0.31996338094804583  Training Accuracy:0.75\n",
      "The training loss at 1515th epoch : 0.31985016614280415  Training Accuracy:0.75\n",
      "The training loss at 1516th epoch : 0.3197368786973332  Training Accuracy:0.75\n",
      "The training loss at 1517th epoch : 0.31962351809758033  Training Accuracy:0.75\n",
      "The training loss at 1518th epoch : 0.31951008382812496  Training Accuracy:0.75\n",
      "The training loss at 1519th epoch : 0.31939657537217775  Training Accuracy:0.75\n",
      "The training loss at 1520th epoch : 0.3192829922115795  Training Accuracy:0.75\n",
      "The training loss at 1521th epoch : 0.3191693338268013  Training Accuracy:0.75\n",
      "The training loss at 1522th epoch : 0.3190555996969431  Training Accuracy:0.75\n",
      "The training loss at 1523th epoch : 0.31894178929973377  Training Accuracy:0.75\n",
      "The training loss at 1524th epoch : 0.3188279021115305  Training Accuracy:0.75\n",
      "The training loss at 1525th epoch : 0.3187139376073183  Training Accuracy:0.75\n",
      "The training loss at 1526th epoch : 0.31859989526070975  Training Accuracy:0.75\n",
      "The training loss at 1527th epoch : 0.3184857745439445  Training Accuracy:0.75\n",
      "The training loss at 1528th epoch : 0.31837157492788937  Training Accuracy:0.75\n",
      "The training loss at 1529th epoch : 0.31825729588203766  Training Accuracy:0.75\n",
      "The training loss at 1530th epoch : 0.3181429368745097  Training Accuracy:0.75\n",
      "The training loss at 1531th epoch : 0.318028497372052  Training Accuracy:0.75\n",
      "The training loss at 1532th epoch : 0.31791397684003797  Training Accuracy:0.75\n",
      "The training loss at 1533th epoch : 0.3177993747424675  Training Accuracy:0.75\n",
      "The training loss at 1534th epoch : 0.31768469054196724  Training Accuracy:0.75\n",
      "The training loss at 1535th epoch : 0.3175699236997908  Training Accuracy:0.75\n",
      "The training loss at 1536th epoch : 0.3174550736758189  Training Accuracy:0.75\n",
      "The training loss at 1537th epoch : 0.31734013992855975  Training Accuracy:0.75\n",
      "The training loss at 1538th epoch : 0.3172251219151495  Training Accuracy:0.75\n",
      "The training loss at 1539th epoch : 0.3171100190913525  Training Accuracy:0.75\n",
      "The training loss at 1540th epoch : 0.316994830911562  Training Accuracy:0.75\n",
      "The training loss at 1541th epoch : 0.3168795568288006  Training Accuracy:0.75\n",
      "The training loss at 1542th epoch : 0.31676419629472086  Training Accuracy:0.75\n",
      "The training loss at 1543th epoch : 0.31664874875960625  Training Accuracy:0.75\n",
      "The training loss at 1544th epoch : 0.31653321367237175  Training Accuracy:0.75\n",
      "The training loss at 1545th epoch : 0.3164175904805647  Training Accuracy:0.75\n",
      "The training loss at 1546th epoch : 0.31630187863036596  Training Accuracy:0.75\n",
      "The training loss at 1547th epoch : 0.3161860775665906  Training Accuracy:0.75\n",
      "The training loss at 1548th epoch : 0.31607018673268933  Training Accuracy:0.75\n",
      "The training loss at 1549th epoch : 0.3159542055707494  Training Accuracy:0.75\n",
      "The training loss at 1550th epoch : 0.31583813352149603  Training Accuracy:0.75\n",
      "The training loss at 1551th epoch : 0.31572197002429364  Training Accuracy:0.75\n",
      "The training loss at 1552th epoch : 0.31560571451714725  Training Accuracy:0.75\n",
      "The training loss at 1553th epoch : 0.3154893664367041  Training Accuracy:0.75\n",
      "The training loss at 1554th epoch : 0.31537292521825516  Training Accuracy:0.75\n",
      "The training loss at 1555th epoch : 0.3152563902957366  Training Accuracy:0.75\n",
      "The training loss at 1556th epoch : 0.31513976110173186  Training Accuracy:0.75\n",
      "The training loss at 1557th epoch : 0.3150230370674732  Training Accuracy:0.75\n",
      "The training loss at 1558th epoch : 0.3149062176228438  Training Accuracy:0.75\n",
      "The training loss at 1559th epoch : 0.3147893021963797  Training Accuracy:0.75\n",
      "The training loss at 1560th epoch : 0.3146722902152718  Training Accuracy:0.75\n",
      "The training loss at 1561th epoch : 0.3145551811053683  Training Accuracy:0.75\n",
      "The training loss at 1562th epoch : 0.31443797429117665  Training Accuracy:0.75\n",
      "The training loss at 1563th epoch : 0.3143206691958661  Training Accuracy:0.75\n",
      "The training loss at 1564th epoch : 0.31420326524127024  Training Accuracy:0.75\n",
      "The training loss at 1565th epoch : 0.31408576184788933  Training Accuracy:0.75\n",
      "The training loss at 1566th epoch : 0.31396815843489323  Training Accuracy:0.75\n",
      "The training loss at 1567th epoch : 0.3138504544201239  Training Accuracy:0.75\n",
      "The training loss at 1568th epoch : 0.3137326492200984  Training Accuracy:0.75\n",
      "The training loss at 1569th epoch : 0.3136147422500118  Training Accuracy:0.75\n",
      "The training loss at 1570th epoch : 0.31349673292374014  Training Accuracy:0.75\n",
      "The training loss at 1571th epoch : 0.3133786206538439  Training Accuracy:0.75\n",
      "The training loss at 1572th epoch : 0.3132604048515709  Training Accuracy:0.75\n",
      "The training loss at 1573th epoch : 0.3131420849268598  Training Accuracy:0.75\n",
      "The training loss at 1574th epoch : 0.31302366028834355  Training Accuracy:0.75\n",
      "The training loss at 1575th epoch : 0.31290513034335316  Training Accuracy:0.75\n",
      "The training loss at 1576th epoch : 0.312786494497921  Training Accuracy:0.75\n",
      "The training loss at 1577th epoch : 0.312667752156785  Training Accuracy:0.75\n",
      "The training loss at 1578th epoch : 0.3125489027233923  Training Accuracy:0.75\n",
      "The training loss at 1579th epoch : 0.31242994559990345  Training Accuracy:0.75\n",
      "The training loss at 1580th epoch : 0.3123108801871964  Training Accuracy:0.75\n",
      "The training loss at 1581th epoch : 0.31219170588487066  Training Accuracy:0.75\n",
      "The training loss at 1582th epoch : 0.3120724220912521  Training Accuracy:0.75\n",
      "The training loss at 1583th epoch : 0.311953028203397  Training Accuracy:0.75\n",
      "The training loss at 1584th epoch : 0.31183352361709676  Training Accuracy:0.75\n",
      "The training loss at 1585th epoch : 0.3117139077268828  Training Accuracy:0.75\n",
      "The training loss at 1586th epoch : 0.3115941799260312  Training Accuracy:0.75\n",
      "The training loss at 1587th epoch : 0.31147433960656795  Training Accuracy:0.75\n",
      "The training loss at 1588th epoch : 0.3113543861592736  Training Accuracy:0.75\n",
      "The training loss at 1589th epoch : 0.31123431897368886  Training Accuracy:0.75\n",
      "The training loss at 1590th epoch : 0.31111413743812  Training Accuracy:0.75\n",
      "The training loss at 1591th epoch : 0.31099384093964394  Training Accuracy:0.75\n",
      "The training loss at 1592th epoch : 0.3108734288641143  Training Accuracy:0.75\n",
      "The training loss at 1593th epoch : 0.3107529005961667  Training Accuracy:0.75\n",
      "The training loss at 1594th epoch : 0.3106322555192253  Training Accuracy:0.75\n",
      "The training loss at 1595th epoch : 0.31051149301550796  Training Accuracy:0.75\n",
      "The training loss at 1596th epoch : 0.3103906124660331  Training Accuracy:0.75\n",
      "The training loss at 1597th epoch : 0.3102696132506257  Training Accuracy:0.75\n",
      "The training loss at 1598th epoch : 0.3101484947479236  Training Accuracy:0.75\n",
      "The training loss at 1599th epoch : 0.3100272563353844  Training Accuracy:0.75\n",
      "The training loss at 1600th epoch : 0.30990589738929186  Training Accuracy:0.75\n",
      "The training loss at 1601th epoch : 0.309784417284763  Training Accuracy:0.75\n",
      "The training loss at 1602th epoch : 0.30966281539575496  Training Accuracy:0.75\n",
      "The training loss at 1603th epoch : 0.30954109109507205  Training Accuracy:0.75\n",
      "The training loss at 1604th epoch : 0.3094192437543733  Training Accuracy:0.75\n",
      "The training loss at 1605th epoch : 0.3092972727441797  Training Accuracy:0.75\n",
      "The training loss at 1606th epoch : 0.30917517743388195  Training Accuracy:0.75\n",
      "The training loss at 1607th epoch : 0.3090529571917481  Training Accuracy:0.75\n",
      "The training loss at 1608th epoch : 0.30893061138493144  Training Accuracy:0.75\n",
      "The training loss at 1609th epoch : 0.30880813937947865  Training Accuracy:0.75\n",
      "The training loss at 1610th epoch : 0.30868554054033787  Training Accuracy:0.75\n",
      "The training loss at 1611th epoch : 0.3085628142313674  Training Accuracy:0.75\n",
      "The training loss at 1612th epoch : 0.3084399598153437  Training Accuracy:0.75\n",
      "The training loss at 1613th epoch : 0.30831697665397073  Training Accuracy:0.75\n",
      "The training loss at 1614th epoch : 0.30819386410788824  Training Accuracy:0.75\n",
      "The training loss at 1615th epoch : 0.30807062153668113  Training Accuracy:0.75\n",
      "The training loss at 1616th epoch : 0.3079472482988886  Training Accuracy:0.75\n",
      "The training loss at 1617th epoch : 0.30782374375201327  Training Accuracy:0.75\n",
      "The training loss at 1618th epoch : 0.3077001072525312  Training Accuracy:0.75\n",
      "The training loss at 1619th epoch : 0.3075763381559012  Training Accuracy:0.75\n",
      "The training loss at 1620th epoch : 0.3074524358165746  Training Accuracy:0.75\n",
      "The training loss at 1621th epoch : 0.30732839958800584  Training Accuracy:0.75\n",
      "The training loss at 1622th epoch : 0.30720422882266213  Training Accuracy:0.75\n",
      "The training loss at 1623th epoch : 0.3070799228720343  Training Accuracy:0.75\n",
      "The training loss at 1624th epoch : 0.306955481086647  Training Accuracy:0.75\n",
      "The training loss at 1625th epoch : 0.30683090281606973  Training Accuracy:0.75\n",
      "The training loss at 1626th epoch : 0.30670618740892786  Training Accuracy:0.75\n",
      "The training loss at 1627th epoch : 0.30658133421291334  Training Accuracy:0.75\n",
      "The training loss at 1628th epoch : 0.3064563425747965  Training Accuracy:0.75\n",
      "The training loss at 1629th epoch : 0.3063312118404373  Training Accuracy:0.75\n",
      "The training loss at 1630th epoch : 0.3062059413547972  Training Accuracy:0.75\n",
      "The training loss at 1631th epoch : 0.3060805304619507  Training Accuracy:0.75\n",
      "The training loss at 1632th epoch : 0.30595497850509795  Training Accuracy:0.75\n",
      "The training loss at 1633th epoch : 0.30582928482657645  Training Accuracy:0.75\n",
      "The training loss at 1634th epoch : 0.30570344876787403  Training Accuracy:0.75\n",
      "The training loss at 1635th epoch : 0.3055774696696412  Training Accuracy:0.75\n",
      "The training loss at 1636th epoch : 0.3054513468717042  Training Accuracy:0.75\n",
      "The training loss at 1637th epoch : 0.3053250797130779  Training Accuracy:0.75\n",
      "The training loss at 1638th epoch : 0.3051986675319791  Training Accuracy:0.75\n",
      "The training loss at 1639th epoch : 0.30507210966584025  Training Accuracy:0.75\n",
      "The training loss at 1640th epoch : 0.30494540545132287  Training Accuracy:0.75\n",
      "The training loss at 1641th epoch : 0.30481855422433146  Training Accuracy:0.75\n",
      "The training loss at 1642th epoch : 0.3046915553200278  Training Accuracy:0.75\n",
      "The training loss at 1643th epoch : 0.3045644080728449  Training Accuracy:0.75\n",
      "The training loss at 1644th epoch : 0.30443711181650196  Training Accuracy:0.75\n",
      "The training loss at 1645th epoch : 0.30430966588401875  Training Accuracy:0.75\n",
      "The training loss at 1646th epoch : 0.3041820696077308  Training Accuracy:0.75\n",
      "The training loss at 1647th epoch : 0.30405432231930435  Training Accuracy:0.75\n",
      "The training loss at 1648th epoch : 0.30392642334975195  Training Accuracy:0.75\n",
      "The training loss at 1649th epoch : 0.303798372029448  Training Accuracy:0.75\n",
      "The training loss at 1650th epoch : 0.3036701676881443  Training Accuracy:0.75\n",
      "The training loss at 1651th epoch : 0.3035418096549868  Training Accuracy:0.75\n",
      "The training loss at 1652th epoch : 0.303413297258531  Training Accuracy:0.75\n",
      "The training loss at 1653th epoch : 0.30328462982675913  Training Accuracy:0.75\n",
      "The training loss at 1654th epoch : 0.3031558066870967  Training Accuracy:0.75\n",
      "The training loss at 1655th epoch : 0.30302682716642915  Training Accuracy:0.75\n",
      "The training loss at 1656th epoch : 0.3028976905911196  Training Accuracy:0.75\n",
      "The training loss at 1657th epoch : 0.30276839628702584  Training Accuracy:0.75\n",
      "The training loss at 1658th epoch : 0.30263894357951815  Training Accuracy:0.75\n",
      "The training loss at 1659th epoch : 0.30250933179349726  Training Accuracy:0.75\n",
      "The training loss at 1660th epoch : 0.3023795602534124  Training Accuracy:0.75\n",
      "The training loss at 1661th epoch : 0.30224962828327967  Training Accuracy:0.75\n",
      "The training loss at 1662th epoch : 0.3021195352067007  Training Accuracy:0.75\n",
      "The training loss at 1663th epoch : 0.3019892803468817  Training Accuracy:0.75\n",
      "The training loss at 1664th epoch : 0.3018588630266521  Training Accuracy:0.75\n",
      "The training loss at 1665th epoch : 0.3017282825684844  Training Accuracy:0.75\n",
      "The training loss at 1666th epoch : 0.30159753829451347  Training Accuracy:0.75\n",
      "The training loss at 1667th epoch : 0.30146662952655645  Training Accuracy:0.75\n",
      "The training loss at 1668th epoch : 0.30133555558613306  Training Accuracy:0.75\n",
      "The training loss at 1669th epoch : 0.30120431579448553  Training Accuracy:0.75\n",
      "The training loss at 1670th epoch : 0.3010729094725997  Training Accuracy:0.75\n",
      "The training loss at 1671th epoch : 0.3009413359412255  Training Accuracy:0.75\n",
      "The training loss at 1672th epoch : 0.3008095945208982  Training Accuracy:0.75\n",
      "The training loss at 1673th epoch : 0.30067768453196  Training Accuracy:0.75\n",
      "The training loss at 1674th epoch : 0.300545605294581  Training Accuracy:0.75\n",
      "The training loss at 1675th epoch : 0.3004133561287821  Training Accuracy:0.75\n",
      "The training loss at 1676th epoch : 0.30028093635445624  Training Accuracy:0.75\n",
      "The training loss at 1677th epoch : 0.3001483452913913  Training Accuracy:0.75\n",
      "The training loss at 1678th epoch : 0.3000155822592926  Training Accuracy:0.75\n",
      "The training loss at 1679th epoch : 0.299882646577806  Training Accuracy:0.75\n",
      "The training loss at 1680th epoch : 0.29974953756654105  Training Accuracy:0.75\n",
      "The training loss at 1681th epoch : 0.29961625454509433  Training Accuracy:0.75\n",
      "The training loss at 1682th epoch : 0.29948279683307344  Training Accuracy:0.75\n",
      "The training loss at 1683th epoch : 0.29934916375012094  Training Accuracy:0.75\n",
      "The training loss at 1684th epoch : 0.2992153546159385  Training Accuracy:0.75\n",
      "The training loss at 1685th epoch : 0.29908136875031177  Training Accuracy:0.75\n",
      "The training loss at 1686th epoch : 0.2989472054731349  Training Accuracy:0.75\n",
      "The training loss at 1687th epoch : 0.29881286410443597  Training Accuracy:0.75\n",
      "The training loss at 1688th epoch : 0.29867834396440207  Training Accuracy:0.75\n",
      "The training loss at 1689th epoch : 0.29854364437340525  Training Accuracy:0.75\n",
      "The training loss at 1690th epoch : 0.29840876465202837  Training Accuracy:0.75\n",
      "The training loss at 1691th epoch : 0.29827370412109133  Training Accuracy:0.75\n",
      "The training loss at 1692th epoch : 0.2981384621016776  Training Accuracy:0.75\n",
      "The training loss at 1693th epoch : 0.29800303791516103  Training Accuracy:0.75\n",
      "The training loss at 1694th epoch : 0.29786743088323286  Training Accuracy:0.75\n",
      "The training loss at 1695th epoch : 0.2977316403279293  Training Accuracy:0.75\n",
      "The training loss at 1696th epoch : 0.2975956655716589  Training Accuracy:0.75\n",
      "The training loss at 1697th epoch : 0.2974595059372307  Training Accuracy:0.75\n",
      "The training loss at 1698th epoch : 0.29732316074788234  Training Accuracy:0.75\n",
      "The training loss at 1699th epoch : 0.29718662932730866  Training Accuracy:0.75\n",
      "The training loss at 1700th epoch : 0.2970499109996904  Training Accuracy:0.75\n",
      "The training loss at 1701th epoch : 0.2969130050897235  Training Accuracy:0.75\n",
      "The training loss at 1702th epoch : 0.2967759109226483  Training Accuracy:0.75\n",
      "The training loss at 1703th epoch : 0.29663862782427913  Training Accuracy:0.75\n",
      "The training loss at 1704th epoch : 0.2965011551210346  Training Accuracy:0.75\n",
      "The training loss at 1705th epoch : 0.2963634921399675  Training Accuracy:0.75\n",
      "The training loss at 1706th epoch : 0.2962256382087956  Training Accuracy:0.75\n",
      "The training loss at 1707th epoch : 0.2960875926559325  Training Accuracy:0.75\n",
      "The training loss at 1708th epoch : 0.29594935481051854  Training Accuracy:0.75\n",
      "The training loss at 1709th epoch : 0.29581092400245246  Training Accuracy:0.75\n",
      "The training loss at 1710th epoch : 0.2956722995624231  Training Accuracy:0.75\n",
      "The training loss at 1711th epoch : 0.2955334808219413  Training Accuracy:0.75\n",
      "The training loss at 1712th epoch : 0.29539446711337236  Training Accuracy:0.75\n",
      "The training loss at 1713th epoch : 0.2952552577699685  Training Accuracy:0.75\n",
      "The training loss at 1714th epoch : 0.29511585212590213  Training Accuracy:0.75\n",
      "The training loss at 1715th epoch : 0.2949762495162984  Training Accuracy:0.75\n",
      "The training loss at 1716th epoch : 0.29483644927726954  Training Accuracy:0.75\n",
      "The training loss at 1717th epoch : 0.29469645074594797  Training Accuracy:0.75\n",
      "The training loss at 1718th epoch : 0.29455625326052076  Training Accuracy:0.75\n",
      "The training loss at 1719th epoch : 0.294415856160264  Training Accuracy:0.75\n",
      "The training loss at 1720th epoch : 0.29427525878557725  Training Accuracy:0.75\n",
      "The training loss at 1721th epoch : 0.294134460478019  Training Accuracy:0.75\n",
      "The training loss at 1722th epoch : 0.2939934605803415  Training Accuracy:0.75\n",
      "The training loss at 1723th epoch : 0.29385225843652657  Training Accuracy:0.75\n",
      "The training loss at 1724th epoch : 0.29371085339182157  Training Accuracy:0.75\n",
      "The training loss at 1725th epoch : 0.29356924479277524  Training Accuracy:0.75\n",
      "The training loss at 1726th epoch : 0.2934274319872746  Training Accuracy:0.75\n",
      "The training loss at 1727th epoch : 0.29328541432458155  Training Accuracy:0.75\n",
      "The training loss at 1728th epoch : 0.2931431911553698  Training Accuracy:0.75\n",
      "The training loss at 1729th epoch : 0.2930007618317624  Training Accuracy:0.75\n",
      "The training loss at 1730th epoch : 0.2928581257073693  Training Accuracy:0.75\n",
      "The training loss at 1731th epoch : 0.29271528213732556  Training Accuracy:0.75\n",
      "The training loss at 1732th epoch : 0.29257223047832925  Training Accuracy:0.75\n",
      "The training loss at 1733th epoch : 0.2924289700886801  Training Accuracy:0.75\n",
      "The training loss at 1734th epoch : 0.2922855003283185  Training Accuracy:0.75\n",
      "The training loss at 1735th epoch : 0.2921418205588645  Training Accuracy:0.75\n",
      "The training loss at 1736th epoch : 0.29199793014365705  Training Accuracy:0.75\n",
      "The training loss at 1737th epoch : 0.2918538284477941  Training Accuracy:0.75\n",
      "The training loss at 1738th epoch : 0.29170951483817226  Training Accuracy:0.75\n",
      "The training loss at 1739th epoch : 0.29156498868352715  Training Accuracy:0.75\n",
      "The training loss at 1740th epoch : 0.2914202493544741  Training Accuracy:0.75\n",
      "The training loss at 1741th epoch : 0.29127529622354875  Training Accuracy:0.75\n",
      "The training loss at 1742th epoch : 0.29113012866524857  Training Accuracy:0.75\n",
      "The training loss at 1743th epoch : 0.2909847460560738  Training Accuracy:0.75\n",
      "The training loss at 1744th epoch : 0.29083914777456954  Training Accuracy:0.75\n",
      "The training loss at 1745th epoch : 0.2906933332013675  Training Accuracy:0.75\n",
      "The training loss at 1746th epoch : 0.2905473017192284  Training Accuracy:0.75\n",
      "The training loss at 1747th epoch : 0.29040105271308425  Training Accuracy:0.75\n",
      "The training loss at 1748th epoch : 0.29025458557008155  Training Accuracy:0.75\n",
      "The training loss at 1749th epoch : 0.29010789967962397  Training Accuracy:0.75\n",
      "The training loss at 1750th epoch : 0.28996099443341594  Training Accuracy:0.75\n",
      "The training loss at 1751th epoch : 0.2898138692255061  Training Accuracy:0.75\n",
      "The training loss at 1752th epoch : 0.2896665234523315  Training Accuracy:0.75\n",
      "The training loss at 1753th epoch : 0.28951895651276127  Training Accuracy:0.75\n",
      "The training loss at 1754th epoch : 0.2893711678081413  Training Accuracy:0.75\n",
      "The training loss at 1755th epoch : 0.289223156742339  Training Accuracy:0.75\n",
      "The training loss at 1756th epoch : 0.2890749227217881  Training Accuracy:0.75\n",
      "The training loss at 1757th epoch : 0.2889264651555336  Training Accuracy:0.75\n",
      "The training loss at 1758th epoch : 0.2887777834552778  Training Accuracy:0.75\n",
      "The training loss at 1759th epoch : 0.28862887703542534  Training Accuracy:0.75\n",
      "The training loss at 1760th epoch : 0.28847974531312953  Training Accuracy:0.75\n",
      "The training loss at 1761th epoch : 0.28833038770833835  Training Accuracy:0.75\n",
      "The training loss at 1762th epoch : 0.28818080364384097  Training Accuracy:0.75\n",
      "The training loss at 1763th epoch : 0.28803099254531433  Training Accuracy:0.75\n",
      "The training loss at 1764th epoch : 0.28788095384137  Training Accuracy:0.75\n",
      "The training loss at 1765th epoch : 0.28773068696360143  Training Accuracy:0.75\n",
      "The training loss at 1766th epoch : 0.28758019134663126  Training Accuracy:0.75\n",
      "The training loss at 1767th epoch : 0.2874294664281587  Training Accuracy:0.75\n",
      "The training loss at 1768th epoch : 0.2872785116490077  Training Accuracy:0.75\n",
      "The training loss at 1769th epoch : 0.28712732645317457  Training Accuracy:0.75\n",
      "The training loss at 1770th epoch : 0.2869759102878765  Training Accuracy:0.75\n",
      "The training loss at 1771th epoch : 0.2868242626036  Training Accuracy:0.75\n",
      "The training loss at 1772th epoch : 0.28667238285414925  Training Accuracy:0.75\n",
      "The training loss at 1773th epoch : 0.2865202704966954  Training Accuracy:0.75\n",
      "The training loss at 1774th epoch : 0.2863679249918252  Training Accuracy:0.75\n",
      "The training loss at 1775th epoch : 0.28621534580359054  Training Accuracy:0.75\n",
      "The training loss at 1776th epoch : 0.28606253239955787  Training Accuracy:0.75\n",
      "The training loss at 1777th epoch : 0.2859094842508576  Training Accuracy:0.75\n",
      "The training loss at 1778th epoch : 0.28575620083223424  Training Accuracy:0.75\n",
      "The training loss at 1779th epoch : 0.2856026816220962  Training Accuracy:0.75\n",
      "The training loss at 1780th epoch : 0.2854489261025658  Training Accuracy:0.75\n",
      "The training loss at 1781th epoch : 0.2852949337595301  Training Accuracy:0.75\n",
      "The training loss at 1782th epoch : 0.2851407040826908  Training Accuracy:0.75\n",
      "The training loss at 1783th epoch : 0.28498623656561545  Training Accuracy:0.75\n",
      "The training loss at 1784th epoch : 0.2848315307057878  Training Accuracy:0.75\n",
      "The training loss at 1785th epoch : 0.2846765860046591  Training Accuracy:0.75\n",
      "The training loss at 1786th epoch : 0.28452140196769904  Training Accuracy:0.75\n",
      "The training loss at 1787th epoch : 0.28436597810444697  Training Accuracy:0.75\n",
      "The training loss at 1788th epoch : 0.2842103139285634  Training Accuracy:0.75\n",
      "The training loss at 1789th epoch : 0.2840544089578814  Training Accuracy:0.75\n",
      "The training loss at 1790th epoch : 0.2838982627144584  Training Accuracy:0.75\n",
      "The training loss at 1791th epoch : 0.2837418747246276  Training Accuracy:0.75\n",
      "The training loss at 1792th epoch : 0.2835852445190502  Training Accuracy:0.75\n",
      "The training loss at 1793th epoch : 0.2834283716327672  Training Accuracy:0.75\n",
      "The training loss at 1794th epoch : 0.2832712556052513  Training Accuracy:0.75\n",
      "The training loss at 1795th epoch : 0.28311389598045933  Training Accuracy:0.75\n",
      "The training loss at 1796th epoch : 0.28295629230688446  Training Accuracy:0.75\n",
      "The training loss at 1797th epoch : 0.2827984441376082  Training Accuracy:0.75\n",
      "The training loss at 1798th epoch : 0.2826403510303531  Training Accuracy:0.75\n",
      "The training loss at 1799th epoch : 0.28248201254753524  Training Accuracy:0.75\n",
      "The training loss at 1800th epoch : 0.2823234282563165  Training Accuracy:0.75\n",
      "The training loss at 1801th epoch : 0.2821645977286574  Training Accuracy:0.75\n",
      "The training loss at 1802th epoch : 0.2820055205413693  Training Accuracy:0.75\n",
      "The training loss at 1803th epoch : 0.2818461962761677  Training Accuracy:0.75\n",
      "The training loss at 1804th epoch : 0.28168662451972426  Training Accuracy:0.75\n",
      "The training loss at 1805th epoch : 0.28152680486372006  Training Accuracy:0.75\n",
      "The training loss at 1806th epoch : 0.281366736904898  Training Accuracy:0.75\n",
      "The training loss at 1807th epoch : 0.2812064202451156  Training Accuracy:0.75\n",
      "The training loss at 1808th epoch : 0.28104585449139785  Training Accuracy:0.75\n",
      "The training loss at 1809th epoch : 0.28088503925598984  Training Accuracy:0.75\n",
      "The training loss at 1810th epoch : 0.28072397415640965  Training Accuracy:0.75\n",
      "The training loss at 1811th epoch : 0.2805626588155008  Training Accuracy:0.75\n",
      "The training loss at 1812th epoch : 0.2804010928614851  Training Accuracy:0.75\n",
      "The training loss at 1813th epoch : 0.2802392759280155  Training Accuracy:0.75\n",
      "The training loss at 1814th epoch : 0.28007720765422817  Training Accuracy:0.75\n",
      "The training loss at 1815th epoch : 0.27991488768479544  Training Accuracy:0.75\n",
      "The training loss at 1816th epoch : 0.2797523156699783  Training Accuracy:0.75\n",
      "The training loss at 1817th epoch : 0.27958949126567856  Training Accuracy:0.75\n",
      "The training loss at 1818th epoch : 0.27942641413349145  Training Accuracy:0.75\n",
      "The training loss at 1819th epoch : 0.27926308394075766  Training Accuracy:0.75\n",
      "The training loss at 1820th epoch : 0.27909950036061565  Training Accuracy:0.75\n",
      "The training loss at 1821th epoch : 0.2789356630720537  Training Accuracy:0.75\n",
      "The training loss at 1822th epoch : 0.27877157175996176  Training Accuracy:0.75\n",
      "The training loss at 1823th epoch : 0.27860722611518335  Training Accuracy:0.75\n",
      "The training loss at 1824th epoch : 0.27844262583456714  Training Accuracy:0.75\n",
      "The training loss at 1825th epoch : 0.2782777706210186  Training Accuracy:0.75\n",
      "The training loss at 1826th epoch : 0.27811266018355146  Training Accuracy:0.75\n",
      "The training loss at 1827th epoch : 0.27794729423733877  Training Accuracy:0.75\n",
      "The training loss at 1828th epoch : 0.2777816725037641  Training Accuracy:0.75\n",
      "The training loss at 1829th epoch : 0.2776157947104725  Training Accuracy:0.75\n",
      "The training loss at 1830th epoch : 0.27744966059142084  Training Accuracy:0.75\n",
      "The training loss at 1831th epoch : 0.2772832698869289  Training Accuracy:0.75\n",
      "The training loss at 1832th epoch : 0.27711662234372925  Training Accuracy:0.75\n",
      "The training loss at 1833th epoch : 0.2769497177150174  Training Accuracy:0.75\n",
      "The training loss at 1834th epoch : 0.27678255576050176  Training Accuracy:0.75\n",
      "The training loss at 1835th epoch : 0.27661513624645323  Training Accuracy:0.75\n",
      "The training loss at 1836th epoch : 0.27644745894575457  Training Accuracy:0.75\n",
      "The training loss at 1837th epoch : 0.27627952363794955  Training Accuracy:0.75\n",
      "The training loss at 1838th epoch : 0.27611133010929173  Training Accuracy:0.75\n",
      "The training loss at 1839th epoch : 0.27594287815279317  Training Accuracy:0.75\n",
      "The training loss at 1840th epoch : 0.27577416756827255  Training Accuracy:0.75\n",
      "The training loss at 1841th epoch : 0.27560519816240336  Training Accuracy:0.75\n",
      "The training loss at 1842th epoch : 0.2754359697487614  Training Accuracy:0.75\n",
      "The training loss at 1843th epoch : 0.2752664821478722  Training Accuracy:0.75\n",
      "The training loss at 1844th epoch : 0.27509673518725825  Training Accuracy:0.75\n",
      "The training loss at 1845th epoch : 0.27492672870148543  Training Accuracy:0.75\n",
      "The training loss at 1846th epoch : 0.2747564625322095  Training Accuracy:0.75\n",
      "The training loss at 1847th epoch : 0.274585936528222  Training Accuracy:0.75\n",
      "The training loss at 1848th epoch : 0.274415150545496  Training Accuracy:0.75\n",
      "The training loss at 1849th epoch : 0.27424410444723124  Training Accuracy:0.75\n",
      "The training loss at 1850th epoch : 0.27407279810389906  Training Accuracy:0.75\n",
      "The training loss at 1851th epoch : 0.2739012313932866  Training Accuracy:0.75\n",
      "The training loss at 1852th epoch : 0.27372940420054115  Training Accuracy:0.75\n",
      "The training loss at 1853th epoch : 0.2735573164182135  Training Accuracy:0.75\n",
      "The training loss at 1854th epoch : 0.2733849679463013  Training Accuracy:0.75\n",
      "The training loss at 1855th epoch : 0.2732123586922915  Training Accuracy:0.75\n",
      "The training loss at 1856th epoch : 0.27303948857120286  Training Accuracy:0.75\n",
      "The training loss at 1857th epoch : 0.2728663575056277  Training Accuracy:0.75\n",
      "The training loss at 1858th epoch : 0.272692965425773  Training Accuracy:0.75\n",
      "The training loss at 1859th epoch : 0.2725193122695014  Training Accuracy:0.75\n",
      "The training loss at 1860th epoch : 0.2723453979823715  Training Accuracy:0.75\n",
      "The training loss at 1861th epoch : 0.2721712225176776  Training Accuracy:0.75\n",
      "The training loss at 1862th epoch : 0.27199678583648906  Training Accuracy:0.75\n",
      "The training loss at 1863th epoch : 0.27182208790768875  Training Accuracy:0.75\n",
      "The training loss at 1864th epoch : 0.27164712870801166  Training Accuracy:0.75\n",
      "The training loss at 1865th epoch : 0.2714719082220823  Training Accuracy:0.75\n",
      "The training loss at 1866th epoch : 0.2712964264424516  Training Accuracy:0.75\n",
      "The training loss at 1867th epoch : 0.2711206833696338  Training Accuracy:0.75\n",
      "The training loss at 1868th epoch : 0.270944679012142  Training Accuracy:0.75\n",
      "The training loss at 1869th epoch : 0.2707684133865235  Training Accuracy:0.75\n",
      "The training loss at 1870th epoch : 0.27059188651739474  Training Accuracy:0.75\n",
      "The training loss at 1871th epoch : 0.270415098437475  Training Accuracy:0.75\n",
      "The training loss at 1872th epoch : 0.27023804918762007  Training Accuracy:0.75\n",
      "The training loss at 1873th epoch : 0.27006073881685483  Training Accuracy:0.75\n",
      "The training loss at 1874th epoch : 0.2698831673824055  Training Accuracy:0.75\n",
      "The training loss at 1875th epoch : 0.2697053349497311  Training Accuracy:0.75\n",
      "The training loss at 1876th epoch : 0.2695272415925542  Training Accuracy:0.75\n",
      "The training loss at 1877th epoch : 0.26934888739289103  Training Accuracy:0.75\n",
      "The training loss at 1878th epoch : 0.2691702724410807  Training Accuracy:0.75\n",
      "The training loss at 1879th epoch : 0.2689913968358142  Training Accuracy:0.75\n",
      "The training loss at 1880th epoch : 0.2688122606841621  Training Accuracy:0.75\n",
      "The training loss at 1881th epoch : 0.26863286410160175  Training Accuracy:0.75\n",
      "The training loss at 1882th epoch : 0.2684532072120442  Training Accuracy:0.75\n",
      "The training loss at 1883th epoch : 0.2682732901478594  Training Accuracy:0.75\n",
      "The training loss at 1884th epoch : 0.2680931130499015  Training Accuracy:0.75\n",
      "The training loss at 1885th epoch : 0.267912676067533  Training Accuracy:0.75\n",
      "The training loss at 1886th epoch : 0.2677319793586482  Training Accuracy:0.75\n",
      "The training loss at 1887th epoch : 0.26755102308969575  Training Accuracy:1.0\n",
      "The training loss at 1888th epoch : 0.26736980743570077  Training Accuracy:1.0\n",
      "The training loss at 1889th epoch : 0.2671883325802855  Training Accuracy:1.0\n",
      "The training loss at 1890th epoch : 0.2670065987156899  Training Accuracy:1.0\n",
      "The training loss at 1891th epoch : 0.2668246060427907  Training Accuracy:1.0\n",
      "The training loss at 1892th epoch : 0.26664235477112025  Training Accuracy:1.0\n",
      "The training loss at 1893th epoch : 0.26645984511888415  Training Accuracy:1.0\n",
      "The training loss at 1894th epoch : 0.266277077312978  Training Accuracy:1.0\n",
      "The training loss at 1895th epoch : 0.2660940515890035  Training Accuracy:1.0\n",
      "The training loss at 1896th epoch : 0.2659107681912837  Training Accuracy:1.0\n",
      "The training loss at 1897th epoch : 0.2657272273728768  Training Accuracy:1.0\n",
      "The training loss at 1898th epoch : 0.26554342939559006  Training Accuracy:1.0\n",
      "The training loss at 1899th epoch : 0.26535937452999203  Training Accuracy:1.0\n",
      "The training loss at 1900th epoch : 0.2651750630554239  Training Accuracy:1.0\n",
      "The training loss at 1901th epoch : 0.2649904952600105  Training Accuracy:1.0\n",
      "The training loss at 1902th epoch : 0.26480567144066974  Training Accuracy:1.0\n",
      "The training loss at 1903th epoch : 0.2646205919031217  Training Accuracy:1.0\n",
      "The training loss at 1904th epoch : 0.26443525696189607  Training Accuracy:1.0\n",
      "The training loss at 1905th epoch : 0.26424966694033947  Training Accuracy:1.0\n",
      "The training loss at 1906th epoch : 0.2640638221706213  Training Accuracy:1.0\n",
      "The training loss at 1907th epoch : 0.2638777229937385  Training Accuracy:1.0\n",
      "The training loss at 1908th epoch : 0.26369136975952007  Training Accuracy:1.0\n",
      "The training loss at 1909th epoch : 0.26350476282662966  Training Accuracy:1.0\n",
      "The training loss at 1910th epoch : 0.2633179025625681  Training Accuracy:1.0\n",
      "The training loss at 1911th epoch : 0.2631307893436741  Training Accuracy:1.0\n",
      "The training loss at 1912th epoch : 0.26294342355512496  Training Accuracy:1.0\n",
      "The training loss at 1913th epoch : 0.2627558055909349  Training Accuracy:1.0\n",
      "The training loss at 1914th epoch : 0.26256793585395416  Training Accuracy:1.0\n",
      "The training loss at 1915th epoch : 0.2623798147558652  Training Accuracy:1.0\n",
      "The training loss at 1916th epoch : 0.26219144271717953  Training Accuracy:1.0\n",
      "The training loss at 1917th epoch : 0.26200282016723264  Training Accuracy:1.0\n",
      "The training loss at 1918th epoch : 0.2618139475441778  Training Accuracy:1.0\n",
      "The training loss at 1919th epoch : 0.26162482529497955  Training Accuracy:1.0\n",
      "The training loss at 1920th epoch : 0.26143545387540557  Training Accuracy:1.0\n",
      "The training loss at 1921th epoch : 0.26124583375001764  Training Accuracy:1.0\n",
      "The training loss at 1922th epoch : 0.26105596539216175  Training Accuracy:1.0\n",
      "The training loss at 1923th epoch : 0.260865849283957  Training Accuracy:1.0\n",
      "The training loss at 1924th epoch : 0.2606754859162836  Training Accuracy:1.0\n",
      "The training loss at 1925th epoch : 0.26048487578876955  Training Accuracy:1.0\n",
      "The training loss at 1926th epoch : 0.26029401940977664  Training Accuracy:1.0\n",
      "The training loss at 1927th epoch : 0.2601029172963852  Training Accuracy:1.0\n",
      "The training loss at 1928th epoch : 0.2599115699743777  Training Accuracy:1.0\n",
      "The training loss at 1929th epoch : 0.25971997797822177  Training Accuracy:1.0\n",
      "The training loss at 1930th epoch : 0.2595281418510514  Training Accuracy:1.0\n",
      "The training loss at 1931th epoch : 0.2593360621446477  Training Accuracy:1.0\n",
      "The training loss at 1932th epoch : 0.2591437394194187  Training Accuracy:1.0\n",
      "The training loss at 1933th epoch : 0.25895117424437736  Training Accuracy:1.0\n",
      "The training loss at 1934th epoch : 0.25875836719711914  Training Accuracy:1.0\n",
      "The training loss at 1935th epoch : 0.2585653188637986  Training Accuracy:1.0\n",
      "The training loss at 1936th epoch : 0.25837202983910434  Training Accuracy:1.0\n",
      "The training loss at 1937th epoch : 0.25817850072623355  Training Accuracy:1.0\n",
      "The training loss at 1938th epoch : 0.25798473213686507  Training Accuracy:1.0\n",
      "The training loss at 1939th epoch : 0.25779072469113157  Training Accuracy:1.0\n",
      "The training loss at 1940th epoch : 0.2575964790175905  Training Accuracy:1.0\n",
      "The training loss at 1941th epoch : 0.25740199575319445  Training Accuracy:1.0\n",
      "The training loss at 1942th epoch : 0.25720727554325984  Training Accuracy:1.0\n",
      "The training loss at 1943th epoch : 0.2570123190414351  Training Accuracy:1.0\n",
      "The training loss at 1944th epoch : 0.25681712690966757  Training Accuracy:1.0\n",
      "The training loss at 1945th epoch : 0.256621699818169  Training Accuracy:1.0\n",
      "The training loss at 1946th epoch : 0.2564260384453811  Training Accuracy:1.0\n",
      "The training loss at 1947th epoch : 0.25623014347793865  Training Accuracy:1.0\n",
      "The training loss at 1948th epoch : 0.2560340156106327  Training Accuracy:1.0\n",
      "The training loss at 1949th epoch : 0.2558376555463722  Training Accuracy:1.0\n",
      "The training loss at 1950th epoch : 0.2556410639961447  Training Accuracy:1.0\n",
      "The training loss at 1951th epoch : 0.2554442416789763  Training Accuracy:1.0\n",
      "The training loss at 1952th epoch : 0.25524718932188983  Training Accuracy:1.0\n",
      "The training loss at 1953th epoch : 0.2550499076598633  Training Accuracy:1.0\n",
      "The training loss at 1954th epoch : 0.254852397435786  Training Accuracy:1.0\n",
      "The training loss at 1955th epoch : 0.2546546594004146  Training Accuracy:1.0\n",
      "The training loss at 1956th epoch : 0.25445669431232754  Training Accuracy:1.0\n",
      "The training loss at 1957th epoch : 0.2542585029378791  Training Accuracy:1.0\n",
      "The training loss at 1958th epoch : 0.25406008605115205  Training Accuracy:1.0\n",
      "The training loss at 1959th epoch : 0.25386144443390946  Training Accuracy:1.0\n",
      "The training loss at 1960th epoch : 0.25366257887554555  Training Accuracy:1.0\n",
      "The training loss at 1961th epoch : 0.2534634901730356  Training Accuracy:1.0\n",
      "The training loss at 1962th epoch : 0.25326417913088495  Training Accuracy:1.0\n",
      "The training loss at 1963th epoch : 0.253064646561077  Training Accuracy:1.0\n",
      "The training loss at 1964th epoch : 0.25286489328302036  Training Accuracy:1.0\n",
      "The training loss at 1965th epoch : 0.2526649201234949  Training Accuracy:1.0\n",
      "The training loss at 1966th epoch : 0.25246472791659713  Training Accuracy:1.0\n",
      "The training loss at 1967th epoch : 0.2522643175036847  Training Accuracy:1.0\n",
      "The training loss at 1968th epoch : 0.2520636897333198  Training Accuracy:1.0\n",
      "The training loss at 1969th epoch : 0.2518628454612114  Training Accuracy:1.0\n",
      "The training loss at 1970th epoch : 0.25166178555015783  Training Accuracy:1.0\n",
      "The training loss at 1971th epoch : 0.25146051086998694  Training Accuracy:1.0\n",
      "The training loss at 1972th epoch : 0.2512590222974964  Training Accuracy:1.0\n",
      "The training loss at 1973th epoch : 0.25105732071639303  Training Accuracy:1.0\n",
      "The training loss at 1974th epoch : 0.25085540701723097  Training Accuracy:1.0\n",
      "The training loss at 1975th epoch : 0.2506532820973495  Training Accuracy:1.0\n",
      "The training loss at 1976th epoch : 0.2504509468608096  Training Accuracy:1.0\n",
      "The training loss at 1977th epoch : 0.25024840221833  Training Accuracy:1.0\n",
      "The training loss at 1978th epoch : 0.25004564908722265  Training Accuracy:1.0\n",
      "The training loss at 1979th epoch : 0.24984268839132667  Training Accuracy:1.0\n",
      "The training loss at 1980th epoch : 0.24963952106094262  Training Accuracy:1.0\n",
      "The training loss at 1981th epoch : 0.24943614803276506  Training Accuracy:1.0\n",
      "The training loss at 1982th epoch : 0.24923257024981502  Training Accuracy:1.0\n",
      "The training loss at 1983th epoch : 0.24902878866137146  Training Accuracy:1.0\n",
      "The training loss at 1984th epoch : 0.24882480422290212  Training Accuracy:1.0\n",
      "The training loss at 1985th epoch : 0.24862061789599377  Training Accuracy:1.0\n",
      "The training loss at 1986th epoch : 0.24841623064828164  Training Accuracy:1.0\n",
      "The training loss at 1987th epoch : 0.24821164345337826  Training Accuracy:1.0\n",
      "The training loss at 1988th epoch : 0.24800685729080174  Training Accuracy:1.0\n",
      "The training loss at 1989th epoch : 0.24780187314590338  Training Accuracy:1.0\n",
      "The training loss at 1990th epoch : 0.24759669200979456  Training Accuracy:1.0\n",
      "The training loss at 1991th epoch : 0.24739131487927324  Training Accuracy:1.0\n",
      "The training loss at 1992th epoch : 0.24718574275674982  Training Accuracy:1.0\n",
      "The training loss at 1993th epoch : 0.24697997665017224  Training Accuracy:1.0\n",
      "The training loss at 1994th epoch : 0.2467740175729509  Training Accuracy:1.0\n",
      "The training loss at 1995th epoch : 0.24656786654388277  Training Accuracy:1.0\n",
      "The training loss at 1996th epoch : 0.24636152458707503  Training Accuracy:1.0\n",
      "The training loss at 1997th epoch : 0.24615499273186842  Training Accuracy:1.0\n",
      "The training loss at 1998th epoch : 0.2459482720127598  Training Accuracy:1.0\n",
      "The training loss at 1999th epoch : 0.2457413634693245  Training Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "layer_list = [2 ,3, 1]\n",
    "model = Neural_Net(layer_list)\n",
    "loss_m = Loss()\n",
    "\n",
    "def train_gradient_update(model ,loss_m,X_train , Y_train,epochs,alpha =0.1):\n",
    "    for i in range(epochs):\n",
    "        act , cache = model.forward(X_train)\n",
    "        loss,d_back,_ = loss_m.sq_loss(act,Y_train)\n",
    "        acc = accuracy_neural_net(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        model.update_gradient(cache,d_back,alpha)        \n",
    "\n",
    "train_gradient_update(model , loss_m , X_train,Y_train , 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78167059],\n",
       "       [0.36434847],\n",
       "       [0.29372793],\n",
       "       [0.52631773]], dtype=float128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred,_ = model.forward(X_train)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_neural_net(model,X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Bit XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets try working with just a little better data. A n XOR operator. So lets create the dataset for n bit xor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have atmost 2^n data point in this type of data set.BUt we would limit our dataset to a 1000 data points\n",
    "whichever is smaller.\n",
    "\n",
    "Then we can divide into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 5\n",
    "max_datapoint = 10000\n",
    "datapoints = min(pow(2,n) , max_datapoint)\n",
    "\n",
    "X = np.zeros((datapoints , n) , dtype=np.int32)\n",
    "Y = np.zeros((datapoints , 1), dtype=np.int32)\n",
    "\n",
    "for i in range(datapoints):\n",
    "    tmp = i\n",
    "    y_tmp = 0\n",
    "    for j in range(n-1 , -1 , -1):\n",
    "        X[i,j] = tmp&1\n",
    "        y_tmp = y_tmp^X[i,j]\n",
    "        tmp = tmp>>1\n",
    "    Y[i] = y_tmp\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1] [1]\n"
     ]
    }
   ],
   "source": [
    "# for sanity check lets print one example\n",
    "ind = 11\n",
    "print(X[ind] , Y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets divide the set in training and testing\n",
    "div = 0.9\n",
    "train_n = int(div * datapoints)\n",
    "X_train = X[:train_n]\n",
    "Y_train = Y[:train_n]\n",
    "\n",
    "X_test = X[train_n:]\n",
    "Y_test = Y[train_n:]\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4) (4,)\n",
      "(4, 2) (2,)\n",
      "(2, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "layer_list = [n,4,2,1]\n",
    "model = Neural_Net(layer_list)\n",
    "loss_m = Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 0th epoch : 4.2088408504880235  Training Accuracy:0.5\n",
      "The training loss at 1th epoch : 3.9665384877213765  Training Accuracy:0.5\n",
      "The training loss at 2th epoch : 3.789999719313251  Training Accuracy:0.5\n",
      "The training loss at 3th epoch : 3.673684337637267  Training Accuracy:0.5\n",
      "The training loss at 4th epoch : 3.6022548568274537  Training Accuracy:0.5\n",
      "The training loss at 5th epoch : 3.5602133030678544  Training Accuracy:0.5\n",
      "The training loss at 6th epoch : 3.5360190580230437  Training Accuracy:0.5\n",
      "The training loss at 7th epoch : 3.5222385813969197  Training Accuracy:0.5\n",
      "The training loss at 8th epoch : 3.5144178217325446  Training Accuracy:0.5\n",
      "The training loss at 9th epoch : 3.5099798771322197  Training Accuracy:0.5\n",
      "The training loss at 10th epoch : 3.507457210899727  Training Accuracy:0.5\n",
      "The training loss at 11th epoch : 3.506019100296306  Training Accuracy:0.5\n",
      "The training loss at 12th epoch : 3.5051959212630743  Training Accuracy:0.5\n",
      "The training loss at 13th epoch : 3.504721971170303  Training Accuracy:0.5\n",
      "The training loss at 14th epoch : 3.504446676956197  Training Accuracy:0.5\n",
      "The training loss at 15th epoch : 3.504284555034346  Training Accuracy:0.5\n",
      "The training loss at 16th epoch : 3.5041869920374  Training Accuracy:0.5\n",
      "The training loss at 17th epoch : 3.5041263012080917  Training Accuracy:0.5\n",
      "The training loss at 18th epoch : 3.504086694522347  Training Accuracy:0.5\n",
      "The training loss at 19th epoch : 3.5040591598863333  Training Accuracy:0.5\n",
      "The training loss at 20th epoch : 3.504038548777803  Training Accuracy:0.5\n",
      "The training loss at 21th epoch : 3.5040219179222833  Training Accuracy:0.5\n",
      "The training loss at 22th epoch : 3.5040075838010565  Training Accuracy:0.5\n",
      "The training loss at 23th epoch : 3.5039945830137103  Training Accuracy:0.5\n",
      "The training loss at 24th epoch : 3.5039823640223173  Training Accuracy:0.5\n",
      "The training loss at 25th epoch : 3.503970610949032  Training Accuracy:0.5357142857142857\n",
      "The training loss at 26th epoch : 3.5039591428028998  Training Accuracy:0.5357142857142857\n",
      "The training loss at 27th epoch : 3.503947855821177  Training Accuracy:0.5357142857142857\n",
      "The training loss at 28th epoch : 3.5039366904677487  Training Accuracy:0.5357142857142857\n",
      "The training loss at 29th epoch : 3.503925612538984  Training Accuracy:0.5357142857142857\n",
      "The training loss at 30th epoch : 3.5039146023439165  Training Accuracy:0.5357142857142857\n",
      "The training loss at 31th epoch : 3.5039036485070314  Training Accuracy:0.5357142857142857\n",
      "The training loss at 32th epoch : 3.5038927444181533  Training Accuracy:0.5357142857142857\n",
      "The training loss at 33th epoch : 3.503881886198463  Training Accuracy:0.5357142857142857\n",
      "The training loss at 34th epoch : 3.50387107153503  Training Accuracy:0.5357142857142857\n",
      "The training loss at 35th epoch : 3.503860299012932  Training Accuracy:0.5357142857142857\n",
      "The training loss at 36th epoch : 3.5038495677324955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 37th epoch : 3.5038388770899203  Training Accuracy:0.5357142857142857\n",
      "The training loss at 38th epoch : 3.5038282266515433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 39th epoch : 3.5038176160817662  Training Accuracy:0.5357142857142857\n",
      "The training loss at 40th epoch : 3.503807045101746  Training Accuracy:0.5357142857142857\n",
      "The training loss at 41th epoch : 3.5037965134657125  Training Accuracy:0.5357142857142857\n",
      "The training loss at 42th epoch : 3.5037860209473974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 43th epoch : 3.5037755673322497  Training Accuracy:0.5357142857142857\n",
      "The training loss at 44th epoch : 3.5037651524129756  Training Accuracy:0.5357142857142857\n",
      "The training loss at 45th epoch : 3.503754775986979  Training Accuracy:0.5357142857142857\n",
      "The training loss at 46th epoch : 3.5037444378548925  Training Accuracy:0.5357142857142857\n",
      "The training loss at 47th epoch : 3.503734137819734  Training Accuracy:0.5357142857142857\n",
      "The training loss at 48th epoch : 3.5037238756864175  Training Accuracy:0.5357142857142857\n",
      "The training loss at 49th epoch : 3.5037136512614735  Training Accuracy:0.5357142857142857\n",
      "The training loss at 50th epoch : 3.5037034643528826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 51th epoch : 3.503693314769979  Training Accuracy:0.5357142857142857\n",
      "The training loss at 52th epoch : 3.5036832023233897  Training Accuracy:0.5357142857142857\n",
      "The training loss at 53th epoch : 3.5036731268249968  Training Accuracy:0.5357142857142857\n",
      "The training loss at 54th epoch : 3.503663088087912  Training Accuracy:0.5357142857142857\n",
      "The training loss at 55th epoch : 3.503653085926459  Training Accuracy:0.5357142857142857\n",
      "The training loss at 56th epoch : 3.50364312015616  Training Accuracy:0.5357142857142857\n",
      "The training loss at 57th epoch : 3.5036331905937206  Training Accuracy:0.5357142857142857\n",
      "The training loss at 58th epoch : 3.5036232970570222  Training Accuracy:0.5357142857142857\n",
      "The training loss at 59th epoch : 3.5036134393651124  Training Accuracy:0.5357142857142857\n",
      "The training loss at 60th epoch : 3.503603617338192  Training Accuracy:0.5357142857142857\n",
      "The training loss at 61th epoch : 3.50359383079761  Training Accuracy:0.5357142857142857\n",
      "The training loss at 62th epoch : 3.503584079565852  Training Accuracy:0.5357142857142857\n",
      "The training loss at 63th epoch : 3.5035743634665333  Training Accuracy:0.5357142857142857\n",
      "The training loss at 64th epoch : 3.5035646823243876  Training Accuracy:0.5357142857142857\n",
      "The training loss at 65th epoch : 3.5035550359652614  Training Accuracy:0.5357142857142857\n",
      "The training loss at 66th epoch : 3.5035454242161026  Training Accuracy:0.5357142857142857\n",
      "The training loss at 67th epoch : 3.503535846904955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 68th epoch : 3.503526303860946  Training Accuracy:0.5357142857142857\n",
      "The training loss at 69th epoch : 3.503516794914283  Training Accuracy:0.5357142857142857\n",
      "The training loss at 70th epoch : 3.503507319896241  Training Accuracy:0.5357142857142857\n",
      "The training loss at 71th epoch : 3.5034978786391564  Training Accuracy:0.5357142857142857\n",
      "The training loss at 72th epoch : 3.503488470976419  Training Accuracy:0.5357142857142857\n",
      "The training loss at 73th epoch : 3.5034790967424634  Training Accuracy:0.5357142857142857\n",
      "The training loss at 74th epoch : 3.50346975577276  Training Accuracy:0.5357142857142857\n",
      "The training loss at 75th epoch : 3.5034604479038096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 76th epoch : 3.503451172973134  Training Accuracy:0.5357142857142857\n",
      "The training loss at 77th epoch : 3.5034419308192675  Training Accuracy:0.5357142857142857\n",
      "The training loss at 78th epoch : 3.503432721281751  Training Accuracy:0.5357142857142857\n",
      "The training loss at 79th epoch : 3.5034235442011226  Training Accuracy:0.5357142857142857\n",
      "The training loss at 80th epoch : 3.503414399418912  Training Accuracy:0.5357142857142857\n",
      "The training loss at 81th epoch : 3.503405286777631  Training Accuracy:0.5357142857142857\n",
      "The training loss at 82th epoch : 3.5033962061207666  Training Accuracy:0.5357142857142857\n",
      "The training loss at 83th epoch : 3.5033871572927757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 84th epoch : 3.5033781401390747  Training Accuracy:0.5357142857142857\n",
      "The training loss at 85th epoch : 3.503369154506034  Training Accuracy:0.5357142857142857\n",
      "The training loss at 86th epoch : 3.5033602002409707  Training Accuracy:0.5357142857142857\n",
      "The training loss at 87th epoch : 3.5033512771921407  Training Accuracy:0.5357142857142857\n",
      "The training loss at 88th epoch : 3.503342385208733  Training Accuracy:0.5357142857142857\n",
      "The training loss at 89th epoch : 3.503333524140862  Training Accuracy:0.5357142857142857\n",
      "The training loss at 90th epoch : 3.5033246938395592  Training Accuracy:0.5357142857142857\n",
      "The training loss at 91th epoch : 3.50331589415677  Training Accuracy:0.5357142857142857\n",
      "The training loss at 92th epoch : 3.5033071249453425  Training Accuracy:0.5357142857142857\n",
      "The training loss at 93th epoch : 3.503298386059024  Training Accuracy:0.5357142857142857\n",
      "The training loss at 94th epoch : 3.503289677352453  Training Accuracy:0.5357142857142857\n",
      "The training loss at 95th epoch : 3.5032809986811517  Training Accuracy:0.5357142857142857\n",
      "The training loss at 96th epoch : 3.503272349901523  Training Accuracy:0.5357142857142857\n",
      "The training loss at 97th epoch : 3.5032637308708385  Training Accuracy:0.5357142857142857\n",
      "The training loss at 98th epoch : 3.503255141447237  Training Accuracy:0.5357142857142857\n",
      "The training loss at 99th epoch : 3.5032465814897153  Training Accuracy:0.5357142857142857\n",
      "The training loss at 100th epoch : 3.5032380508581236  Training Accuracy:0.5357142857142857\n",
      "The training loss at 101th epoch : 3.503229549413157  Training Accuracy:0.5357142857142857\n",
      "The training loss at 102th epoch : 3.503221077016352  Training Accuracy:0.5357142857142857\n",
      "The training loss at 103th epoch : 3.5032126335300773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 104th epoch : 3.5032042188175314  Training Accuracy:0.5357142857142857\n",
      "The training loss at 105th epoch : 3.5031958327427324  Training Accuracy:0.5357142857142857\n",
      "The training loss at 106th epoch : 3.5031874751705154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 107th epoch : 3.5031791459665245  Training Accuracy:0.5357142857142857\n",
      "The training loss at 108th epoch : 3.5031708449972077  Training Accuracy:0.5357142857142857\n",
      "The training loss at 109th epoch : 3.5031625721298107  Training Accuracy:0.5357142857142857\n",
      "The training loss at 110th epoch : 3.5031543272323717  Training Accuracy:0.5357142857142857\n",
      "The training loss at 111th epoch : 3.503146110173715  Training Accuracy:0.5357142857142857\n",
      "The training loss at 112th epoch : 3.503137920823446  Training Accuracy:0.5357142857142857\n",
      "The training loss at 113th epoch : 3.5031297590519435  Training Accuracy:0.5357142857142857\n",
      "The training loss at 114th epoch : 3.5031216247303574  Training Accuracy:0.5357142857142857\n",
      "The training loss at 115th epoch : 3.5031135177306  Training Accuracy:0.5357142857142857\n",
      "The training loss at 116th epoch : 3.5031054379253432  Training Accuracy:0.5357142857142857\n",
      "The training loss at 117th epoch : 3.5030973851880107  Training Accuracy:0.5357142857142857\n",
      "The training loss at 118th epoch : 3.5030893593927734  Training Accuracy:0.5357142857142857\n",
      "The training loss at 119th epoch : 3.5030813604145448  Training Accuracy:0.5357142857142857\n",
      "The training loss at 120th epoch : 3.5030733881289753  Training Accuracy:0.5\n",
      "The training loss at 121th epoch : 3.503065442412445  Training Accuracy:0.5\n",
      "The training loss at 122th epoch : 3.5030575231420626  Training Accuracy:0.5\n",
      "The training loss at 123th epoch : 3.503049630195655  Training Accuracy:0.5\n",
      "The training loss at 124th epoch : 3.503041763451767  Training Accuracy:0.5\n",
      "The training loss at 125th epoch : 3.503033922789653  Training Accuracy:0.5\n",
      "The training loss at 126th epoch : 3.5030261080892733  Training Accuracy:0.5\n",
      "The training loss at 127th epoch : 3.5030183192312885  Training Accuracy:0.5\n",
      "The training loss at 128th epoch : 3.503010556097055  Training Accuracy:0.5\n",
      "The training loss at 129th epoch : 3.503002818568619  Training Accuracy:0.5\n",
      "The training loss at 130th epoch : 3.5029951065287137  Training Accuracy:0.5\n",
      "The training loss at 131th epoch : 3.5029874198607525  Training Accuracy:0.5\n",
      "The training loss at 132th epoch : 3.502979758448825  Training Accuracy:0.5\n",
      "The training loss at 133th epoch : 3.5029721221776917  Training Accuracy:0.5\n",
      "The training loss at 134th epoch : 3.5029645109327796  Training Accuracy:0.5\n",
      "The training loss at 135th epoch : 3.502956924600178  Training Accuracy:0.5\n",
      "The training loss at 136th epoch : 3.5029493630666333  Training Accuracy:0.5\n",
      "The training loss at 137th epoch : 3.5029418262195438  Training Accuracy:0.5\n",
      "The training loss at 138th epoch : 3.502934313946956  Training Accuracy:0.5\n",
      "The training loss at 139th epoch : 3.5029268261375606  Training Accuracy:0.5\n",
      "The training loss at 140th epoch : 3.5029193626806863  Training Accuracy:0.5\n",
      "The training loss at 141th epoch : 3.5029119234662964  Training Accuracy:0.5\n",
      "The training loss at 142th epoch : 3.502904508384984  Training Accuracy:0.5\n",
      "The training loss at 143th epoch : 3.502897117327968  Training Accuracy:0.5\n",
      "The training loss at 144th epoch : 3.5028897501870895  Training Accuracy:0.5\n",
      "The training loss at 145th epoch : 3.5028824068548046  Training Accuracy:0.5\n",
      "The training loss at 146th epoch : 3.502875087224183  Training Accuracy:0.5\n",
      "The training loss at 147th epoch : 3.5028677911889026  Training Accuracy:0.5\n",
      "The training loss at 148th epoch : 3.502860518643246  Training Accuracy:0.5\n",
      "The training loss at 149th epoch : 3.5028532694820953  Training Accuracy:0.5\n",
      "The training loss at 150th epoch : 3.502846043600928  Training Accuracy:0.5\n",
      "The training loss at 151th epoch : 3.502838840895814  Training Accuracy:0.5\n",
      "The training loss at 152th epoch : 3.50283166126341  Training Accuracy:0.5\n",
      "The training loss at 153th epoch : 3.502824504600957  Training Accuracy:0.5\n",
      "The training loss at 154th epoch : 3.502817370806275  Training Accuracy:0.5\n",
      "The training loss at 155th epoch : 3.50281025977776  Training Accuracy:0.5\n",
      "The training loss at 156th epoch : 3.502803171414379  Training Accuracy:0.5\n",
      "The training loss at 157th epoch : 3.502796105615667  Training Accuracy:0.5\n",
      "The training loss at 158th epoch : 3.502789062281723  Training Accuracy:0.5\n",
      "The training loss at 159th epoch : 3.5027820413132056  Training Accuracy:0.5\n",
      "The training loss at 160th epoch : 3.5027750426113293  Training Accuracy:0.5\n",
      "The training loss at 161th epoch : 3.502768066077861  Training Accuracy:0.5\n",
      "The training loss at 162th epoch : 3.5027611116151167  Training Accuracy:0.5\n",
      "The training loss at 163th epoch : 3.5027541791259567  Training Accuracy:0.5\n",
      "The training loss at 164th epoch : 3.502747268513782  Training Accuracy:0.5\n",
      "The training loss at 165th epoch : 3.5027403796825323  Training Accuracy:0.5\n",
      "The training loss at 166th epoch : 3.502733512536679  Training Accuracy:0.5\n",
      "The training loss at 167th epoch : 3.502726666981226  Training Accuracy:0.5\n",
      "The training loss at 168th epoch : 3.5027198429217017  Training Accuracy:0.5\n",
      "The training loss at 169th epoch : 3.5027130402641586  Training Accuracy:0.5\n",
      "The training loss at 170th epoch : 3.5027062589151683  Training Accuracy:0.5\n",
      "The training loss at 171th epoch : 3.502699498781819  Training Accuracy:0.5\n",
      "The training loss at 172th epoch : 3.502692759771711  Training Accuracy:0.5\n",
      "The training loss at 173th epoch : 3.502686041792953  Training Accuracy:0.5\n",
      "The training loss at 174th epoch : 3.5026793447541595  Training Accuracy:0.5\n",
      "The training loss at 175th epoch : 3.5026726685644487  Training Accuracy:0.5\n",
      "The training loss at 176th epoch : 3.5026660131334353  Training Accuracy:0.5\n",
      "The training loss at 177th epoch : 3.5026593783712316  Training Accuracy:0.5\n",
      "The training loss at 178th epoch : 3.5026527641884413  Training Accuracy:0.5\n",
      "The training loss at 179th epoch : 3.5026461704961562  Training Accuracy:0.5\n",
      "The training loss at 180th epoch : 3.502639597205955  Training Accuracy:0.5\n",
      "The training loss at 181th epoch : 3.5026330442298987  Training Accuracy:0.5\n",
      "The training loss at 182th epoch : 3.502626511480526  Training Accuracy:0.5\n",
      "The training loss at 183th epoch : 3.502619998870854  Training Accuracy:0.5\n",
      "The training loss at 184th epoch : 3.502613506314371  Training Accuracy:0.5\n",
      "The training loss at 185th epoch : 3.502607033725035  Training Accuracy:0.5\n",
      "The training loss at 186th epoch : 3.502600581017272  Training Accuracy:0.5\n",
      "The training loss at 187th epoch : 3.5025941481059695  Training Accuracy:0.5\n",
      "The training loss at 188th epoch : 3.502587734906477  Training Accuracy:0.5\n",
      "The training loss at 189th epoch : 3.502581341334601  Training Accuracy:0.5\n",
      "The training loss at 190th epoch : 3.5025749673066024  Training Accuracy:0.5\n",
      "The training loss at 191th epoch : 3.5025686127391937  Training Accuracy:0.5\n",
      "The training loss at 192th epoch : 3.502562277549536  Training Accuracy:0.5\n",
      "The training loss at 193th epoch : 3.502555961655234  Training Accuracy:0.5\n",
      "The training loss at 194th epoch : 3.5025496649743384  Training Accuracy:0.5\n",
      "The training loss at 195th epoch : 3.502543387425337  Training Accuracy:0.5\n",
      "The training loss at 196th epoch : 3.502537128927155  Training Accuracy:0.5\n",
      "The training loss at 197th epoch : 3.5025308893991514  Training Accuracy:0.5\n",
      "The training loss at 198th epoch : 3.5025246687611173  Training Accuracy:0.5\n",
      "The training loss at 199th epoch : 3.502518466933271  Training Accuracy:0.5\n",
      "The training loss at 200th epoch : 3.5025122838362566  Training Accuracy:0.5\n",
      "The training loss at 201th epoch : 3.5025061193911413  Training Accuracy:0.5\n",
      "The training loss at 202th epoch : 3.5024999735194124  Training Accuracy:0.5\n",
      "The training loss at 203th epoch : 3.5024938461429733  Training Accuracy:0.5\n",
      "The training loss at 204th epoch : 3.5024877371841434  Training Accuracy:0.5\n",
      "The training loss at 205th epoch : 3.502481646565653  Training Accuracy:0.5\n",
      "The training loss at 206th epoch : 3.5024755742106426  Training Accuracy:0.5\n",
      "The training loss at 207th epoch : 3.502469520042658  Training Accuracy:0.5\n",
      "The training loss at 208th epoch : 3.5024634839856494  Training Accuracy:0.5\n",
      "The training loss at 209th epoch : 3.5024574659639693  Training Accuracy:0.5\n",
      "The training loss at 210th epoch : 3.502451465902368  Training Accuracy:0.5\n",
      "The training loss at 211th epoch : 3.502445483725992  Training Accuracy:0.5\n",
      "The training loss at 212th epoch : 3.5024395193603817  Training Accuracy:0.5\n",
      "The training loss at 213th epoch : 3.502433572731469  Training Accuracy:0.5\n",
      "The training loss at 214th epoch : 3.502427643765573  Training Accuracy:0.5\n",
      "The training loss at 215th epoch : 3.5024217323894007  Training Accuracy:0.5\n",
      "The training loss at 216th epoch : 3.5024158385300415  Training Accuracy:0.5\n",
      "The training loss at 217th epoch : 3.502409962114967  Training Accuracy:0.5\n",
      "The training loss at 218th epoch : 3.5024041030720268  Training Accuracy:0.5\n",
      "The training loss at 219th epoch : 3.502398261329447  Training Accuracy:0.5\n",
      "The training loss at 220th epoch : 3.5023924368158283  Training Accuracy:0.5\n",
      "The training loss at 221th epoch : 3.502386629460142  Training Accuracy:0.5\n",
      "The training loss at 222th epoch : 3.5023808391917286  Training Accuracy:0.5\n",
      "The training loss at 223th epoch : 3.5023750659402975  Training Accuracy:0.5\n",
      "The training loss at 224th epoch : 3.50236930963592  Training Accuracy:0.5\n",
      "The training loss at 225th epoch : 3.502363570209031  Training Accuracy:0.5\n",
      "The training loss at 226th epoch : 3.5023578475904253  Training Accuracy:0.5\n",
      "The training loss at 227th epoch : 3.5023521417112553  Training Accuracy:0.5\n",
      "The training loss at 228th epoch : 3.502346452503029  Training Accuracy:0.5\n",
      "The training loss at 229th epoch : 3.502340779897607  Training Accuracy:0.5\n",
      "The training loss at 230th epoch : 3.502335123827202  Training Accuracy:0.5\n",
      "The training loss at 231th epoch : 3.5023294842243735  Training Accuracy:0.5\n",
      "The training loss at 232th epoch : 3.50232386102203  Training Accuracy:0.5\n",
      "The training loss at 233th epoch : 3.5023182541534235  Training Accuracy:0.5\n",
      "The training loss at 234th epoch : 3.502312663552147  Training Accuracy:0.5\n",
      "The training loss at 235th epoch : 3.502307089152135  Training Accuracy:0.5\n",
      "The training loss at 236th epoch : 3.5023015308876597  Training Accuracy:0.5\n",
      "The training loss at 237th epoch : 3.502295988693329  Training Accuracy:0.5\n",
      "The training loss at 238th epoch : 3.5022904625040847  Training Accuracy:0.5\n",
      "The training loss at 239th epoch : 3.5022849522552  Training Accuracy:0.5\n",
      "The training loss at 240th epoch : 3.502279457882278  Training Accuracy:0.5\n",
      "The training loss at 241th epoch : 3.50227397932125  Training Accuracy:0.5\n",
      "The training loss at 242th epoch : 3.5022685165083716  Training Accuracy:0.5\n",
      "The training loss at 243th epoch : 3.5022630693802226  Training Accuracy:0.5\n",
      "The training loss at 244th epoch : 3.5022576378737043  Training Accuracy:0.5\n",
      "The training loss at 245th epoch : 3.502252221926038  Training Accuracy:0.5\n",
      "The training loss at 246th epoch : 3.502246821474761  Training Accuracy:0.5\n",
      "The training loss at 247th epoch : 3.5022414364577283  Training Accuracy:0.5\n",
      "The training loss at 248th epoch : 3.5022360668131074  Training Accuracy:0.5\n",
      "The training loss at 249th epoch : 3.5022307124793772  Training Accuracy:0.5\n",
      "The training loss at 250th epoch : 3.5022253733953272  Training Accuracy:0.5\n",
      "The training loss at 251th epoch : 3.5022200495000546  Training Accuracy:0.5\n",
      "The training loss at 252th epoch : 3.5022147407329625  Training Accuracy:0.5\n",
      "The training loss at 253th epoch : 3.5022094470337577  Training Accuracy:0.5\n",
      "The training loss at 254th epoch : 3.50220416834245  Training Accuracy:0.5\n",
      "The training loss at 255th epoch : 3.5021989045993496  Training Accuracy:0.5\n",
      "The training loss at 256th epoch : 3.5021936557450646  Training Accuracy:0.5\n",
      "The training loss at 257th epoch : 3.5021884217205006  Training Accuracy:0.5\n",
      "The training loss at 258th epoch : 3.5021832024668575  Training Accuracy:0.5\n",
      "The training loss at 259th epoch : 3.5021779979256293  Training Accuracy:0.5\n",
      "The training loss at 260th epoch : 3.5021728080386  Training Accuracy:0.5\n",
      "The training loss at 261th epoch : 3.5021676327478444  Training Accuracy:0.5\n",
      "The training loss at 262th epoch : 3.502162471995725  Training Accuracy:0.5\n",
      "The training loss at 263th epoch : 3.5021573257248897  Training Accuracy:0.5\n",
      "The training loss at 264th epoch : 3.5021521938782714  Training Accuracy:0.5\n",
      "The training loss at 265th epoch : 3.502147076399085  Training Accuracy:0.5\n",
      "The training loss at 266th epoch : 3.5021419732308274  Training Accuracy:0.5\n",
      "The training loss at 267th epoch : 3.502136884317274  Training Accuracy:0.5\n",
      "The training loss at 268th epoch : 3.502131809602478  Training Accuracy:0.5\n",
      "The training loss at 269th epoch : 3.5021267490307677  Training Accuracy:0.5\n",
      "The training loss at 270th epoch : 3.5021217025467464  Training Accuracy:0.5\n",
      "The training loss at 271th epoch : 3.5021166700952904  Training Accuracy:0.5\n",
      "The training loss at 272th epoch : 3.5021116516215463  Training Accuracy:0.5\n",
      "The training loss at 273th epoch : 3.5021066470709297  Training Accuracy:0.5\n",
      "The training loss at 274th epoch : 3.5021016563891245  Training Accuracy:0.5\n",
      "The training loss at 275th epoch : 3.5020966795220807  Training Accuracy:0.5\n",
      "The training loss at 276th epoch : 3.502091716416012  Training Accuracy:0.5\n",
      "The training loss at 277th epoch : 3.502086767017396  Training Accuracy:0.5\n",
      "The training loss at 278th epoch : 3.502081831272972  Training Accuracy:0.5\n",
      "The training loss at 279th epoch : 3.5020769091297366  Training Accuracy:0.5\n",
      "The training loss at 280th epoch : 3.502072000534948  Training Accuracy:0.5\n",
      "The training loss at 281th epoch : 3.5020671054361188  Training Accuracy:0.5\n",
      "The training loss at 282th epoch : 3.502062223781018  Training Accuracy:0.5\n",
      "The training loss at 283th epoch : 3.502057355517667  Training Accuracy:0.5\n",
      "The training loss at 284th epoch : 3.502052500594341  Training Accuracy:0.5\n",
      "The training loss at 285th epoch : 3.502047658959565  Training Accuracy:0.5\n",
      "The training loss at 286th epoch : 3.5020428305621123  Training Accuracy:0.5\n",
      "The training loss at 287th epoch : 3.5020380153510056  Training Accuracy:0.5\n",
      "The training loss at 288th epoch : 3.502033213275513  Training Accuracy:0.5\n",
      "The training loss at 289th epoch : 3.5020284242851476  Training Accuracy:0.5\n",
      "The training loss at 290th epoch : 3.5020236483296654  Training Accuracy:0.5\n",
      "The training loss at 291th epoch : 3.5020188853590652  Training Accuracy:0.5\n",
      "The training loss at 292th epoch : 3.5020141353235856  Training Accuracy:0.5\n",
      "The training loss at 293th epoch : 3.5020093981737044  Training Accuracy:0.5\n",
      "The training loss at 294th epoch : 3.5020046738601374  Training Accuracy:0.5\n",
      "The training loss at 295th epoch : 3.5019999623338363  Training Accuracy:0.5\n",
      "The training loss at 296th epoch : 3.501995263545988  Training Accuracy:0.5\n",
      "The training loss at 297th epoch : 3.501990577448013  Training Accuracy:0.5\n",
      "The training loss at 298th epoch : 3.5019859039915637  Training Accuracy:0.5\n",
      "The training loss at 299th epoch : 3.5019812431285238  Training Accuracy:0.5\n",
      "The training loss at 300th epoch : 3.5019765948110058  Training Accuracy:0.5\n",
      "The training loss at 301th epoch : 3.501971958991351  Training Accuracy:0.5\n",
      "The training loss at 302th epoch : 3.5019673356221266  Training Accuracy:0.5\n",
      "The training loss at 303th epoch : 3.501962724656127  Training Accuracy:0.5\n",
      "The training loss at 304th epoch : 3.5019581260463686  Training Accuracy:0.5\n",
      "The training loss at 305th epoch : 3.5019535397460926  Training Accuracy:0.5\n",
      "The training loss at 306th epoch : 3.501948965708761  Training Accuracy:0.5\n",
      "The training loss at 307th epoch : 3.5019444038880554  Training Accuracy:0.5\n",
      "The training loss at 308th epoch : 3.501939854237878  Training Accuracy:0.5\n",
      "The training loss at 309th epoch : 3.501935316712347  Training Accuracy:0.5\n",
      "The training loss at 310th epoch : 3.5019307912657993  Training Accuracy:0.5\n",
      "The training loss at 311th epoch : 3.501926277852785  Training Accuracy:0.5\n",
      "The training loss at 312th epoch : 3.501921776428069  Training Accuracy:0.5\n",
      "The training loss at 313th epoch : 3.5019172869466297  Training Accuracy:0.5\n",
      "The training loss at 314th epoch : 3.501912809363656  Training Accuracy:0.5\n",
      "The training loss at 315th epoch : 3.5019083436345477  Training Accuracy:0.5\n",
      "The training loss at 316th epoch : 3.5019038897149137  Training Accuracy:0.5\n",
      "The training loss at 317th epoch : 3.501899447560571  Training Accuracy:0.5\n",
      "The training loss at 318th epoch : 3.5018950171275436  Training Accuracy:0.5\n",
      "The training loss at 319th epoch : 3.5018905983720603  Training Accuracy:0.5\n",
      "The training loss at 320th epoch : 3.501886191250555  Training Accuracy:0.5\n",
      "The training loss at 321th epoch : 3.5018817957196635  Training Accuracy:0.5\n",
      "The training loss at 322th epoch : 3.501877411736227  Training Accuracy:0.5\n",
      "The training loss at 323th epoch : 3.5018730392572834  Training Accuracy:0.5\n",
      "The training loss at 324th epoch : 3.5018686782400734  Training Accuracy:0.5\n",
      "The training loss at 325th epoch : 3.5018643286420357  Training Accuracy:0.5\n",
      "The training loss at 326th epoch : 3.501859990420806  Training Accuracy:0.5\n",
      "The training loss at 327th epoch : 3.5018556635342164  Training Accuracy:0.5\n",
      "The training loss at 328th epoch : 3.5018513479402946  Training Accuracy:0.5\n",
      "The training loss at 329th epoch : 3.5018470435972633  Training Accuracy:0.5\n",
      "The training loss at 330th epoch : 3.501842750463537  Training Accuracy:0.5\n",
      "The training loss at 331th epoch : 3.5018384684977226  Training Accuracy:0.5\n",
      "The training loss at 332th epoch : 3.5018341976586185  Training Accuracy:0.5\n",
      "The training loss at 333th epoch : 3.5018299379052125  Training Accuracy:0.5\n",
      "The training loss at 334th epoch : 3.501825689196681  Training Accuracy:0.5\n",
      "The training loss at 335th epoch : 3.5018214514923884  Training Accuracy:0.5\n",
      "The training loss at 336th epoch : 3.501817224751886  Training Accuracy:0.5\n",
      "The training loss at 337th epoch : 3.5018130089349104  Training Accuracy:0.5\n",
      "The training loss at 338th epoch : 3.501808804001383  Training Accuracy:0.5\n",
      "The training loss at 339th epoch : 3.5018046099114084  Training Accuracy:0.5\n",
      "The training loss at 340th epoch : 3.501800426625274  Training Accuracy:0.5\n",
      "The training loss at 341th epoch : 3.5017962541034486  Training Accuracy:0.5\n",
      "The training loss at 342th epoch : 3.501792092306582  Training Accuracy:0.5\n",
      "The training loss at 343th epoch : 3.501787941195503  Training Accuracy:0.5\n",
      "The training loss at 344th epoch : 3.5017838007312183  Training Accuracy:0.5\n",
      "The training loss at 345th epoch : 3.501779670874914  Training Accuracy:0.5\n",
      "The training loss at 346th epoch : 3.5017755515879503  Training Accuracy:0.5\n",
      "The training loss at 347th epoch : 3.5017714428318643  Training Accuracy:0.5\n",
      "The training loss at 348th epoch : 3.501767344568368  Training Accuracy:0.5\n",
      "The training loss at 349th epoch : 3.501763256759346  Training Accuracy:0.5\n",
      "The training loss at 350th epoch : 3.5017591793668568  Training Accuracy:0.5\n",
      "The training loss at 351th epoch : 3.5017551123531283  Training Accuracy:0.5\n",
      "The training loss at 352th epoch : 3.501751055680562  Training Accuracy:0.5\n",
      "The training loss at 353th epoch : 3.501747009311727  Training Accuracy:0.5\n",
      "The training loss at 354th epoch : 3.501742973209362  Training Accuracy:0.5\n",
      "The training loss at 355th epoch : 3.501738947336374  Training Accuracy:0.5\n",
      "The training loss at 356th epoch : 3.5017349316558364  Training Accuracy:0.5\n",
      "The training loss at 357th epoch : 3.501730926130989  Training Accuracy:0.5\n",
      "The training loss at 358th epoch : 3.5017269307252366  Training Accuracy:0.5\n",
      "The training loss at 359th epoch : 3.501722945402148  Training Accuracy:0.5\n",
      "The training loss at 360th epoch : 3.5017189701254567  Training Accuracy:0.5\n",
      "The training loss at 361th epoch : 3.5017150048590566  Training Accuracy:0.5\n",
      "The training loss at 362th epoch : 3.5017110495670045  Training Accuracy:0.5\n",
      "The training loss at 363th epoch : 3.5017071042135175  Training Accuracy:0.5\n",
      "The training loss at 364th epoch : 3.501703168762973  Training Accuracy:0.5\n",
      "The training loss at 365th epoch : 3.5016992431799068  Training Accuracy:0.5\n",
      "The training loss at 366th epoch : 3.5016953274290126  Training Accuracy:0.5\n",
      "The training loss at 367th epoch : 3.501691421475142  Training Accuracy:0.5\n",
      "The training loss at 368th epoch : 3.5016875252833026  Training Accuracy:0.5\n",
      "The training loss at 369th epoch : 3.5016836388186574  Training Accuracy:0.5\n",
      "The training loss at 370th epoch : 3.5016797620465243  Training Accuracy:0.5\n",
      "The training loss at 371th epoch : 3.5016758949323745  Training Accuracy:0.5\n",
      "The training loss at 372th epoch : 3.501672037441833  Training Accuracy:0.5\n",
      "The training loss at 373th epoch : 3.5016681895406765  Training Accuracy:0.5\n",
      "The training loss at 374th epoch : 3.5016643511948327  Training Accuracy:0.5\n",
      "The training loss at 375th epoch : 3.501660522370381  Training Accuracy:0.5\n",
      "The training loss at 376th epoch : 3.501656703033549  Training Accuracy:0.5\n",
      "The training loss at 377th epoch : 3.5016528931507143  Training Accuracy:0.5\n",
      "The training loss at 378th epoch : 3.5016490926884023  Training Accuracy:0.5\n",
      "The training loss at 379th epoch : 3.5016453016132854  Training Accuracy:0.5\n",
      "The training loss at 380th epoch : 3.501641519892183  Training Accuracy:0.5\n",
      "The training loss at 381th epoch : 3.50163774749206  Training Accuracy:0.5\n",
      "The training loss at 382th epoch : 3.501633984380026  Training Accuracy:0.5\n",
      "The training loss at 383th epoch : 3.501630230523335  Training Accuracy:0.5\n",
      "The training loss at 384th epoch : 3.501626485889385  Training Accuracy:0.5\n",
      "The training loss at 385th epoch : 3.5016227504457156  Training Accuracy:0.5\n",
      "The training loss at 386th epoch : 3.501619024160009  Training Accuracy:0.5\n",
      "The training loss at 387th epoch : 3.5016153070000877  Training Accuracy:0.5\n",
      "The training loss at 388th epoch : 3.5016115989339154  Training Accuracy:0.5\n",
      "The training loss at 389th epoch : 3.5016078999295956  Training Accuracy:0.5\n",
      "The training loss at 390th epoch : 3.501604209955369  Training Accuracy:0.5\n",
      "The training loss at 391th epoch : 3.501600528979617  Training Accuracy:0.5\n",
      "The training loss at 392th epoch : 3.5015968569708558  Training Accuracy:0.5\n",
      "The training loss at 393th epoch : 3.5015931938977403  Training Accuracy:0.5\n",
      "The training loss at 394th epoch : 3.5015895397290597  Training Accuracy:0.5\n",
      "The training loss at 395th epoch : 3.5015858944337404  Training Accuracy:0.5\n",
      "The training loss at 396th epoch : 3.5015822579808407  Training Accuracy:0.5\n",
      "The training loss at 397th epoch : 3.501578630339555  Training Accuracy:0.5\n",
      "The training loss at 398th epoch : 3.5015750114792104  Training Accuracy:0.5\n",
      "The training loss at 399th epoch : 3.5015714013692647  Training Accuracy:0.5\n",
      "The training loss at 400th epoch : 3.5015677999793096  Training Accuracy:0.5\n",
      "The training loss at 401th epoch : 3.501564207279066  Training Accuracy:0.5\n",
      "The training loss at 402th epoch : 3.5015606232383862  Training Accuracy:0.5\n",
      "The training loss at 403th epoch : 3.5015570478272524  Training Accuracy:0.5\n",
      "The training loss at 404th epoch : 3.5015534810157742  Training Accuracy:0.5\n",
      "The training loss at 405th epoch : 3.501549922774191  Training Accuracy:0.5\n",
      "The training loss at 406th epoch : 3.501546373072869  Training Accuracy:0.5\n",
      "The training loss at 407th epoch : 3.501542831882302  Training Accuracy:0.5\n",
      "The training loss at 408th epoch : 3.5015392991731087  Training Accuracy:0.5\n",
      "The training loss at 409th epoch : 3.501535774916035  Training Accuracy:0.5\n",
      "The training loss at 410th epoch : 3.5015322590819506  Training Accuracy:0.5\n",
      "The training loss at 411th epoch : 3.5015287516418505  Training Accuracy:0.5\n",
      "The training loss at 412th epoch : 3.5015252525668523  Training Accuracy:0.5\n",
      "The training loss at 413th epoch : 3.501521761828197  Training Accuracy:0.5\n",
      "The training loss at 414th epoch : 3.5015182793972484  Training Accuracy:0.5\n",
      "The training loss at 415th epoch : 3.5015148052454914  Training Accuracy:0.5\n",
      "The training loss at 416th epoch : 3.5015113393445323  Training Accuracy:0.5\n",
      "The training loss at 417th epoch : 3.5015078816660976  Training Accuracy:0.5\n",
      "The training loss at 418th epoch : 3.501504432182034  Training Accuracy:0.5\n",
      "The training loss at 419th epoch : 3.5015009908643075  Training Accuracy:0.5\n",
      "The training loss at 420th epoch : 3.5014975576850023  Training Accuracy:0.5\n",
      "The training loss at 421th epoch : 3.5014941326163203  Training Accuracy:0.5\n",
      "The training loss at 422th epoch : 3.501490715630582  Training Accuracy:0.5\n",
      "The training loss at 423th epoch : 3.5014873067002235  Training Accuracy:0.5\n",
      "The training loss at 424th epoch : 3.5014839057977976  Training Accuracy:0.5\n",
      "The training loss at 425th epoch : 3.5014805128959723  Training Accuracy:0.5\n",
      "The training loss at 426th epoch : 3.5014771279675307  Training Accuracy:0.5\n",
      "The training loss at 427th epoch : 3.501473750985371  Training Accuracy:0.5\n",
      "The training loss at 428th epoch : 3.5014703819225046  Training Accuracy:0.5\n",
      "The training loss at 429th epoch : 3.5014670207520555  Training Accuracy:0.5\n",
      "The training loss at 430th epoch : 3.5014636674472612  Training Accuracy:0.5\n",
      "The training loss at 431th epoch : 3.5014603219814715  Training Accuracy:0.5\n",
      "The training loss at 432th epoch : 3.5014569843281467  Training Accuracy:0.5\n",
      "The training loss at 433th epoch : 3.5014536544608585  Training Accuracy:0.5\n",
      "The training loss at 434th epoch : 3.5014503323532895  Training Accuracy:0.5\n",
      "The training loss at 435th epoch : 3.501447017979231  Training Accuracy:0.5\n",
      "The training loss at 436th epoch : 3.501443711312585  Training Accuracy:0.5\n",
      "The training loss at 437th epoch : 3.50144041232736  Training Accuracy:0.5\n",
      "The training loss at 438th epoch : 3.5014371209976747  Training Accuracy:0.5\n",
      "The training loss at 439th epoch : 3.5014338372977547  Training Accuracy:0.5\n",
      "The training loss at 440th epoch : 3.501430561201932  Training Accuracy:0.5\n",
      "The training loss at 441th epoch : 3.5014272926846455  Training Accuracy:0.5\n",
      "The training loss at 442th epoch : 3.501424031720441  Training Accuracy:0.5\n",
      "The training loss at 443th epoch : 3.501420778283968  Training Accuracy:0.5\n",
      "The training loss at 444th epoch : 3.5014175323499814  Training Accuracy:0.5\n",
      "The training loss at 445th epoch : 3.5014142938933417  Training Accuracy:0.5\n",
      "The training loss at 446th epoch : 3.501411062889012  Training Accuracy:0.5\n",
      "The training loss at 447th epoch : 3.501407839312058  Training Accuracy:0.5\n",
      "The training loss at 448th epoch : 3.5014046231376503  Training Accuracy:0.5\n",
      "The training loss at 449th epoch : 3.50140141434106  Training Accuracy:0.5\n",
      "The training loss at 450th epoch : 3.501398212897661  Training Accuracy:0.5\n",
      "The training loss at 451th epoch : 3.501395018782927  Training Accuracy:0.5\n",
      "The training loss at 452th epoch : 3.5013918319724335  Training Accuracy:0.5\n",
      "The training loss at 453th epoch : 3.501388652441857  Training Accuracy:0.5\n",
      "The training loss at 454th epoch : 3.5013854801669715  Training Accuracy:0.5\n",
      "The training loss at 455th epoch : 3.5013823151236525  Training Accuracy:0.5\n",
      "The training loss at 456th epoch : 3.501379157287873  Training Accuracy:0.5\n",
      "The training loss at 457th epoch : 3.501376006635704  Training Accuracy:0.5\n",
      "The training loss at 458th epoch : 3.5013728631433145  Training Accuracy:0.5\n",
      "The training loss at 459th epoch : 3.501369726786972  Training Accuracy:0.5\n",
      "The training loss at 460th epoch : 3.501366597543038  Training Accuracy:0.5\n",
      "The training loss at 461th epoch : 3.5013634753879734  Training Accuracy:0.5\n",
      "The training loss at 462th epoch : 3.501360360298333  Training Accuracy:0.5\n",
      "The training loss at 463th epoch : 3.5013572522507665  Training Accuracy:0.5\n",
      "The training loss at 464th epoch : 3.5013541512220203  Training Accuracy:0.5\n",
      "The training loss at 465th epoch : 3.5013510571889337  Training Accuracy:0.5\n",
      "The training loss at 466th epoch : 3.5013479701284402  Training Accuracy:0.5\n",
      "The training loss at 467th epoch : 3.5013448900175677  Training Accuracy:0.5\n",
      "The training loss at 468th epoch : 3.501341816833435  Training Accuracy:0.5\n",
      "The training loss at 469th epoch : 3.501338750553256  Training Accuracy:0.5\n",
      "The training loss at 470th epoch : 3.5013356911543347  Training Accuracy:0.5\n",
      "The training loss at 471th epoch : 3.5013326386140675  Training Accuracy:0.5\n",
      "The training loss at 472th epoch : 3.5013295929099417  Training Accuracy:0.5\n",
      "The training loss at 473th epoch : 3.5013265540195357  Training Accuracy:0.5\n",
      "The training loss at 474th epoch : 3.5013235219205177  Training Accuracy:0.5\n",
      "The training loss at 475th epoch : 3.5013204965906457  Training Accuracy:0.5\n",
      "The training loss at 476th epoch : 3.5013174780077683  Training Accuracy:0.5\n",
      "The training loss at 477th epoch : 3.501314466149821  Training Accuracy:0.5\n",
      "The training loss at 478th epoch : 3.501311460994829  Training Accuracy:0.5\n",
      "The training loss at 479th epoch : 3.5013084625209054  Training Accuracy:0.5\n",
      "The training loss at 480th epoch : 3.501305470706251  Training Accuracy:0.5\n",
      "The training loss at 481th epoch : 3.5013024855291546  Training Accuracy:0.5\n",
      "The training loss at 482th epoch : 3.5012995069679897  Training Accuracy:0.5\n",
      "The training loss at 483th epoch : 3.501296535001218  Training Accuracy:0.5\n",
      "The training loss at 484th epoch : 3.501293569607386  Training Accuracy:0.5\n",
      "The training loss at 485th epoch : 3.501290610765127  Training Accuracy:0.5\n",
      "The training loss at 486th epoch : 3.501287658453158  Training Accuracy:0.5\n",
      "The training loss at 487th epoch : 3.5012847126502815  Training Accuracy:0.5\n",
      "The training loss at 488th epoch : 3.5012817733353843  Training Accuracy:0.5\n",
      "The training loss at 489th epoch : 3.501278840487436  Training Accuracy:0.5\n",
      "The training loss at 490th epoch : 3.501275914085492  Training Accuracy:0.5\n",
      "The training loss at 491th epoch : 3.501272994108688  Training Accuracy:0.5\n",
      "The training loss at 492th epoch : 3.5012700805362442  Training Accuracy:0.5\n",
      "The training loss at 493th epoch : 3.5012671733474625  Training Accuracy:0.5\n",
      "The training loss at 494th epoch : 3.501264272521726  Training Accuracy:0.5\n",
      "The training loss at 495th epoch : 3.5012613780385005  Training Accuracy:0.5\n",
      "The training loss at 496th epoch : 3.501258489877332  Training Accuracy:0.5\n",
      "The training loss at 497th epoch : 3.501255608017847  Training Accuracy:0.5\n",
      "The training loss at 498th epoch : 3.5012527324397533  Training Accuracy:0.5\n",
      "The training loss at 499th epoch : 3.501249863122838  Training Accuracy:0.5\n",
      "The training loss at 500th epoch : 3.5012470000469675  Training Accuracy:0.5\n",
      "The training loss at 501th epoch : 3.5012441431920873  Training Accuracy:0.5\n",
      "The training loss at 502th epoch : 3.501241292538222  Training Accuracy:0.5\n",
      "The training loss at 503th epoch : 3.5012384480654744  Training Accuracy:0.5\n",
      "The training loss at 504th epoch : 3.5012356097540254  Training Accuracy:0.5\n",
      "The training loss at 505th epoch : 3.501232777584134  Training Accuracy:0.5\n",
      "The training loss at 506th epoch : 3.5012299515361347  Training Accuracy:0.5\n",
      "The training loss at 507th epoch : 3.501227131590441  Training Accuracy:0.5\n",
      "The training loss at 508th epoch : 3.5012243177275417  Training Accuracy:0.5\n",
      "The training loss at 509th epoch : 3.501221509928002  Training Accuracy:0.5\n",
      "The training loss at 510th epoch : 3.5012187081724635  Training Accuracy:0.5\n",
      "The training loss at 511th epoch : 3.5012159124416415  Training Accuracy:0.5\n",
      "The training loss at 512th epoch : 3.501213122716329  Training Accuracy:0.5\n",
      "The training loss at 513th epoch : 3.501210338977391  Training Accuracy:0.5\n",
      "The training loss at 514th epoch : 3.5012075612057685  Training Accuracy:0.5\n",
      "The training loss at 515th epoch : 3.5012047893824763  Training Accuracy:0.5\n",
      "The training loss at 516th epoch : 3.5012020234886023  Training Accuracy:0.5\n",
      "The training loss at 517th epoch : 3.501199263505308  Training Accuracy:0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 518th epoch : 3.501196509413828  Training Accuracy:0.5\n",
      "The training loss at 519th epoch : 3.50119376119547  Training Accuracy:0.5\n",
      "The training loss at 520th epoch : 3.5011910188316127  Training Accuracy:0.5\n",
      "The training loss at 521th epoch : 3.501188282303707  Training Accuracy:0.5\n",
      "The training loss at 522th epoch : 3.5011855515932764  Training Accuracy:0.5\n",
      "The training loss at 523th epoch : 3.5011828266819145  Training Accuracy:0.5\n",
      "The training loss at 524th epoch : 3.5011801075512867  Training Accuracy:0.5\n",
      "The training loss at 525th epoch : 3.5011773941831286  Training Accuracy:0.5\n",
      "The training loss at 526th epoch : 3.5011746865592457  Training Accuracy:0.5\n",
      "The training loss at 527th epoch : 3.501171984661514  Training Accuracy:0.5\n",
      "The training loss at 528th epoch : 3.501169288471879  Training Accuracy:0.5\n",
      "The training loss at 529th epoch : 3.5011665979723543  Training Accuracy:0.5\n",
      "The training loss at 530th epoch : 3.501163913145024  Training Accuracy:0.5\n",
      "The training loss at 531th epoch : 3.501161233972041  Training Accuracy:0.5\n",
      "The training loss at 532th epoch : 3.5011585604356243  Training Accuracy:0.5\n",
      "The training loss at 533th epoch : 3.5011558925180633  Training Accuracy:0.5\n",
      "The training loss at 534th epoch : 3.5011532302017137  Training Accuracy:0.5\n",
      "The training loss at 535th epoch : 3.501150573468999  Training Accuracy:0.5\n",
      "The training loss at 536th epoch : 3.5011479223024087  Training Accuracy:0.5\n",
      "The training loss at 537th epoch : 3.5011452766845013  Training Accuracy:0.5\n",
      "The training loss at 538th epoch : 3.501142636597899  Training Accuracy:0.5\n",
      "The training loss at 539th epoch : 3.5011400020252923  Training Accuracy:0.5\n",
      "The training loss at 540th epoch : 3.5011373729494357  Training Accuracy:0.5\n",
      "The training loss at 541th epoch : 3.5011347493531506  Training Accuracy:0.5\n",
      "The training loss at 542th epoch : 3.501132131219323  Training Accuracy:0.5\n",
      "The training loss at 543th epoch : 3.5011295185309037  Training Accuracy:0.5\n",
      "The training loss at 544th epoch : 3.5011269112709082  Training Accuracy:0.5\n",
      "The training loss at 545th epoch : 3.501124309422416  Training Accuracy:0.5\n",
      "The training loss at 546th epoch : 3.5011217129685708  Training Accuracy:0.5\n",
      "The training loss at 547th epoch : 3.5011191218925797  Training Accuracy:0.5\n",
      "The training loss at 548th epoch : 3.501116536177714  Training Accuracy:0.5\n",
      "The training loss at 549th epoch : 3.501113955807307  Training Accuracy:0.5\n",
      "The training loss at 550th epoch : 3.5011113807647565  Training Accuracy:0.5\n",
      "The training loss at 551th epoch : 3.50110881103352  Training Accuracy:0.5\n",
      "The training loss at 552th epoch : 3.5011062465971197  Training Accuracy:0.5\n",
      "The training loss at 553th epoch : 3.501103687439139  Training Accuracy:0.5\n",
      "The training loss at 554th epoch : 3.5011011335432225  Training Accuracy:0.5\n",
      "The training loss at 555th epoch : 3.5010985848930765  Training Accuracy:0.5\n",
      "The training loss at 556th epoch : 3.501096041472469  Training Accuracy:0.5\n",
      "The training loss at 557th epoch : 3.5010935032652273  Training Accuracy:0.5\n",
      "The training loss at 558th epoch : 3.501090970255241  Training Accuracy:0.5\n",
      "The training loss at 559th epoch : 3.5010884424264583  Training Accuracy:0.5\n",
      "The training loss at 560th epoch : 3.5010859197628887  Training Accuracy:0.5\n",
      "The training loss at 561th epoch : 3.501083402248601  Training Accuracy:0.5\n",
      "The training loss at 562th epoch : 3.501080889867723  Training Accuracy:0.5\n",
      "The training loss at 563th epoch : 3.501078382604442  Training Accuracy:0.5\n",
      "The training loss at 564th epoch : 3.501075880443004  Training Accuracy:0.5\n",
      "The training loss at 565th epoch : 3.501073383367714  Training Accuracy:0.5\n",
      "The training loss at 566th epoch : 3.5010708913629345  Training Accuracy:0.5\n",
      "The training loss at 567th epoch : 3.5010684044130875  Training Accuracy:0.5\n",
      "The training loss at 568th epoch : 3.501065922502652  Training Accuracy:0.5\n",
      "The training loss at 569th epoch : 3.5010634456161642  Training Accuracy:0.5\n",
      "The training loss at 570th epoch : 3.5010609737382183  Training Accuracy:0.5\n",
      "The training loss at 571th epoch : 3.501058506853465  Training Accuracy:0.5\n",
      "The training loss at 572th epoch : 3.501056044946612  Training Accuracy:0.5\n",
      "The training loss at 573th epoch : 3.5010535880024234  Training Accuracy:0.5\n",
      "The training loss at 574th epoch : 3.50105113600572  Training Accuracy:0.5\n",
      "The training loss at 575th epoch : 3.5010486889413786  Training Accuracy:0.5\n",
      "The training loss at 576th epoch : 3.501046246794331  Training Accuracy:0.5\n",
      "The training loss at 577th epoch : 3.501043809549565  Training Accuracy:0.5\n",
      "The training loss at 578th epoch : 3.5010413771921236  Training Accuracy:0.5\n",
      "The training loss at 579th epoch : 3.5010389497071053  Training Accuracy:0.5\n",
      "The training loss at 580th epoch : 3.501036527079663  Training Accuracy:0.5\n",
      "The training loss at 581th epoch : 3.5010341092950035  Training Accuracy:0.5\n",
      "The training loss at 582th epoch : 3.501031696338389  Training Accuracy:0.5\n",
      "The training loss at 583th epoch : 3.501029288195135  Training Accuracy:0.5\n",
      "The training loss at 584th epoch : 3.5010268848506105  Training Accuracy:0.5\n",
      "The training loss at 585th epoch : 3.501024486290239  Training Accuracy:0.5\n",
      "The training loss at 586th epoch : 3.501022092499497  Training Accuracy:0.5\n",
      "The training loss at 587th epoch : 3.5010197034639132  Training Accuracy:0.5\n",
      "The training loss at 588th epoch : 3.5010173191690703  Training Accuracy:0.5\n",
      "The training loss at 589th epoch : 3.501014939600603  Training Accuracy:0.5\n",
      "The training loss at 590th epoch : 3.5010125647441983  Training Accuracy:0.5\n",
      "The training loss at 591th epoch : 3.501010194585596  Training Accuracy:0.5\n",
      "The training loss at 592th epoch : 3.501007829110587  Training Accuracy:0.5\n",
      "The training loss at 593th epoch : 3.501005468305014  Training Accuracy:0.5\n",
      "The training loss at 594th epoch : 3.5010031121547716  Training Accuracy:0.5\n",
      "The training loss at 595th epoch : 3.501000760645805  Training Accuracy:0.5\n",
      "The training loss at 596th epoch : 3.5009984137641106  Training Accuracy:0.5\n",
      "The training loss at 597th epoch : 3.500996071495736  Training Accuracy:0.5\n",
      "The training loss at 598th epoch : 3.500993733826779  Training Accuracy:0.5\n",
      "The training loss at 599th epoch : 3.5009914007433873  Training Accuracy:0.5\n",
      "The training loss at 600th epoch : 3.5009890722317594  Training Accuracy:0.5\n",
      "The training loss at 601th epoch : 3.500986748278143  Training Accuracy:0.5\n",
      "The training loss at 602th epoch : 3.5009844288688363  Training Accuracy:0.5\n",
      "The training loss at 603th epoch : 3.5009821139901858  Training Accuracy:0.5\n",
      "The training loss at 604th epoch : 3.500979803628588  Training Accuracy:0.5\n",
      "The training loss at 605th epoch : 3.500977497770488  Training Accuracy:0.5\n",
      "The training loss at 606th epoch : 3.50097519640238  Training Accuracy:0.5\n",
      "The training loss at 607th epoch : 3.5009728995108067  Training Accuracy:0.5\n",
      "The training loss at 608th epoch : 3.5009706070823587  Training Accuracy:0.5\n",
      "The training loss at 609th epoch : 3.500968319103675  Training Accuracy:0.5\n",
      "The training loss at 610th epoch : 3.500966035561443  Training Accuracy:0.5\n",
      "The training loss at 611th epoch : 3.500963756442397  Training Accuracy:0.5\n",
      "The training loss at 612th epoch : 3.5009614817333197  Training Accuracy:0.5\n",
      "The training loss at 613th epoch : 3.5009592114210397  Training Accuracy:0.5\n",
      "The training loss at 614th epoch : 3.5009569454924345  Training Accuracy:0.5\n",
      "The training loss at 615th epoch : 3.500954683934427  Training Accuracy:0.5\n",
      "The training loss at 616th epoch : 3.500952426733987  Training Accuracy:0.5\n",
      "The training loss at 617th epoch : 3.500950173878132  Training Accuracy:0.5\n",
      "The training loss at 618th epoch : 3.5009479253539237  Training Accuracy:0.5\n",
      "The training loss at 619th epoch : 3.500945681148472  Training Accuracy:0.5\n",
      "The training loss at 620th epoch : 3.500943441248931  Training Accuracy:0.5\n",
      "The training loss at 621th epoch : 3.5009412056425013  Training Accuracy:0.5\n",
      "The training loss at 622th epoch : 3.500938974316429  Training Accuracy:0.5\n",
      "The training loss at 623th epoch : 3.500936747258005  Training Accuracy:0.5\n",
      "The training loss at 624th epoch : 3.5009345244545655  Training Accuracy:0.5\n",
      "The training loss at 625th epoch : 3.500932305893492  Training Accuracy:0.5\n",
      "The training loss at 626th epoch : 3.5009300915622097  Training Accuracy:0.5\n",
      "The training loss at 627th epoch : 3.5009278814481894  Training Accuracy:0.5\n",
      "The training loss at 628th epoch : 3.5009256755389453  Training Accuracy:0.5\n",
      "The training loss at 629th epoch : 3.500923473822036  Training Accuracy:0.5\n",
      "The training loss at 630th epoch : 3.500921276285064  Training Accuracy:0.5\n",
      "The training loss at 631th epoch : 3.500919082915676  Training Accuracy:0.5\n",
      "The training loss at 632th epoch : 3.5009168937015622  Training Accuracy:0.5\n",
      "The training loss at 633th epoch : 3.5009147086304546  Training Accuracy:0.5\n",
      "The training loss at 634th epoch : 3.5009125276901307  Training Accuracy:0.5\n",
      "The training loss at 635th epoch : 3.5009103508684087  Training Accuracy:0.5\n",
      "The training loss at 636th epoch : 3.5009081781531517  Training Accuracy:0.5\n",
      "The training loss at 637th epoch : 3.500906009532264  Training Accuracy:0.5\n",
      "The training loss at 638th epoch : 3.5009038449936924  Training Accuracy:0.5\n",
      "The training loss at 639th epoch : 3.5009016845254264  Training Accuracy:0.5\n",
      "The training loss at 640th epoch : 3.5008995281154975  Training Accuracy:0.5\n",
      "The training loss at 641th epoch : 3.5008973757519795  Training Accuracy:0.5\n",
      "The training loss at 642th epoch : 3.5008952274229865  Training Accuracy:0.5\n",
      "The training loss at 643th epoch : 3.500893083116676  Training Accuracy:0.5\n",
      "The training loss at 644th epoch : 3.5008909428212447  Training Accuracy:0.5\n",
      "The training loss at 645th epoch : 3.500888806524932  Training Accuracy:0.5\n",
      "The training loss at 646th epoch : 3.5008866742160185  Training Accuracy:0.5\n",
      "The training loss at 647th epoch : 3.5008845458828244  Training Accuracy:0.5\n",
      "The training loss at 648th epoch : 3.5008824215137118  Training Accuracy:0.5\n",
      "The training loss at 649th epoch : 3.500880301097082  Training Accuracy:0.5\n",
      "The training loss at 650th epoch : 3.500878184621377  Training Accuracy:0.5\n",
      "The training loss at 651th epoch : 3.50087607207508  Training Accuracy:0.5\n",
      "The training loss at 652th epoch : 3.5008739634467125  Training Accuracy:0.5\n",
      "The training loss at 653th epoch : 3.500871858724837  Training Accuracy:0.5\n",
      "The training loss at 654th epoch : 3.500869757898055  Training Accuracy:0.5\n",
      "The training loss at 655th epoch : 3.5008676609550085  Training Accuracy:0.5\n",
      "The training loss at 656th epoch : 3.5008655678843765  Training Accuracy:0.5\n",
      "The training loss at 657th epoch : 3.500863478674879  Training Accuracy:0.5\n",
      "The training loss at 658th epoch : 3.5008613933152755  Training Accuracy:0.5\n",
      "The training loss at 659th epoch : 3.500859311794362  Training Accuracy:0.5\n",
      "The training loss at 660th epoch : 3.5008572341009745  Training Accuracy:0.5\n",
      "The training loss at 661th epoch : 3.5008551602239883  Training Accuracy:0.5\n",
      "The training loss at 662th epoch : 3.500853090152315  Training Accuracy:0.5\n",
      "The training loss at 663th epoch : 3.500851023874906  Training Accuracy:0.5\n",
      "The training loss at 664th epoch : 3.5008489613807496  Training Accuracy:0.5\n",
      "The training loss at 665th epoch : 3.5008469026588727  Training Accuracy:0.5\n",
      "The training loss at 666th epoch : 3.5008448476983394  Training Accuracy:0.5\n",
      "The training loss at 667th epoch : 3.5008427964882514  Training Accuracy:0.5\n",
      "The training loss at 668th epoch : 3.500840749017747  Training Accuracy:0.5\n",
      "The training loss at 669th epoch : 3.500838705276004  Training Accuracy:0.5\n",
      "The training loss at 670th epoch : 3.5008366652522342  Training Accuracy:0.5\n",
      "The training loss at 671th epoch : 3.5008346289356886  Training Accuracy:0.5\n",
      "The training loss at 672th epoch : 3.5008325963156532  Training Accuracy:0.5\n",
      "The training loss at 673th epoch : 3.500830567381452  Training Accuracy:0.5\n",
      "The training loss at 674th epoch : 3.500828542122445  Training Accuracy:0.5\n",
      "The training loss at 675th epoch : 3.5008265205280273  Training Accuracy:0.5\n",
      "The training loss at 676th epoch : 3.500824502587632  Training Accuracy:0.5\n",
      "The training loss at 677th epoch : 3.500822488290727  Training Accuracy:0.5\n",
      "The training loss at 678th epoch : 3.5008204776268155  Training Accuracy:0.5\n",
      "The training loss at 679th epoch : 3.5008184705854375  Training Accuracy:0.5\n",
      "The training loss at 680th epoch : 3.500816467156169  Training Accuracy:0.5\n",
      "The training loss at 681th epoch : 3.5008144673286186  Training Accuracy:0.5\n",
      "The training loss at 682th epoch : 3.5008124710924338  Training Accuracy:0.5\n",
      "The training loss at 683th epoch : 3.5008104784372938  Training Accuracy:0.5\n",
      "The training loss at 684th epoch : 3.500808489352915  Training Accuracy:0.5\n",
      "The training loss at 685th epoch : 3.500806503829048  Training Accuracy:0.5\n",
      "The training loss at 686th epoch : 3.5008045218554775  Training Accuracy:0.5\n",
      "The training loss at 687th epoch : 3.500802543422023  Training Accuracy:0.5\n",
      "The training loss at 688th epoch : 3.5008005685185384  Training Accuracy:0.5\n",
      "The training loss at 689th epoch : 3.500798597134912  Training Accuracy:0.5\n",
      "The training loss at 690th epoch : 3.5007966292610657  Training Accuracy:0.5\n",
      "The training loss at 691th epoch : 3.5007946648869552  Training Accuracy:0.5\n",
      "The training loss at 692th epoch : 3.5007927040025715  Training Accuracy:0.5\n",
      "The training loss at 693th epoch : 3.5007907465979367  Training Accuracy:0.5\n",
      "The training loss at 694th epoch : 3.5007887926631085  Training Accuracy:0.5\n",
      "The training loss at 695th epoch : 3.5007868421881776  Training Accuracy:0.5\n",
      "The training loss at 696th epoch : 3.500784895163267  Training Accuracy:0.5\n",
      "The training loss at 697th epoch : 3.5007829515785334  Training Accuracy:0.5\n",
      "The training loss at 698th epoch : 3.5007810114241664  Training Accuracy:0.5\n",
      "The training loss at 699th epoch : 3.500779074690389  Training Accuracy:0.5\n",
      "The training loss at 700th epoch : 3.5007771413674558  Training Accuracy:0.5\n",
      "The training loss at 701th epoch : 3.5007752114456547  Training Accuracy:0.5\n",
      "The training loss at 702th epoch : 3.5007732849153057  Training Accuracy:0.5\n",
      "The training loss at 703th epoch : 3.5007713617667613  Training Accuracy:0.5\n",
      "The training loss at 704th epoch : 3.500769441990406  Training Accuracy:0.5\n",
      "The training loss at 705th epoch : 3.5007675255766566  Training Accuracy:0.5\n",
      "The training loss at 706th epoch : 3.500765612515961  Training Accuracy:0.5\n",
      "The training loss at 707th epoch : 3.5007637027988  Training Accuracy:0.5\n",
      "The training loss at 708th epoch : 3.500761796415685  Training Accuracy:0.5\n",
      "The training loss at 709th epoch : 3.50075989335716  Training Accuracy:0.5\n",
      "The training loss at 710th epoch : 3.5007579936138  Training Accuracy:0.5\n",
      "The training loss at 711th epoch : 3.5007560971762093  Training Accuracy:0.5\n",
      "The training loss at 712th epoch : 3.5007542040350264  Training Accuracy:0.5\n",
      "The training loss at 713th epoch : 3.500752314180919  Training Accuracy:0.5\n",
      "The training loss at 714th epoch : 3.5007504276045864  Training Accuracy:0.5\n",
      "The training loss at 715th epoch : 3.500748544296758  Training Accuracy:0.5\n",
      "The training loss at 716th epoch : 3.500746664248194  Training Accuracy:0.5\n",
      "The training loss at 717th epoch : 3.5007447874496855  Training Accuracy:0.5\n",
      "The training loss at 718th epoch : 3.500742913892054  Training Accuracy:0.5\n",
      "The training loss at 719th epoch : 3.5007410435661503  Training Accuracy:0.5\n",
      "The training loss at 720th epoch : 3.500739176462856  Training Accuracy:0.5\n",
      "The training loss at 721th epoch : 3.5007373125730834  Training Accuracy:0.5\n",
      "The training loss at 722th epoch : 3.500735451887773  Training Accuracy:0.5\n",
      "The training loss at 723th epoch : 3.500733594397897  Training Accuracy:0.5\n",
      "The training loss at 724th epoch : 3.500731740094456  Training Accuracy:0.5\n",
      "The training loss at 725th epoch : 3.50072988896848  Training Accuracy:0.5\n",
      "The training loss at 726th epoch : 3.500728041011029  Training Accuracy:0.5\n",
      "The training loss at 727th epoch : 3.5007261962131917  Training Accuracy:0.5\n",
      "The training loss at 728th epoch : 3.500724354566087  Training Accuracy:0.5\n",
      "The training loss at 729th epoch : 3.500722516060862  Training Accuracy:0.5\n",
      "The training loss at 730th epoch : 3.500720680688693  Training Accuracy:0.5\n",
      "The training loss at 731th epoch : 3.5007188484407847  Training Accuracy:0.5\n",
      "The training loss at 732th epoch : 3.500717019308371  Training Accuracy:0.5\n",
      "The training loss at 733th epoch : 3.500715193282715  Training Accuracy:0.5\n",
      "The training loss at 734th epoch : 3.5007133703551063  Training Accuracy:0.5\n",
      "The training loss at 735th epoch : 3.500711550516865  Training Accuracy:0.5\n",
      "The training loss at 736th epoch : 3.5007097337593382  Training Accuracy:0.5\n",
      "The training loss at 737th epoch : 3.5007079200739013  Training Accuracy:0.5\n",
      "The training loss at 738th epoch : 3.500706109451958  Training Accuracy:0.5\n",
      "The training loss at 739th epoch : 3.50070430188494  Training Accuracy:0.5\n",
      "The training loss at 740th epoch : 3.500702497364306  Training Accuracy:0.5\n",
      "The training loss at 741th epoch : 3.500700695881544  Training Accuracy:0.5\n",
      "The training loss at 742th epoch : 3.5006988974281676  Training Accuracy:0.5\n",
      "The training loss at 743th epoch : 3.5006971019957196  Training Accuracy:0.5\n",
      "The training loss at 744th epoch : 3.500695309575769  Training Accuracy:0.5\n",
      "The training loss at 745th epoch : 3.500693520159912  Training Accuracy:0.5\n",
      "The training loss at 746th epoch : 3.500691733739773  Training Accuracy:0.5\n",
      "The training loss at 747th epoch : 3.500689950307003  Training Accuracy:0.5\n",
      "The training loss at 748th epoch : 3.500688169853279  Training Accuracy:0.5\n",
      "The training loss at 749th epoch : 3.500686392370306  Training Accuracy:0.5\n",
      "The training loss at 750th epoch : 3.500684617849815  Training Accuracy:0.5\n",
      "The training loss at 751th epoch : 3.5006828462835644  Training Accuracy:0.5\n",
      "The training loss at 752th epoch : 3.5006810776633386  Training Accuracy:0.5\n",
      "The training loss at 753th epoch : 3.5006793119809476  Training Accuracy:0.5\n",
      "The training loss at 754th epoch : 3.500677549228229  Training Accuracy:0.5\n",
      "The training loss at 755th epoch : 3.500675789397046  Training Accuracy:0.5\n",
      "The training loss at 756th epoch : 3.500674032479288  Training Accuracy:0.5\n",
      "The training loss at 757th epoch : 3.500672278466871  Training Accuracy:0.5\n",
      "The training loss at 758th epoch : 3.500670527351735  Training Accuracy:0.5\n",
      "The training loss at 759th epoch : 3.500668779125848  Training Accuracy:0.5\n",
      "The training loss at 760th epoch : 3.500667033781202  Training Accuracy:0.5\n",
      "The training loss at 761th epoch : 3.5006652913098155  Training Accuracy:0.5\n",
      "The training loss at 762th epoch : 3.5006635517037323  Training Accuracy:0.5\n",
      "The training loss at 763th epoch : 3.5006618149550217  Training Accuracy:0.5\n",
      "The training loss at 764th epoch : 3.5006600810557784  Training Accuracy:0.5\n",
      "The training loss at 765th epoch : 3.5006583499981208  Training Accuracy:0.5\n",
      "The training loss at 766th epoch : 3.500656621774195  Training Accuracy:0.5\n",
      "The training loss at 767th epoch : 3.5006548963761697  Training Accuracy:0.5\n",
      "The training loss at 768th epoch : 3.5006531737962394  Training Accuracy:0.5\n",
      "The training loss at 769th epoch : 3.5006514540266243  Training Accuracy:0.5\n",
      "The training loss at 770th epoch : 3.5006497370595673  Training Accuracy:0.5\n",
      "The training loss at 771th epoch : 3.500648022887338  Training Accuracy:0.5\n",
      "The training loss at 772th epoch : 3.500646311502229  Training Accuracy:0.5\n",
      "The training loss at 773th epoch : 3.500644602896558  Training Accuracy:0.5\n",
      "The training loss at 774th epoch : 3.500642897062667  Training Accuracy:0.5\n",
      "The training loss at 775th epoch : 3.500641193992921  Training Accuracy:0.5\n",
      "The training loss at 776th epoch : 3.500639493679712  Training Accuracy:0.5\n",
      "The training loss at 777th epoch : 3.5006377961154524  Training Accuracy:0.5\n",
      "The training loss at 778th epoch : 3.500636101292581  Training Accuracy:0.5\n",
      "The training loss at 779th epoch : 3.5006344092035606  Training Accuracy:0.5\n",
      "The training loss at 780th epoch : 3.5006327198408758  Training Accuracy:0.5\n",
      "The training loss at 781th epoch : 3.5006310331970365  Training Accuracy:0.5\n",
      "The training loss at 782th epoch : 3.500629349264575  Training Accuracy:0.5\n",
      "The training loss at 783th epoch : 3.500627668036049  Training Accuracy:0.5\n",
      "The training loss at 784th epoch : 3.500625989504037  Training Accuracy:0.5\n",
      "The training loss at 785th epoch : 3.5006243136611426  Training Accuracy:0.5\n",
      "The training loss at 786th epoch : 3.500622640499992  Training Accuracy:0.5\n",
      "The training loss at 787th epoch : 3.500620970013235  Training Accuracy:0.5\n",
      "The training loss at 788th epoch : 3.500619302193544  Training Accuracy:0.5\n",
      "The training loss at 789th epoch : 3.5006176370336135  Training Accuracy:0.5\n",
      "The training loss at 790th epoch : 3.5006159745261622  Training Accuracy:0.5\n",
      "The training loss at 791th epoch : 3.5006143146639315  Training Accuracy:0.5\n",
      "The training loss at 792th epoch : 3.5006126574396847  Training Accuracy:0.5\n",
      "The training loss at 793th epoch : 3.500611002846208  Training Accuracy:0.5\n",
      "The training loss at 794th epoch : 3.50060935087631  Training Accuracy:0.5\n",
      "The training loss at 795th epoch : 3.5006077015228225  Training Accuracy:0.5\n",
      "The training loss at 796th epoch : 3.500606054778598  Training Accuracy:0.5\n",
      "The training loss at 797th epoch : 3.500604410636513  Training Accuracy:0.5\n",
      "The training loss at 798th epoch : 3.5006027690894643  Training Accuracy:0.5\n",
      "The training loss at 799th epoch : 3.500601130130373  Training Accuracy:0.5\n",
      "The training loss at 800th epoch : 3.5005994937521807  Training Accuracy:0.5\n",
      "The training loss at 801th epoch : 3.500597859947851  Training Accuracy:0.5\n",
      "The training loss at 802th epoch : 3.5005962287103696  Training Accuracy:0.5\n",
      "The training loss at 803th epoch : 3.5005946000327435  Training Accuracy:0.5\n",
      "The training loss at 804th epoch : 3.5005929739080024  Training Accuracy:0.5\n",
      "The training loss at 805th epoch : 3.5005913503291963  Training Accuracy:0.5\n",
      "The training loss at 806th epoch : 3.500589729289398  Training Accuracy:0.5\n",
      "The training loss at 807th epoch : 3.5005881107817003  Training Accuracy:0.5\n",
      "The training loss at 808th epoch : 3.5005864947992182  Training Accuracy:0.5\n",
      "The training loss at 809th epoch : 3.5005848813350875  Training Accuracy:0.5\n",
      "The training loss at 810th epoch : 3.500583270382466  Training Accuracy:0.5\n",
      "The training loss at 811th epoch : 3.5005816619345316  Training Accuracy:0.5\n",
      "The training loss at 812th epoch : 3.5005800559844835  Training Accuracy:0.5\n",
      "The training loss at 813th epoch : 3.5005784525255423  Training Accuracy:0.5\n",
      "The training loss at 814th epoch : 3.5005768515509486  Training Accuracy:0.5\n",
      "The training loss at 815th epoch : 3.5005752530539644  Training Accuracy:0.5\n",
      "The training loss at 816th epoch : 3.5005736570278723  Training Accuracy:0.5\n",
      "The training loss at 817th epoch : 3.500572063465975  Training Accuracy:0.5\n",
      "The training loss at 818th epoch : 3.500570472361597  Training Accuracy:0.5\n",
      "The training loss at 819th epoch : 3.5005688837080817  Training Accuracy:0.5\n",
      "The training loss at 820th epoch : 3.500567297498794  Training Accuracy:0.5\n",
      "The training loss at 821th epoch : 3.5005657137271182  Training Accuracy:0.5\n",
      "The training loss at 822th epoch : 3.5005641323864594  Training Accuracy:0.5\n",
      "The training loss at 823th epoch : 3.500562553470243  Training Accuracy:0.5\n",
      "The training loss at 824th epoch : 3.5005609769719137  Training Accuracy:0.5\n",
      "The training loss at 825th epoch : 3.500559402884937  Training Accuracy:0.5\n",
      "The training loss at 826th epoch : 3.5005578312027983  Training Accuracy:0.5\n",
      "The training loss at 827th epoch : 3.500556261919002  Training Accuracy:0.5\n",
      "The training loss at 828th epoch : 3.5005546950270734  Training Accuracy:0.5\n",
      "The training loss at 829th epoch : 3.500553130520556  Training Accuracy:0.5\n",
      "The training loss at 830th epoch : 3.500551568393015  Training Accuracy:0.5\n",
      "The training loss at 831th epoch : 3.5005500086380335  Training Accuracy:0.5\n",
      "The training loss at 832th epoch : 3.500548451249214  Training Accuracy:0.5\n",
      "The training loss at 833th epoch : 3.50054689622018  Training Accuracy:0.5\n",
      "The training loss at 834th epoch : 3.500545343544572  Training Accuracy:0.5\n",
      "The training loss at 835th epoch : 3.5005437932160524  Training Accuracy:0.5\n",
      "The training loss at 836th epoch : 3.5005422452283  Training Accuracy:0.5\n",
      "The training loss at 837th epoch : 3.5005406995750157  Training Accuracy:0.5\n",
      "The training loss at 838th epoch : 3.500539156249917  Training Accuracy:0.5\n",
      "The training loss at 839th epoch : 3.500537615246741  Training Accuracy:0.5\n",
      "The training loss at 840th epoch : 3.5005360765592446  Training Accuracy:0.5\n",
      "The training loss at 841th epoch : 3.5005345401812025  Training Accuracy:0.5\n",
      "The training loss at 842th epoch : 3.5005330061064086  Training Accuracy:0.5\n",
      "The training loss at 843th epoch : 3.5005314743286755  Training Accuracy:0.5\n",
      "The training loss at 844th epoch : 3.5005299448418343  Training Accuracy:0.5\n",
      "The training loss at 845th epoch : 3.500528417639735  Training Accuracy:0.5\n",
      "The training loss at 846th epoch : 3.5005268927162447  Training Accuracy:0.5\n",
      "The training loss at 847th epoch : 3.5005253700652514  Training Accuracy:0.5\n",
      "The training loss at 848th epoch : 3.5005238496806594  Training Accuracy:0.5\n",
      "The training loss at 849th epoch : 3.500522331556392  Training Accuracy:0.5\n",
      "The training loss at 850th epoch : 3.5005208156863903  Training Accuracy:0.5\n",
      "The training loss at 851th epoch : 3.5005193020646144  Training Accuracy:0.5\n",
      "The training loss at 852th epoch : 3.5005177906850418  Training Accuracy:0.5\n",
      "The training loss at 853th epoch : 3.500516281541668  Training Accuracy:0.5\n",
      "The training loss at 854th epoch : 3.5005147746285066  Training Accuracy:0.5\n",
      "The training loss at 855th epoch : 3.5005132699395887  Training Accuracy:0.5\n",
      "The training loss at 856th epoch : 3.5005117674689643  Training Accuracy:0.5\n",
      "The training loss at 857th epoch : 3.5005102672107005  Training Accuracy:0.5\n",
      "The training loss at 858th epoch : 3.500508769158881  Training Accuracy:0.5\n",
      "The training loss at 859th epoch : 3.5005072733076092  Training Accuracy:0.5\n",
      "The training loss at 860th epoch : 3.500505779651004  Training Accuracy:0.5\n",
      "The training loss at 861th epoch : 3.500504288183204  Training Accuracy:0.5\n",
      "The training loss at 862th epoch : 3.5005027988983626  Training Accuracy:0.5\n",
      "The training loss at 863th epoch : 3.500501311790653  Training Accuracy:0.5\n",
      "The training loss at 864th epoch : 3.5004998268542638  Training Accuracy:0.5\n",
      "The training loss at 865th epoch : 3.500498344083402  Training Accuracy:0.5\n",
      "The training loss at 866th epoch : 3.500496863472292  Training Accuracy:0.5\n",
      "The training loss at 867th epoch : 3.500495385015174  Training Accuracy:0.5\n",
      "The training loss at 868th epoch : 3.5004939087063054  Training Accuracy:0.5\n",
      "The training loss at 869th epoch : 3.500492434539962  Training Accuracy:0.5\n",
      "The training loss at 870th epoch : 3.5004909625104363  Training Accuracy:0.5\n",
      "The training loss at 871th epoch : 3.5004894926120356  Training Accuracy:0.5\n",
      "The training loss at 872th epoch : 3.5004880248390857  Training Accuracy:0.5\n",
      "The training loss at 873th epoch : 3.5004865591859295  Training Accuracy:0.5\n",
      "The training loss at 874th epoch : 3.5004850956469253  Training Accuracy:0.5\n",
      "The training loss at 875th epoch : 3.500483634216449  Training Accuracy:0.5\n",
      "The training loss at 876th epoch : 3.5004821748888926  Training Accuracy:0.5\n",
      "The training loss at 877th epoch : 3.500480717658664  Training Accuracy:0.5\n",
      "The training loss at 878th epoch : 3.500479262520189  Training Accuracy:0.5\n",
      "The training loss at 879th epoch : 3.5004778094679083  Training Accuracy:0.5\n",
      "The training loss at 880th epoch : 3.50047635849628  Training Accuracy:0.5\n",
      "The training loss at 881th epoch : 3.5004749095997783  Training Accuracy:0.5\n",
      "The training loss at 882th epoch : 3.5004734627728924  Training Accuracy:0.5\n",
      "The training loss at 883th epoch : 3.500472018010129  Training Accuracy:0.5\n",
      "The training loss at 884th epoch : 3.5004705753060104  Training Accuracy:0.5\n",
      "The training loss at 885th epoch : 3.500469134655075  Training Accuracy:0.5\n",
      "The training loss at 886th epoch : 3.5004676960518766  Training Accuracy:0.5\n",
      "The training loss at 887th epoch : 3.5004662594909863  Training Accuracy:0.5\n",
      "The training loss at 888th epoch : 3.500464824966989  Training Accuracy:0.5\n",
      "The training loss at 889th epoch : 3.500463392474487  Training Accuracy:0.5\n",
      "The training loss at 890th epoch : 3.500461962008098  Training Accuracy:0.5\n",
      "The training loss at 891th epoch : 3.5004605335624555  Training Accuracy:0.5\n",
      "The training loss at 892th epoch : 3.5004591071322073  Training Accuracy:0.5\n",
      "The training loss at 893th epoch : 3.5004576827120184  Training Accuracy:0.5\n",
      "The training loss at 894th epoch : 3.5004562602965685  Training Accuracy:0.5\n",
      "The training loss at 895th epoch : 3.500454839880553  Training Accuracy:0.5\n",
      "The training loss at 896th epoch : 3.500453421458683  Training Accuracy:0.5\n",
      "The training loss at 897th epoch : 3.500452005025684  Training Accuracy:0.5\n",
      "The training loss at 898th epoch : 3.5004505905762975  Training Accuracy:0.5\n",
      "The training loss at 899th epoch : 3.50044917810528  Training Accuracy:0.5357142857142857\n",
      "The training loss at 900th epoch : 3.500447767607403  Training Accuracy:0.5357142857142857\n",
      "The training loss at 901th epoch : 3.5004463590774537  Training Accuracy:0.5357142857142857\n",
      "The training loss at 902th epoch : 3.500444952510234  Training Accuracy:0.5357142857142857\n",
      "The training loss at 903th epoch : 3.500443547900561  Training Accuracy:0.5357142857142857\n",
      "The training loss at 904th epoch : 3.500442145243266  Training Accuracy:0.5357142857142857\n",
      "The training loss at 905th epoch : 3.500440744533196  Training Accuracy:0.5357142857142857\n",
      "The training loss at 906th epoch : 3.500439345765213  Training Accuracy:0.5357142857142857\n",
      "The training loss at 907th epoch : 3.500437948934193  Training Accuracy:0.5357142857142857\n",
      "The training loss at 908th epoch : 3.500436554035027  Training Accuracy:0.5357142857142857\n",
      "The training loss at 909th epoch : 3.500435161062621  Training Accuracy:0.5357142857142857\n",
      "The training loss at 910th epoch : 3.5004337700118957  Training Accuracy:0.5357142857142857\n",
      "The training loss at 911th epoch : 3.5004323808777857  Training Accuracy:0.5357142857142857\n",
      "The training loss at 912th epoch : 3.5004309936552414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 913th epoch : 3.500429608339226  Training Accuracy:0.5357142857142857\n",
      "The training loss at 914th epoch : 3.5004282249247183  Training Accuracy:0.5357142857142857\n",
      "The training loss at 915th epoch : 3.5004268434067116  Training Accuracy:0.5357142857142857\n",
      "The training loss at 916th epoch : 3.5004254637802124  Training Accuracy:0.5357142857142857\n",
      "The training loss at 917th epoch : 3.5004240860402427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 918th epoch : 3.500422710181838  Training Accuracy:0.5357142857142857\n",
      "The training loss at 919th epoch : 3.5004213362000485  Training Accuracy:0.5357142857142857\n",
      "The training loss at 920th epoch : 3.5004199640899376  Training Accuracy:0.5357142857142857\n",
      "The training loss at 921th epoch : 3.500418593846584  Training Accuracy:0.5357142857142857\n",
      "The training loss at 922th epoch : 3.500417225465079  Training Accuracy:0.5357142857142857\n",
      "The training loss at 923th epoch : 3.50041585894053  Training Accuracy:0.5357142857142857\n",
      "The training loss at 924th epoch : 3.5004144942680555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 925th epoch : 3.5004131314427904  Training Accuracy:0.5357142857142857\n",
      "The training loss at 926th epoch : 3.5004117704598823  Training Accuracy:0.5357142857142857\n",
      "The training loss at 927th epoch : 3.5004104113144923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 928th epoch : 3.500409054001796  Training Accuracy:0.5357142857142857\n",
      "The training loss at 929th epoch : 3.500407698516982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 930th epoch : 3.5004063448552527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 931th epoch : 3.500404993011825  Training Accuracy:0.5357142857142857\n",
      "The training loss at 932th epoch : 3.500403642981927  Training Accuracy:0.5357142857142857\n",
      "The training loss at 933th epoch : 3.500402294760804  Training Accuracy:0.5357142857142857\n",
      "The training loss at 934th epoch : 3.500400948343711  Training Accuracy:0.5357142857142857\n",
      "The training loss at 935th epoch : 3.5003996037259184  Training Accuracy:0.5357142857142857\n",
      "The training loss at 936th epoch : 3.5003982609027093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 937th epoch : 3.500396919869381  Training Accuracy:0.5357142857142857\n",
      "The training loss at 938th epoch : 3.500395580621243  Training Accuracy:0.5357142857142857\n",
      "The training loss at 939th epoch : 3.5003942431536177  Training Accuracy:0.5357142857142857\n",
      "The training loss at 940th epoch : 3.5003929074618427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 941th epoch : 3.500391573541266  Training Accuracy:0.5357142857142857\n",
      "The training loss at 942th epoch : 3.5003902413872514  Training Accuracy:0.5357142857142857\n",
      "The training loss at 943th epoch : 3.500388910995173  Training Accuracy:0.5357142857142857\n",
      "The training loss at 944th epoch : 3.5003875823604202  Training Accuracy:0.5357142857142857\n",
      "The training loss at 945th epoch : 3.500386255478394  Training Accuracy:0.5357142857142857\n",
      "The training loss at 946th epoch : 3.500384930344509  Training Accuracy:0.5357142857142857\n",
      "The training loss at 947th epoch : 3.5003836069541916  Training Accuracy:0.5357142857142857\n",
      "The training loss at 948th epoch : 3.500382285302882  Training Accuracy:0.5357142857142857\n",
      "The training loss at 949th epoch : 3.500380965386033  Training Accuracy:0.5357142857142857\n",
      "The training loss at 950th epoch : 3.50037964719911  Training Accuracy:0.5357142857142857\n",
      "The training loss at 951th epoch : 3.5003783307375906  Training Accuracy:0.5357142857142857\n",
      "The training loss at 952th epoch : 3.5003770159969663  Training Accuracy:0.5357142857142857\n",
      "The training loss at 953th epoch : 3.500375702972739  Training Accuracy:0.5357142857142857\n",
      "The training loss at 954th epoch : 3.5003743916604257  Training Accuracy:0.5357142857142857\n",
      "The training loss at 955th epoch : 3.500373082055554  Training Accuracy:0.5357142857142857\n",
      "The training loss at 956th epoch : 3.5003717741536646  Training Accuracy:0.5357142857142857\n",
      "The training loss at 957th epoch : 3.5003704679503107  Training Accuracy:0.5357142857142857\n",
      "The training loss at 958th epoch : 3.5003691634410576  Training Accuracy:0.5357142857142857\n",
      "The training loss at 959th epoch : 3.5003678606214836  Training Accuracy:0.5357142857142857\n",
      "The training loss at 960th epoch : 3.500366559487178  Training Accuracy:0.5357142857142857\n",
      "The training loss at 961th epoch : 3.5003652600337434  Training Accuracy:0.5357142857142857\n",
      "The training loss at 962th epoch : 3.500363962256794  Training Accuracy:0.5357142857142857\n",
      "The training loss at 963th epoch : 3.5003626661519567  Training Accuracy:0.5357142857142857\n",
      "The training loss at 964th epoch : 3.50036137171487  Training Accuracy:0.5357142857142857\n",
      "The training loss at 965th epoch : 3.500360078941185  Training Accuracy:0.5357142857142857\n",
      "The training loss at 966th epoch : 3.500358787826564  Training Accuracy:0.5357142857142857\n",
      "The training loss at 967th epoch : 3.500357498366682  Training Accuracy:0.5357142857142857\n",
      "The training loss at 968th epoch : 3.5003562105572255  Training Accuracy:0.5357142857142857\n",
      "The training loss at 969th epoch : 3.500354924393893  Training Accuracy:0.5357142857142857\n",
      "The training loss at 970th epoch : 3.500353639872396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 971th epoch : 3.5003523569884556  Training Accuracy:0.5357142857142857\n",
      "The training loss at 972th epoch : 3.500351075737806  Training Accuracy:0.5357142857142857\n",
      "The training loss at 973th epoch : 3.500349796116194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 974th epoch : 3.500348518119375  Training Accuracy:0.5357142857142857\n",
      "The training loss at 975th epoch : 3.5003472417431203  Training Accuracy:0.5357142857142857\n",
      "The training loss at 976th epoch : 3.5003459669832093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 977th epoch : 3.5003446938354346  Training Accuracy:0.5357142857142857\n",
      "The training loss at 978th epoch : 3.5003434222956002  Training Accuracy:0.5357142857142857\n",
      "The training loss at 979th epoch : 3.5003421523595217  Training Accuracy:0.5357142857142857\n",
      "The training loss at 980th epoch : 3.5003408840230255  Training Accuracy:0.5357142857142857\n",
      "The training loss at 981th epoch : 3.5003396172819494  Training Accuracy:0.5357142857142857\n",
      "The training loss at 982th epoch : 3.5003383521321436  Training Accuracy:0.5357142857142857\n",
      "The training loss at 983th epoch : 3.5003370885694687  Training Accuracy:0.5357142857142857\n",
      "The training loss at 984th epoch : 3.5003358265897973  Training Accuracy:0.5357142857142857\n",
      "The training loss at 985th epoch : 3.5003345661890126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 986th epoch : 3.500333307363009  Training Accuracy:0.5357142857142857\n",
      "The training loss at 987th epoch : 3.500332050107693  Training Accuracy:0.5357142857142857\n",
      "The training loss at 988th epoch : 3.500330794418981  Training Accuracy:0.5357142857142857\n",
      "The training loss at 989th epoch : 3.5003295402928014  Training Accuracy:0.5357142857142857\n",
      "The training loss at 990th epoch : 3.5003282877250936  Training Accuracy:0.5357142857142857\n",
      "The training loss at 991th epoch : 3.500327036711808  Training Accuracy:0.5357142857142857\n",
      "The training loss at 992th epoch : 3.5003257872489044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 993th epoch : 3.500324539332357  Training Accuracy:0.5357142857142857\n",
      "The training loss at 994th epoch : 3.5003232929581474  Training Accuracy:0.5357142857142857\n",
      "The training loss at 995th epoch : 3.50032204812227  Training Accuracy:0.5357142857142857\n",
      "The training loss at 996th epoch : 3.50032080482073  Training Accuracy:0.5357142857142857\n",
      "The training loss at 997th epoch : 3.5003195630495427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 998th epoch : 3.500318322804734  Training Accuracy:0.5357142857142857\n",
      "The training loss at 999th epoch : 3.5003170840823423  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1000th epoch : 3.500315846878414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1001th epoch : 3.500314611189009  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1002th epoch : 3.5003133770101953  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1003th epoch : 3.5003121443380527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1004th epoch : 3.5003109131686725  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1005th epoch : 3.500309683498154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1006th epoch : 3.5003084553226094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1007th epoch : 3.5003072286381607  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1008th epoch : 3.500306003440939  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1009th epoch : 3.500304779727087  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1010th epoch : 3.500303557492759  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1011th epoch : 3.500302336734116  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1012th epoch : 3.5003011174473326  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1013th epoch : 3.5002998996285926  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1014th epoch : 3.500298683274089  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1015th epoch : 3.500297468380027  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1016th epoch : 3.50029625494262  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1017th epoch : 3.500295042958092  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1018th epoch : 3.500293832422678  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1019th epoch : 3.500292623332622  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1020th epoch : 3.5002914156841785  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1021th epoch : 3.500290209473612  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1022th epoch : 3.500289004697196  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1023th epoch : 3.5002878013512153  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1024th epoch : 3.500286599431964  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1025th epoch : 3.5002853989357456  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1026th epoch : 3.500284199858874  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1027th epoch : 3.5002830021976727  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1028th epoch : 3.5002818059484744  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1029th epoch : 3.5002806111076223  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1030th epoch : 3.5002794176714693  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1031th epoch : 3.5002782256363765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1032th epoch : 3.500277034998717  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1033th epoch : 3.500275845754871  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1034th epoch : 3.5002746579012296  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1035th epoch : 3.500273471434194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1036th epoch : 3.500272286350173  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1037th epoch : 3.500271102645587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1038th epoch : 3.5002699203168635  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1039th epoch : 3.5002687393604415  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1040th epoch : 3.5002675597727686  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1041th epoch : 3.5002663815503006  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1042th epoch : 3.5002652046895046  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1043th epoch : 3.5002640291868556  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1044th epoch : 3.5002628550388377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1045th epoch : 3.5002616822419457  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1046th epoch : 3.5002605107926814  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1047th epoch : 3.5002593406875575  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1048th epoch : 3.500258171923095  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1049th epoch : 3.5002570044958246  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1050th epoch : 3.5002558384022846  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1051th epoch : 3.5002546736390245  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1052th epoch : 3.5002535102026004  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1053th epoch : 3.50025234808958  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1054th epoch : 3.500251187296537  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1055th epoch : 3.5002500278200563  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1056th epoch : 3.500248869656731  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1057th epoch : 3.5002477128031626  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1058th epoch : 3.5002465572559616  Training Accuracy:0.5357142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1059th epoch : 3.5002454030117476  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1060th epoch : 3.500244250067149  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1061th epoch : 3.500243098418802  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1062th epoch : 3.5002419480633526  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1063th epoch : 3.500240798997455  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1064th epoch : 3.5002396512177723  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1065th epoch : 3.5002385047209756  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1066th epoch : 3.500237359503745  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1067th epoch : 3.500236215562769  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1068th epoch : 3.5002350728947453  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1069th epoch : 3.5002339314963793  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1070th epoch : 3.5002327913643847  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1071th epoch : 3.5002316524954846  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1072th epoch : 3.5002305148864097  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1073th epoch : 3.5002293785338994  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1074th epoch : 3.5002282434347016  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1075th epoch : 3.500227109585572  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1076th epoch : 3.500225976983275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1077th epoch : 3.500224845624584  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1078th epoch : 3.5002237155062788  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1079th epoch : 3.500222586625149  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1080th epoch : 3.500221458977992  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1081th epoch : 3.5002203325616135  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1082th epoch : 3.5002192073728264  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1083th epoch : 3.500218083408453  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1084th epoch : 3.500216960665323  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1085th epoch : 3.5002158391402745  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1086th epoch : 3.500214718830153  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1087th epoch : 3.5002135997318127  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1088th epoch : 3.500212481842116  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1089th epoch : 3.5002113651579316  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1090th epoch : 3.5002102496761385  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1091th epoch : 3.500209135393622  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1092th epoch : 3.5002080223072762  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1093th epoch : 3.500206910414002  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1094th epoch : 3.5002057997107086  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1095th epoch : 3.5002046901943134  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1096th epoch : 3.500203581861742  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1097th epoch : 3.500202474709926  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1098th epoch : 3.500201368735806  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1099th epoch : 3.5002002639363305  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1100th epoch : 3.5001991603084552  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1101th epoch : 3.500198057849144  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1102th epoch : 3.500196956555367  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1103th epoch : 3.5001958564241034  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1104th epoch : 3.5001947574523395  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1105th epoch : 3.500193659637069  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1106th epoch : 3.5001925629752937  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1107th epoch : 3.5001914674640218  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1108th epoch : 3.5001903731002706  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1109th epoch : 3.500189279881063  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1110th epoch : 3.5001881878034307  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1111th epoch : 3.5001870968644124  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1112th epoch : 3.500186007061054  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1113th epoch : 3.5001849183904095  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1114th epoch : 3.500183830849539  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1115th epoch : 3.500182744435511  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1116th epoch : 3.500181659145401  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1117th epoch : 3.5001805749762913  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1118th epoch : 3.5001794919252722  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1119th epoch : 3.5001784099894406  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1120th epoch : 3.500177329165901  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1121th epoch : 3.5001762494517648  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1122th epoch : 3.500175170844151  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1123th epoch : 3.5001740933401853  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1124th epoch : 3.5001730169370004  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1125th epoch : 3.5001719416317365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1126th epoch : 3.500170867421541  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1127th epoch : 3.500169794303568  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1128th epoch : 3.5001687222749784  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1129th epoch : 3.5001676513329407  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1130th epoch : 3.5001665814746294  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1131th epoch : 3.5001655126972273  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1132th epoch : 3.5001644449979237  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1133th epoch : 3.5001633783739137  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1134th epoch : 3.5001623128224004  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1135th epoch : 3.5001612483405937  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1136th epoch : 3.50016018492571  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1137th epoch : 3.500159122574973  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1138th epoch : 3.5001580612856125  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1139th epoch : 3.5001570010548657  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1140th epoch : 3.500155941879976  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1141th epoch : 3.500154883758195  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1142th epoch : 3.500153826686778  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1143th epoch : 3.5001527706629902  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1144th epoch : 3.500151715684102  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1145th epoch : 3.5001506617473903  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1146th epoch : 3.5001496088501396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1147th epoch : 3.500148556989639  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1148th epoch : 3.500147506163187  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1149th epoch : 3.5001464563680864  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1150th epoch : 3.5001454076016474  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1151th epoch : 3.5001443598611868  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1152th epoch : 3.5001433131440276  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1153th epoch : 3.5001422674475  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1154th epoch : 3.5001412227689395  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1155th epoch : 3.5001401791056894  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1156th epoch : 3.500139136455098  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1157th epoch : 3.5001380948145213  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1158th epoch : 3.5001370541813204  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1159th epoch : 3.5001360145528646  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1160th epoch : 3.5001349759265272  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1161th epoch : 3.50013393829969  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1162th epoch : 3.500132901669739  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1163th epoch : 3.500131866034069  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1164th epoch : 3.500130831390079  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1165th epoch : 3.5001297977351746  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1166th epoch : 3.5001287650667687  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1167th epoch : 3.5001277333822793  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1168th epoch : 3.500126702679131  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1169th epoch : 3.5001256729547547  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1170th epoch : 3.500124644206587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1171th epoch : 3.5001236164320715  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1172th epoch : 3.5001225896286563  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1173th epoch : 3.5001215637937975  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1174th epoch : 3.500120538924956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1175th epoch : 3.5001195150195996  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1176th epoch : 3.500118492075201  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1177th epoch : 3.5001174700892403  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1178th epoch : 3.500116449059202  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1179th epoch : 3.5001154289825784  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1180th epoch : 3.5001144098568666  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1181th epoch : 3.5001133916795695  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1182th epoch : 3.5001123744481966  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1183th epoch : 3.5001113581602628  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1184th epoch : 3.500110342813289  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1185th epoch : 3.5001093284048026  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1186th epoch : 3.500108314932336  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1187th epoch : 3.500107302393428  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1188th epoch : 3.5001062907856224  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1189th epoch : 3.5001052801064696  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1190th epoch : 3.5001042703535252  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1191th epoch : 3.5001032615243517  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1192th epoch : 3.500102253616516  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1193th epoch : 3.500101246627591  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1194th epoch : 3.5001002405551565  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1195th epoch : 3.500099235396796  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1196th epoch : 3.5000982311501  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1197th epoch : 3.5000972278126645  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1198th epoch : 3.5000962253820913  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1199th epoch : 3.500095223855987  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1200th epoch : 3.5000942232319647  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1201th epoch : 3.5000932235076423  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1202th epoch : 3.5000922246806443  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1203th epoch : 3.5000912267485993  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1204th epoch : 3.500090229709143  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1205th epoch : 3.5000892335599154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1206th epoch : 3.500088238298563  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1207th epoch : 3.5000872439227364  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1208th epoch : 3.500086250430093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1209th epoch : 3.5000852578182955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1210th epoch : 3.500084266085011  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1211th epoch : 3.5000832752279134  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1212th epoch : 3.500082285244681  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1213th epoch : 3.5000812961329975  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1214th epoch : 3.5000803078905527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1215th epoch : 3.5000793205150407  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1216th epoch : 3.5000783340041624  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1217th epoch : 3.5000773483556222  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1218th epoch : 3.5000763635671315  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1219th epoch : 3.5000753796364057  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1220th epoch : 3.5000743965611663  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1221th epoch : 3.5000734143391394  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1222th epoch : 3.5000724329680573  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1223th epoch : 3.500071452445656  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1224th epoch : 3.5000704727696785  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1225th epoch : 3.5000694939378714  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1226th epoch : 3.5000685159479876  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1227th epoch : 3.500067538797784  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1228th epoch : 3.5000665624850242  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1229th epoch : 3.5000655870074757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1230th epoch : 3.5000646123629116  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1231th epoch : 3.5000636385491095  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1232th epoch : 3.500062665563853  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1233th epoch : 3.5000616934049305  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1234th epoch : 3.5000607220701343  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1235th epoch : 3.5000597515572633  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1236th epoch : 3.500058781864121  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1237th epoch : 3.500057812988515  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1238th epoch : 3.5000568449282596  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1239th epoch : 3.500055877681172  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1240th epoch : 3.500054911245076  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1241th epoch : 3.5000539456177995  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1242th epoch : 3.500052980797175  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1243th epoch : 3.500052016781042  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1244th epoch : 3.5000510535672418  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1245th epoch : 3.5000500911536228  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1246th epoch : 3.5000491295380374  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1247th epoch : 3.5000481687183433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1248th epoch : 3.500047208692403  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1249th epoch : 3.5000462494580824  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1250th epoch : 3.5000452910132545  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1251th epoch : 3.500044333355796  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1252th epoch : 3.5000433764835877  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1253th epoch : 3.5000424203945166  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1254th epoch : 3.500041465086473  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1255th epoch : 3.5000405105573527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1256th epoch : 3.5000395568050564  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1257th epoch : 3.5000386038274893  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1258th epoch : 3.500037651622561  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1259th epoch : 3.5000367001881862  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1260th epoch : 3.5000357495222834  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1261th epoch : 3.500034799622777  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1262th epoch : 3.5000338504875956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1263th epoch : 3.500032902114672  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1264th epoch : 3.5000319545019436  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1265th epoch : 3.500031007647353  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1266th epoch : 3.500030061548847  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1267th epoch : 3.500029116204377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1268th epoch : 3.5000281716118984  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1269th epoch : 3.500027227769372  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1270th epoch : 3.5000262846747634  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1271th epoch : 3.5000253423260412  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1272th epoch : 3.5000244007211805  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1273th epoch : 3.5000234598581583  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1274th epoch : 3.500022519734959  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1275th epoch : 3.500021580349569  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1276th epoch : 3.5000206416999804  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1277th epoch : 3.50001970378419  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1278th epoch : 3.500018766600198  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1279th epoch : 3.500017830146009  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1280th epoch : 3.5000168944196335  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1281th epoch : 3.500015959419085  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1282th epoch : 3.5000150251423814  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1283th epoch : 3.5000140915875453  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1284th epoch : 3.5000131587526044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1285th epoch : 3.500012226635589  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1286th epoch : 3.500011295234535  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1287th epoch : 3.5000103645474816  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1288th epoch : 3.500009434572474  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1289th epoch : 3.50000850530756  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1290th epoch : 3.5000075767507925  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1291th epoch : 3.500006648900228  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1292th epoch : 3.500005721753928  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1293th epoch : 3.5000047953099576  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1294th epoch : 3.500003869566386  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1295th epoch : 3.5000029445212877  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1296th epoch : 3.50000202017274  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1297th epoch : 3.500001096518826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1298th epoch : 3.500000173557631  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1299th epoch : 3.499999251287245  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1300th epoch : 3.4999983297057637  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1301th epoch : 3.4999974088112853  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1302th epoch : 3.4999964886019126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1303th epoch : 3.499995569075752  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1304th epoch : 3.499994650230915  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1305th epoch : 3.499993732065516  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1306th epoch : 3.499992814577675  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1307th epoch : 3.499991897765514  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1308th epoch : 3.499990981627161  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1309th epoch : 3.499990066160747  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1310th epoch : 3.499989151364407  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1311th epoch : 3.49998823723628  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1312th epoch : 3.49998732377451  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1313th epoch : 3.499986410977243  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1314th epoch : 3.4999854988426313  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1315th epoch : 3.499984587368829  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1316th epoch : 3.499983676553996  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1317th epoch : 3.499982766396294  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1318th epoch : 3.499981856893891  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1319th epoch : 3.499980948044957  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1320th epoch : 3.4999800398476673  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1321th epoch : 3.4999791323002  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1322th epoch : 3.499978225400737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1323th epoch : 3.4999773191474657  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1324th epoch : 3.4999764135385756  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1325th epoch : 3.499975508572261  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1326th epoch : 3.499974604246719  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1327th epoch : 3.4999737005601514  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1328th epoch : 3.4999727975107637  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1329th epoch : 3.499971895096765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1330th epoch : 3.499970993316369  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1331th epoch : 3.499970092167791  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1332th epoch : 3.4999691916492526  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1333th epoch : 3.499968291758978  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1334th epoch : 3.499967392495194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1335th epoch : 3.4999664938561335  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1336th epoch : 3.4999655958400315  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1337th epoch : 3.499964698445127  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1338th epoch : 3.499963801669663  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1339th epoch : 3.499962905511886  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1340th epoch : 3.4999620099700457  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1341th epoch : 3.499961115042396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1342th epoch : 3.499960220727195  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1343th epoch : 3.4999593270227027  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1344th epoch : 3.4999584339271848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1345th epoch : 3.499957541438909  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1346th epoch : 3.4999566495561476  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1347th epoch : 3.499955758277176  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1348th epoch : 3.499954867600273  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1349th epoch : 3.499953977523722  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1350th epoch : 3.499953088045809  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1351th epoch : 3.499952199164823  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1352th epoch : 3.499951310879058  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1353th epoch : 3.499950423186811  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1354th epoch : 3.499949536086382  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1355th epoch : 3.499948649576075  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1356th epoch : 3.4999477636541974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1357th epoch : 3.49994687831906  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1358th epoch : 3.499945993568978  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1359th epoch : 3.499945109402268  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1360th epoch : 3.4999442258172517  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1361th epoch : 3.499943342812254  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1362th epoch : 3.4999424603856037  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1363th epoch : 3.499941578535631  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1364th epoch : 3.499940697260672  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1365th epoch : 3.4999398165590647  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1366th epoch : 3.4999389364291513  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1367th epoch : 3.4999380568692766  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1368th epoch : 3.4999371778777895  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1369th epoch : 3.4999362994530414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1370th epoch : 3.4999354215933884  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1371th epoch : 3.499934544297189  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1372th epoch : 3.499933667562805  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1373th epoch : 3.4999327913886016  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1374th epoch : 3.499931915772948  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1375th epoch : 3.4999310407142157  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1376th epoch : 3.4999301662107802  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1377th epoch : 3.49992929226102  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1378th epoch : 3.4999284188633166  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1379th epoch : 3.499927546016056  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1380th epoch : 3.499926673717626  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1381th epoch : 3.499925801966418  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1382th epoch : 3.499924930760827  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1383th epoch : 3.499924060099252  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1384th epoch : 3.499923189980093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1385th epoch : 3.4999223204017555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1386th epoch : 3.499921451362647  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1387th epoch : 3.499920582861178  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1388th epoch : 3.499919714895763  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1389th epoch : 3.4999188474648193  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1390th epoch : 3.4999179805667677  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1391th epoch : 3.499917114200031  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1392th epoch : 3.499916248363037  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1393th epoch : 3.499915383054215  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1394th epoch : 3.499914518271998  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1395th epoch : 3.4999136540148226  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1396th epoch : 3.4999127902811282  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1397th epoch : 3.4999119270693564  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1398th epoch : 3.499911064377953  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1399th epoch : 3.4999102022053674  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1400th epoch : 3.49990934055005  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1401th epoch : 3.4999084794104562  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1402th epoch : 3.499907618785044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1403th epoch : 3.4999067586722736  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1404th epoch : 3.4999058990706096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1405th epoch : 3.499905039978518  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1406th epoch : 3.4999041813944696  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1407th epoch : 3.4999033233169365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1408th epoch : 3.4999024657443956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1409th epoch : 3.499901608675325  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1410th epoch : 3.499900752108207  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1411th epoch : 3.499899896041527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1412th epoch : 3.499899040473772  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1413th epoch : 3.499898185403433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1414th epoch : 3.4998973308290044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1415th epoch : 3.499896476748982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1416th epoch : 3.4998956231618665  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1417th epoch : 3.49989477006616  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1418th epoch : 3.4998939174603683  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1419th epoch : 3.499893065342999  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1420th epoch : 3.4998922137125645  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1421th epoch : 3.4998913625675785  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1422th epoch : 3.499890511906558  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1423th epoch : 3.4998896617280235  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1424th epoch : 3.4998888120304974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1425th epoch : 3.4998879628125055  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1426th epoch : 3.4998871140725765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1427th epoch : 3.4998862658092422  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1428th epoch : 3.499885418021036  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1429th epoch : 3.4998845707064956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1430th epoch : 3.4998837238641602  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1431th epoch : 3.4998828774925737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1432th epoch : 3.499882031590281  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1433th epoch : 3.49988118615583  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1434th epoch : 3.4998803411877724  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1435th epoch : 3.499879496684662  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1436th epoch : 3.4998786526450547  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1437th epoch : 3.4998778090675113  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1438th epoch : 3.499876965950593  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1439th epoch : 3.499876123292865  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1440th epoch : 3.499875281092894  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1441th epoch : 3.4998744393492522  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1442th epoch : 3.499873598060512  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1443th epoch : 3.499872757225248  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1444th epoch : 3.4998719168420402  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1445th epoch : 3.4998710769094696  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1446th epoch : 3.4998702374261197  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1447th epoch : 3.4998693983905773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1448th epoch : 3.4998685598014316  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1449th epoch : 3.499867721657275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1450th epoch : 3.499866883956701  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1451th epoch : 3.4998660466983083  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1452th epoch : 3.4998652098806957  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1453th epoch : 3.4998643735024664  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1454th epoch : 3.4998635375622253  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1455th epoch : 3.49986270205858  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1456th epoch : 3.499861866990141  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1457th epoch : 3.499861032355522  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1458th epoch : 3.4998601981533377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1459th epoch : 3.499859364382207  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1460th epoch : 3.49985853104075  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1461th epoch : 3.4998576981275913  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1462th epoch : 3.4998568656413553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1463th epoch : 3.4998560335806714  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1464th epoch : 3.4998552019441704  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1465th epoch : 3.4998543707304863  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1466th epoch : 3.499853539938255  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1467th epoch : 3.4998527095661145  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1468th epoch : 3.499851879612707  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1469th epoch : 3.499851050076676  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1470th epoch : 3.499850220956668  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1471th epoch : 3.4998493922513307  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1472th epoch : 3.4998485639593166  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1473th epoch : 3.4998477360792783  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1474th epoch : 3.499846908609873  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1475th epoch : 3.4998460815497587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1476th epoch : 3.499845254897597  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1477th epoch : 3.499844428652051  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1478th epoch : 3.4998436028117874  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1479th epoch : 3.4998427773754743  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1480th epoch : 3.4998419523417827  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1481th epoch : 3.4998411277093866  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1482th epoch : 3.4998403034769607  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1483th epoch : 3.499839479643184  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1484th epoch : 3.499838656206737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1485th epoch : 3.4998378331663025  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1486th epoch : 3.4998370105205665  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1487th epoch : 3.4998361882682163  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1488th epoch : 3.4998353664079427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1489th epoch : 3.4998345449384374  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1490th epoch : 3.499833723858396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1491th epoch : 3.4998329031665163  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1492th epoch : 3.499832082861497  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1493th epoch : 3.4998312629420405  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1494th epoch : 3.4998304434068515  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1495th epoch : 3.4998296242546365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1496th epoch : 3.4998288054841047  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1497th epoch : 3.499827987093967  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1498th epoch : 3.4998271690829377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1499th epoch : 3.499826351449732  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1500th epoch : 3.4998255341930693  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1501th epoch : 3.4998247173116694  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1502th epoch : 3.4998239008042558  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1503th epoch : 3.499823084669553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1504th epoch : 3.499822268906289  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1505th epoch : 3.4998214535131926  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1506th epoch : 3.499820638488997  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1507th epoch : 3.4998198238324356  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1508th epoch : 3.4998190095422457  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1509th epoch : 3.4998181956171655  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1510th epoch : 3.4998173820559355  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1511th epoch : 3.4998165688573  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1512th epoch : 3.4998157560200034  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1513th epoch : 3.4998149435427943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1514th epoch : 3.4998141314244218  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1515th epoch : 3.4998133196636383  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1516th epoch : 3.4998125082591978  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1517th epoch : 3.499811697209857  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1518th epoch : 3.499810886514375  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1519th epoch : 3.499810076171512  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1520th epoch : 3.499809266180031  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1521th epoch : 3.4998084565386973  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1522th epoch : 3.499807647246278  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1523th epoch : 3.4998068383015433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1524th epoch : 3.4998060297032643  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1525th epoch : 3.499805221450215  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1526th epoch : 3.4998044135411708  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1527th epoch : 3.4998036059749102  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1528th epoch : 3.499802798750214  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1529th epoch : 3.499801991865863  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1530th epoch : 3.4998011853206425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1531th epoch : 3.4998003791133394  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1532th epoch : 3.4997995732427416  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1533th epoch : 3.49979876770764  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1534th epoch : 3.4997979625068276  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1535th epoch : 3.4997971576390987  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1536th epoch : 3.499796353103251  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1537th epoch : 3.499795548898083  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1538th epoch : 3.4997947450223967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1539th epoch : 3.499793941474994  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1540th epoch : 3.4997931382546805  Training Accuracy:0.5714285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1541th epoch : 3.499792335360264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1542th epoch : 3.4997915327905527  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1543th epoch : 3.499790730544359  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1544th epoch : 3.499789928620496  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1545th epoch : 3.499789127017779  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1546th epoch : 3.499788325735025  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1547th epoch : 3.4997875247710537  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1548th epoch : 3.4997867241246867  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1549th epoch : 3.499785923794747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1550th epoch : 3.4997851237800606  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1551th epoch : 3.4997843240794544  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1552th epoch : 3.499783524691758  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1553th epoch : 3.4997827256158027  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1554th epoch : 3.4997819268504218  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1555th epoch : 3.4997811283944507  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1556th epoch : 3.4997803302467263  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1557th epoch : 3.499779532406088  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1558th epoch : 3.499778734871377  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1559th epoch : 3.499777937641437  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1560th epoch : 3.499777140715112  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1561th epoch : 3.4997763440912495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1562th epoch : 3.499775547768698  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1563th epoch : 3.499774751746309  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1564th epoch : 3.499773956022935  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1565th epoch : 3.4997731605974303  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1566th epoch : 3.499772365468652  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1567th epoch : 3.499771570635458  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1568th epoch : 3.4997707760967085  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1569th epoch : 3.4997699818512666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1570th epoch : 3.499769187897996  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1571th epoch : 3.4997683942357622  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1572th epoch : 3.4997676008634335  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1573th epoch : 3.4997668077798796  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1574th epoch : 3.4997660149839724  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1575th epoch : 3.4997652224745845  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1576th epoch : 3.4997644302505924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1577th epoch : 3.499763638310872  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1578th epoch : 3.499762846654303  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1579th epoch : 3.499762055279766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1580th epoch : 3.499761264186144  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1581th epoch : 3.499760473372321  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1582th epoch : 3.4997596828371837  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1583th epoch : 3.49975889257962  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1584th epoch : 3.4997581025985194  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1585th epoch : 3.499757312892774  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1586th epoch : 3.4997565234612775  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1587th epoch : 3.499755734302925  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1588th epoch : 3.499754945416614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1589th epoch : 3.4997541568012425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1590th epoch : 3.499753368455712  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1591th epoch : 3.4997525803789244  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1592th epoch : 3.4997517925697843  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1593th epoch : 3.499751005027197  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1594th epoch : 3.499750217750071  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1595th epoch : 3.499749430737315  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1596th epoch : 3.499748643987841  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1597th epoch : 3.499747857500562  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1598th epoch : 3.4997470712743914  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1599th epoch : 3.499746285308247  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1600th epoch : 3.499745499601046  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1601th epoch : 3.4997447141517095  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1602th epoch : 3.4997439289591576  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1603th epoch : 3.4997431440223146  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1604th epoch : 3.499742359340105  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1605th epoch : 3.499741574911456  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1606th epoch : 3.4997407907352955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1607th epoch : 3.499740006810554  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1608th epoch : 3.499739223136163  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1609th epoch : 3.499738439711056  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1610th epoch : 3.499737656534168  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1611th epoch : 3.4997368736044363  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1612th epoch : 3.4997360909207993  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1613th epoch : 3.499735308482197  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1614th epoch : 3.4997345262875705  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1615th epoch : 3.499733744335865  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1616th epoch : 3.4997329626260236  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1617th epoch : 3.4997321811569946  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1618th epoch : 3.4997313999277258  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1619th epoch : 3.499730618937167  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1620th epoch : 3.4997298381842703  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1621th epoch : 3.4997290576679885  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1622th epoch : 3.499728277387277  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1623th epoch : 3.4997274973410923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1624th epoch : 3.499726717528392  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1625th epoch : 3.4997259379481362  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1626th epoch : 3.4997251585992863  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1627th epoch : 3.4997243794808055  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1628th epoch : 3.4997236005916577  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1629th epoch : 3.4997228219308094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1630th epoch : 3.499722043497228  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1631th epoch : 3.499721265289883  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1632th epoch : 3.499720487307745  Training Accuracy:0.5357142857142857\n",
      "The training loss at 1633th epoch : 3.4997197095497876  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1634th epoch : 3.499718932014983  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1635th epoch : 3.499718154702308  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1636th epoch : 3.499717377610739  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1637th epoch : 3.4997166007392555  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1638th epoch : 3.4997158240868367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1639th epoch : 3.4997150476524648  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1640th epoch : 3.4997142714351233  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1641th epoch : 3.499713495433797  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1642th epoch : 3.4997127196474715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1643th epoch : 3.499711944075136  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1644th epoch : 3.4997111687157783  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1645th epoch : 3.4997103935683906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1646th epoch : 3.499709618631965  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1647th epoch : 3.499708843905495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1648th epoch : 3.4997080693879763  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1649th epoch : 3.499707295078406  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1650th epoch : 3.4997065209757823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1651th epoch : 3.499705747079105  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1652th epoch : 3.499704973387376  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1653th epoch : 3.4997041998995972  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1654th epoch : 3.4997034266147744  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1655th epoch : 3.4997026535319122  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1656th epoch : 3.499701880650018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1657th epoch : 3.4997011079681015  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1658th epoch : 3.499700335485172  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1659th epoch : 3.4996995632002417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1660th epoch : 3.499698791112323  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1661th epoch : 3.4996980192204314  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1662th epoch : 3.4996972475235824  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1663th epoch : 3.499696476020793  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1664th epoch : 3.4996957047110833  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1665th epoch : 3.4996949335934726  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1666th epoch : 3.499694162666983  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1667th epoch : 3.4996933919306374  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1668th epoch : 3.4996926213834607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1669th epoch : 3.4996918510244788  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1670th epoch : 3.4996910808527195  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1671th epoch : 3.499690310867211  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1672th epoch : 3.4996895410669833  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1673th epoch : 3.4996887714510687  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1674th epoch : 3.4996880020185  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1675th epoch : 3.4996872327683115  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1676th epoch : 3.499686463699539  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1677th epoch : 3.499685694811219  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1678th epoch : 3.4996849261023915  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1679th epoch : 3.499684157572095  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1680th epoch : 3.4996833892193715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1681th epoch : 3.499682621043264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1682th epoch : 3.4996818530428153  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1683th epoch : 3.4996810852170714  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1684th epoch : 3.4996803175650792  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1685th epoch : 3.4996795500858866  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1686th epoch : 3.499678782778543  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1687th epoch : 3.499678015642099  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1688th epoch : 3.499677248675607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1689th epoch : 3.49967648187812  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1690th epoch : 3.499675715248693  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1691th epoch : 3.499674948786382  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1692th epoch : 3.4996741824902444  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1693th epoch : 3.4996734163593386  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1694th epoch : 3.4996726503927253  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1695th epoch : 3.499671884589465  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1696th epoch : 3.499671118948621  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1697th epoch : 3.4996703534692566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1698th epoch : 3.499669588150438  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1699th epoch : 3.4996688229912305  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1700th epoch : 3.499668057990703  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1701th epoch : 3.499667293147924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1702th epoch : 3.499666528461964  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1703th epoch : 3.4996657639318944  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1704th epoch : 3.4996649995567886  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1705th epoch : 3.499664235335721  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1706th epoch : 3.499663471267766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1707th epoch : 3.4996627073520017  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1708th epoch : 3.4996619435875047  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1709th epoch : 3.4996611799733555  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1710th epoch : 3.4996604165086342  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1711th epoch : 3.4996596531924222  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1712th epoch : 3.499658890023803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1713th epoch : 3.4996581270018603  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1714th epoch : 3.49965736412568  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1715th epoch : 3.4996566013943484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1716th epoch : 3.499655838806954  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1717th epoch : 3.4996550763625858  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1718th epoch : 3.499654314060334  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1719th epoch : 3.49965355189929  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1720th epoch : 3.4996527898785477  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1721th epoch : 3.4996520279972  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1722th epoch : 3.4996512662543426  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1723th epoch : 3.499650504649072  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1724th epoch : 3.4996497431804854  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1725th epoch : 3.4996489818476824  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1726th epoch : 3.4996482206497626  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1727th epoch : 3.4996474595858276  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1728th epoch : 3.499646698654979  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1729th epoch : 3.4996459378563216  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1730th epoch : 3.499645177188959  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1731th epoch : 3.499644416651998  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1732th epoch : 3.4996436562445457  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1733th epoch : 3.49964289596571  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1734th epoch : 3.4996421358146006  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1735th epoch : 3.4996413757903286  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1736th epoch : 3.499640615892005  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1737th epoch : 3.4996398561187427  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1738th epoch : 3.499639096469657  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1739th epoch : 3.4996383369438617  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1740th epoch : 3.499637577540474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1741th epoch : 3.4996368182586117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1742th epoch : 3.499636059097393  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1743th epoch : 3.4996353000559375  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1744th epoch : 3.499634541133367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1745th epoch : 3.499633782328803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1746th epoch : 3.4996330236413686  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1747th epoch : 3.499632265070188  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1748th epoch : 3.4996315066143877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1749th epoch : 3.499630748273093  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1750th epoch : 3.4996299900454324  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1751th epoch : 3.4996292319305344  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1752th epoch : 3.4996284739275287  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1753th epoch : 3.4996277160355467  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1754th epoch : 3.49962695825372  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1755th epoch : 3.499626200581182  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1756th epoch : 3.4996254430170675  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1757th epoch : 3.499624685560511  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1758th epoch : 3.4996239282106494  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1759th epoch : 3.49962317096662  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1760th epoch : 3.4996224138275616  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1761th epoch : 3.499621656792614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1762th epoch : 3.4996208998609175  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1763th epoch : 3.4996201430316147  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1764th epoch : 3.4996193863038476  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1765th epoch : 3.499618629676761  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1766th epoch : 3.499617873149499  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1767th epoch : 3.4996171167212085  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1768th epoch : 3.4996163603910357  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1769th epoch : 3.49961560415813  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1770th epoch : 3.4996148480216394  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1771th epoch : 3.499614091980715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1772th epoch : 3.499613336034508  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1773th epoch : 3.49961258018217  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1774th epoch : 3.499611824422855  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1775th epoch : 3.4996110687557174  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1776th epoch : 3.499610313179913  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1777th epoch : 3.4996095576945967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1778th epoch : 3.4996088022989276  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1779th epoch : 3.499608046992064  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1780th epoch : 3.4996072917731644  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1781th epoch : 3.49960653664139  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1782th epoch : 3.4996057815959025  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1783th epoch : 3.499605026635864  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1784th epoch : 3.4996042717604383  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1785th epoch : 3.49960351696879  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1786th epoch : 3.4996027622600843  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1787th epoch : 3.4996020076334875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1788th epoch : 3.499601253088168  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1789th epoch : 3.4996004986232934  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1790th epoch : 3.4995997442380338  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1791th epoch : 3.4995989899315596  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1792th epoch : 3.4995982357030417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1793th epoch : 3.499597481551653  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1794th epoch : 3.499596727476567  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1795th epoch : 3.4995959734769575  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1796th epoch : 3.499595219552  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1797th epoch : 3.4995944657008713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1798th epoch : 3.499593711922748  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1799th epoch : 3.4995929582168084  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1800th epoch : 3.499592204582232  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1801th epoch : 3.4995914510181985  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1802th epoch : 3.4995906975238893  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1803th epoch : 3.4995899440984863  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1804th epoch : 3.4995891907411725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1805th epoch : 3.4995884374511315  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1806th epoch : 3.4995876842275484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1807th epoch : 3.499586931069609  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1808th epoch : 3.499586177976499  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1809th epoch : 3.4995854249474077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1810th epoch : 3.4995846719815225  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1811th epoch : 3.499583919078033  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1812th epoch : 3.4995831662361296  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1813th epoch : 3.4995824134550038  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1814th epoch : 3.4995816607338477  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1815th epoch : 3.499580908071854  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1816th epoch : 3.4995801554682178  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1817th epoch : 3.4995794029221328  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1818th epoch : 3.4995786504327953  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1819th epoch : 3.4995778979994023  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1820th epoch : 3.499577145621151  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1821th epoch : 3.4995763932972404  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1822th epoch : 3.499575641026869  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1823th epoch : 3.499574888809238  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1824th epoch : 3.499574136643549  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1825th epoch : 3.4995733845290022  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1826th epoch : 3.4995726324648024  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1827th epoch : 3.4995718804501523  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1828th epoch : 3.499571128484257  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1829th epoch : 3.4995703765663224  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1830th epoch : 3.499569624695554  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1831th epoch : 3.4995688728711603  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1832th epoch : 3.499568121092348  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1833th epoch : 3.499567369358328  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1834th epoch : 3.4995666176683082  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1835th epoch : 3.4995658660215008  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1836th epoch : 3.4995651144171163  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1837th epoch : 3.499564362854368  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1838th epoch : 3.4995636113324684  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1839th epoch : 3.4995628598506325  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1840th epoch : 3.4995621084080746  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1841th epoch : 3.4995613570040107  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1842th epoch : 3.4995606056376576  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1843th epoch : 3.4995598543082322  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1844th epoch : 3.4995591030149535  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1845th epoch : 3.4995583517570403  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1846th epoch : 3.4995576005337123  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1847th epoch : 3.4995568493441906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1848th epoch : 3.499556098187697  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1849th epoch : 3.4995553470634535  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1850th epoch : 3.4995545959706837  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1851th epoch : 3.499553844908611  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1852th epoch : 3.499553093876461  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1853th epoch : 3.499552342873459  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1854th epoch : 3.499551591898831  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1855th epoch : 3.4995508409518052  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1856th epoch : 3.499550090031609  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1857th epoch : 3.4995493391374715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1858th epoch : 3.499548588268622  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1859th epoch : 3.4995478374242914  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1860th epoch : 3.4995470866037106  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1861th epoch : 3.499546335806112  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1862th epoch : 3.4995455850307278  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1863th epoch : 3.4995448342767923  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1864th epoch : 3.499544083543539  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1865th epoch : 3.499543332830204  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1866th epoch : 3.4995425821360224  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1867th epoch : 3.499541831460231  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1868th epoch : 3.4995410808020675  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1869th epoch : 3.4995403301607704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1870th epoch : 3.4995395795355777  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1871th epoch : 3.49953882892573  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1872th epoch : 3.4995380783304677  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1873th epoch : 3.4995373277490316  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1874th epoch : 3.499536577180664  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1875th epoch : 3.4995358266246077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1876th epoch : 3.499535076080106  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1877th epoch : 3.4995343255464033  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1878th epoch : 3.499533575022744  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1879th epoch : 3.499532824508375  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1880th epoch : 3.4995320740025417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1881th epoch : 3.4995313235044923  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1882th epoch : 3.4995305730134736  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1883th epoch : 3.499529822528735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1884th epoch : 3.4995290720495253  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1885th epoch : 3.499528321575095  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1886th epoch : 3.4995275711046956  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1887th epoch : 3.499526820637578  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1888th epoch : 3.499526070172994  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1889th epoch : 3.499525319710197  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1890th epoch : 3.4995245692484414  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1891th epoch : 3.4995238187869804  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1892th epoch : 3.4995230683250704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1893th epoch : 3.4995223178619663  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1894th epoch : 3.4995215673969247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1895th epoch : 3.4995208169292034  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1896th epoch : 3.49952006645806  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1897th epoch : 3.499519315982753  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1898th epoch : 3.4995185655025423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1899th epoch : 3.4995178150166875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1900th epoch : 3.4995170645244493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1901th epoch : 3.499516314025089  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1902th epoch : 3.499515563517869  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1903th epoch : 3.499514813002052  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1904th epoch : 3.4995140624769014  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1905th epoch : 3.4995133119416817  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1906th epoch : 3.499512561395657  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1907th epoch : 3.499511810838093  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1908th epoch : 3.4995110602682566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1909th epoch : 3.4995103096854137  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1910th epoch : 3.4995095590888323  Training Accuracy:0.5714285714285714\n",
      "The training loss at 1911th epoch : 3.4995088084777803  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1912th epoch : 3.499508057851527  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1913th epoch : 3.4995073072093414  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1914th epoch : 3.4995065565504935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1915th epoch : 3.4995058058742545  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1916th epoch : 3.499505055179896  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1917th epoch : 3.4995043044666896  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1918th epoch : 3.4995035537339083  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1919th epoch : 3.4995028029808255  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1920th epoch : 3.4995020522067155  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1921th epoch : 3.4995013014108527  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1922th epoch : 3.4995005505925123  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1923th epoch : 3.49949979975097  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1924th epoch : 3.4994990488855033  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1925th epoch : 3.499498297995389  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1926th epoch : 3.499497547079905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1927th epoch : 3.499496796138329  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1928th epoch : 3.4994960451699417  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1929th epoch : 3.4994952941740216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1930th epoch : 3.4994945431498494  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1931th epoch : 3.499493792096706  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1932th epoch : 3.499493041013874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1933th epoch : 3.4994922899006338  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1934th epoch : 3.4994915387562697  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1935th epoch : 3.4994907875800645  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1936th epoch : 3.499490036371302  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1937th epoch : 3.499489285129268  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1938th epoch : 3.4994885338532464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1939th epoch : 3.499487782542524  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1940th epoch : 3.499487031196387  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1941th epoch : 3.4994862798141226  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1942th epoch : 3.499485528395018  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1943th epoch : 3.499484776938362  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1944th epoch : 3.4994840254434427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1945th epoch : 3.4994832739095507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1946th epoch : 3.4994825223359753  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1947th epoch : 3.499481770722007  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1948th epoch : 3.499481019066937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1949th epoch : 3.499480267370058  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1950th epoch : 3.4994795156306613  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1951th epoch : 3.4994787638480402  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1952th epoch : 3.499478012021488  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1953th epoch : 3.4994772601502993  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1954th epoch : 3.4994765082337684  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1955th epoch : 3.4994757562711905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1956th epoch : 3.4994750042618614  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1957th epoch : 3.4994742522050775  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1958th epoch : 3.499473500100136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1959th epoch : 3.499472747946334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1960th epoch : 3.4994719957429696  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1961th epoch : 3.499471243489342  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1962th epoch : 3.499470491184749  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1963th epoch : 3.4994697388284917  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1964th epoch : 3.4994689864198696  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1965th epoch : 3.4994682339581837  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1966th epoch : 3.4994674814427356  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1967th epoch : 3.4994667288728265  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1968th epoch : 3.49946597624776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1969th epoch : 3.4994652235668378  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1970th epoch : 3.4994644708293636  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1971th epoch : 3.4994637180346424  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1972th epoch : 3.499462965181978  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1973th epoch : 3.499462212270676  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1974th epoch : 3.4994614593000417  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1975th epoch : 3.499460706269381  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1976th epoch : 3.4994599531780013  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1977th epoch : 3.4994592000252096  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1978th epoch : 3.4994584468103134  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1979th epoch : 3.499457693532621  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1980th epoch : 3.4994569401914415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1981th epoch : 3.499456186786084  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1982th epoch : 3.499455433315858  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1983th epoch : 3.4994546797800745  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1984th epoch : 3.4994539261780435  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1985th epoch : 3.4994531725090776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1986th epoch : 3.4994524187724876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1987th epoch : 3.499451664967586  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1988th epoch : 3.499450911093686  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1989th epoch : 3.499450157150101  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1990th epoch : 3.4994494031361443  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1991th epoch : 3.4994486490511307  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1992th epoch : 3.4994478948943755  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1993th epoch : 3.4994471406651932  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1994th epoch : 3.4994463863628997  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1995th epoch : 3.499445631986812  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1996th epoch : 3.499444877536247  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1997th epoch : 3.499444123010521  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1998th epoch : 3.499443368408952  Training Accuracy:0.6071428571428571\n",
      "The training loss at 1999th epoch : 3.499442613730859  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2000th epoch : 3.4994418589755605  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2001th epoch : 3.4994411041423756  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2002th epoch : 3.499440349230624  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2003th epoch : 3.4994395942396257  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2004th epoch : 3.4994388391687017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2005th epoch : 3.4994380840171733  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2006th epoch : 3.499437328784361  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2007th epoch : 3.499436573469588  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2008th epoch : 3.4994358180721767  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2009th epoch : 3.4994350625914494  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2010th epoch : 3.49943430702673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2011th epoch : 3.4994335513773427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2012th epoch : 3.4994327956426114  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2013th epoch : 3.499432039821861  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2014th epoch : 3.499431283914417  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2015th epoch : 3.4994305279196047  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2016th epoch : 3.4994297718367506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2017th epoch : 3.4994290156651813  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2018th epoch : 3.499428259404224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2019th epoch : 3.4994275030532056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2020th epoch : 3.499426746611455  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2021th epoch : 3.4994259900783  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2022th epoch : 3.499425233453069  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2023th epoch : 3.499424476735092  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2024th epoch : 3.499423719923699  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2025th epoch : 3.4994229630182194  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2026th epoch : 3.499422206017984  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2027th epoch : 3.4994214489223237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2028th epoch : 3.4994206917305704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2029th epoch : 3.4994199344420553  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2030th epoch : 3.4994191770561116  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2031th epoch : 3.499418419572071  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2032th epoch : 3.499417661989267  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2033th epoch : 3.4994169043070333  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2034th epoch : 3.499416146524704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2035th epoch : 3.4994153886416135  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2036th epoch : 3.4994146306570957  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2037th epoch : 3.499413872570487  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2038th epoch : 3.4994131143811225  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2039th epoch : 3.499412356088338  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2040th epoch : 3.4994115976914704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2041th epoch : 3.499410839189856  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2042th epoch : 3.4994100805828325  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2043th epoch : 3.499409321869738  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2044th epoch : 3.499408563049909  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2045th epoch : 3.499407804122686  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2046th epoch : 3.499407045087406  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2047th epoch : 3.4994062859434094  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2048th epoch : 3.499405526690035  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2049th epoch : 3.4994047673266238  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2050th epoch : 3.4994040078525153  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2051th epoch : 3.499403248267051  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2052th epoch : 3.499402488569572  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2053th epoch : 3.499401728759419  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2054th epoch : 3.499400968835935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2055th epoch : 3.4994002087984617  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2056th epoch : 3.4993994486463427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2057th epoch : 3.49939868837892  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2058th epoch : 3.499397927995538  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2059th epoch : 3.4993971674955393  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2060th epoch : 3.4993964068782697  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2061th epoch : 3.4993956461430726  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2062th epoch : 3.4993948852892935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2063th epoch : 3.499394124316278  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2064th epoch : 3.499393363223371  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2065th epoch : 3.499392602009919  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2066th epoch : 3.4993918406752687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2067th epoch : 3.4993910792187664  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2068th epoch : 3.4993903176397594  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2069th epoch : 3.4993895559375954  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2070th epoch : 3.4993887941116224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2071th epoch : 3.499388032161188  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2072th epoch : 3.499387270085641  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2073th epoch : 3.499386507884331  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2074th epoch : 3.499385745556606  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2075th epoch : 3.499384983101817  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2076th epoch : 3.4993842205193126  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2077th epoch : 3.4993834578084444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2078th epoch : 3.499382694968562  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2079th epoch : 3.499381931999017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2080th epoch : 3.499381168899161  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2081th epoch : 3.499380405668345  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2082th epoch : 3.499379642305921  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2083th epoch : 3.499378878811242  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2084th epoch : 3.4993781151836605  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2085th epoch : 3.499377351422529  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2086th epoch : 3.4993765875272014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2087th epoch : 3.4993758234970307  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2088th epoch : 3.499375059331372  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2089th epoch : 3.4993742950295785  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2090th epoch : 3.4993735305910056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2091th epoch : 3.4993727660150076  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2092th epoch : 3.499372001300941  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2093th epoch : 3.4993712364481597  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2094th epoch : 3.499370471456021  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2095th epoch : 3.499369706323881  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2096th epoch : 3.4993689410510953  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2097th epoch : 3.499368175637022  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2098th epoch : 3.4993674100810175  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2099th epoch : 3.4993666443824396  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2100th epoch : 3.499365878540646  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2101th epoch : 3.4993651125549947  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2102th epoch : 3.4993643464248447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2103th epoch : 3.499363580149554  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2104th epoch : 3.499362813728482  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2105th epoch : 3.4993620471609876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2106th epoch : 3.4993612804464314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2107th epoch : 3.4993605135841723  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2108th epoch : 3.4993597465735706  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2109th epoch : 3.4993589794139877  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2110th epoch : 3.4993582121047835  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2111th epoch : 3.4993574446453195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2112th epoch : 3.499356677034957  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2113th epoch : 3.499355909273058  Training Accuracy:0.6071428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 2114th epoch : 3.499355141358984  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2115th epoch : 3.499354373292097  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2116th epoch : 3.4993536050717604  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2117th epoch : 3.4993528366973368  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2118th epoch : 3.4993520681681884  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2119th epoch : 3.4993512994836795  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2120th epoch : 3.4993505306431736  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2121th epoch : 3.4993497616460347  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2122th epoch : 3.4993489924916266  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2123th epoch : 3.4993482231793136  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2124th epoch : 3.4993474537084612  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2125th epoch : 3.4993466840784344  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2126th epoch : 3.4993459142885976  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2127th epoch : 3.4993451443383172  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2128th epoch : 3.499344374226959  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2129th epoch : 3.4993436039538888  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2130th epoch : 3.4993428335184724  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2131th epoch : 3.4993420629200775  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2132th epoch : 3.4993412921580704  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2133th epoch : 3.4993405212318183  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2134th epoch : 3.4993397501406887  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2135th epoch : 3.4993389788840488  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2136th epoch : 3.499338207461267  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2137th epoch : 3.4993374358717118  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2138th epoch : 3.4993366641147503  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2139th epoch : 3.4993358921897526  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2140th epoch : 3.4993351200960867  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2141th epoch : 3.499334347833122  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2142th epoch : 3.499333575400228  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2143th epoch : 3.499332802796774  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2144th epoch : 3.4993320300221304  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2145th epoch : 3.4993312570756667  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2146th epoch : 3.499330483956754  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2147th epoch : 3.499329710664762  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2148th epoch : 3.4993289371990626  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2149th epoch : 3.499328163559026  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2150th epoch : 3.4993273897440242  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2151th epoch : 3.499326615753428  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2152th epoch : 3.49932584158661  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2153th epoch : 3.4993250672429412  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2154th epoch : 3.4993242927217945  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2155th epoch : 3.4993235180225426  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2156th epoch : 3.4993227431445573  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2157th epoch : 3.4993219680872123  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2158th epoch : 3.4993211928498806  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2159th epoch : 3.4993204174319352  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2160th epoch : 3.49931964183275  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2161th epoch : 3.4993188660516985  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2162th epoch : 3.4993180900881553  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2163th epoch : 3.4993173139414937  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2164th epoch : 3.499316537611089  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2165th epoch : 3.499315761096315  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2166th epoch : 3.4993149843965474  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2167th epoch : 3.499314207511161  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2168th epoch : 3.499313430439531  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2169th epoch : 3.499312653181033  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2170th epoch : 3.4993118757350423  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2171th epoch : 3.499311098100935  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2172th epoch : 3.4993103202780875  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2173th epoch : 3.499309542265876  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2174th epoch : 3.499308764063677  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2175th epoch : 3.4993079856708666  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2176th epoch : 3.4993072070868227  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2177th epoch : 3.4993064283109216  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2178th epoch : 3.499305649342541  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2179th epoch : 3.4993048701810587  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2180th epoch : 3.4993040908258517  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2181th epoch : 3.4993033112762983  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2182th epoch : 3.499302531531776  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2183th epoch : 3.499301751591664  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2184th epoch : 3.49930097145534  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2185th epoch : 3.499300191122183  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2186th epoch : 3.499299410591571  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2187th epoch : 3.499298629862884  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2188th epoch : 3.499297848935501  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2189th epoch : 3.499297067808801  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2190th epoch : 3.499296286482164  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2191th epoch : 3.499295504954969  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2192th epoch : 3.4992947232265967  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2193th epoch : 3.4992939412964263  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2194th epoch : 3.4992931591638388  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2195th epoch : 3.4992923768282145  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2196th epoch : 3.4992915942889335  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2197th epoch : 3.499290811545377  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2198th epoch : 3.4992900285969255  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2199th epoch : 3.4992892454429603  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2200th epoch : 3.499288462082863  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2201th epoch : 3.4992876785160147  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2202th epoch : 3.4992868947417968  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2203th epoch : 3.4992861107595914  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2204th epoch : 3.49928532656878  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2205th epoch : 3.499284542168745  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2206th epoch : 3.4992837575588687  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2207th epoch : 3.499282972738533  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2208th epoch : 3.499282187707121  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2209th epoch : 3.499281402464015  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2210th epoch : 3.4992806170085977  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2211th epoch : 3.4992798313402527  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2212th epoch : 3.4992790454583624  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2213th epoch : 3.4992782593623106  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2214th epoch : 3.499277473051481  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2215th epoch : 3.4992766865252563  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2216th epoch : 3.499275899783021  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2217th epoch : 3.499275112824159  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2218th epoch : 3.4992743256480536  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2219th epoch : 3.4992735382540894  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2220th epoch : 3.4992727506416506  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2221th epoch : 3.4992719628101217  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2222th epoch : 3.4992711747588876  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2223th epoch : 3.4992703864873325  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2224th epoch : 3.499269597994841  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2225th epoch : 3.499268809280799  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2226th epoch : 3.499268020344591  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2227th epoch : 3.499267231185603  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2228th epoch : 3.499266441803219  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2229th epoch : 3.4992656521968253  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2230th epoch : 3.499264862365808  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2231th epoch : 3.4992640723095514  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2232th epoch : 3.499263282027443  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2233th epoch : 3.499262491518868  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2234th epoch : 3.4992617007832125  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2235th epoch : 3.499260909819863  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2236th epoch : 3.499260118628206  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2237th epoch : 3.4992593272076276  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2238th epoch : 3.4992585355575145  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2239th epoch : 3.4992577436772536  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2240th epoch : 3.4992569515662315  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2241th epoch : 3.4992561592238354  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2242th epoch : 3.4992553666494524  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2243th epoch : 3.499254573842469  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2244th epoch : 3.4992537808022735  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2245th epoch : 3.4992529875282523  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2246th epoch : 3.499252194019794  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2247th epoch : 3.499251400276285  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2248th epoch : 3.499250606297114  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2249th epoch : 3.4992498120816684  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2250th epoch : 3.499249017629336  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2251th epoch : 3.499248222939505  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2252th epoch : 3.4992474280115635  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2253th epoch : 3.4992466328449  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2254th epoch : 3.4992458374389024  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2255th epoch : 3.499245041792959  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2256th epoch : 3.499244245906459  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2257th epoch : 3.4992434497787905  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2258th epoch : 3.4992426534093424  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2259th epoch : 3.499241856797503  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2260th epoch : 3.499241059942662  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2261th epoch : 3.4992402628442076  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2262th epoch : 3.499239465501529  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2263th epoch : 3.499238667914016  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2264th epoch : 3.4992378700810574  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2265th epoch : 3.4992370720020425  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2266th epoch : 3.499236273676361  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2267th epoch : 3.4992354751034016  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2268th epoch : 3.4992346762825544  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2269th epoch : 3.4992338772132094  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2270th epoch : 3.499233077894756  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2271th epoch : 3.4992322783265832  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2272th epoch : 3.4992314785080825  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2273th epoch : 3.4992306784386424  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2274th epoch : 3.499229878117654  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2275th epoch : 3.499229077544507  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2276th epoch : 3.499228276718591  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2277th epoch : 3.499227475639297  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2278th epoch : 3.499226674306015  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2279th epoch : 3.499225872718136  Training Accuracy:0.6428571428571429\n",
      "The training loss at 2280th epoch : 3.49922507087505  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2281th epoch : 3.499224268776147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2282th epoch : 3.499223466420818  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2283th epoch : 3.499222663808454  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2284th epoch : 3.4992218609384453  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2285th epoch : 3.4992210578101828  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2286th epoch : 3.499220254423057  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2287th epoch : 3.4992194507764594  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2288th epoch : 3.499218646869781  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2289th epoch : 3.4992178427024117  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2290th epoch : 3.499217038273744  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2291th epoch : 3.499216233583168  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2292th epoch : 3.4992154286300754  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2293th epoch : 3.4992146234138573  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2294th epoch : 3.499213817933905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2295th epoch : 3.49921301218961  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2296th epoch : 3.499212206180363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2297th epoch : 3.4992113999055556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2298th epoch : 3.4992105933645803  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2299th epoch : 3.4992097865568272  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2300th epoch : 3.499208979481689  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2301th epoch : 3.4992081721385566  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2302th epoch : 3.4992073645268222  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2303th epoch : 3.4992065566458765  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2304th epoch : 3.4992057484951125  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2305th epoch : 3.499204940073921  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2306th epoch : 3.4992041313816946  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2307th epoch : 3.4992033224178245  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2308th epoch : 3.4992025131817024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2309th epoch : 3.499201703672721  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2310th epoch : 3.4992008938902717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2311th epoch : 3.4992000838337467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2312th epoch : 3.499199273502538  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2313th epoch : 3.4991984628960373  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2314th epoch : 3.499197652013637  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2315th epoch : 3.4991968408547294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2316th epoch : 3.499196029418706  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2317th epoch : 3.4991952177049597  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2318th epoch : 3.4991944057128817  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2319th epoch : 3.499193593441865  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2320th epoch : 3.4991927808913017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2321th epoch : 3.499191968060584  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2322th epoch : 3.499191154949104  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2323th epoch : 3.4991903415562535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2324th epoch : 3.499189527881426  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2325th epoch : 3.499188713924013  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2326th epoch : 3.499187899683407  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2327th epoch : 3.4991870851590003  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2328th epoch : 3.4991862703501853  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2329th epoch : 3.499185455256354  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2330th epoch : 3.4991846398768995  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2331th epoch : 3.4991838242112134  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2332th epoch : 3.499183008258689  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2333th epoch : 3.499182192018718  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2334th epoch : 3.499181375490693  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2335th epoch : 3.4991805586740066  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2336th epoch : 3.499179741568051  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2337th epoch : 3.4991789241722184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2338th epoch : 3.499178106485902  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2339th epoch : 3.4991772885084935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2340th epoch : 3.499176470239386  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2341th epoch : 3.499175651677971  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2342th epoch : 3.4991748328236416  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2343th epoch : 3.4991740136757903  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2344th epoch : 3.499173194233809  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2345th epoch : 3.4991723744970904  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2346th epoch : 3.4991715544650273  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2347th epoch : 3.4991707341370115  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2348th epoch : 3.4991699135124357  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2349th epoch : 3.499169092590692  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2350th epoch : 3.4991682713711736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2351th epoch : 3.499167449853272  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2352th epoch : 3.49916662803638  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2353th epoch : 3.4991658059198896  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2354th epoch : 3.499164983503193  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2355th epoch : 3.4991641607856834  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2356th epoch : 3.499163337766752  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2357th epoch : 3.499162514445792  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2358th epoch : 3.499161690822195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2359th epoch : 3.4991608668953535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2360th epoch : 3.49916004266466  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2361th epoch : 3.499159218129506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2362th epoch : 3.4991583932892847  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2363th epoch : 3.4991575681433873  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2364th epoch : 3.4991567426912065  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2365th epoch : 3.499155916932134  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2366th epoch : 3.4991550908655618  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2367th epoch : 3.4991542644908824  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2368th epoch : 3.4991534378074878  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2369th epoch : 3.4991526108147695  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2370th epoch : 3.49915178351212  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2371th epoch : 3.499150955898931  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2372th epoch : 3.4991501279745942  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2373th epoch : 3.4991492997385016  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2374th epoch : 3.499148471190045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2375th epoch : 3.4991476423286167  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2376th epoch : 3.4991468131536076  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2377th epoch : 3.49914598366441  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2378th epoch : 3.4991451538604155  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2379th epoch : 3.499144323741015  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2380th epoch : 3.4991434933056014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2381th epoch : 3.4991426625535653  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2382th epoch : 3.4991418314842986  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2383th epoch : 3.4991410000971923  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2384th epoch : 3.4991401683916386  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2385th epoch : 3.499139336367028  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2386th epoch : 3.4991385040227523  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2387th epoch : 3.4991376713582025  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2388th epoch : 3.4991368383727703  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2389th epoch : 3.4991360050658464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2390th epoch : 3.4991351714368224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2391th epoch : 3.499134337485089  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2392th epoch : 3.4991335032100372  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2393th epoch : 3.499132668611058  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2394th epoch : 3.4991318336875428  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2395th epoch : 3.4991309984388814  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2396th epoch : 3.4991301628644655  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2397th epoch : 3.4991293269636854  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2398th epoch : 3.499128490735932  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2399th epoch : 3.499127654180596  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2400th epoch : 3.4991268172970678  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2401th epoch : 3.4991259800847376  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2402th epoch : 3.4991251425429963  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2403th epoch : 3.499124304671234  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2404th epoch : 3.4991234664688413  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2405th epoch : 3.4991226279352077  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2406th epoch : 3.4991217890697244  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2407th epoch : 3.4991209498717804  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2408th epoch : 3.4991201103407668  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2409th epoch : 3.4991192704760725  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2410th epoch : 3.4991184302770884  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2411th epoch : 3.499117589743203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2412th epoch : 3.4991167488738077  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2413th epoch : 3.4991159076682914  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2414th epoch : 3.499115066126043  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2415th epoch : 3.499114224246453  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2416th epoch : 3.4991133820289106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2417th epoch : 3.499112539472805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2418th epoch : 3.499111696577525  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2419th epoch : 3.4991108533424606  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2420th epoch : 3.4991100097670005  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2421th epoch : 3.499109165850534  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2422th epoch : 3.4991083215924497  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2423th epoch : 3.499107476992137  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2424th epoch : 3.499106632048984  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2425th epoch : 3.49910578676238  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2426th epoch : 3.499104941131713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2427th epoch : 3.499104095156372  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2428th epoch : 3.4991032488357456  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2429th epoch : 3.4991024021692216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2430th epoch : 3.4991015551561886  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2431th epoch : 3.499100707796034  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2432th epoch : 3.4990998600881476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2433th epoch : 3.4990990120319156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2434th epoch : 3.4990981636267264  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2435th epoch : 3.4990973148719684  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2436th epoch : 3.4990964657670287  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2437th epoch : 3.499095616311295  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2438th epoch : 3.4990947665041547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2439th epoch : 3.4990939163449952  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2440th epoch : 3.4990930658332045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2441th epoch : 3.4990922149681687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2442th epoch : 3.499091363749275  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2443th epoch : 3.4990905121759113  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2444th epoch : 3.499089660247464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2445th epoch : 3.4990888079633193  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2446th epoch : 3.4990879553228647  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2447th epoch : 3.499087102325486  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2448th epoch : 3.4990862489705705  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2449th epoch : 3.499085395257504  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2450th epoch : 3.499084541185673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2451th epoch : 3.4990836867544632  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2452th epoch : 3.499082831963261  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2453th epoch : 3.499081976811452  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2454th epoch : 3.4990811212984223  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2455th epoch : 3.4990802654235575  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2456th epoch : 3.4990794091862427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2457th epoch : 3.499078552585864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2458th epoch : 3.4990776956218066  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2459th epoch : 3.499076838293455  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2460th epoch : 3.499075980600195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2461th epoch : 3.4990751225414116  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2462th epoch : 3.4990742641164894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2463th epoch : 3.499073405324813  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2464th epoch : 3.499072546165767  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2465th epoch : 3.499071686638736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2466th epoch : 3.4990708267431043  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2467th epoch : 3.499069966478256  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2468th epoch : 3.4990691058435757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2469th epoch : 3.4990682448384467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2470th epoch : 3.499067383462253  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2471th epoch : 3.499066521714379  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2472th epoch : 3.499065659594207  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2473th epoch : 3.4990647971011217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2474th epoch : 3.4990639342345053  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2475th epoch : 3.499063070993742  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2476th epoch : 3.499062207378214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2477th epoch : 3.499061343387305  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2478th epoch : 3.499060479020397  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2479th epoch : 3.4990596142768733  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2480th epoch : 3.499058749156116  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2481th epoch : 3.4990578836575077  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2482th epoch : 3.49905701778043  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2483th epoch : 3.4990561515242655  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2484th epoch : 3.4990552848883967  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2485th epoch : 3.499054417872204  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2486th epoch : 3.49905355047507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2487th epoch : 3.499052682696376  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2488th epoch : 3.4990518145355036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2489th epoch : 3.4990509459918337  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2490th epoch : 3.4990500770647475  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2491th epoch : 3.4990492077536257  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2492th epoch : 3.4990483380578494  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2493th epoch : 3.499047467976799  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2494th epoch : 3.4990465975098552  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2495th epoch : 3.499045726656398  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2496th epoch : 3.4990448554158076  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2497th epoch : 3.499043983787464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2498th epoch : 3.4990431117707472  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2499th epoch : 3.4990422393650373  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2500th epoch : 3.499041366569713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2501th epoch : 3.4990404933841543  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2502th epoch : 3.49903961980774  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2503th epoch : 3.4990387458398495  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2504th epoch : 3.4990378714798616  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2505th epoch : 3.4990369967271553  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2506th epoch : 3.4990361215811085  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2507th epoch : 3.4990352460411005  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2508th epoch : 3.499034370106509  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2509th epoch : 3.4990334937767122  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2510th epoch : 3.499032617051088  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2511th epoch : 3.4990317399290145  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2512th epoch : 3.4990308624098687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2513th epoch : 3.4990299844930286  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2514th epoch : 3.499029106177871  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2515th epoch : 3.4990282274637736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2516th epoch : 3.4990273483501126  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2517th epoch : 3.499026468836265  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2518th epoch : 3.499025588921608  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2519th epoch : 3.499024708605517  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2520th epoch : 3.4990238278873687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2521th epoch : 3.4990229467665395  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2522th epoch : 3.4990220652424044  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2523th epoch : 3.49902118331434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2524th epoch : 3.4990203009817216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2525th epoch : 3.4990194182439245  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2526th epoch : 3.4990185351003236  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2527th epoch : 3.499017651550294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2528th epoch : 3.4990167675932105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2529th epoch : 3.4990158832284477  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2530th epoch : 3.4990149984553804  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2531th epoch : 3.4990141132733825  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2532th epoch : 3.499013227681828  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2533th epoch : 3.499012341680092  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2534th epoch : 3.4990114552675458  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2535th epoch : 3.499010568443565  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2536th epoch : 3.499009681207522  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2537th epoch : 3.49900879355879  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2538th epoch : 3.4990079054967422  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2539th epoch : 3.4990070170207517  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2540th epoch : 3.49900612813019  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2541th epoch : 3.4990052388244304  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2542th epoch : 3.499004349102844  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2543th epoch : 3.4990034589648045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2544th epoch : 3.4990025684096824  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2545th epoch : 3.4990016774368495  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2546th epoch : 3.499000786045677  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2547th epoch : 3.498999894235537  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2548th epoch : 3.4989990020057995  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2549th epoch : 3.4989981093558358  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2550th epoch : 3.4989972162850163  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2551th epoch : 3.4989963227927117  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2552th epoch : 3.498995428878292  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2553th epoch : 3.4989945345411266  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2554th epoch : 3.4989936397805863  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2555th epoch : 3.4989927445960403  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2556th epoch : 3.4989918489868574  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2557th epoch : 3.4989909529524077  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2558th epoch : 3.49899005649206  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2559th epoch : 3.4989891596051823  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2560th epoch : 3.4989882622911437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2561th epoch : 3.4989873645493126  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2562th epoch : 3.498986466379057  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2563th epoch : 3.498985567779745  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2564th epoch : 3.4989846687507433  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2565th epoch : 3.4989837692914207  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2566th epoch : 3.4989828694011442  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2567th epoch : 3.4989819690792805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2568th epoch : 3.4989810683251963  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2569th epoch : 3.4989801671382588  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2570th epoch : 3.498979265517834  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2571th epoch : 3.498978363463288  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2572th epoch : 3.498977460973987  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2573th epoch : 3.498976558049297  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2574th epoch : 3.4989756546885826  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2575th epoch : 3.49897475089121  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2576th epoch : 3.4989738466565443  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2577th epoch : 3.4989729419839497  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2578th epoch : 3.4989720368727917  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2579th epoch : 3.4989711313224334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2580th epoch : 3.4989702253322403  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2581th epoch : 3.4989693189015756  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2582th epoch : 3.4989684120298037  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2583th epoch : 3.4989675047162874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2584th epoch : 3.49896659696039  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2585th epoch : 3.498965688761475  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2586th epoch : 3.498964780118905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2587th epoch : 3.4989638710320423  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2588th epoch : 3.4989629615002498  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2589th epoch : 3.498962051522889  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2590th epoch : 3.498961141099322  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2591th epoch : 3.498960230228911  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2592th epoch : 3.4989593189110164  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2593th epoch : 3.498958407145  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2594th epoch : 3.498957494930223  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2595th epoch : 3.4989565822660453  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2596th epoch : 3.4989556691518278  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2597th epoch : 3.4989547555869303  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2598th epoch : 3.4989538415707133  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2599th epoch : 3.4989529271025366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2600th epoch : 3.498952012181759  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2601th epoch : 3.4989510968077404  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2602th epoch : 3.4989501809798393  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2603th epoch : 3.4989492646974147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2604th epoch : 3.4989483479598253  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2605th epoch : 3.498947430766429  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2606th epoch : 3.498946513116584  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2607th epoch : 3.4989455950096477  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2608th epoch : 3.498944676444978  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2609th epoch : 3.498943757421932  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2610th epoch : 3.498942837939867  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2611th epoch : 3.498941917998139  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2612th epoch : 3.498940997596105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2613th epoch : 3.4989400767331214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2614th epoch : 3.4989391554085443  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2615th epoch : 3.4989382336217285  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2616th epoch : 3.4989373113720306  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2617th epoch : 3.498936388658805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2618th epoch : 3.498935465481407  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2619th epoch : 3.4989345418391915  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2620th epoch : 3.4989336177315127  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2621th epoch : 3.498932693157725  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2622th epoch : 3.4989317681171817  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2623th epoch : 3.498930842609237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2624th epoch : 3.4989299166332444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2625th epoch : 3.4989289901885563  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2626th epoch : 3.4989280632745263  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2627th epoch : 3.498927135890507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2628th epoch : 3.4989262080358503  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2629th epoch : 3.4989252797099084  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2630th epoch : 3.4989243509120334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2631th epoch : 3.4989234216415763  Training Accuracy:0.6071428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 2632th epoch : 3.498922491897889  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2633th epoch : 3.498921561680322  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2634th epoch : 3.4989206309882257  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2635th epoch : 3.4989196998209513  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2636th epoch : 3.498918768177849  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2637th epoch : 3.498917836058268  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2638th epoch : 3.4989169034615584  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2639th epoch : 3.498915970387069  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2640th epoch : 3.49891503683415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2641th epoch : 3.498914102802149  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2642th epoch : 3.4989131682904153  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2643th epoch : 3.498912233298297  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2644th epoch : 3.4989112978251415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2645th epoch : 3.498910361870297  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2646th epoch : 3.498909425433111  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2647th epoch : 3.4989084885129302  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2648th epoch : 3.4989075511091015  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2649th epoch : 3.4989066132209716  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2650th epoch : 3.498905674847887  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2651th epoch : 3.498904735989193  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2652th epoch : 3.4989037966442362  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2653th epoch : 3.4989028568123612  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2654th epoch : 3.4989019164929136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2655th epoch : 3.498900975685238  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2656th epoch : 3.498900034388679  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2657th epoch : 3.498899092602581  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2658th epoch : 3.4988981503262875  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2659th epoch : 3.4988972075591427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2660th epoch : 3.4988962643004897  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2661th epoch : 3.4988953205496713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2662th epoch : 3.498894376306031  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2663th epoch : 3.4988934315689106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2664th epoch : 3.498892486337653  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2665th epoch : 3.4988915406115995  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2666th epoch : 3.498890594390092  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2667th epoch : 3.498889647672472  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2668th epoch : 3.4988887004580795  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2669th epoch : 3.4988877527462563  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2670th epoch : 3.498886804536342  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2671th epoch : 3.4988858558276776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2672th epoch : 3.4988849066196024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2673th epoch : 3.4988839569114556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2674th epoch : 3.498883006702577  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2675th epoch : 3.498882055992305  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2676th epoch : 3.498881104779979  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2677th epoch : 3.498880153064936  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2678th epoch : 3.4988792008465146  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2679th epoch : 3.498878248124053  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2680th epoch : 3.4988772948968876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2681th epoch : 3.498876341164356  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2682th epoch : 3.4988753869257945  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2683th epoch : 3.49887443218054  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2684th epoch : 3.498873476927929  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2685th epoch : 3.498872521167296  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2686th epoch : 3.4988715648979776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2687th epoch : 3.4988706081193084  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2688th epoch : 3.4988696508306236  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2689th epoch : 3.4988686930312576  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2690th epoch : 3.4988677347205446  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2691th epoch : 3.4988667758978185  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2692th epoch : 3.498865816562413  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2693th epoch : 3.498864856713661  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2694th epoch : 3.4988638963508962  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2695th epoch : 3.49886293547345  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2696th epoch : 3.498861974080656  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2697th epoch : 3.4988610121718455  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2698th epoch : 3.4988600497463502  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2699th epoch : 3.4988590868035017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2700th epoch : 3.4988581233426306  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2701th epoch : 3.498857159363068  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2702th epoch : 3.498856194864144  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2703th epoch : 3.4988552298451885  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2704th epoch : 3.498854264305532  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2705th epoch : 3.4988532982445024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2706th epoch : 3.49885233166143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2707th epoch : 3.4988513645556436  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2708th epoch : 3.498850396926471  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2709th epoch : 3.49884942877324  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2710th epoch : 3.4988484600952785  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2711th epoch : 3.4988474908919143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2712th epoch : 3.4988465211624744  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2713th epoch : 3.4988455509062852  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2714th epoch : 3.4988445801226735  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2715th epoch : 3.4988436088109647  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2716th epoch : 3.498842636970485  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2717th epoch : 3.4988416646005596  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2718th epoch : 3.4988406917005137  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2719th epoch : 3.498839718269672  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2720th epoch : 3.4988387443073585  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2721th epoch : 3.4988377698128974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2722th epoch : 3.4988367947856127  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2723th epoch : 3.4988358192248272  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2724th epoch : 3.498834843129864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2725th epoch : 3.498833866500046  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2726th epoch : 3.498832889334695  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2727th epoch : 3.4988319116331335  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2728th epoch : 3.4988309333946828  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2729th epoch : 3.4988299546186643  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2730th epoch : 3.4988289753043986  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2731th epoch : 3.4988279954512067  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2732th epoch : 3.4988270150584087  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2733th epoch : 3.4988260341253237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2734th epoch : 3.4988250526512723  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2735th epoch : 3.498824070635573  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2736th epoch : 3.498823088077545  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2737th epoch : 3.4988221049765063  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2738th epoch : 3.498821121331775  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2739th epoch : 3.498820137142669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2740th epoch : 3.498819152408506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2741th epoch : 3.4988181671286025  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2742th epoch : 3.4988171813022753  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2743th epoch : 3.4988161949288408  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2744th epoch : 3.4988152080076147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2745th epoch : 3.498814220537913  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2746th epoch : 3.4988132325190504  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2747th epoch : 3.4988122439503426  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2748th epoch : 3.4988112548311032  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2749th epoch : 3.4988102651606465  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2750th epoch : 3.4988092749382864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2751th epoch : 3.498808284163337  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2752th epoch : 3.4988072928351097  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2753th epoch : 3.4988063009529187  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2754th epoch : 3.4988053085160757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2755th epoch : 3.4988043155238926  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2756th epoch : 3.4988033219756813  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2757th epoch : 3.4988023278707523  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2758th epoch : 3.498801333208417  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2759th epoch : 3.498800337987986  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2760th epoch : 3.498799342208769  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2761th epoch : 3.4987983458700755  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2762th epoch : 3.4987973489712156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2763th epoch : 3.4987963515114977  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2764th epoch : 3.4987953534902303  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2765th epoch : 3.498794354906722  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2766th epoch : 3.4987933557602804  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2767th epoch : 3.4987923560502128  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2768th epoch : 3.498791355775827  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2769th epoch : 3.4987903549364283  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2770th epoch : 3.4987893535313246  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2771th epoch : 3.498788351559821  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2772th epoch : 3.498787349021223  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2773th epoch : 3.4987863459148363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2774th epoch : 3.498785342239965  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2775th epoch : 3.4987843379959145  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2776th epoch : 3.4987833331819878  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2777th epoch : 3.498782327797489  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2778th epoch : 3.4987813218417214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2779th epoch : 3.4987803153139874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2780th epoch : 3.49877930821359  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2781th epoch : 3.4987783005398314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2782th epoch : 3.4987772922920133  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2783th epoch : 3.4987762834694363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2784th epoch : 3.4987752740714018  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2785th epoch : 3.4987742640972104  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2786th epoch : 3.4987732535461626  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2787th epoch : 3.4987722424175574  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2788th epoch : 3.498771230710694  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2789th epoch : 3.4987702184248723  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2790th epoch : 3.4987692055593906  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2791th epoch : 3.4987681921135465  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2792th epoch : 3.4987671780866383  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2793th epoch : 3.4987661634779634  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2794th epoch : 3.498765148286818  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2795th epoch : 3.4987641325125  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2796th epoch : 3.4987631161543042  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2797th epoch : 3.4987620992115276  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2798th epoch : 3.4987610816834644  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2799th epoch : 3.4987600635694105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2800th epoch : 3.4987590448686605  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2801th epoch : 3.4987580255805075  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2802th epoch : 3.4987570057042463  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2803th epoch : 3.4987559852391703  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2804th epoch : 3.4987549641845717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2805th epoch : 3.4987539425397434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2806th epoch : 3.4987529203039776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2807th epoch : 3.498751897476566  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2808th epoch : 3.4987508740567996  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2809th epoch : 3.49874985004397  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2810th epoch : 3.4987488254373673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2811th epoch : 3.4987478002362815  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2812th epoch : 3.4987467744400025  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2813th epoch : 3.4987457480478197  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2814th epoch : 3.4987447210590212  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2815th epoch : 3.498743693472896  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2816th epoch : 3.498742665288732  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2817th epoch : 3.4987416365058173  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2818th epoch : 3.4987406071234384  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2819th epoch : 3.4987395771408822  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2820th epoch : 3.4987385465574357  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2821th epoch : 3.4987375153723836  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2822th epoch : 3.4987364835850125  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2823th epoch : 3.498735451194607  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2824th epoch : 3.498734418200452  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2825th epoch : 3.4987333846018314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2826th epoch : 3.498732350398029  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2827th epoch : 3.498731315588329  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2828th epoch : 3.498730280172014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2829th epoch : 3.498729244148366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2830th epoch : 3.4987282075166677  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2831th epoch : 3.4987271702762004  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2832th epoch : 3.4987261324262455  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2833th epoch : 3.4987250939660846  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2834th epoch : 3.4987240548949967  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2835th epoch : 3.498723015212263  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2836th epoch : 3.4987219749171623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2837th epoch : 3.498720934008974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2838th epoch : 3.498719892486977  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2839th epoch : 3.4987188503504494  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2840th epoch : 3.498717807598669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2841th epoch : 3.498716764230913  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2842th epoch : 3.4987157202464587  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2843th epoch : 3.4987146756445826  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2844th epoch : 3.4987136304245605  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2845th epoch : 3.4987125845856686  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2846th epoch : 3.498711538127181  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2847th epoch : 3.4987104910483735  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2848th epoch : 3.4987094433485204  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2849th epoch : 3.498708395026895  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2850th epoch : 3.4987073460827713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2851th epoch : 3.498706296515422  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2852th epoch : 3.4987052463241195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2853th epoch : 3.498704195508136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2854th epoch : 3.4987031440667438  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2855th epoch : 3.4987020919992133  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2856th epoch : 3.498701039304816  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2857th epoch : 3.498699985982822  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2858th epoch : 3.4986989320325006  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2859th epoch : 3.4986978774531217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2860th epoch : 3.4986968222439545  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2861th epoch : 3.4986957664042673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2862th epoch : 3.4986947099333285  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2863th epoch : 3.4986936528304056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2864th epoch : 3.498692595094765  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2865th epoch : 3.498691536725675  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2866th epoch : 3.4986904777224006  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2867th epoch : 3.4986894180842083  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2868th epoch : 3.498688357810363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2869th epoch : 3.4986872969001297  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2870th epoch : 3.4986862353527735  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2871th epoch : 3.4986851731675577  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2872th epoch : 3.498684110343746  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2873th epoch : 3.498683046880602  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2874th epoch : 3.4986819827773874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2875th epoch : 3.498680918033365  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2876th epoch : 3.498679852647797  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2877th epoch : 3.4986787866199434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2878th epoch : 3.498677719949066  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2879th epoch : 3.4986766526344244  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2880th epoch : 3.4986755846752793  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2881th epoch : 3.4986745160708894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2882th epoch : 3.4986734468205136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2883th epoch : 3.498672376923411  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2884th epoch : 3.498671306378839  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2885th epoch : 3.4986702351860557  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2886th epoch : 3.4986691633443177  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2887th epoch : 3.4986680908528816  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2888th epoch : 3.4986670177110035  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2889th epoch : 3.4986659439179393  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2890th epoch : 3.4986648694729445  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2891th epoch : 3.4986637943752728  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2892th epoch : 3.498662718624179  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2893th epoch : 3.4986616422189174  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2894th epoch : 3.4986605651587404  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2895th epoch : 3.498659487442901  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2896th epoch : 3.498658409070652  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2897th epoch : 3.4986573300412447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2898th epoch : 3.498656250353931  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2899th epoch : 3.4986551700079613  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2900th epoch : 3.498654089002587  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2901th epoch : 3.4986530073370563  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2902th epoch : 3.4986519250106203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2903th epoch : 3.498650842022527  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2904th epoch : 3.4986497583720255  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2905th epoch : 3.4986486740583636  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2906th epoch : 3.4986475890807887  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2907th epoch : 3.4986465034385477  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2908th epoch : 3.498645417130888  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2909th epoch : 3.4986443301570547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2910th epoch : 3.4986432425162937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2911th epoch : 3.4986421542078503  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2912th epoch : 3.498641065230969  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2913th epoch : 3.498639975584894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2914th epoch : 3.498638885268869  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2915th epoch : 3.4986377942821365  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2916th epoch : 3.49863670262394  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2917th epoch : 3.4986356102935217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2918th epoch : 3.4986345172901223  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2919th epoch : 3.4986334236129837  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2920th epoch : 3.498632329261347  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2921th epoch : 3.498631234234451  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2922th epoch : 3.498630138531537  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2923th epoch : 3.4986290421518427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2924th epoch : 3.498627945094608  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2925th epoch : 3.4986268473590707  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2926th epoch : 3.4986257489444683  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2927th epoch : 3.498624649850038  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2928th epoch : 3.498623550075017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2929th epoch : 3.4986224496186407  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2930th epoch : 3.498621348480145  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2931th epoch : 3.498620246658766  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2932th epoch : 3.4986191441537375  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2933th epoch : 3.4986180409642937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2934th epoch : 3.4986169370896687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2935th epoch : 3.4986158325290955  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2936th epoch : 3.4986147272818067  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2937th epoch : 3.4986136213470345  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2938th epoch : 3.4986125147240106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2939th epoch : 3.4986114074119663  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2940th epoch : 3.4986102994101316  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2941th epoch : 3.4986091907177372  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2942th epoch : 3.498608081334013  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2943th epoch : 3.4986069712581873  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2944th epoch : 3.4986058604894894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2945th epoch : 3.498604749027147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2946th epoch : 3.4986036368703877  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2947th epoch : 3.4986025240184384  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2948th epoch : 3.498601410470526  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2949th epoch : 3.4986002962258764  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2950th epoch : 3.498599181283715  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2951th epoch : 3.498598065643267  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2952th epoch : 3.498596949303757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2953th epoch : 3.498595832264408  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2954th epoch : 3.4985947145244447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2955th epoch : 3.498593596083089  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2956th epoch : 3.4985924769395638  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2957th epoch : 3.4985913570930913  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2958th epoch : 3.498590236542892  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2959th epoch : 3.498589115288187  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2960th epoch : 3.498587993328197  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2961th epoch : 3.4985868706621415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2962th epoch : 3.4985857472892397  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2963th epoch : 3.49858462320871  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2964th epoch : 3.4985834984197717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2965th epoch : 3.498582372921641  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2966th epoch : 3.498581246713536  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2967th epoch : 3.4985801197946733  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2968th epoch : 3.4985789921642683  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2969th epoch : 3.498577863821537  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2970th epoch : 3.4985767347656944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2971th epoch : 3.4985756049959553  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2972th epoch : 3.498574474511533  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2973th epoch : 3.4985733433116413  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2974th epoch : 3.498572211395493  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2975th epoch : 3.4985710787623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2976th epoch : 3.498569945411275  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2977th epoch : 3.4985688113416282  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2978th epoch : 3.4985676765525713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2979th epoch : 3.498566541043314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2980th epoch : 3.4985654048130663  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2981th epoch : 3.498564267861037  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2982th epoch : 3.4985631301864344  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2983th epoch : 3.498561991788467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2984th epoch : 3.498560852666342  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2985th epoch : 3.4985597128192665  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2986th epoch : 3.4985585722464467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2987th epoch : 3.498557430947089  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2988th epoch : 3.498556288920398  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2989th epoch : 3.498555146165579  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2990th epoch : 3.498554002681836  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2991th epoch : 3.4985528584683725  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2992th epoch : 3.4985517135243915  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2993th epoch : 3.498550567849096  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2994th epoch : 3.4985494214416883  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2995th epoch : 3.4985482743013687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2996th epoch : 3.4985471264273396  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2997th epoch : 3.4985459778188  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2998th epoch : 3.4985448284749503  Training Accuracy:0.6071428571428571\n",
      "The training loss at 2999th epoch : 3.49854367839499  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3000th epoch : 3.4985425275781177  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3001th epoch : 3.498541376023531  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3002th epoch : 3.498540223730428  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3003th epoch : 3.4985390706980057  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3004th epoch : 3.4985379169254607  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3005th epoch : 3.4985367624119883  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3006th epoch : 3.4985356071567844  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3007th epoch : 3.4985344511590437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3008th epoch : 3.4985332944179603  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3009th epoch : 3.4985321369327282  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3010th epoch : 3.4985309787025405  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3011th epoch : 3.4985298197265893  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3012th epoch : 3.4985286600040664  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3013th epoch : 3.498527499534164  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3014th epoch : 3.498526338316073  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3015th epoch : 3.498525176348983  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3016th epoch : 3.4985240136320837  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3017th epoch : 3.498522850164565  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3018th epoch : 3.4985216859456147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3019th epoch : 3.4985205209744215  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3020th epoch : 3.4985193552501728  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3021th epoch : 3.4985181887720547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3022th epoch : 3.4985170215392545  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3023th epoch : 3.4985158535509573  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3024th epoch : 3.498514684806348  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3025th epoch : 3.4985135153046123  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3026th epoch : 3.4985123450449334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3027th epoch : 3.4985111740264947  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3028th epoch : 3.498510002248479  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3029th epoch : 3.4985088297100697  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3030th epoch : 3.498507656410447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3031th epoch : 3.498506482348793  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3032th epoch : 3.498505307524288  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3033th epoch : 3.498504131936112  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3034th epoch : 3.4985029555834437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3035th epoch : 3.4985017784654633  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3036th epoch : 3.498500600581348  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3037th epoch : 3.498499421930276  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3038th epoch : 3.4984982425114235  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3039th epoch : 3.498497062323968  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3040th epoch : 3.4984958813670852  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3041th epoch : 3.49849469963995  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3042th epoch : 3.4984935171417373  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3043th epoch : 3.4984923338716216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3044th epoch : 3.4984911498287756  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3045th epoch : 3.4984899650123733  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3046th epoch : 3.4984887794215864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3047th epoch : 3.4984875930555868  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3048th epoch : 3.498486405913546  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3049th epoch : 3.4984852179946344  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3050th epoch : 3.4984840292980217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3051th epoch : 3.4984828398228776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3052th epoch : 3.498481649568371  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3053th epoch : 3.4984804585336704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3054th epoch : 3.498479266717943  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3055th epoch : 3.4984780741203556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3056th epoch : 3.4984768807400752  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3057th epoch : 3.4984756865762674  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3058th epoch : 3.4984744916280976  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3059th epoch : 3.49847329589473  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3060th epoch : 3.4984720993753293  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3061th epoch : 3.4984709020690588  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3062th epoch : 3.4984697039750805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3063th epoch : 3.498468505092558  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3064th epoch : 3.498467305420652  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3065th epoch : 3.4984661049585237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3066th epoch : 3.4984649037053335  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3067th epoch : 3.4984637016602416  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3068th epoch : 3.498462498822407  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3069th epoch : 3.4984612951909884  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3070th epoch : 3.4984600907651435  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3071th epoch : 3.49845888554403  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3072th epoch : 3.4984576795268048  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3073th epoch : 3.4984564727126233  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3074th epoch : 3.498455265100642  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3075th epoch : 3.4984540566900155  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3076th epoch : 3.4984528474798986  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3077th epoch : 3.498451637469444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3078th epoch : 3.4984504266578056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3079th epoch : 3.4984492150441358  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3080th epoch : 3.4984480026275864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3081th epoch : 3.498446789407309  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3082th epoch : 3.4984455753824535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3083th epoch : 3.4984443605521705  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3084th epoch : 3.4984431449156097  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3085th epoch : 3.498441928471919  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3086th epoch : 3.4984407112202476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3087th epoch : 3.4984394931597422  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3088th epoch : 3.498438274289551  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3089th epoch : 3.4984370546088184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3090th epoch : 3.498435834116692  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3091th epoch : 3.4984346128123156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3092th epoch : 3.498433390694834  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3093th epoch : 3.498432167763392  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3094th epoch : 3.498430944017131  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3095th epoch : 3.498429719455195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3096th epoch : 3.4984284940767254  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3097th epoch : 3.4984272678808637  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3098th epoch : 3.4984260408667507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3099th epoch : 3.498424813033526  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3100th epoch : 3.4984235843803293  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3101th epoch : 3.4984223549062996  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3102th epoch : 3.4984211246105748  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3103th epoch : 3.4984198934922923  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3104th epoch : 3.4984186615505894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3105th epoch : 3.4984174287846024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3106th epoch : 3.498416195193467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3107th epoch : 3.4984149607763175  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3108th epoch : 3.498413725532289  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3109th epoch : 3.498412489460515  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3110th epoch : 3.4984112525601283  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3111th epoch : 3.4984100148302617  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3112th epoch : 3.4984087762700473  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3113th epoch : 3.4984075368786156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3114th epoch : 3.4984062966550975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3115th epoch : 3.498405055598623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3116th epoch : 3.498403813708321  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3117th epoch : 3.4984025709833206  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3118th epoch : 3.4984013274227492  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3119th epoch : 3.4984000830257345  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3120th epoch : 3.4983988377914033  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3121th epoch : 3.498397591718881  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3122th epoch : 3.498396344807294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3123th epoch : 3.4983950970557656  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3124th epoch : 3.4983938484634214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3125th epoch : 3.498392599029384  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3126th epoch : 3.4983913487527762  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3127th epoch : 3.4983900976327207  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3128th epoch : 3.4983888456683383  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3129th epoch : 3.4983875928587502  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3130th epoch : 3.4983863392030763  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3131th epoch : 3.4983850847004367  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3132th epoch : 3.4983838293499496  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3133th epoch : 3.4983825731507334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3134th epoch : 3.498381316101906  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3135th epoch : 3.4983800582025846  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3136th epoch : 3.4983787994518845  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3137th epoch : 3.4983775398489216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3138th epoch : 3.498376279392811  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3139th epoch : 3.498375018082667  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3140th epoch : 3.4983737559176036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3141th epoch : 3.4983724928967326  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3142th epoch : 3.4983712290191677  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3143th epoch : 3.498369964284019  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3144th epoch : 3.498368698690399  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3145th epoch : 3.4983674322374174  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3146th epoch : 3.4983661649241835  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3147th epoch : 3.4983648967498064  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3148th epoch : 3.4983636277133945  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3149th epoch : 3.4983623578140555  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3150th epoch : 3.4983610870508963  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3151th epoch : 3.498359815423023  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3152th epoch : 3.498358542929542  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3153th epoch : 3.4983572695695573  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3154th epoch : 3.4983559953421737  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3155th epoch : 3.4983547202464944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3156th epoch : 3.498353444281623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3157th epoch : 3.4983521674466616  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3158th epoch : 3.498350889740711  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3159th epoch : 3.4983496111628734  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3160th epoch : 3.498348331712248  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3161th epoch : 3.4983470513879347  Training Accuracy:0.6071428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 3162th epoch : 3.4983457701890326  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3163th epoch : 3.4983444881146393  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3164th epoch : 3.498343205163853  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3165th epoch : 3.4983419213357707  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3166th epoch : 3.498340636629488  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3167th epoch : 3.4983393510441005  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3168th epoch : 3.498338064578703  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3169th epoch : 3.4983367772323906  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3170th epoch : 3.498335489004255  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3171th epoch : 3.49833419989339  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3172th epoch : 3.498332909898888  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3173th epoch : 3.4983316190198397  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3174th epoch : 3.498330327255336  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3175th epoch : 3.4983290346044664  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3176th epoch : 3.4983277410663214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3177th epoch : 3.498326446639989  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3178th epoch : 3.4983251513245572  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3179th epoch : 3.498323855119113  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3180th epoch : 3.4983225580227435  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3181th epoch : 3.498321260034534  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3182th epoch : 3.4983199611535705  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3183th epoch : 3.4983186613789363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3184th epoch : 3.4983173607097164  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3185th epoch : 3.498316059144993  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3186th epoch : 3.498314756683849  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3187th epoch : 3.498313453325366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3188th epoch : 3.4983121490686253  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3189th epoch : 3.498310843912707  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3190th epoch : 3.49830953785669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3191th epoch : 3.4983082308996547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3192th epoch : 3.498306923040678  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3193th epoch : 3.498305614278838  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3194th epoch : 3.4983043046132116  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3195th epoch : 3.4983029940428745  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3196th epoch : 3.4983016825669027  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3197th epoch : 3.4983003701843702  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3198th epoch : 3.4982990568943517  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3199th epoch : 3.49829774269592  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3200th epoch : 3.498296427588148  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3201th epoch : 3.4982951115701075  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3202th epoch : 3.4982937946408694  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3203th epoch : 3.4982924767995045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3204th epoch : 3.498291158045083  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3205th epoch : 3.4982898383766727  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3206th epoch : 3.498288517793343  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3207th epoch : 3.498287196294161  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3208th epoch : 3.498285873878194  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3209th epoch : 3.4982845505445077  Training Accuracy:0.6071428571428571\n",
      "The training loss at 3210th epoch : 3.498283226292168  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3211th epoch : 3.4982819011202397  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3212th epoch : 3.4982805750277866  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3213th epoch : 3.4982792480138722  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3214th epoch : 3.498277920077559  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3215th epoch : 3.498276591217909  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3216th epoch : 3.4982752614339834  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3217th epoch : 3.4982739307248427  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3218th epoch : 3.4982725990895465  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3219th epoch : 3.498271266527154  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3220th epoch : 3.4982699330367235  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3221th epoch : 3.4982685986173125  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3222th epoch : 3.498267263267978  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3223th epoch : 3.4982659269877754  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3224th epoch : 3.4982645897757614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3225th epoch : 3.4982632516309895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3226th epoch : 3.4982619125525143  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3227th epoch : 3.4982605725393894  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3228th epoch : 3.498259231590666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3229th epoch : 3.498257889705397  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3230th epoch : 3.4982565468826334  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3231th epoch : 3.498255203121425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3232th epoch : 3.4982538584208216  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3233th epoch : 3.4982525127798723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3234th epoch : 3.4982511661976248  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3235th epoch : 3.4982498186731266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3236th epoch : 3.4982484702054246  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3237th epoch : 3.498247120793564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3238th epoch : 3.4982457704365912  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3239th epoch : 3.49824441913355  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3240th epoch : 3.498243066883484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3241th epoch : 3.4982417136854362  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3242th epoch : 3.498240359538449  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3243th epoch : 3.498239004441564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3244th epoch : 3.4982376483938213  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3245th epoch : 3.4982362913942615  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3246th epoch : 3.498234933441924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3247th epoch : 3.498233574535847  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3248th epoch : 3.498232214675068  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3249th epoch : 3.498230853858625  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3250th epoch : 3.4982294920855534  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3251th epoch : 3.498228129354889  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3252th epoch : 3.4982267656656667  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3253th epoch : 3.4982254010169207  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3254th epoch : 3.498224035407684  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3255th epoch : 3.4982226688369895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3256th epoch : 3.4982213013038685  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3257th epoch : 3.4982199328073524  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3258th epoch : 3.4982185633464717  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3259th epoch : 3.4982171929202557  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3260th epoch : 3.498215821527733  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3261th epoch : 3.498214449167932  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3262th epoch : 3.4982130758398804  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3263th epoch : 3.4982117015426035  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3264th epoch : 3.4982103262751285  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3265th epoch : 3.4982089500364792  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3266th epoch : 3.498207572825681  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3267th epoch : 3.4982061946417566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3268th epoch : 3.498204815483729  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3269th epoch : 3.49820343535062  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3270th epoch : 3.4982020542414514  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3271th epoch : 3.498200672155243  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3272th epoch : 3.4981992890910156  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3273th epoch : 3.4981979050477867  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3274th epoch : 3.4981965200245755  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3275th epoch : 3.498195134020399  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3276th epoch : 3.498193747034274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3277th epoch : 3.4981923590652166  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3278th epoch : 3.4981909701122413  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3279th epoch : 3.498189580174363  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3280th epoch : 3.4981881892505955  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3281th epoch : 3.498186797339951  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3282th epoch : 3.498185404441442  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3283th epoch : 3.4981840105540796  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3284th epoch : 3.4981826156768743  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3285th epoch : 3.498181219808836  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3286th epoch : 3.4981798229489733  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3287th epoch : 3.4981784250962944  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3288th epoch : 3.4981770262498073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3289th epoch : 3.4981756264085186  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3290th epoch : 3.4981742255714336  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3291th epoch : 3.4981728237375576  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3292th epoch : 3.498171420905895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3293th epoch : 3.4981700170754495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3294th epoch : 3.4981686122452236  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3295th epoch : 3.498167206414219  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3296th epoch : 3.4981657995814377  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3297th epoch : 3.4981643917458793  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3298th epoch : 3.4981629829065444  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3299th epoch : 3.498161573062431  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3300th epoch : 3.498160162212537  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3301th epoch : 3.4981587503558607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3302th epoch : 3.4981573374913975  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3303th epoch : 3.498155923618144  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3304th epoch : 3.4981545087350945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3305th epoch : 3.4981530928412434  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3306th epoch : 3.498151675935584  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3307th epoch : 3.498150258017109  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3308th epoch : 3.49814883908481  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3309th epoch : 3.4981474191376782  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3310th epoch : 3.4981459981747034  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3311th epoch : 3.4981445761948753  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3312th epoch : 3.4981431531971823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3313th epoch : 3.4981417291806123  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3314th epoch : 3.498140304144153  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3315th epoch : 3.498138878086789  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3316th epoch : 3.498137451007507  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3317th epoch : 3.4981360229052916  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3318th epoch : 3.4981345937791257  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3319th epoch : 3.4981331636279935  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3320th epoch : 3.4981317324508767  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3321th epoch : 3.4981303002467565  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3322th epoch : 3.498128867014614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3323th epoch : 3.498127432753428  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3324th epoch : 3.498125997462179  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3325th epoch : 3.498124561139844  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3326th epoch : 3.4981231237854016  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3327th epoch : 3.498121685397827  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3328th epoch : 3.4981202459760974  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3329th epoch : 3.4981188055191867  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3330th epoch : 3.49811736402607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3331th epoch : 3.4981159214957196  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3332th epoch : 3.4981144779271087  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3333th epoch : 3.4981130333192096  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3334th epoch : 3.498111587670992  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3335th epoch : 3.4981101409814275  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3336th epoch : 3.4981086932494843  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3337th epoch : 3.4981072444741312  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3338th epoch : 3.498105794654336  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3339th epoch : 3.4981043437890658  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3340th epoch : 3.498102891877286  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3341th epoch : 3.4981014389179625  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3342th epoch : 3.49809998491006  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3343th epoch : 3.498098529852541  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3344th epoch : 3.4980970737443697  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3345th epoch : 3.498095616584507  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3346th epoch : 3.4980941583719147  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3347th epoch : 3.4980926991055523  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3348th epoch : 3.4980912387843808  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3349th epoch : 3.4980897774073574  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3350th epoch : 3.4980883149734407  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3351th epoch : 3.4980868514815877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3352th epoch : 3.4980853869307547  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3353th epoch : 3.4980839213198966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3354th epoch : 3.4980824546479687  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3355th epoch : 3.4980809869139247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3356th epoch : 3.498079518116717  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3357th epoch : 3.498078048255298  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3358th epoch : 3.498076577328619  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3359th epoch : 3.49807510533563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3360th epoch : 3.4980736322752812  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3361th epoch : 3.498072158146521  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3362th epoch : 3.4980706829482977  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3363th epoch : 3.498069206679558  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3364th epoch : 3.4980677293392484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3365th epoch : 3.4980662509263145  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3366th epoch : 3.4980647714397004  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3367th epoch : 3.4980632908783504  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3368th epoch : 3.4980618092412072  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3369th epoch : 3.4980603265272125  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3370th epoch : 3.4980588427353085  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3371th epoch : 3.4980573578644347  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3372th epoch : 3.498055871913531  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3373th epoch : 3.4980543848815366  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3374th epoch : 3.4980528967673887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3375th epoch : 3.4980514075700246  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3376th epoch : 3.4980499172883803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3377th epoch : 3.4980484259213918  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3378th epoch : 3.4980469334679927  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3379th epoch : 3.4980454399271173  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3380th epoch : 3.4980439452976984  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3381th epoch : 3.4980424495786675  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3382th epoch : 3.4980409527689567  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3383th epoch : 3.498039454867495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3384th epoch : 3.4980379558732126  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3385th epoch : 3.498036455785038  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3386th epoch : 3.498034954601899  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3387th epoch : 3.498033452322722  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3388th epoch : 3.4980319489464335  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3389th epoch : 3.4980304444719583  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3390th epoch : 3.498028938898221  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3391th epoch : 3.4980274322241454  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3392th epoch : 3.498025924448653  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3393th epoch : 3.4980244155706663  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3394th epoch : 3.498022905589106  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3395th epoch : 3.4980213945028926  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3396th epoch : 3.4980198823109445  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3397th epoch : 3.4980183690121804  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3398th epoch : 3.498016854605518  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3399th epoch : 3.498015339089873  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3400th epoch : 3.4980138224641624  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3401th epoch : 3.4980123047273  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3402th epoch : 3.4980107858781997  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3403th epoch : 3.4980092659157753  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3404th epoch : 3.498007744838939  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3405th epoch : 3.4980062226466018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3406th epoch : 3.4980046993376743  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3407th epoch : 3.4980031749110663  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3408th epoch : 3.4980016493656865  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3409th epoch : 3.498000122700443  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3410th epoch : 3.4979985949142423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3411th epoch : 3.497997066005991  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3412th epoch : 3.497995535974595  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3413th epoch : 3.4979940048189575  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3414th epoch : 3.4979924725379825  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3415th epoch : 3.497990939130573  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3416th epoch : 3.497989404595631  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3417th epoch : 3.4979878689320563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3418th epoch : 3.49798633213875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3419th epoch : 3.4979847942146107  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3420th epoch : 3.4979832551585375  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3421th epoch : 3.4979817149694266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3422th epoch : 3.4979801736461753  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3423th epoch : 3.4979786311876793  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3424th epoch : 3.4979770875928327  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3425th epoch : 3.49797554286053  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3426th epoch : 3.4979739969896646  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3427th epoch : 3.4979724499791276  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3428th epoch : 3.4979709018278107  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3429th epoch : 3.497969352534604  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3430th epoch : 3.4979678020983975  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3431th epoch : 3.497966250518079  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3432th epoch : 3.497964697792537  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3433th epoch : 3.497963143920658  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3434th epoch : 3.4979615889013274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3435th epoch : 3.497960032733431  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3436th epoch : 3.497958475415852  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3437th epoch : 3.4979569169474747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3438th epoch : 3.4979553573271804  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3439th epoch : 3.497953796553851  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3440th epoch : 3.4979522346263674  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3441th epoch : 3.4979506715436086  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3442th epoch : 3.497949107304454  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3443th epoch : 3.497947541907781  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3444th epoch : 3.497945975352466  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3445th epoch : 3.497944407637386  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3446th epoch : 3.497942838761416  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3447th epoch : 3.49794126872343  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3448th epoch : 3.4979396975223014  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3449th epoch : 3.4979381251569026  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3450th epoch : 3.4979365516261054  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3451th epoch : 3.49793497692878  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3452th epoch : 3.4979334010637966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3453th epoch : 3.4979318240300237  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3454th epoch : 3.4979302458263293  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3455th epoch : 3.4979286664515805  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3456th epoch : 3.4979270859046436  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3457th epoch : 3.497925504184383  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3458th epoch : 3.497923921289664  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3459th epoch : 3.4979223372193493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3460th epoch : 3.4979207519723015  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3461th epoch : 3.4979191655473825  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3462th epoch : 3.4979175779434524  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3463th epoch : 3.497915989159371  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3464th epoch : 3.4979143991939976  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3465th epoch : 3.49791280804619  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3466th epoch : 3.497911215714805  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3467th epoch : 3.4979096221986983  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3468th epoch : 3.497908027496725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3469th epoch : 3.4979064316077406  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3470th epoch : 3.4979048345305968  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3471th epoch : 3.4979032362641473  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3472th epoch : 3.4979016368072426  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3473th epoch : 3.497900036158734  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3474th epoch : 3.49789843431747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3475th epoch : 3.4978968312823002  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3476th epoch : 3.4978952270520725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3477th epoch : 3.4978936216256336  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3478th epoch : 3.497892015001829  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3479th epoch : 3.497890407179504  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3480th epoch : 3.4978887981575024  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3481th epoch : 3.4978871879346674  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3482th epoch : 3.4978855765098418  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3483th epoch : 3.497883963881866  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3484th epoch : 3.4978823500495815  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3485th epoch : 3.4978807350118264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3486th epoch : 3.4978791187674396  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3487th epoch : 3.4978775013152594  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3488th epoch : 3.4978758826541214  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3489th epoch : 3.497874262782862  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3490th epoch : 3.497872641700315  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3491th epoch : 3.497871019405316  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3492th epoch : 3.497869395896696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3493th epoch : 3.4978677711732877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3494th epoch : 3.497866145233922  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3495th epoch : 3.497864518077429  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3496th epoch : 3.497862889702638  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3497th epoch : 3.4978612601083765  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3498th epoch : 3.4978596292934725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3499th epoch : 3.4978579972567516  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3500th epoch : 3.49785636399704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3501th epoch : 3.4978547295131612  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3502th epoch : 3.4978530938039394  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3503th epoch : 3.4978514568681964  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3504th epoch : 3.497849818704754  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3505th epoch : 3.497848179312433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3506th epoch : 3.4978465386900535  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3507th epoch : 3.497844896836433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3508th epoch : 3.49784325375039  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3509th epoch : 3.497841609430741  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3510th epoch : 3.4978399638763027  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3511th epoch : 3.4978383170858884  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3512th epoch : 3.4978366690583136  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3513th epoch : 3.4978350197923906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3514th epoch : 3.4978333692869312  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3515th epoch : 3.497831717540747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3516th epoch : 3.4978300645526477  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3517th epoch : 3.4978284103214423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3518th epoch : 3.49782675484594  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3519th epoch : 3.497825098124947  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3520th epoch : 3.4978234401572696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3521th epoch : 3.497821780941714  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3522th epoch : 3.4978201204770833  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3523th epoch : 3.497818458762182  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3524th epoch : 3.497816795795812  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3525th epoch : 3.497815131576775  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3526th epoch : 3.4978134661038713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3527th epoch : 3.4978117993759006  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3528th epoch : 3.497810131391661  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3529th epoch : 3.497808462149951  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3530th epoch : 3.4978067916495656  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3531th epoch : 3.497805119889302  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3532th epoch : 3.497803446867955  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3533th epoch : 3.497801772584317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3534th epoch : 3.497800097037181  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3535th epoch : 3.49779842022534  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3536th epoch : 3.4977967421475835  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3537th epoch : 3.4977950628027017  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3538th epoch : 3.4977933821894838  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3539th epoch : 3.4977917003067174  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3540th epoch : 3.497790017153189  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3541th epoch : 3.497788332727685  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3542th epoch : 3.49778664702899  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3543th epoch : 3.4977849600558883  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3544th epoch : 3.4977832718071626  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3545th epoch : 3.4977815822815947  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3546th epoch : 3.4977798914779665  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3547th epoch : 3.4977781993950567  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3548th epoch : 3.4977765060316455  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3549th epoch : 3.49777481138651  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3550th epoch : 3.4977731154584277  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3551th epoch : 3.4977714182461748  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3552th epoch : 3.4977697197485265  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3553th epoch : 3.4977680199642562  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3554th epoch : 3.4977663188921375  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3555th epoch : 3.497764616530943  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3556th epoch : 3.4977629128794425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3557th epoch : 3.4977612079364073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3558th epoch : 3.4977595017006062  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3559th epoch : 3.4977577941708073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3560th epoch : 3.4977560853457774  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3561th epoch : 3.4977543752242832  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3562th epoch : 3.4977526638050898  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3563th epoch : 3.497750951086961  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3564th epoch : 3.4977492370686605  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3565th epoch : 3.49774752174895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3566th epoch : 3.497745805126591  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3567th epoch : 3.4977440872003434  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3568th epoch : 3.497742367968966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3569th epoch : 3.497740647431218  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3570th epoch : 3.4977389255858555  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3571th epoch : 3.4977372024316353  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3572th epoch : 3.4977354779673124  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3573th epoch : 3.497733752191641  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3574th epoch : 3.497732025103374  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3575th epoch : 3.497730296701264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3576th epoch : 3.4977285669840614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3577th epoch : 3.497726835950517  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3578th epoch : 3.4977251035993793  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3579th epoch : 3.497723369929397  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3580th epoch : 3.4977216349393165  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3581th epoch : 3.4977198986278846  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3582th epoch : 3.497718160993846  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3583th epoch : 3.497716422035945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3584th epoch : 3.497714681752924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3585th epoch : 3.4977129401435256  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3586th epoch : 3.4977111972064905  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3587th epoch : 3.497709452940559  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3588th epoch : 3.4977077073444693  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3589th epoch : 3.4977059604169605  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3590th epoch : 3.4977042121567683  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3591th epoch : 3.4977024625626294  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3592th epoch : 3.4977007116332786  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3593th epoch : 3.4976989593674497  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3594th epoch : 3.4976972057638753  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3595th epoch : 3.497695450821287  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3596th epoch : 3.4976936945384165  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3597th epoch : 3.4976919369139927  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3598th epoch : 3.497690177946745  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3599th epoch : 3.4976884176354  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3600th epoch : 3.4976866559786854  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3601th epoch : 3.4976848929753266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3602th epoch : 3.497683128624048  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3603th epoch : 3.4976813629235735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3604th epoch : 3.4976795958726252  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3605th epoch : 3.4976778274699254  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3606th epoch : 3.4976760577141937  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3607th epoch : 3.4976742866041497  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3608th epoch : 3.497672514138512  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3609th epoch : 3.497670740315998  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3610th epoch : 3.497668965135324  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3611th epoch : 3.4976671885952055  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3612th epoch : 3.4976654106943568  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3613th epoch : 3.4976636314314904  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3614th epoch : 3.497661850805319  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3615th epoch : 3.497660068814554  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3616th epoch : 3.497658285457905  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3617th epoch : 3.4976565007340814  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3618th epoch : 3.497654714641791  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3619th epoch : 3.4976529271797405  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3620th epoch : 3.497651138346636  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3621th epoch : 3.497649348141183  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3622th epoch : 3.4976475565620846  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3623th epoch : 3.497645763608044  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3624th epoch : 3.497643969277762  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3625th epoch : 3.4976421735699406  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3626th epoch : 3.4976403764832784  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3627th epoch : 3.4976385780164745  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3628th epoch : 3.4976367781682263  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3629th epoch : 3.49763497693723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3630th epoch : 3.4976331743221816  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3631th epoch : 3.4976313703217747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3632th epoch : 3.4976295649347033  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3633th epoch : 3.497627758159659  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3634th epoch : 3.4976259499953333  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3635th epoch : 3.4976241404404167  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3636th epoch : 3.4976223294935975  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3637th epoch : 3.497620517153564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3638th epoch : 3.497618703419003  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3639th epoch : 3.497616888288601  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3640th epoch : 3.497615071761042  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3641th epoch : 3.4976132538350106  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3642th epoch : 3.4976114345091887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3643th epoch : 3.497609613782258  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3644th epoch : 3.4976077916528996  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3645th epoch : 3.4976059681197924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3646th epoch : 3.497604143181615  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3647th epoch : 3.497602316837045  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3648th epoch : 3.4976004890847583  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3649th epoch : 3.49759865992343  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3650th epoch : 3.497596829351735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3651th epoch : 3.4975949973683456  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3652th epoch : 3.4975931639719335  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3653th epoch : 3.4975913291611707  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3654th epoch : 3.497589492934726  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3655th epoch : 3.4975876552912686  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3656th epoch : 3.4975858162294666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3657th epoch : 3.4975839757479856  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3658th epoch : 3.497582133845492  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3659th epoch : 3.4975802905206494  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3660th epoch : 3.497578445772122  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3661th epoch : 3.4975765995985717  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3662th epoch : 3.4975747519986595  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3663th epoch : 3.497572902971046  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3664th epoch : 3.4975710525143895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3665th epoch : 3.4975692006273484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3666th epoch : 3.4975673473085793  Training Accuracy:0.5714285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 3667th epoch : 3.4975654925567388  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3668th epoch : 3.4975636363704803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3669th epoch : 3.497561778748458  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3670th epoch : 3.4975599196893246  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3671th epoch : 3.4975580591917312  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3672th epoch : 3.497556197254328  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3673th epoch : 3.4975543338757644  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3674th epoch : 3.4975524690546886  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3675th epoch : 3.497550602789748  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3676th epoch : 3.497548735079587  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3677th epoch : 3.4975468659228524  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3678th epoch : 3.4975449953181865  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3679th epoch : 3.497543123264233  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3680th epoch : 3.4975412497596325  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3681th epoch : 3.4975393748030257  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3682th epoch : 3.497537498393052  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3683th epoch : 3.49753562052835  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3684th epoch : 3.497533741207557  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3685th epoch : 3.4975318604293077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3686th epoch : 3.4975299781922384  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3687th epoch : 3.497528094494982  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3688th epoch : 3.497526209336172  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3689th epoch : 3.4975243227144395  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3690th epoch : 3.497522434628415  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3691th epoch : 3.4975205450767284  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3692th epoch : 3.497518654058007  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3693th epoch : 3.497516761570879  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3694th epoch : 3.49751486761397  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3695th epoch : 3.4975129721859046  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3696th epoch : 3.497511075285307  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3697th epoch : 3.4975091769107998  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3698th epoch : 3.497507277061005  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3699th epoch : 3.497505375734543  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3700th epoch : 3.497503472930032  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3701th epoch : 3.497501568646092  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3702th epoch : 3.497499662881339  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3703th epoch : 3.4974977556343894  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3704th epoch : 3.497495846903858  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3705th epoch : 3.4974939366883584  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3706th epoch : 3.4974920249865034  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3707th epoch : 3.4974901117969046  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3708th epoch : 3.497488197118172  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3709th epoch : 3.4974862809489156  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3710th epoch : 3.4974843632877426  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3711th epoch : 3.497482444133261  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3712th epoch : 3.497480523484076  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3713th epoch : 3.4974786013387926  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3714th epoch : 3.4974766776960142  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3715th epoch : 3.4974747525543437  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3716th epoch : 3.497472825912382  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3717th epoch : 3.49747089776873  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3718th epoch : 3.4974689681219857  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3719th epoch : 3.497467036970748  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3720th epoch : 3.4974651043136133  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3721th epoch : 3.497463170149178  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3722th epoch : 3.4974612344760354  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3723th epoch : 3.4974592972927803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3724th epoch : 3.4974573585980036  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3725th epoch : 3.4974554183902975  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3726th epoch : 3.4974534766682512  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3727th epoch : 3.4974515334304543  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3728th epoch : 3.4974495886754937  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3729th epoch : 3.4974476424019567  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3730th epoch : 3.4974456946084285  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3731th epoch : 3.4974437452934932  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3732th epoch : 3.497441794455734  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3733th epoch : 3.497439842093733  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3734th epoch : 3.4974378882060706  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3735th epoch : 3.497435932791327  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3736th epoch : 3.4974339758480806  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3737th epoch : 3.4974320173749085  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3738th epoch : 3.497430057370387  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3739th epoch : 3.497428095833092  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3740th epoch : 3.497426132761596  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3741th epoch : 3.4974241681544727  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3742th epoch : 3.497422202010293  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3743th epoch : 3.4974202343276284  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3744th epoch : 3.4974182651050474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3745th epoch : 3.4974162943411184  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3746th epoch : 3.497414322034408  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3747th epoch : 3.4974123481834827  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3748th epoch : 3.4974103727869066  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3749th epoch : 3.497408395843243  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3750th epoch : 3.497406417351055  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3751th epoch : 3.4974044373089033  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3752th epoch : 3.4974024557153474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3753th epoch : 3.497400472568947  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3754th epoch : 3.4973984878682596  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3755th epoch : 3.497396501611841  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3756th epoch : 3.497394513798247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3757th epoch : 3.497392524426032  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3758th epoch : 3.4973905334937485  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3759th epoch : 3.497388540999949  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3760th epoch : 3.497386546943183  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3761th epoch : 3.4973845513220008  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3762th epoch : 3.4973825541349504  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3763th epoch : 3.4973805553805795  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3764th epoch : 3.497378555057433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3765th epoch : 3.497376553164056  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3766th epoch : 3.4973745496989928  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3767th epoch : 3.497372544660785  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3768th epoch : 3.497370538047974  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3769th epoch : 3.4973685298590995  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3770th epoch : 3.497366520092701  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3771th epoch : 3.497364508747316  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3772th epoch : 3.4973624958214806  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3773th epoch : 3.4973604813137302  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3774th epoch : 3.4973584652225993  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3775th epoch : 3.4973564475466206  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3776th epoch : 3.497354428284326  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3777th epoch : 3.4973524074342452  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3778th epoch : 3.497350384994909  Training Accuracy:0.5714285714285714\n",
      "The training loss at 3779th epoch : 3.497348360964844  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3780th epoch : 3.497346335342578  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3781th epoch : 3.4973443081266367  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3782th epoch : 3.497342279315545  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3783th epoch : 3.4973402489078254  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3784th epoch : 3.497338216902001  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3785th epoch : 3.4973361832965923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3786th epoch : 3.497334148090119  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3787th epoch : 3.4973321112811  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3788th epoch : 3.4973300728680528  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3789th epoch : 3.4973280328494933  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3790th epoch : 3.4973259912239363  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3791th epoch : 3.4973239479898957  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3792th epoch : 3.4973219031458846  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3793th epoch : 3.497319856690414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3794th epoch : 3.4973178086219936  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3795th epoch : 3.4973157589391333  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3796th epoch : 3.4973137076403398  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3797th epoch : 3.4973116547241205  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3798th epoch : 3.4973096001889807  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3799th epoch : 3.497307544033424  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3800th epoch : 3.4973054862559536  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3801th epoch : 3.4973034268550713  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3802th epoch : 3.4973013658292773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3803th epoch : 3.497299303177071  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3804th epoch : 3.4972972388969508  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3805th epoch : 3.4972951729874127  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3806th epoch : 3.4972931054469534  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3807th epoch : 3.497291036274066  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3808th epoch : 3.497288965467245  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3809th epoch : 3.497286893024982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3810th epoch : 3.497284818945767  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3811th epoch : 3.49728274322809  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3812th epoch : 3.4972806658704396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3813th epoch : 3.4972785868713023  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3814th epoch : 3.4972765062291646  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3815th epoch : 3.4972744239425104  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3816th epoch : 3.4972723400098236  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3817th epoch : 3.497270254429586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3818th epoch : 3.497268167200279  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3819th epoch : 3.497266078320382  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3820th epoch : 3.497263987788373  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3821th epoch : 3.49726189560273  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3822th epoch : 3.497259801761929  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3823th epoch : 3.497257706264444  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3824th epoch : 3.497255609108749  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3825th epoch : 3.4972535102933167  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3826th epoch : 3.4972514098166174  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3827th epoch : 3.497249307677121  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3828th epoch : 3.4972472038732967  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3829th epoch : 3.4972450984036114  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3830th epoch : 3.497242991266531  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3831th epoch : 3.497240882460521  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3832th epoch : 3.497238771984044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3833th epoch : 3.4972366598355635  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3834th epoch : 3.49723454601354  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3835th epoch : 3.497232430516433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3836th epoch : 3.4972303133427016  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3837th epoch : 3.4972281944908032  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3838th epoch : 3.497226073959194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3839th epoch : 3.4972239517463284  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3840th epoch : 3.4972218278506606  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3841th epoch : 3.4972197022706424  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3842th epoch : 3.497217575004725  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3843th epoch : 3.4972154460513587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3844th epoch : 3.4972133154089917  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3845th epoch : 3.4972111830760717  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3846th epoch : 3.4972090490510443  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3847th epoch : 3.497206913332355  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3848th epoch : 3.4972047759184464  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3849th epoch : 3.4972026368077613  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3850th epoch : 3.497200495998741  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3851th epoch : 3.4971983534898246  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3852th epoch : 3.4971962092794513  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3853th epoch : 3.4971940633660585  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3854th epoch : 3.4971919157480813  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3855th epoch : 3.4971897664239546  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3856th epoch : 3.4971876153921126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3857th epoch : 3.497185462650987  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3858th epoch : 3.4971833081990082  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3859th epoch : 3.4971811520346066  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3860th epoch : 3.4971789941562106  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3861th epoch : 3.4971768345622465  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3862th epoch : 3.4971746732511404  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3863th epoch : 3.497172510221317  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3864th epoch : 3.4971703454712  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3865th epoch : 3.497168178999211  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3866th epoch : 3.49716601080377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3867th epoch : 3.4971638408832972  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3868th epoch : 3.4971616692362106  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3869th epoch : 3.497159495860927  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3870th epoch : 3.497157320755862  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3871th epoch : 3.49715514391943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3872th epoch : 3.4971529653500437  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3873th epoch : 3.497150785046115  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3874th epoch : 3.4971486030060546  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3875th epoch : 3.4971464192282706  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3876th epoch : 3.4971442337111722  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3877th epoch : 3.4971420464531655  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3878th epoch : 3.4971398574526553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3879th epoch : 3.4971376667080456  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3880th epoch : 3.49713547421774  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3881th epoch : 3.497133279980139  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3882th epoch : 3.4971310839936427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3883th epoch : 3.4971288862566503  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3884th epoch : 3.497126686767559  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3885th epoch : 3.497124485524765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3886th epoch : 3.4971222825266635  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3887th epoch : 3.497120077771648  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3888th epoch : 3.497117871258111  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3889th epoch : 3.4971156629844424  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3890th epoch : 3.497113452949033  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3891th epoch : 3.4971112411502707  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3892th epoch : 3.497109027586543  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3893th epoch : 3.4971068122562348  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3894th epoch : 3.4971045951577318  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3895th epoch : 3.497102376289416  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3896th epoch : 3.4971001556496697  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3897th epoch : 3.4970979332368732  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3898th epoch : 3.497095709049406  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3899th epoch : 3.497093483085646  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3900th epoch : 3.4970912553439697  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3901th epoch : 3.4970890258227523  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3902th epoch : 3.4970867945203676  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3903th epoch : 3.4970845614351886  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3904th epoch : 3.497082326565586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3905th epoch : 3.4970800899099306  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3906th epoch : 3.49707785146659  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3907th epoch : 3.497075611233933  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3908th epoch : 3.497073369210324  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3909th epoch : 3.4970711253941285  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3910th epoch : 3.49706887978371  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3911th epoch : 3.49706663237743  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3912th epoch : 3.49706438317365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3913th epoch : 3.4970621321707287  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3914th epoch : 3.4970598793670242  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3915th epoch : 3.4970576247608935  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3916th epoch : 3.4970553683506918  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3917th epoch : 3.497053110134773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3918th epoch : 3.4970508501114903  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3919th epoch : 3.497048588279194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3920th epoch : 3.4970463246362358  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3921th epoch : 3.497044059180963  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3922th epoch : 3.497041791911723  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3923th epoch : 3.4970395228268627  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3924th epoch : 3.497037251924726  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3925th epoch : 3.497034979203657  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3926th epoch : 3.4970327046619967  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3927th epoch : 3.4970304282980864  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3928th epoch : 3.4970281501102654  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3929th epoch : 3.497025870096871  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3930th epoch : 3.4970235882562406  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3931th epoch : 3.497021304586709  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3932th epoch : 3.49701901908661  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3933th epoch : 3.497016731754276  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3934th epoch : 3.497014442588039  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3935th epoch : 3.4970121515862282  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3936th epoch : 3.4970098587471723  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3937th epoch : 3.4970075640691984  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3938th epoch : 3.4970052675506316  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3939th epoch : 3.4970029691897975  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3940th epoch : 3.497000668985018  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3941th epoch : 3.4969983669346156  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3942th epoch : 3.49699606303691  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3943th epoch : 3.496993757290221  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3944th epoch : 3.496991449692865  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3945th epoch : 3.4969891402431594  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3946th epoch : 3.496986828939418  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3947th epoch : 3.496984515779955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3948th epoch : 3.4969822007630826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3949th epoch : 3.4969798838871107  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3950th epoch : 3.4969775651503494  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3951th epoch : 3.496975244551107  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3952th epoch : 3.496972922087689  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3953th epoch : 3.4969705977584016  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3954th epoch : 3.496968271561548  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3955th epoch : 3.4969659434954314  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3956th epoch : 3.496963613558352  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3957th epoch : 3.496961281748611  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3958th epoch : 3.4969589480645054  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3959th epoch : 3.496956612504332  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3960th epoch : 3.496954275066388  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3961th epoch : 3.496951935748966  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3962th epoch : 3.4969495945503595  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3963th epoch : 3.49694725146886  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3964th epoch : 3.496944906502757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3965th epoch : 3.4969425596503396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3966th epoch : 3.4969402109098953  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3967th epoch : 3.4969378602797097  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3968th epoch : 3.496935507758067  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3969th epoch : 3.4969331533432504  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3970th epoch : 3.4969307970335417  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3971th epoch : 3.4969284388272213  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3972th epoch : 3.4969260787225678  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3973th epoch : 3.4969237167178586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3974th epoch : 3.4969213528113703  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3975th epoch : 3.4969189870013775  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3976th epoch : 3.496916619286153  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3977th epoch : 3.496914249663969  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3978th epoch : 3.496911878133096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3979th epoch : 3.496909504691803  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3980th epoch : 3.4969071293383576  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3981th epoch : 3.496904752071026  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3982th epoch : 3.4969023728880737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3983th epoch : 3.496899991787763  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3984th epoch : 3.4968976087683568  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3985th epoch : 3.496895223828115  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3986th epoch : 3.496892836965298  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3987th epoch : 3.4968904481781617  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3988th epoch : 3.496888057464964  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3989th epoch : 3.4968856648239592  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3990th epoch : 3.4968832702534014  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3991th epoch : 3.4968808737515418  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3992th epoch : 3.4968784753166315  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3993th epoch : 3.4968760749469197  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3994th epoch : 3.4968736726406546  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3995th epoch : 3.496871268396082  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3996th epoch : 3.496868862211447  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3997th epoch : 3.4968664540849934  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3998th epoch : 3.496864044014963  Training Accuracy:0.5357142857142857\n",
      "The training loss at 3999th epoch : 3.496861631999597  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4000th epoch : 3.4968592180371343  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4001th epoch : 3.4968568021258126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4002th epoch : 3.496854384263868  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4003th epoch : 3.496851964449536  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4004th epoch : 3.49684954268105  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4005th epoch : 3.496847118956642  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4006th epoch : 3.4968446932745425  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4007th epoch : 3.4968422656329805  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4008th epoch : 3.4968398360301842  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4009th epoch : 3.49683740446438  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4010th epoch : 3.4968349709337923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4011th epoch : 3.4968325354366443  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4012th epoch : 3.4968300979711584  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4013th epoch : 3.496827658535555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4014th epoch : 3.496825217128053  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4015th epoch : 3.4968227737468704  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4016th epoch : 3.496820328390223  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4017th epoch : 3.4968178810563257  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4018th epoch : 3.4968154317433915  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4019th epoch : 3.4968129804496324  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4020th epoch : 3.496810527173259  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4021th epoch : 3.496808071912479  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4022th epoch : 3.496805614665501  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4023th epoch : 3.4968031554305306  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4024th epoch : 3.496800694205772  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4025th epoch : 3.4967982309894285  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4026th epoch : 3.4967957657797015  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4027th epoch : 3.4967932985747914  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4028th epoch : 3.4967908293728964  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4029th epoch : 3.4967883581722137  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4030th epoch : 3.4967858849709392  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4031th epoch : 3.496783409767267  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4032th epoch : 3.4967809325593895  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4033th epoch : 3.4967784533454984  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4034th epoch : 3.4967759721237837  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4035th epoch : 3.496773488892433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4036th epoch : 3.4967710036496333  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4037th epoch : 3.49676851639357  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4038th epoch : 3.496766027122427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4039th epoch : 3.4967635358343867  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4040th epoch : 3.49676104252763  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4041th epoch : 3.4967585472003364  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4042th epoch : 3.4967560498506836  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4043th epoch : 3.496753550476848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4044th epoch : 3.496751049077005  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4045th epoch : 3.4967485456493272  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4046th epoch : 3.496746040191987  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4047th epoch : 3.496743532703155  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4048th epoch : 3.496741023181  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4049th epoch : 3.4967385116236893  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4050th epoch : 3.4967359980293895  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4051th epoch : 3.496733482396264  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4052th epoch : 3.496730964722477  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4053th epoch : 3.496728445006189  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4054th epoch : 3.49672592324556  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4055th epoch : 3.496723399438749  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4056th epoch : 3.4967208735839126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4057th epoch : 3.4967183456792066  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4058th epoch : 3.4967158157227844  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4059th epoch : 3.4967132837127983  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4060th epoch : 3.4967107496474004  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4061th epoch : 3.4967082135247387  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4062th epoch : 3.4967056753429615  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4063th epoch : 3.4967031351002156  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4064th epoch : 3.4967005927946455  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4065th epoch : 3.4966980484243946  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4066th epoch : 3.4966955019876047  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4067th epoch : 3.496692953482416  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4068th epoch : 3.496690402906967  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4069th epoch : 3.496687850259396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4070th epoch : 3.496685295537837  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4071th epoch : 3.496682738740426  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4072th epoch : 3.4966801798652942  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4073th epoch : 3.4966776189105735  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4074th epoch : 3.4966750558743933  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4075th epoch : 3.496672490754882  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4076th epoch : 3.4966699235501655  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4077th epoch : 3.496667354258369  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4078th epoch : 3.496664782877616  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4079th epoch : 3.4966622094060282  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4080th epoch : 3.496659633841727  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4081th epoch : 3.49665705618283  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4082th epoch : 3.4966544764274543  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4083th epoch : 3.496651894573717  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4084th epoch : 3.4966493106197314  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4085th epoch : 3.49664672456361  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4086th epoch : 3.496644136403465  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4087th epoch : 3.496641546137404  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4088th epoch : 3.496638953763537  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4089th epoch : 3.496636359279969  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4090th epoch : 3.496633762684806  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4091th epoch : 3.4966311639761503  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4092th epoch : 3.4966285631521044  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4093th epoch : 3.4966259602107685  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4094th epoch : 3.496623355150241  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4095th epoch : 3.4966207479686187  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4096th epoch : 3.4966181386639974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4097th epoch : 3.4966155272344714  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4098th epoch : 3.4966129136781325  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4099th epoch : 3.496610297993072  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4100th epoch : 3.496607680177379  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4101th epoch : 3.496605060229141  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4102th epoch : 3.4966024381464447  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4103th epoch : 3.4965998139273737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4104th epoch : 3.496597187570012  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4105th epoch : 3.49659455907244  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4106th epoch : 3.4965919284327382  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4107th epoch : 3.4965892956489846  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4108th epoch : 3.4965866607192555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4109th epoch : 3.4965840236416263  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4110th epoch : 3.496581384414171  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4111th epoch : 3.4965787430349606  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4112th epoch : 3.496576099502066  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4113th epoch : 3.4965734538135553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4114th epoch : 3.496570805967496  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4115th epoch : 3.4965681559619535  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4116th epoch : 3.4965655037949923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4117th epoch : 3.496562849464674  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4118th epoch : 3.4965601929690595  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4119th epoch : 3.4965575343062083  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4120th epoch : 3.4965548734741776  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4121th epoch : 3.496552210471023  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4122th epoch : 3.4965495452948  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4123th epoch : 3.4965468779435604  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4124th epoch : 3.4965442084153553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4125th epoch : 3.4965415367082344  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4126th epoch : 3.4965388628202456  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4127th epoch : 3.4965361867494353  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4128th epoch : 3.4965335084938483  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4129th epoch : 3.4965308280515273  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4130th epoch : 3.496528145420514  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4131th epoch : 3.496525460598848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4132th epoch : 3.4965227735845676  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4133th epoch : 3.4965200843757094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4134th epoch : 3.4965173929703086  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4135th epoch : 3.4965146993663985  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4136th epoch : 3.4965120035620103  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4137th epoch : 3.4965093055551746  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4138th epoch : 3.4965066053439195  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4139th epoch : 3.4965039029262726  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4140th epoch : 3.4965011983002583  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4141th epoch : 3.4964984914639  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4142th epoch : 3.4964957824152205  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4143th epoch : 3.4964930711522393  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4144th epoch : 3.496490357672976  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4145th epoch : 3.4964876419754463  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4146th epoch : 3.496484924057666  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4147th epoch : 3.4964822039176497  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4148th epoch : 3.4964794815534086  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4149th epoch : 3.4964767569629536  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4150th epoch : 3.496474030144293  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4151th epoch : 3.4964713010954345  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4152th epoch : 3.496468569814383  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4153th epoch : 3.4964658362991425  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4154th epoch : 3.496463100547716  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4155th epoch : 3.4964603625581026  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4156th epoch : 3.4964576223283017  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4157th epoch : 3.496454879856311  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4158th epoch : 3.4964521351401254  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4159th epoch : 3.496449388177739  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4160th epoch : 3.4964466389671442  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4161th epoch : 3.4964438875063317  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4162th epoch : 3.4964411337932897  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4163th epoch : 3.4964383778260055  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4164th epoch : 3.496435619602465  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4165th epoch : 3.496432859120652  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4166th epoch : 3.4964300963785484  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4167th epoch : 3.496427331374135  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4168th epoch : 3.49642456410539  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4169th epoch : 3.4964217945702916  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4170th epoch : 3.4964190227668146  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4171th epoch : 3.4964162486929324  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4172th epoch : 3.496413472346618  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4173th epoch : 3.496410693725841  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4174th epoch : 3.49640791282857  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4175th epoch : 3.4964051296527727  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4176th epoch : 3.4964023441964143  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4177th epoch : 3.496399556457458  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4178th epoch : 3.496396766433866  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4179th epoch : 3.4963939741235985  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4180th epoch : 3.496391179524614  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4181th epoch : 3.496388382634869  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4182th epoch : 3.4963855834523194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4183th epoch : 3.496382781974918  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4184th epoch : 3.4963799782006166  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4185th epoch : 3.496377172127365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4186th epoch : 3.496374363753112  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4187th epoch : 3.4963715530758037  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4188th epoch : 3.496368740093385  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4189th epoch : 3.4963659248037997  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4190th epoch : 3.4963631072049886  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4191th epoch : 3.496360287294891  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4192th epoch : 3.4963574650714455  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4193th epoch : 3.4963546405325885  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4194th epoch : 3.496351813676254  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4195th epoch : 3.4963489845003757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4196th epoch : 3.496346153002883  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4197th epoch : 3.4963433191817073  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4198th epoch : 3.4963404830347744  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4199th epoch : 3.496337644560011  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4200th epoch : 3.4963348037553414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4201th epoch : 3.496331960618688  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4202th epoch : 3.496329115147971  Training Accuracy:0.5357142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 4203th epoch : 3.496326267341109  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4204th epoch : 3.4963234171960202  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4205th epoch : 3.4963205647106195  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4206th epoch : 3.4963177098828204  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4207th epoch : 3.4963148527105354  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4208th epoch : 3.4963119931916737  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4209th epoch : 3.496309131324145  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4210th epoch : 3.4963062671058545  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4211th epoch : 3.4963034005347082  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4212th epoch : 3.496300531608609  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4213th epoch : 3.496297660325458  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4214th epoch : 3.4962947866831553  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4215th epoch : 3.496291910679598  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4216th epoch : 3.4962890323126827  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4217th epoch : 3.496286151580304  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4218th epoch : 3.496283268480354  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4219th epoch : 3.496280383010723  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4220th epoch : 3.496277495169301  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4221th epoch : 3.496274604953975  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4222th epoch : 3.49627171236263  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4223th epoch : 3.4962688173931498  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4224th epoch : 3.4962659200434163  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4225th epoch : 3.49626302031131  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4226th epoch : 3.496260118194708  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4227th epoch : 3.4962572136914885  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4228th epoch : 3.4962543067995253  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4229th epoch : 3.496251397516691  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4230th epoch : 3.4962484858408573  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4231th epoch : 3.4962455717698937  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4232th epoch : 3.4962426553016672  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4233th epoch : 3.4962397364340436  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4234th epoch : 3.4962368151648873  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4235th epoch : 3.49623389149206  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4236th epoch : 3.4962309654134223  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4237th epoch : 3.4962280369268326  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4238th epoch : 3.4962251060301472  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4239th epoch : 3.4962221727212217  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4240th epoch : 3.496219236997909  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4241th epoch : 3.4962162988580596  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4242th epoch : 3.4962133582995243  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4243th epoch : 3.4962104153201494  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4244th epoch : 3.4962074699177816  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4245th epoch : 3.4962045220902644  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4246th epoch : 3.49620157183544  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4247th epoch : 3.4961986191511487  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4248th epoch : 3.4961956640352296  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4249th epoch : 3.4961927064855183  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4250th epoch : 3.49618974649985  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4251th epoch : 3.4961867840760585  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4252th epoch : 3.4961838192119736  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4253th epoch : 3.4961808519054256  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4254th epoch : 3.4961778821542415  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4255th epoch : 3.4961749099562467  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4256th epoch : 3.4961719353092655  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4257th epoch : 3.4961689582111197  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4258th epoch : 3.496165978659629  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4259th epoch : 3.4961629966526115  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4260th epoch : 3.496160012187884  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4261th epoch : 3.496157025263261  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4262th epoch : 3.4961540358765544  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4263th epoch : 3.496151044025576  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4264th epoch : 3.496148049708134  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4265th epoch : 3.496145052922035  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4266th epoch : 3.496142053665085  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4267th epoch : 3.4961390519350872  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4268th epoch : 3.4961360477298427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4269th epoch : 3.496133041047151  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4270th epoch : 3.49613003188481  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4271th epoch : 3.4961270202406154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4272th epoch : 3.4961240061123604  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4273th epoch : 3.4961209894978382  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4274th epoch : 3.4961179703948377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4275th epoch : 3.4961149488011483  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4276th epoch : 3.496111924714555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4277th epoch : 3.4961088981328436  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4278th epoch : 3.4961058690537956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4279th epoch : 3.4961028374751923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4280th epoch : 3.496099803394812  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4281th epoch : 3.4960967668104317  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4282th epoch : 3.496093727719826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4283th epoch : 3.4960906861207683  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4284th epoch : 3.49608764201103  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4285th epoch : 3.4960845953883797  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4286th epoch : 3.4960815462505845  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4287th epoch : 3.4960784945954106  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4288th epoch : 3.4960754404206207  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4289th epoch : 3.496072383723977  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4290th epoch : 3.4960693245032384  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4291th epoch : 3.4960662627561625  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4292th epoch : 3.4960631984805057  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4293th epoch : 3.4960601316740214  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4294th epoch : 3.4960570623344616  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4295th epoch : 3.4960539904595764  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4296th epoch : 3.496050916047113  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4297th epoch : 3.496047839094819  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4298th epoch : 3.4960447596004367  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4299th epoch : 3.4960416775617094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4300th epoch : 3.496038592976377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4301th epoch : 3.496035505842178  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4302th epoch : 3.496032416156848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4303th epoch : 3.496029323918122  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4304th epoch : 3.4960262291237325  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4305th epoch : 3.49602313177141  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4306th epoch : 3.4960200318588823  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4307th epoch : 3.4960169293838765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4308th epoch : 3.496013824344117  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4309th epoch : 3.496010716737326  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4310th epoch : 3.496007606561225  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4311th epoch : 3.4960044938135315  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4312th epoch : 3.496001378491963  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4313th epoch : 3.495998260594234  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4314th epoch : 3.495995140118057  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4315th epoch : 3.495992017061143  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4316th epoch : 3.4959888914212  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4317th epoch : 3.495985763195936  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4318th epoch : 3.4959826323830545  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4319th epoch : 3.495979498980259  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4320th epoch : 3.49597636298525  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4321th epoch : 3.495973224395726  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4322th epoch : 3.4959700832093845  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4323th epoch : 3.4959669394239192  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4324th epoch : 3.4959637930370238  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4325th epoch : 3.4959606440463884  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4326th epoch : 3.4959574924497017  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4327th epoch : 3.495954338244651  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4328th epoch : 3.4959511814289206  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4329th epoch : 3.495948022000193  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4330th epoch : 3.495944859956149  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4331th epoch : 3.495941695294467  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4332th epoch : 3.4959385280128243  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4333th epoch : 3.4959353581088948  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4334th epoch : 3.495932185580351  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4335th epoch : 3.495929010424864  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4336th epoch : 3.495925832640101  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4337th epoch : 3.49592265222373  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4338th epoch : 3.495919469173414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4339th epoch : 3.4959162834868165  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4340th epoch : 3.495913095161597  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4341th epoch : 3.495909904195414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4342th epoch : 3.495906710585923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4343th epoch : 3.495903514330779  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4344th epoch : 3.495900315427634  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4345th epoch : 3.4958971138741375  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4346th epoch : 3.4958939096679376  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4347th epoch : 3.49589070280668  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4348th epoch : 3.4958874932880093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4349th epoch : 3.495884281109566  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4350th epoch : 3.4958810662689905  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4351th epoch : 3.49587784876392  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4352th epoch : 3.4958746285919906  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4353th epoch : 3.495871405750835  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4354th epoch : 3.4958681802380847  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4355th epoch : 3.495864952051369  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4356th epoch : 3.495861721188315  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4357th epoch : 3.4958584876465473  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4358th epoch : 3.4958552514236896  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4359th epoch : 3.4958520125173624  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4360th epoch : 3.4958487709251846  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4361th epoch : 3.4958455266447723  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4362th epoch : 3.4958422796737403  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4363th epoch : 3.495839030009701  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4364th epoch : 3.495835777650265  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4365th epoch : 3.49583252259304  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4366th epoch : 3.4958292648356326  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4367th epoch : 3.495826004375646  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4368th epoch : 3.4958227412106826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4369th epoch : 3.4958194753383416  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4370th epoch : 3.4958162067562206  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4371th epoch : 3.4958129354619154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4372th epoch : 3.495809661453019  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4373th epoch : 3.4958063847271226  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4374th epoch : 3.495803105281815  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4375th epoch : 3.4957998231146834  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4376th epoch : 3.495796538223312  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4377th epoch : 3.4957932506052836  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4378th epoch : 3.4957899602581786  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4379th epoch : 3.4957866671795754  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4380th epoch : 3.4957833713670494  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4381th epoch : 3.4957800728181754  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4382th epoch : 3.495776771530524  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4383th epoch : 3.495773467501666  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4384th epoch : 3.495770160729168  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4385th epoch : 3.4957668512105955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4386th epoch : 3.4957635389435113  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4387th epoch : 3.4957602239254766  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4388th epoch : 3.4957569061540497  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4389th epoch : 3.495753585626787  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4390th epoch : 3.4957502623412435  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4391th epoch : 3.4957469362949705  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4392th epoch : 3.4957436074855184  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4393th epoch : 3.4957402759104346  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4394th epoch : 3.495736941567264  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4395th epoch : 3.495733604453551  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4396th epoch : 3.4957302645668364  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4397th epoch : 3.4957269219046587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4398th epoch : 3.4957235764645547  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4399th epoch : 3.495720228244059  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4400th epoch : 3.4957168772407035  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4401th epoch : 3.495713523452018  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4402th epoch : 3.495710166875531  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4403th epoch : 3.495706807508767  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4404th epoch : 3.4957034453492506  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4405th epoch : 3.4957000803945015  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4406th epoch : 3.4956967126420393  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4407th epoch : 3.49569334208938  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4408th epoch : 3.495689968734039  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4409th epoch : 3.4956865925735268  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4410th epoch : 3.4956832136053544  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4411th epoch : 3.495679831827029  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4412th epoch : 3.4956764472360558  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4413th epoch : 3.4956730598299375  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4414th epoch : 3.4956696696061753  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4415th epoch : 3.495666276562268  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4416th epoch : 3.4956628806957113  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4417th epoch : 3.495659482003999  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4418th epoch : 3.495656080484623  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4419th epoch : 3.4956526761350726  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4420th epoch : 3.4956492689528353  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4421th epoch : 3.4956458589353954  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4422th epoch : 3.4956424460802356  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4423th epoch : 3.4956390303848357  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4424th epoch : 3.4956356118466743  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4425th epoch : 3.495632190463226  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4426th epoch : 3.4956287662319654  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4427th epoch : 3.495625339150363  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4428th epoch : 3.495621909215887  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4429th epoch : 3.495618476426004  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4430th epoch : 3.4956150407781776  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4431th epoch : 3.4956116022698707  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4432th epoch : 3.4956081608985414  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4433th epoch : 3.4956047166616475  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4434th epoch : 3.495601269556644  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4435th epoch : 3.495597819580982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4436th epoch : 3.4955943667321128  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4437th epoch : 3.495590911007483  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4438th epoch : 3.495587452404539  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4439th epoch : 3.4955839909207236  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4440th epoch : 3.4955805265534767  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4441th epoch : 3.495577059300237  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4442th epoch : 3.495573589158441  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4443th epoch : 3.4955701161255215  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4444th epoch : 3.4955666401989096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4445th epoch : 3.4955631613760345  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4446th epoch : 3.4955596796543227  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4447th epoch : 3.4955561950311975  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4448th epoch : 3.4955527075040815  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4449th epoch : 3.4955492170703937  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4450th epoch : 3.4955457237275507  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4451th epoch : 3.4955422274729675  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4452th epoch : 3.4955387283040555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4453th epoch : 3.495535226218225  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4454th epoch : 3.495531721212883  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4455th epoch : 3.495528213285434  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4456th epoch : 3.495524702433281  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4457th epoch : 3.495521188653824  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4458th epoch : 3.495517671944461  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4459th epoch : 3.495514152302586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4460th epoch : 3.495510629725593  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4461th epoch : 3.4955071042108714  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4462th epoch : 3.49550357575581  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4463th epoch : 3.4955000443577937  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4464th epoch : 3.4954965100142052  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4465th epoch : 3.495492972722426  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4466th epoch : 3.495489432479834  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4467th epoch : 3.495485889283804  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4468th epoch : 3.49548234313171  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4469th epoch : 3.4954787940209227  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4470th epoch : 3.49547524194881  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4471th epoch : 3.4954716869127385  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4472th epoch : 3.4954681289100704  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4473th epoch : 3.4954645679381677  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4474th epoch : 3.4954610039943876  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4475th epoch : 3.4954574370760874  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4476th epoch : 3.4954538671806192  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4477th epoch : 3.495450294305335  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4478th epoch : 3.4954467184475826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4479th epoch : 3.4954431396047076  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4480th epoch : 3.4954395577740542  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4481th epoch : 3.4954359729529627  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4482th epoch : 3.495432385138772  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4483th epoch : 3.495428794328818  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4484th epoch : 3.495425200520433  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4485th epoch : 3.4954216037109487  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4486th epoch : 3.4954180038976936  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4487th epoch : 3.4954144010779933  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4488th epoch : 3.4954107952491706  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4489th epoch : 3.4954071864085465  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4490th epoch : 3.495403574553439  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4491th epoch : 3.4953999596811642  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4492th epoch : 3.4953963417890344  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4493th epoch : 3.495392720874361  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4494th epoch : 3.4953890969344505  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4495th epoch : 3.49538546996661  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4496th epoch : 3.495381839968141  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4497th epoch : 3.4953782069363437  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4498th epoch : 3.4953745708685164  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4499th epoch : 3.495370931761954  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4500th epoch : 3.495367289613949  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4501th epoch : 3.4953636444217913  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4502th epoch : 3.495359996182768  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4503th epoch : 3.4953563448941636  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4504th epoch : 3.4953526905532604  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4505th epoch : 3.495349033157338  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4506th epoch : 3.4953453727036727  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4507th epoch : 3.4953417091895393  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4508th epoch : 3.4953380426122096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4509th epoch : 3.495334372968952  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4510th epoch : 3.4953307002570333  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4511th epoch : 3.495327024473717  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4512th epoch : 3.4953233456162645  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4513th epoch : 3.4953196636819337  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4514th epoch : 3.4953159786679806  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4515th epoch : 3.495312290571659  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4516th epoch : 3.4953085993902184  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4517th epoch : 3.4953049051209075  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4518th epoch : 3.495301207760971  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4519th epoch : 3.4952975073076513  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4520th epoch : 3.4952938037581887  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4521th epoch : 3.49529009710982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4522th epoch : 3.49528638735978  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4523th epoch : 3.4952826745053  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4524th epoch : 3.4952789585436093  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4525th epoch : 3.4952752394719346  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4526th epoch : 3.4952715172874993  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4527th epoch : 3.495267791987524  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4528th epoch : 3.495264063569228  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4529th epoch : 3.4952603320298263  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4530th epoch : 3.4952565973665313  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4531th epoch : 3.495252859576554  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4532th epoch : 3.4952491186571013  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4533th epoch : 3.495245374605378  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4534th epoch : 3.495241627418586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4535th epoch : 3.4952378770939245  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4536th epoch : 3.49523412362859  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4537th epoch : 3.4952303670197757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4538th epoch : 3.4952266072646734  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4539th epoch : 3.495222844360471  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4540th epoch : 3.4952190783043533  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4541th epoch : 3.4952153090935036  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4542th epoch : 3.4952115367251015  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4543th epoch : 3.4952077611963244  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4544th epoch : 3.4952039825043464  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4545th epoch : 3.4952002006463387  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4546th epoch : 3.4951964156194704  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4547th epoch : 3.4951926274209075  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4548th epoch : 3.4951888360478125  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4549th epoch : 3.4951850414973467  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4550th epoch : 3.4951812437666665  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4551th epoch : 3.495177442852927  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4552th epoch : 3.495173638753281  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4553th epoch : 3.4951698314648763  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4554th epoch : 3.495166020984859  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4555th epoch : 3.4951622073103734  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4556th epoch : 3.4951583904385597  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4557th epoch : 3.495154570366555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4558th epoch : 3.495150747091495  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4559th epoch : 3.495146920610511  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4560th epoch : 3.495143090920732  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4561th epoch : 3.495139258019285  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4562th epoch : 3.495135421903292  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4563th epoch : 3.495131582569875  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4564th epoch : 3.495127740016151  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4565th epoch : 3.4951238942392346  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4566th epoch : 3.4951200452362374  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4567th epoch : 3.4951161930042685  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4568th epoch : 3.495112337540434  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4569th epoch : 3.4951084788418365  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4570th epoch : 3.4951046169055773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4571th epoch : 3.4951007517287525  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4572th epoch : 3.495096883308457  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4573th epoch : 3.495093011641782  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4574th epoch : 3.495089136725816  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4575th epoch : 3.4950852585576446  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4576th epoch : 3.4950813771343503  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4577th epoch : 3.4950774924530132  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4578th epoch : 3.495073604510709  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4579th epoch : 3.4950697133045128  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4580th epoch : 3.495065818831494  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4581th epoch : 3.495061921088721  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4582th epoch : 3.4950580200732584  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4583th epoch : 3.4950541157821684  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4584th epoch : 3.4950502082125094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4585th epoch : 3.495046297361337  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4586th epoch : 3.495042383225705  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4587th epoch : 3.4950384658026623  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4588th epoch : 3.4950345450892564  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4589th epoch : 3.4950306210825306  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4590th epoch : 3.495026693779526  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4591th epoch : 3.49502276317728  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4592th epoch : 3.4950188292728277  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4593th epoch : 3.4950148920632005  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4594th epoch : 3.495010951545427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4595th epoch : 3.495007007716533  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4596th epoch : 3.495003060573541  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4597th epoch : 3.4949991101134703  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4598th epoch : 3.4949951563333377  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4599th epoch : 3.494991199230156  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4600th epoch : 3.4949872388009364  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4601th epoch : 3.494983275042685  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4602th epoch : 3.494979307952406  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4603th epoch : 3.494975337527101  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4604th epoch : 3.4949713637637676  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4605th epoch : 3.494967386659401  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4606th epoch : 3.4949634062109918  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4607th epoch : 3.4949594224155294  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4608th epoch : 3.494955435269999  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4609th epoch : 3.494951444771383  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4610th epoch : 3.4949474509166607  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4611th epoch : 3.494943453702808  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4612th epoch : 3.4949394531267974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4613th epoch : 3.4949354491855993  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4614th epoch : 3.49493144187618  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4615th epoch : 3.4949274311955025  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4616th epoch : 3.4949234171405275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4617th epoch : 3.4949193997082117  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4618th epoch : 3.4949153788955094  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4619th epoch : 3.494911354699371  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4620th epoch : 3.494907327116744  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4621th epoch : 3.4949032961445727  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4622th epoch : 3.4948992617797985  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4623th epoch : 3.4948952240193587  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4624th epoch : 3.4948911828601887  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4625th epoch : 3.494887138299219  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4626th epoch : 3.4948830903333783  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4627th epoch : 3.4948790389595916  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4628th epoch : 3.4948749841747806  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4629th epoch : 3.4948709259758637  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4630th epoch : 3.4948668643597562  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4631th epoch : 3.4948627993233696  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4632th epoch : 3.4948587308636134  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4633th epoch : 3.494854658977392  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4634th epoch : 3.494850583661608  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4635th epoch : 3.4948465049131605  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4636th epoch : 3.4948424227289445  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4637th epoch : 3.494838337105853  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4638th epoch : 3.494834248040774  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4639th epoch : 3.4948301555305936  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4640th epoch : 3.494826059572194  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4641th epoch : 3.4948219601624544  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4642th epoch : 3.49481785729825  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4643th epoch : 3.4948137509764536  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4644th epoch : 3.4948096411939336  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4645th epoch : 3.494805527947556  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4646th epoch : 3.494801411234183  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4647th epoch : 3.494797291050673  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4648th epoch : 3.4947931673938823  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4649th epoch : 3.4947890402606623  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4650th epoch : 3.494784909647862  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4651th epoch : 3.4947807755523272  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4652th epoch : 3.494776637970899  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4653th epoch : 3.4947724969004166  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4654th epoch : 3.4947683523377147  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4655th epoch : 3.494764204279625  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4656th epoch : 3.4947600527229765  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4657th epoch : 3.494755897664593  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4658th epoch : 3.494751739101297  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4659th epoch : 3.4947475770299055  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4660th epoch : 3.4947434114472333  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4661th epoch : 3.494739242350092  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4662th epoch : 3.4947350697352886  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4663th epoch : 3.4947308935996273  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4664th epoch : 3.4947267139399085  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4665th epoch : 3.4947225307529304  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4666th epoch : 3.494718344035485  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4667th epoch : 3.494714153784364  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4668th epoch : 3.4947099599963534  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4669th epoch : 3.4947057626682363  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4670th epoch : 3.4947015617967923  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4671th epoch : 3.494697357378797  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4672th epoch : 3.494693149411024  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4673th epoch : 3.4946889378902415  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4674th epoch : 3.4946847228132154  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4675th epoch : 3.4946805041767073  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4676th epoch : 3.4946762819774757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4677th epoch : 3.494672056212275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4678th epoch : 3.4946678268778566  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4679th epoch : 3.4946635939709685  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4680th epoch : 3.494659357488354  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4681th epoch : 3.494655117426754  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4682th epoch : 3.4946508737829047  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4683th epoch : 3.4946466265535396  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4684th epoch : 3.4946423757353884  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4685th epoch : 3.494638121325177  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4686th epoch : 3.4946338633196277  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4687th epoch : 3.4946296017154586  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4688th epoch : 3.4946253365093853  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4689th epoch : 3.4946210676981186  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4690th epoch : 3.4946167952783664  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4691th epoch : 3.4946125192468327  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4692th epoch : 3.494608239600218  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4693th epoch : 3.4946039563352183  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4694th epoch : 3.494599669448527  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4695th epoch : 3.4945953789368334  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4696th epoch : 3.4945910847968222  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4697th epoch : 3.4945867870251757  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4698th epoch : 3.494582485618572  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4699th epoch : 3.4945781805736855  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4700th epoch : 3.494573871887186  Training Accuracy:0.5357142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 4701th epoch : 3.494569559555741  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4702th epoch : 3.4945652435760137  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4703th epoch : 3.4945609239446624  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4704th epoch : 3.4945566006583437  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4705th epoch : 3.4945522737137087  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4706th epoch : 3.494547943107405  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4707th epoch : 3.4945436088360773  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4708th epoch : 3.494539270896366  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4709th epoch : 3.494534929284907  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4710th epoch : 3.4945305839983334  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4711th epoch : 3.4945262350332738  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4712th epoch : 3.494521882386353  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4713th epoch : 3.494517526054193  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4714th epoch : 3.49451316603341  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4715th epoch : 3.4945088023206186  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4716th epoch : 3.4945044349124275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4717th epoch : 3.4945000638054426  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4718th epoch : 3.4944956889962655  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4719th epoch : 3.4944913104814943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4720th epoch : 3.4944869282577233  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4721th epoch : 3.494482542321542  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4722th epoch : 3.494478152669537  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4723th epoch : 3.49447375929829  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4724th epoch : 3.49446936220438  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4725th epoch : 3.494464961384381  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4726th epoch : 3.494460556834863  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4727th epoch : 3.4944561485523926  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4728th epoch : 3.494451736533533  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4729th epoch : 3.494447320774842  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4730th epoch : 3.494442901272874  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4731th epoch : 3.4944384780241795  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4732th epoch : 3.4944340510253054  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4733th epoch : 3.494429620272794  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4734th epoch : 3.494425185763183  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4735th epoch : 3.4944207474930082  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4736th epoch : 3.4944163054587993  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4737th epoch : 3.4944118596570823  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4738th epoch : 3.4944074100843796  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4739th epoch : 3.49440295673721  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4740th epoch : 3.4943984996120867  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4741th epoch : 3.4943940387055203  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4742th epoch : 3.4943895740140167  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4743th epoch : 3.4943851055340778  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4744th epoch : 3.494380633262201  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4745th epoch : 3.49437615719488  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4746th epoch : 3.4943716773286053  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4747th epoch : 3.4943671936598606  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4748th epoch : 3.4943627061851283  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4749th epoch : 3.4943582149008847  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4750th epoch : 3.494353719803603  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4751th epoch : 3.4943492208897524  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4752th epoch : 3.494344718155797  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4753th epoch : 3.494340211598197  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4754th epoch : 3.494335701213408  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4755th epoch : 3.4943311869978837  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4756th epoch : 3.49432666894807  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4757th epoch : 3.4943221470604113  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4758th epoch : 3.4943176213313465  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4759th epoch : 3.494313091757311  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4760th epoch : 3.494308558334735  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4761th epoch : 3.4943040210600453  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4762th epoch : 3.494299479929664  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4763th epoch : 3.494294934940009  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4764th epoch : 3.4942903860874943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4765th epoch : 3.4942858333685285  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4766th epoch : 3.494281276779517  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4767th epoch : 3.4942767163168607  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4768th epoch : 3.494272151976956  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4769th epoch : 3.4942675837561943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4770th epoch : 3.4942630116509634  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4771th epoch : 3.494258435657647  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4772th epoch : 3.494253855772624  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4773th epoch : 3.494249271992268  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4774th epoch : 3.494244684312951  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4775th epoch : 3.494240092731037  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4776th epoch : 3.494235497242888  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4777th epoch : 3.494230897844861  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4778th epoch : 3.4942262945333087  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4779th epoch : 3.4942216873045786  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4780th epoch : 3.4942170761550146  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4781th epoch : 3.4942124610809557  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4782th epoch : 3.4942078420787372  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4783th epoch : 3.4942032191446883  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4784th epoch : 3.4941985922751355  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4785th epoch : 3.4941939614664  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4786th epoch : 3.494189326714798  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4787th epoch : 3.4941846880166416  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4788th epoch : 3.494180045368239  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4789th epoch : 3.494175398765893  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4790th epoch : 3.4941707482059026  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4791th epoch : 3.494166093684561  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4792th epoch : 3.494161435198158  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4793th epoch : 3.4941567727429788  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4794th epoch : 3.4941521063153034  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4795th epoch : 3.4941474359114073  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4796th epoch : 3.4941427615275615  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4797th epoch : 3.4941380831600326  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4798th epoch : 3.4941334008050826  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4799th epoch : 3.494128714458968  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4800th epoch : 3.494124024117942  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4801th epoch : 3.494119329778252  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4802th epoch : 3.494114631436141  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4803th epoch : 3.494109929087848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4804th epoch : 3.494105222729606  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4805th epoch : 3.4941005123576447  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4806th epoch : 3.494095797968188  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4807th epoch : 3.494091079557456  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4808th epoch : 3.494086357121663  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4809th epoch : 3.4940816306570195  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4810th epoch : 3.494076900159731  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4811th epoch : 3.4940721656259974  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4812th epoch : 3.494067427052015  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4813th epoch : 3.4940626844339744  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4814th epoch : 3.4940579377680625  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4815th epoch : 3.4940531870504596  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4816th epoch : 3.4940484322773435  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4817th epoch : 3.4940436734448848  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4818th epoch : 3.494038910549251  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4819th epoch : 3.4940341435866036  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4820th epoch : 3.4940293725531  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4821th epoch : 3.4940245974448927  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4822th epoch : 3.4940198182581286  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4823th epoch : 3.49401503498895  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4824th epoch : 3.494010247633495  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4825th epoch : 3.4940054561878955  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4826th epoch : 3.4940006606482794  Training Accuracy:0.5357142857142857\n",
      "The training loss at 4827th epoch : 3.4939958610107698  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4828th epoch : 3.493991057271484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4829th epoch : 3.4939862494265346  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4830th epoch : 3.4939814374720295  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4831th epoch : 3.4939766214040713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4832th epoch : 3.493971801218758  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4833th epoch : 3.493966976912182  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4834th epoch : 3.4939621484804317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4835th epoch : 3.4939573159195887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4836th epoch : 3.4939524792257313  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4837th epoch : 3.4939476383949315  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4838th epoch : 3.4939427934232574  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4839th epoch : 3.4939379443067704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4840th epoch : 3.4939330910415287  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4841th epoch : 3.4939282336235835  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4842th epoch : 3.4939233720489824  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4843th epoch : 3.4939185063137668  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4844th epoch : 3.4939136364139736  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4845th epoch : 3.4939087623456344  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4846th epoch : 3.493903884104775  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4847th epoch : 3.493899001687417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4848th epoch : 3.4938941150895766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4849th epoch : 3.4938892243072637  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4850th epoch : 3.4938843293364847  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4851th epoch : 3.493879430173239  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4852th epoch : 3.4938745268135216  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4853th epoch : 3.493869619253323  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4854th epoch : 3.493864707488627  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4855th epoch : 3.493859791515413  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4856th epoch : 3.493854871329655  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4857th epoch : 3.493849946927321  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4858th epoch : 3.4938450183043743  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4859th epoch : 3.4938400854567733  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4860th epoch : 3.49383514838047  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4861th epoch : 3.4938302070714116  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4862th epoch : 3.49382526152554  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4863th epoch : 3.4938203117387916  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4864th epoch : 3.493815357707097  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4865th epoch : 3.493810399426382  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4866th epoch : 3.493805436892567  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4867th epoch : 3.4938004701015664  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4868th epoch : 3.493795499049289  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4869th epoch : 3.4937905237316387  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4870th epoch : 3.4937855441445143  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4871th epoch : 3.493780560283808  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4872th epoch : 3.4937755721454073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4873th epoch : 3.4937705797251937  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4874th epoch : 3.4937655830190435  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4875th epoch : 3.4937605820228272  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4876th epoch : 3.49375557673241  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4877th epoch : 3.493750567143651  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4878th epoch : 3.493745553252405  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4879th epoch : 3.493740535054519  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4880th epoch : 3.493735512545837  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4881th epoch : 3.4937304857221947  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4882th epoch : 3.4937254545794247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4883th epoch : 3.4937204191133517  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4884th epoch : 3.493715379319797  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4885th epoch : 3.4937103351945735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4886th epoch : 3.4937052867334906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4887th epoch : 3.4937002339323513  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4888th epoch : 3.4936951767869524  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4889th epoch : 3.493690115293086  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4890th epoch : 3.4936850494465372  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4891th epoch : 3.493679979243087  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4892th epoch : 3.4936749046785076  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4893th epoch : 3.493669825748569  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4894th epoch : 3.4936647424490337  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4895th epoch : 3.4936596547756578  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4896th epoch : 3.4936545627241924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4897th epoch : 3.4936494662903823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4898th epoch : 3.493644365469967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4899th epoch : 3.4936392602586794  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4900th epoch : 3.493634150652247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4901th epoch : 3.4936290366463916  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4902th epoch : 3.493623918236828  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4903th epoch : 3.4936187954192666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4904th epoch : 3.4936136681894103  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4905th epoch : 3.4936085365429568  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4906th epoch : 3.4936034004755987  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4907th epoch : 3.4935982599830204  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4908th epoch : 3.4935931150609023  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4909th epoch : 3.4935879657049176  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4910th epoch : 3.4935828119107337  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4911th epoch : 3.493577653674013  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4912th epoch : 3.49357249099041  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4913th epoch : 3.4935673238555744  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4914th epoch : 3.493562152265149  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4915th epoch : 3.493556976214772  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4916th epoch : 3.493551795700073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4917th epoch : 3.4935466107166775  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4918th epoch : 3.493541421260204  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4919th epoch : 3.493536227326265  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4920th epoch : 3.4935310289104664  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4921th epoch : 3.4935258260084088  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4922th epoch : 3.4935206186156855  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4923th epoch : 3.4935154067278846  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4924th epoch : 3.493510190340587  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4925th epoch : 3.493504969449367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4926th epoch : 3.493499744049795  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4927th epoch : 3.493494514137432  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4928th epoch : 3.4934892797078345  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4929th epoch : 3.493484040756553  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4930th epoch : 3.4934787972791295  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4931th epoch : 3.4934735492711018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4932th epoch : 3.4934682967280004  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4933th epoch : 3.49346303964535  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4934th epoch : 3.4934577780186675  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4935th epoch : 3.4934525118434645  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4936th epoch : 3.4934472411152466  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4937th epoch : 3.4934419658295117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4938th epoch : 3.4934366859817514  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4939th epoch : 3.493431401567452  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4940th epoch : 3.493426112582092  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4941th epoch : 3.4934208190211438  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4942th epoch : 3.493415520880073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4943th epoch : 3.493410218154339  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4944th epoch : 3.493404910839395  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4945th epoch : 3.4933995989306865  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4946th epoch : 3.4933942824236532  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4947th epoch : 3.4933889613137277  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4948th epoch : 3.4933836355963366  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4949th epoch : 3.493378305266899  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4950th epoch : 3.4933729703208285  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4951th epoch : 3.4933676307535304  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4952th epoch : 3.493362286560404  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4953th epoch : 3.4933569377368427  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4954th epoch : 3.493351584278232  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4955th epoch : 3.493346226179951  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4956th epoch : 3.493340863437372  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4957th epoch : 3.4933354960458614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4958th epoch : 3.4933301240007766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4959th epoch : 3.4933247472974704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4960th epoch : 3.4933193659312876  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4961th epoch : 3.493313979897566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4962th epoch : 3.493308589191637  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4963th epoch : 3.4933031938088255  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4964th epoch : 3.4932977937444485  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4965th epoch : 3.493292388993816  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4966th epoch : 3.4932869795522326  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4967th epoch : 3.493281565414994  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4968th epoch : 3.4932761465773896  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4969th epoch : 3.4932707230347027  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4970th epoch : 3.493265294782208  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4971th epoch : 3.4932598618151744  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4972th epoch : 3.493254424128863  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4973th epoch : 3.4932489817185277  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4974th epoch : 3.4932435345794164  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4975th epoch : 3.493238082706769  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4976th epoch : 3.4932326260958177  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4977th epoch : 3.4932271647417887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4978th epoch : 3.4932216986399003  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4979th epoch : 3.4932162277853642  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4980th epoch : 3.493210752173384  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4981th epoch : 3.4932052717991566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4982th epoch : 3.4931997866578723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4983th epoch : 3.4931942967447123  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4984th epoch : 3.4931888020548527  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4985th epoch : 3.4931833025834607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4986th epoch : 3.4931777983256964  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4987th epoch : 3.493172289276713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4988th epoch : 3.493166775431657  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4989th epoch : 3.4931612567856654  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4990th epoch : 3.49315573333387  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4991th epoch : 3.493150205071393  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4992th epoch : 3.493144671993352  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4993th epoch : 3.4931391340948545  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4994th epoch : 3.4931335913710018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4995th epoch : 3.493128043816887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4996th epoch : 3.4931224914275965  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4997th epoch : 3.4931169341982087  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4998th epoch : 3.4931113721237943  Training Accuracy:0.5714285714285714\n",
      "The training loss at 4999th epoch : 3.493105805199417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5000th epoch : 3.4931002334201318  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5001th epoch : 3.4930946567809875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5002th epoch : 3.4930890752770236  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5003th epoch : 3.493083488903274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5004th epoch : 3.4930778976547625  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5005th epoch : 3.4930723015265075  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5006th epoch : 3.4930667005135176  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5007th epoch : 3.4930610946107956  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5008th epoch : 3.4930554838133356  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5009th epoch : 3.493049868116123  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5010th epoch : 3.4930442475141374  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5011th epoch : 3.4930386220023486  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5012th epoch : 3.49303299157572  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5013th epoch : 3.4930273562292067  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5014th epoch : 3.493021715957755  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5015th epoch : 3.4930160707563043  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5016th epoch : 3.4930104206197865  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5017th epoch : 3.493004765543124  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5018th epoch : 3.492999105521233  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5019th epoch : 3.4929934405490197  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5020th epoch : 3.4929877706213843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5021th epoch : 3.492982095733218  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5022th epoch : 3.4929764158794034  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5023th epoch : 3.492970731054816  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5024th epoch : 3.492965041254323  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5025th epoch : 3.492959346472783  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5026th epoch : 3.4929536467050464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5027th epoch : 3.4929479419459564  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5028th epoch : 3.492942232190347  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5029th epoch : 3.4929365174330447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5030th epoch : 3.4929307976688673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5031th epoch : 3.492925072892624  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5032th epoch : 3.492919343099117  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5033th epoch : 3.492913608283139  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5034th epoch : 3.4929078684394748  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5035th epoch : 3.4929021235629008  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5036th epoch : 3.4928963736481853  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5037th epoch : 3.492890618690088  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5038th epoch : 3.49288485868336  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5039th epoch : 3.4928790936227445  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5040th epoch : 3.492873323502975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5041th epoch : 3.4928675483187788  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5042th epoch : 3.492861768064872  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5043th epoch : 3.492855982735964  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5044th epoch : 3.492850192326756  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5045th epoch : 3.4928443968319387  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5046th epoch : 3.4928385962461954  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5047th epoch : 3.492832790564201  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5048th epoch : 3.4928269797806215  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5049th epoch : 3.492821163890114  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5050th epoch : 3.492815342887327  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5051th epoch : 3.492809516766901  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5052th epoch : 3.4928036855234668  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5053th epoch : 3.4927978491516463  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5054th epoch : 3.4927920076460537  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5055th epoch : 3.492786161001294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5056th epoch : 3.4927803092119625  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5057th epoch : 3.4927744522726467  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5058th epoch : 3.4927685901779255  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5059th epoch : 3.4927627229223672  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5060th epoch : 3.492756850500533  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5061th epoch : 3.4927509729069746  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5062th epoch : 3.492745090136234  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5063th epoch : 3.4927392021828445  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5064th epoch : 3.4927333090413315  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5065th epoch : 3.4927274107062103  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5066th epoch : 3.4927215071719866  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5067th epoch : 3.4927155984331586  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5068th epoch : 3.4927096844842143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5069th epoch : 3.4927037653196327  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5070th epoch : 3.4926978409338836  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5071th epoch : 3.492691911321428  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5072th epoch : 3.492685976476717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5073th epoch : 3.492680036394193  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5074th epoch : 3.4926740910682894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5075th epoch : 3.49266814049343  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5076th epoch : 3.4926621846640287  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5077th epoch : 3.4926562235744902  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5078th epoch : 3.4926502572192115  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5079th epoch : 3.4926442855925774  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5080th epoch : 3.4926383086889663  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5081th epoch : 3.4926323265027444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5082th epoch : 3.4926263390282704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5083th epoch : 3.4926203462598924  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5084th epoch : 3.4926143481919496  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5085th epoch : 3.492608344818771  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5086th epoch : 3.492602336134677  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5087th epoch : 3.4925963221339775  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5088th epoch : 3.4925903028109735  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5089th epoch : 3.4925842781599554  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5090th epoch : 3.4925782481752043  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5091th epoch : 3.492572212850993  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5092th epoch : 3.4925661721815824  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5093th epoch : 3.4925601261612242  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5094th epoch : 3.4925540747841617  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5095th epoch : 3.492548018044627  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5096th epoch : 3.4925419559368427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5097th epoch : 3.4925358884550213  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5098th epoch : 3.4925298155933664  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5099th epoch : 3.4925237373460702  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5100th epoch : 3.4925176537073166  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5101th epoch : 3.4925115646712777  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5102th epoch : 3.492505470232117  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5103th epoch : 3.4924993703839875  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5104th epoch : 3.4924932651210323  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5105th epoch : 3.4924871544373843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5106th epoch : 3.492481038327166  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5107th epoch : 3.49247491678449  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5108th epoch : 3.492468789803459  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5109th epoch : 3.4924626573781654  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5110th epoch : 3.4924565195026904  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5111th epoch : 3.492450376171107  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5112th epoch : 3.492444227377476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5113th epoch : 3.492438073115848  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5114th epoch : 3.492431913380265  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5115th epoch : 3.4924257481647567  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5116th epoch : 3.4924195774633437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5117th epoch : 3.4924134012700354  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5118th epoch : 3.492407219578831  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5119th epoch : 3.4924010323837194  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5120th epoch : 3.492394839678678  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5121th epoch : 3.492388641457676  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5122th epoch : 3.492382437714669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5123th epoch : 3.492376228443604  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5124th epoch : 3.4923700136384177  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5125th epoch : 3.492363793293034  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5126th epoch : 3.4923575674013683  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5127th epoch : 3.492351335957324  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5128th epoch : 3.492345098954794  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5129th epoch : 3.492338856387661  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5130th epoch : 3.4923326082497965  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5131th epoch : 3.4923263545350607  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5132th epoch : 3.4923200952373037  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5133th epoch : 3.4923138303503642  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5134th epoch : 3.4923075598680704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5135th epoch : 3.4923012837842387  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5136th epoch : 3.4922950020926757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5137th epoch : 3.492288714787176  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5138th epoch : 3.4922824218615234  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5139th epoch : 3.492276123309491  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5140th epoch : 3.4922698191248407  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5141th epoch : 3.492263509301323  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5142th epoch : 3.492257193832676  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5143th epoch : 3.49225087271263  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5144th epoch : 3.4922445459349003  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5145th epoch : 3.4922382134931937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5146th epoch : 3.4922318753812034  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5147th epoch : 3.4922255315926134  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5148th epoch : 3.492219182121095  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5149th epoch : 3.492212826960309  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5150th epoch : 3.492206466103903  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5151th epoch : 3.4922000995455154  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5152th epoch : 3.4921937272787718  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5153th epoch : 3.4921873492972866  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5154th epoch : 3.4921809655946627  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5155th epoch : 3.4921745761644907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5156th epoch : 3.492168181000351  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5157th epoch : 3.4921617800958114  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5158th epoch : 3.4921553734444273  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5159th epoch : 3.492148961039744  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5160th epoch : 3.4921425428752944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5161th epoch : 3.4921361189445985  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5162th epoch : 3.4921296892411666  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5163th epoch : 3.4921232537584954  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5164th epoch : 3.49211681249007  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5165th epoch : 3.4921103654293644  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5166th epoch : 3.49210391256984  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5167th epoch : 3.4920974539049463  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5168th epoch : 3.4920909894281205  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5169th epoch : 3.4920845191327885  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5170th epoch : 3.4920780430123632  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5171th epoch : 3.4920715610602464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5172th epoch : 3.492065073269827  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5173th epoch : 3.492058579634481  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5174th epoch : 3.492052080147574  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5175th epoch : 3.4920455748024586  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5176th epoch : 3.4920390635924736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5177th epoch : 3.492032546510948  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5178th epoch : 3.4920260235511966  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5179th epoch : 3.492019494706522  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5180th epoch : 3.4920129599702157  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5181th epoch : 3.4920064193355547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5182th epoch : 3.4919998727958053  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5183th epoch : 3.49199332034422  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5184th epoch : 3.4919867619740392  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5185th epoch : 3.491980197678491  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5186th epoch : 3.4919736274507907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5187th epoch : 3.49196705128414  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5188th epoch : 3.491960469171729  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5189th epoch : 3.4919538811067348  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5190th epoch : 3.491947287082321  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5191th epoch : 3.4919406870916396  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5192th epoch : 3.491934081127829  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5193th epoch : 3.491927469184014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5194th epoch : 3.4919208512533078  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5195th epoch : 3.4919142273288095  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5196th epoch : 3.491907597403606  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5197th epoch : 3.491900961470771  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5198th epoch : 3.4918943195233645  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5199th epoch : 3.491887671554434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5200th epoch : 3.491881017557014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5201th epoch : 3.4918743575241242  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5202th epoch : 3.4918676914487734  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5203th epoch : 3.4918610193239554  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5204th epoch : 3.4918543411426515  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5205th epoch : 3.4918476568978294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5206th epoch : 3.4918409665824433  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5207th epoch : 3.491834270189434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5208th epoch : 3.491827567711729  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5209th epoch : 3.491820859142242  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5210th epoch : 3.491814144473873  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5211th epoch : 3.4918074236995094  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5212th epoch : 3.4918006968120237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5213th epoch : 3.491793963804276  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5214th epoch : 3.491787224669111  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5215th epoch : 3.4917804793993614  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5216th epoch : 3.491773727987845  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5217th epoch : 3.491766970427366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5218th epoch : 3.4917602067107154  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5219th epoch : 3.491753436830669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5220th epoch : 3.4917466607799903  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5221th epoch : 3.491739878551427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5222th epoch : 3.491733090137714  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5223th epoch : 3.4917262955315724  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5224th epoch : 3.4917194947257073  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5225th epoch : 3.491712687712812  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5226th epoch : 3.491705874485564  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5227th epoch : 3.4916990550366274  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5228th epoch : 3.4916922293586516  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5229th epoch : 3.4916853974442716  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5230th epoch : 3.4916785592861084  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5231th epoch : 3.4916717148767686  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5232th epoch : 3.4916648642088437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5233th epoch : 3.491658007274912  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5234th epoch : 3.4916511440675357  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5235th epoch : 3.4916442745792637  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5236th epoch : 3.49163739880263  Training Accuracy:0.6071428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 5237th epoch : 3.491630516730153  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5238th epoch : 3.4916236283543376  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5239th epoch : 3.4916167336676738  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5240th epoch : 3.491609832662636  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5241th epoch : 3.4916029253316845  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5242th epoch : 3.491596011667265  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5243th epoch : 3.491589091661807  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5244th epoch : 3.491582165307726  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5245th epoch : 3.491575232597423  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5246th epoch : 3.491568293523283  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5247th epoch : 3.4915613480776764  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5248th epoch : 3.491554396252958  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5249th epoch : 3.4915474380414677  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5250th epoch : 3.4915404734355304  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5251th epoch : 3.4915335024274556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5252th epoch : 3.4915265250095375  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5253th epoch : 3.4915195411740547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5254th epoch : 3.491512550913271  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5255th epoch : 3.491505554219434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5256th epoch : 3.4914985510847765  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5257th epoch : 3.4914915415015146  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5258th epoch : 3.4914845254618507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5259th epoch : 3.49147750295797  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5260th epoch : 3.4914704739820426  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5261th epoch : 3.491463438526223  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5262th epoch : 3.4914563965826497  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5263th epoch : 3.4914493481434454  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5264th epoch : 3.491442293200717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5265th epoch : 3.491435231746556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5266th epoch : 3.491428163773037  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5267th epoch : 3.491421089272219  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5268th epoch : 3.4914140082361453  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5269th epoch : 3.491406920656843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5270th epoch : 3.491399826526323  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5271th epoch : 3.491392725836579  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5272th epoch : 3.4913856185795904  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5273th epoch : 3.491378504747319  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5274th epoch : 3.4913713843317105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5275th epoch : 3.4913642573246944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5276th epoch : 3.491357123718184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5277th epoch : 3.4913499835040755  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5278th epoch : 3.491342836674249  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5279th epoch : 3.4913356832205675  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5280th epoch : 3.4913285231348787  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5281th epoch : 3.491321356409012  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5282th epoch : 3.491314183034781  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5283th epoch : 3.4913070030039832  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5284th epoch : 3.4912998163083975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5285th epoch : 3.491292622939787  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5286th epoch : 3.491285422889898  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5287th epoch : 3.4912782161504596  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5288th epoch : 3.491271002713184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5289th epoch : 3.491263782569766  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5290th epoch : 3.491256555711884  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5291th epoch : 3.491249322131198  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5292th epoch : 3.4912420818193524  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5293th epoch : 3.491234834767973  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5294th epoch : 3.4912275809686686  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5295th epoch : 3.491220320413031  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5296th epoch : 3.4912130530926344  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5297th epoch : 3.491205778999036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5298th epoch : 3.4911984981237736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5299th epoch : 3.49119121045837  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5300th epoch : 3.4911839159943288  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5301th epoch : 3.4911766147231367  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5302th epoch : 3.491169306636261  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5303th epoch : 3.491161991725154  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5304th epoch : 3.4911546699812477  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5305th epoch : 3.491147341395957  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5306th epoch : 3.4911400059606796  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5307th epoch : 3.4911326636667943  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5308th epoch : 3.491125314505662  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5309th epoch : 3.4911179584686263  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5310th epoch : 3.4911105955470108  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5311th epoch : 3.4911032257321226  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5312th epoch : 3.49109584901525  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5313th epoch : 3.4910884653876635  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5314th epoch : 3.4910810748406136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5315th epoch : 3.4910736773653346  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5316th epoch : 3.4910662729530397  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5317th epoch : 3.4910588615949267  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5318th epoch : 3.4910514432821715  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5319th epoch : 3.491044018005934  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5320th epoch : 3.4910365857573544  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5321th epoch : 3.4910291465275534  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5322th epoch : 3.491021700307634  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5323th epoch : 3.4910142470886796  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5324th epoch : 3.491006786861755  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5325th epoch : 3.4909993196179063  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5326th epoch : 3.4909918453481597  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5327th epoch : 3.4909843640435234  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5328th epoch : 3.4909768756949853  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5329th epoch : 3.4909693802935147  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5330th epoch : 3.4909618778300615  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5331th epoch : 3.4909543682955566  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5332th epoch : 3.490946851680911  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5333th epoch : 3.4909393279770162  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5334th epoch : 3.490931797174745  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5335th epoch : 3.49092425926495  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5336th epoch : 3.490916714238464  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5337th epoch : 3.4909091620861  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5338th epoch : 3.490901602798652  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5339th epoch : 3.490894036366894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5340th epoch : 3.4908864627815794  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5341th epoch : 3.4908788820334427  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5342th epoch : 3.4908712941131976  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5343th epoch : 3.4908636990115385  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5344th epoch : 3.490856096719139  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5345th epoch : 3.4908484872266525  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5346th epoch : 3.490840870524713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5347th epoch : 3.490833246603934  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5348th epoch : 3.490825615454907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5349th epoch : 3.490817977068206  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5350th epoch : 3.490810331434382  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5351th epoch : 3.4908026785439668  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5352th epoch : 3.490795018387471  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5353th epoch : 3.490787350955385  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5354th epoch : 3.490779676238178  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5355th epoch : 3.4907719942262987  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5356th epoch : 3.4907643049101753  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5357th epoch : 3.490756608280215  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5358th epoch : 3.4907489043268023  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5359th epoch : 3.4907411930403036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5360th epoch : 3.490733474411062  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5361th epoch : 3.4907257484294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5362th epoch : 3.4907180150856196  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5363th epoch : 3.490710274370001  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5364th epoch : 3.490702526272802  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5365th epoch : 3.490694770784261  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5366th epoch : 3.4906870078945933  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5367th epoch : 3.4906792375939935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5368th epoch : 3.490671459872634  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5369th epoch : 3.490663674720666  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5370th epoch : 3.4906558821282188  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5371th epoch : 3.4906480820853996  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5372th epoch : 3.490640274582294  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5373th epoch : 3.490632459608966  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5374th epoch : 3.4906246371554572  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5375th epoch : 3.490616807211787  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5376th epoch : 3.4906089697679525  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5377th epoch : 3.4906011248139293  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5378th epoch : 3.49059327233967  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5379th epoch : 3.490585412335105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5380th epoch : 3.490577544790143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5381th epoch : 3.4905696696946693  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5382th epoch : 3.490561787038547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5383th epoch : 3.490553896811616  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5384th epoch : 3.490545999003695  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5385th epoch : 3.4905380936045782  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5386th epoch : 3.4905301806040385  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5387th epoch : 3.490522259991825  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5388th epoch : 3.4905143317576632  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5389th epoch : 3.490506395891257  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5390th epoch : 3.490498452382287  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5391th epoch : 3.490490501220409  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5392th epoch : 3.4904825423952577  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5393th epoch : 3.4904745758964433  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5394th epoch : 3.4904666017135524  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5395th epoch : 3.490458619836149  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5396th epoch : 3.4904506302537723  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5397th epoch : 3.4904426329559395  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5398th epoch : 3.4904346279321428  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5399th epoch : 3.490426615171851  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5400th epoch : 3.49041859466451  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5401th epoch : 3.49041056639954  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5402th epoch : 3.490402530366339  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5403th epoch : 3.4903944865542798  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5404th epoch : 3.4903864349527116  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5405th epoch : 3.490378375550959  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5406th epoch : 3.4903703083383224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5407th epoch : 3.490362233304079  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5408th epoch : 3.4903541504374793  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5409th epoch : 3.490346059727752  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5410th epoch : 3.4903379611640983  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5411th epoch : 3.490329854735698  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5412th epoch : 3.490321740431703  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5413th epoch : 3.4903136182412426  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5414th epoch : 3.4903054881534206  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5415th epoch : 3.4902973501573156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5416th epoch : 3.490289204241981  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5417th epoch : 3.490281050396446  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5418th epoch : 3.490272888609714  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5419th epoch : 3.4902647188707623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5420th epoch : 3.4902565411685447  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5421th epoch : 3.4902483554919885  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5422th epoch : 3.490240161829995  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5423th epoch : 3.4902319601714415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5424th epoch : 3.4902237505051783  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5425th epoch : 3.49021553282003  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5426th epoch : 3.490207307104796  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5427th epoch : 3.49019907334825  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5428th epoch : 3.490190831539139  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5429th epoch : 3.490182581666184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5430th epoch : 3.4901743237180805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5431th epoch : 3.4901660576834974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5432th epoch : 3.4901577835510773  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5433th epoch : 3.4901495013094364  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5434th epoch : 3.490141210947164  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5435th epoch : 3.4901329124528244  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5436th epoch : 3.4901246058149535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5437th epoch : 3.4901162910220616  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5438th epoch : 3.4901079680626315  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5439th epoch : 3.4900996369251196  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5440th epoch : 3.4900912975979557  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5441th epoch : 3.4900829500695414  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5442th epoch : 3.4900745943282523  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5443th epoch : 3.4900662303624364  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5444th epoch : 3.490057858160414  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5445th epoch : 3.4900494777104787  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5446th epoch : 3.4900410890008966  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5447th epoch : 3.490032692019906  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5448th epoch : 3.490024286755717  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5449th epoch : 3.4900158731965134  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5450th epoch : 3.4900074513304498  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5451th epoch : 3.4899990211456533  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5452th epoch : 3.489990582630224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5453th epoch : 3.4899821357722325  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5454th epoch : 3.489973680559723  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5455th epoch : 3.4899652169807087  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5456th epoch : 3.489956745023177  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5457th epoch : 3.4899482646750863  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5458th epoch : 3.489939775924366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5459th epoch : 3.4899312787589176  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5460th epoch : 3.489922773166613  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5461th epoch : 3.4899142591352956  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5462th epoch : 3.489905736652781  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5463th epoch : 3.489897205706854  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5464th epoch : 3.489888666285272  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5465th epoch : 3.4898801183757624  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5466th epoch : 3.489871561966024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5467th epoch : 3.4898629970437254  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5468th epoch : 3.489854423596507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5469th epoch : 3.489845841611978  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5470th epoch : 3.4898372510777205  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5471th epoch : 3.4898286519812842  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5472th epoch : 3.489820044310191  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5473th epoch : 3.4898114280519317  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5474th epoch : 3.4898028031939683  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5475th epoch : 3.4897941697237314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5476th epoch : 3.489785527628623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5477th epoch : 3.489776876896013  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5478th epoch : 3.489768217513243  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5479th epoch : 3.4897595494676232  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5480th epoch : 3.4897508727464324  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5481th epoch : 3.4897421873369203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5482th epoch : 3.489733493226305  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5483th epoch : 3.4897247904017736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5484th epoch : 3.489716078850483  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5485th epoch : 3.4897073585595595  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5486th epoch : 3.4896986295160968  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5487th epoch : 3.489689891707158  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5488th epoch : 3.489681145119776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5489th epoch : 3.48967238974095  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5490th epoch : 3.4896636255576503  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5491th epoch : 3.489654852556814  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5492th epoch : 3.489646070725347  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5493th epoch : 3.4896372800501227  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5494th epoch : 3.4896284805179842  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5495th epoch : 3.4896196721157406  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5496th epoch : 3.4896108548301705  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5497th epoch : 3.48960202864802  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5498th epoch : 3.489593193556002  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5499th epoch : 3.489584349540798  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5500th epoch : 3.489575496589056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5501th epoch : 3.489566634687393  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5502th epoch : 3.489557763822391  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5503th epoch : 3.4895488839806017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5504th epoch : 3.4895399951485424  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5505th epoch : 3.4895310973126974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5506th epoch : 3.4895221904595184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5507th epoch : 3.4895132745754234  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5508th epoch : 3.489504349646797  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5509th epoch : 3.489495415659991  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5510th epoch : 3.4894864726013237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5511th epoch : 3.4894775204570783  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5512th epoch : 3.489468559213506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5513th epoch : 3.489459588856824  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5514th epoch : 3.489450609373214  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5515th epoch : 3.4894416207488246  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5516th epoch : 3.4894326229697703  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5517th epoch : 3.489423616022132  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5518th epoch : 3.4894145998919543  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5519th epoch : 3.489405574565249  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5520th epoch : 3.4893965400279923  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5521th epoch : 3.4893874962661267  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5522th epoch : 3.489378443265559  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5523th epoch : 3.4893693810121604  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5524th epoch : 3.489360309491769  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5525th epoch : 3.489351228690186  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5526th epoch : 3.4893421385931784  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5527th epoch : 3.489333039186477  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5528th epoch : 3.489323930455777  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5529th epoch : 3.4893148123867395  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5530th epoch : 3.489305684964988  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5531th epoch : 3.489296548176111  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5532th epoch : 3.4892874020056617  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5533th epoch : 3.4892782464391554  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5534th epoch : 3.489269081462073  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5535th epoch : 3.489259907059858  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5536th epoch : 3.489250723217918  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5537th epoch : 3.4892415299216246  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5538th epoch : 3.4892323271563113  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5539th epoch : 3.4892231149072757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5540th epoch : 3.4892138931597785  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5541th epoch : 3.4892046618990435  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5542th epoch : 3.4891954211102574  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5543th epoch : 3.4891861707785687  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5544th epoch : 3.48917691088909  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5545th epoch : 3.4891676414268957  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5546th epoch : 3.4891583623770224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5547th epoch : 3.4891490737244695  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5548th epoch : 3.4891397754541975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5549th epoch : 3.4891304675511305  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5550th epoch : 3.4891211500001535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5551th epoch : 3.4891118227861138  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5552th epoch : 3.4891024858938193  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5553th epoch : 3.489093139308041  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5554th epoch : 3.489083783013511  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5555th epoch : 3.489074416994921  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5556th epoch : 3.489065041236926  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5557th epoch : 3.4890556557241412  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5558th epoch : 3.4890462604411425  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5559th epoch : 3.4890368553724675  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5560th epoch : 3.489027440502613  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5561th epoch : 3.489018015816038  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5562th epoch : 3.4890085812971607  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5563th epoch : 3.4889991369303606  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5564th epoch : 3.4889896826999762  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5565th epoch : 3.488980218590307  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5566th epoch : 3.4889707445856124  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5567th epoch : 3.4889612606701106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5568th epoch : 3.4889517668279812  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5569th epoch : 3.4889422630433615  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5570th epoch : 3.488932749300349  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5571th epoch : 3.4889232255830014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5572th epoch : 3.4889136918753336  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5573th epoch : 3.488904148161321  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5574th epoch : 3.4888945944248975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5575th epoch : 3.4888850306499557  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5576th epoch : 3.488875456820347  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5577th epoch : 3.488865872919881  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5578th epoch : 3.4888562789323254  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5579th epoch : 3.4888466748414064  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5580th epoch : 3.4888370606308095  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5581th epoch : 3.4888274362841756  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5582th epoch : 3.4888178017851055  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5583th epoch : 3.4888081571171567  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5584th epoch : 3.4887985022638452  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5585th epoch : 3.4887888372086433  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5586th epoch : 3.4887791619349806  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5587th epoch : 3.488769476426245  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5588th epoch : 3.4887597806657804  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5589th epoch : 3.4887500746368874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5590th epoch : 3.4887403583228243  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5591th epoch : 3.488730631706805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5592th epoch : 3.4887208947720003  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5593th epoch : 3.488711147501537  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5594th epoch : 3.4887013898784986  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5595th epoch : 3.4886916218859243  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5596th epoch : 3.488681843506809  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5597th epoch : 3.4886720547241032  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5598th epoch : 3.488662255520714  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5599th epoch : 3.4886524458795023  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5600th epoch : 3.4886426257832857  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5601th epoch : 3.4886327952148366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5602th epoch : 3.488622954156882  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5603th epoch : 3.488613102592104  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5604th epoch : 3.4886032405031395  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5605th epoch : 3.48859336787258  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5606th epoch : 3.4885834846829713  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5607th epoch : 3.488573590916813  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5608th epoch : 3.48856368655656  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5609th epoch : 3.4885537715846207  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5610th epoch : 3.4885438459833567  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5611th epoch : 3.4885339097350836  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5612th epoch : 3.488523962822071  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5613th epoch : 3.488514005226541  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5614th epoch : 3.48850403693067  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5615th epoch : 3.488494057916587  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5616th epoch : 3.4884840681663736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5617th epoch : 3.4884740676620645  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5618th epoch : 3.488464056385647  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5619th epoch : 3.4884540343190604  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5620th epoch : 3.488444001444198  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5621th epoch : 3.4884339577429024  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5622th epoch : 3.488423903196971  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5623th epoch : 3.4884138377881513  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5624th epoch : 3.488403761498143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5625th epoch : 3.4883936743085977  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5626th epoch : 3.488383576201118  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5627th epoch : 3.4883734671572575  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5628th epoch : 3.4883633471585216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5629th epoch : 3.4883532161863653  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5630th epoch : 3.488343074222196  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5631th epoch : 3.48833292124737  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5632th epoch : 3.4883227572431963  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5633th epoch : 3.488312582190931  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5634th epoch : 3.4883023960717834  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5635th epoch : 3.4882921988669104  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5636th epoch : 3.4882819905574203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5637th epoch : 3.48827177112437  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5638th epoch : 3.488261540548766  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5639th epoch : 3.4882512988115644  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5640th epoch : 3.4882410458936706  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5641th epoch : 3.4882307817759384  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5642th epoch : 3.4882205064391707  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5643th epoch : 3.4882102198641185  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5644th epoch : 3.488199922031482  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5645th epoch : 3.4881896129219094  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5646th epoch : 3.488179292515997  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5647th epoch : 3.4881689607942885  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5648th epoch : 3.4881586177372763  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5649th epoch : 3.4881482633254  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5650th epoch : 3.4881378975390462  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5651th epoch : 3.4881275203585496  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5652th epoch : 3.4881171317641915  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5653th epoch : 3.4881067317362  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5654th epoch : 3.4880963202547495  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5655th epoch : 3.4880858972999627  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5656th epoch : 3.488075462851907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5657th epoch : 3.4880650168905962  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5658th epoch : 3.4880545593959913  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5659th epoch : 3.4880440903479975  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5660th epoch : 3.4880336097264673  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5661th epoch : 3.4880231175111973  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5662th epoch : 3.488012613681931  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5663th epoch : 3.488002098218355  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5664th epoch : 3.487991571100103  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5665th epoch : 3.487981032306752  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5666th epoch : 3.4879704818178237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5667th epoch : 3.487959919612786  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5668th epoch : 3.487949345671048  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5669th epoch : 3.487938759971966  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5670th epoch : 3.487928162494838  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5671th epoch : 3.487917553218907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5672th epoch : 3.4879069321233582  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5673th epoch : 3.4878962991873217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5674th epoch : 3.4878856543898693  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5675th epoch : 3.4878749977100165  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5676th epoch : 3.4878643291267215  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5677th epoch : 3.487853648618885  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5678th epoch : 3.4878429561653506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5679th epoch : 3.4878322517449027  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5680th epoch : 3.4878215353362694  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5681th epoch : 3.48781080691812  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5682th epoch : 3.487800066469065  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5683th epoch : 3.487789313967656  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5684th epoch : 3.4877785493923876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5685th epoch : 3.487767772721694  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5686th epoch : 3.4877569839339504  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5687th epoch : 3.4877461830074727  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5688th epoch : 3.487735369920518  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5689th epoch : 3.4877245446512832  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5690th epoch : 3.4877137071779045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5691th epoch : 3.487702857478459  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5692th epoch : 3.4876919955309638  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5693th epoch : 3.487681121313374  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5694th epoch : 3.4876702348035855  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5695th epoch : 3.487659335979432  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5696th epoch : 3.4876484248186874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5697th epoch : 3.4876375012990635  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5698th epoch : 3.4876265653982106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5699th epoch : 3.4876156170937174  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5700th epoch : 3.4876046563631107  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5701th epoch : 3.487593683183855  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5702th epoch : 3.487582697533353  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5703th epoch : 3.487571699388944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5704th epoch : 3.4875606887279056  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5705th epoch : 3.487549665527452  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5706th epoch : 3.4875386297647335  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5707th epoch : 3.487527581416838  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5708th epoch : 3.4875165204607894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5709th epoch : 3.4875054468735485  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5710th epoch : 3.487494360632011  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5711th epoch : 3.487483261713009  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5712th epoch : 3.4874721500933106  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5713th epoch : 3.4874610257496186  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5714th epoch : 3.4874498886585705  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5715th epoch : 3.4874387387967403  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5716th epoch : 3.487427576140636  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5717th epoch : 3.487416400666699  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5718th epoch : 3.4874052123513066  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5719th epoch : 3.4873940111707697  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5720th epoch : 3.4873827971013327  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5721th epoch : 3.4873715701191736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5722th epoch : 3.4873603302004046  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5723th epoch : 3.4873490773210705  Training Accuracy:0.6071428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 5724th epoch : 3.4873378114571487  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5725th epoch : 3.4873265325845506  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5726th epoch : 3.487315240679119  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5727th epoch : 3.4873039357166293  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5728th epoch : 3.4872926176727894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5729th epoch : 3.4872812865232388  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5730th epoch : 3.487269942243549  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5731th epoch : 3.4872585848092212  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5732th epoch : 3.487247214195691  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5733th epoch : 3.4872358303783217  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5734th epoch : 3.48722443333241  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5735th epoch : 3.4872130230331804  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5736th epoch : 3.48720159945579  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5737th epoch : 3.4871901625753257  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5738th epoch : 3.4871787123668025  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5739th epoch : 3.4871672488051666  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5740th epoch : 3.487155771865293  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5741th epoch : 3.4871442815219864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5742th epoch : 3.487132777749979  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5743th epoch : 3.4871212605239332  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5744th epoch : 3.487109729818439  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5745th epoch : 3.487098185608014  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5746th epoch : 3.487086627867105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5747th epoch : 3.4870750565700863  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5748th epoch : 3.4870634716912585  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5749th epoch : 3.4870518732048508  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5750th epoch : 3.487040261085019  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5751th epoch : 3.4870286353058444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5752th epoch : 3.4870169958413366  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5753th epoch : 3.48700534266543  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5754th epoch : 3.486993675751987  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5755th epoch : 3.486981995074793  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5756th epoch : 3.486970300607561  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5757th epoch : 3.486958592323928  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5758th epoch : 3.4869468701974577  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5759th epoch : 3.4869351342016364  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5760th epoch : 3.4869233843098764  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5761th epoch : 3.486911620495514  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5762th epoch : 3.4868998427318094  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5763th epoch : 3.4868880509919458  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5764th epoch : 3.486876245249032  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5765th epoch : 3.486864425476097  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5766th epoch : 3.486852591646096  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5767th epoch : 3.486840743731905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5768th epoch : 3.486828881706322  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5769th epoch : 3.4868170055420697  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5770th epoch : 3.4868051152117907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5771th epoch : 3.4867932106880493  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5772th epoch : 3.486781291943332  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5773th epoch : 3.486769358950047  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5774th epoch : 3.4867574116805216  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5775th epoch : 3.486745450107006  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5776th epoch : 3.486733474201669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5777th epoch : 3.4867214839366008  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5778th epoch : 3.4867094792838103  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5779th epoch : 3.486697460215227  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5780th epoch : 3.4866854267027  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5781th epoch : 3.4866733787179958  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5782th epoch : 3.486661316232801  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5783th epoch : 3.4866492392187207  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5784th epoch : 3.486637147647278  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5785th epoch : 3.4866250414899143  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5786th epoch : 3.486612920717988  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5787th epoch : 3.486600785302776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5788th epoch : 3.486588635215471  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5789th epoch : 3.486576470427184  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5790th epoch : 3.486564290908942  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5791th epoch : 3.4865520966316876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5792th epoch : 3.4865398875662814  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5793th epoch : 3.4865276636834976  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5794th epoch : 3.4865154249540273  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5795th epoch : 3.486503171348476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5796th epoch : 3.4864909028373656  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5797th epoch : 3.4864786193911304  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5798th epoch : 3.4864663209801208  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5799th epoch : 3.486454007574601  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5800th epoch : 3.4864416791447486  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5801th epoch : 3.4864293356606546  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5802th epoch : 3.4864169770923237  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5803th epoch : 3.4864046034096736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5804th epoch : 3.486392214582534  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5805th epoch : 3.4863798105806474  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5806th epoch : 3.486367391373669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5807th epoch : 3.486354956931164  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5808th epoch : 3.486342507222611  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5809th epoch : 3.486330042217399  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5810th epoch : 3.486317561884827  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5811th epoch : 3.486305066194107  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5812th epoch : 3.4862925551143578  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5813th epoch : 3.486280028614612  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5814th epoch : 3.486267486663808  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5815th epoch : 3.4862549292307974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5816th epoch : 3.4862423562843388  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5817th epoch : 3.486229767793099  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5818th epoch : 3.486217163725655  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5819th epoch : 3.4862045440504907  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5820th epoch : 3.486191908735999  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5821th epoch : 3.486179257750479  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5822th epoch : 3.486166591062138  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5823th epoch : 3.4861539086390905  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5824th epoch : 3.4861412104493565  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5825th epoch : 3.486128496460864  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5826th epoch : 3.4861157666414444  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5827th epoch : 3.4861030209588377  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5828th epoch : 3.4860902593806875  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5829th epoch : 3.4860774818745432  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5830th epoch : 3.486064688407859  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5831th epoch : 3.486051878947993  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5832th epoch : 3.4860390534622074  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5833th epoch : 3.486026211917669  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5834th epoch : 3.4860133542814475  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5835th epoch : 3.4860004805205156  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5836th epoch : 3.4859875906017495  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5837th epoch : 3.4859746844919273  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5838th epoch : 3.4859617621577295  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5839th epoch : 3.4859488235657383  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5840th epoch : 3.485935868682438  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5841th epoch : 3.4859228974742136  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5842th epoch : 3.485909909907351  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5843th epoch : 3.485896905948037  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5844th epoch : 3.485883885562358  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5845th epoch : 3.485870848716301  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5846th epoch : 3.4858577953757517  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5847th epoch : 3.485844725506496  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5848th epoch : 3.485831639074218  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5849th epoch : 3.485818536044501  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5850th epoch : 3.485805416382825  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5851th epoch : 3.4857922800545698  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5852th epoch : 3.485779127025012  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5853th epoch : 3.4857659572593245  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5854th epoch : 3.485752770722578  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5855th epoch : 3.48573956737974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5856th epoch : 3.4857263471956728  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5857th epoch : 3.4857131101351357  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5858th epoch : 3.4856998561627837  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5859th epoch : 3.4856865852431653  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5860th epoch : 3.485673297340725  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5861th epoch : 3.485659992419802  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5862th epoch : 3.4856466704446287  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5863th epoch : 3.4856333313793315  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5864th epoch : 3.4856199751879307  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5865th epoch : 3.485606601834338  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5866th epoch : 3.4855932112823598  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5867th epoch : 3.4855798034956935  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5868th epoch : 3.485566378437929  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5869th epoch : 3.485552936072547  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5870th epoch : 3.48553947636292  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5871th epoch : 3.4855259992723115  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5872th epoch : 3.4855125047638755  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5873th epoch : 3.4854989928006552  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5874th epoch : 3.4854854633455843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5875th epoch : 3.4854719163614862  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5876th epoch : 3.4854583518110727  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5877th epoch : 3.485444769656944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5878th epoch : 3.4854311698615894  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5879th epoch : 3.485417552387386  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5880th epoch : 3.485403917196597  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5881th epoch : 3.485390264251375  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5882th epoch : 3.485376593513758  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5883th epoch : 3.4853629049456702  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5884th epoch : 3.4853491985089224  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5885th epoch : 3.485335474165211  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5886th epoch : 3.485321731876118  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5887th epoch : 3.485307971603109  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5888th epoch : 3.485294193307535  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5889th epoch : 3.4852803969506314  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5890th epoch : 3.4852665824935167  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5891th epoch : 3.4852527498971937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5892th epoch : 3.4852388991225465  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5893th epoch : 3.4852250301303433  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5894th epoch : 3.4852111428812336  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5895th epoch : 3.485197237335749  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5896th epoch : 3.485183313454302  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5897th epoch : 3.4851693711971876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5898th epoch : 3.48515541052458  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5899th epoch : 3.4851414313965328  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5900th epoch : 3.4851274337729814  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5901th epoch : 3.48511341761374  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5902th epoch : 3.485099382878501  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5903th epoch : 3.485085329526836  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5904th epoch : 3.4850712575181944  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5905th epoch : 3.485057166811904  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5906th epoch : 3.4850430573671702  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5907th epoch : 3.485028929143074  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5908th epoch : 3.485014782098574  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5909th epoch : 3.4850006161925045  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5910th epoch : 3.4849864313835766  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5911th epoch : 3.484972227630375  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5912th epoch : 3.484958004891361  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5913th epoch : 3.4849437631248694  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5914th epoch : 3.4849295022891087  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5915th epoch : 3.4849152223421624  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5916th epoch : 3.4849009232419865  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5917th epoch : 3.48488660494641  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5918th epoch : 3.484872267413133  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5919th epoch : 3.4848579105997306  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5920th epoch : 3.484843534463646  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5921th epoch : 3.484829138962196  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5922th epoch : 3.4848147240525664  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5923th epoch : 3.484800289691815  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5924th epoch : 3.484785835836868  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5925th epoch : 3.484771362444522  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5926th epoch : 3.4847568694714415  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5927th epoch : 3.4847423568741607  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5928th epoch : 3.484727824609081  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5929th epoch : 3.484713272632472  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5930th epoch : 3.4846987009004704  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5931th epoch : 3.4846841093690797  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5932th epoch : 3.4846694979941693  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5933th epoch : 3.484654866731476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5934th epoch : 3.4846402155365994  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5935th epoch : 3.4846255443650067  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5936th epoch : 3.4846108531720286  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5937th epoch : 3.48459614191286  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5938th epoch : 3.484581410542559  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5939th epoch : 3.4845666590160476  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5940th epoch : 3.4845518872881107  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5941th epoch : 3.484537095313395  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5942th epoch : 3.4845222830464087  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5943th epoch : 3.4845074504415225  Training Accuracy:0.6071428571428571\n",
      "The training loss at 5944th epoch : 3.484492597452967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5945th epoch : 3.484477724034834  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5946th epoch : 3.484462830141075  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5947th epoch : 3.484447915725501  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5948th epoch : 3.4844329807417824  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5949th epoch : 3.484418025143448  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5950th epoch : 3.4844030488838844  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5951th epoch : 3.484388051916337  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5952th epoch : 3.484373034193907  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5953th epoch : 3.484357995669553  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5954th epoch : 3.4843429362960907  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5955th epoch : 3.4843278560261903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5956th epoch : 3.4843127548123776  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5957th epoch : 3.484297632607034  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5958th epoch : 3.4842824893623945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5959th epoch : 3.4842673250305483  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5960th epoch : 3.484252139563438  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5961th epoch : 3.4842369329128586  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5962th epoch : 3.4842217050304587  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5963th epoch : 3.4842064558677377  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5964th epoch : 3.4841911853760474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5965th epoch : 3.4841758935065896  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5966th epoch : 3.484160580210417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5967th epoch : 3.484145245438433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5968th epoch : 3.4841298891413897  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5969th epoch : 3.4841145112698877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5970th epoch : 3.4840991117743774  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5971th epoch : 3.484083690605156  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5972th epoch : 3.48406824771237  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5973th epoch : 3.48405278304601  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5974th epoch : 3.4840372965559157  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5975th epoch : 3.4840217881917717  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5976th epoch : 3.4840062579031086  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5977th epoch : 3.4839907056393007  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5978th epoch : 3.4839751313495686  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5979th epoch : 3.4839595349829757  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5980th epoch : 3.4839439164884287  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5981th epoch : 3.483928275814678  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5982th epoch : 3.4839126129103155  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5983th epoch : 3.483896927723776  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5984th epoch : 3.4838812202033353  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5985th epoch : 3.48386549029711  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5986th epoch : 3.483849737953056  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5987th epoch : 3.483833963118971  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5988th epoch : 3.4838181657424907  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5989th epoch : 3.48380234577109  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5990th epoch : 3.483786503152081  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5991th epoch : 3.4837706378326154  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5992th epoch : 3.483754749759681  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5993th epoch : 3.4837388388801007  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5994th epoch : 3.483722905140537  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5995th epoch : 3.4837069484874847  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5996th epoch : 3.4836909688672755  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5997th epoch : 3.483674966226075  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5998th epoch : 3.4836589405098826  Training Accuracy:0.5714285714285714\n",
      "The training loss at 5999th epoch : 3.483642891664531  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6000th epoch : 3.483626819635686  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6001th epoch : 3.4836107243688463  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6002th epoch : 3.483594605809341  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6003th epoch : 3.4835784639023313  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6004th epoch : 3.483562298592809  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6005th epoch : 3.4835461098255966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6006th epoch : 3.483529897545344  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6007th epoch : 3.4835136616965325  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6008th epoch : 3.4834974022234704  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6009th epoch : 3.483481119070295  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6010th epoch : 3.483464812180969  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6011th epoch : 3.483448481499284  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6012th epoch : 3.4834321269688564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6013th epoch : 3.483415748533129  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6014th epoch : 3.4833993461353696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6015th epoch : 3.4833829197186694  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6016th epoch : 3.4833664692259445  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6017th epoch : 3.483349994599934  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6018th epoch : 3.4833334957832003  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6019th epoch : 3.483316972718127  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6020th epoch : 3.4833004253469197  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6021th epoch : 3.483283853611606  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6022th epoch : 3.4832672574540324  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6023th epoch : 3.4832506368158658  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6024th epoch : 3.483233991638593  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6025th epoch : 3.4832173218635183  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6026th epoch : 3.483200627431765  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6027th epoch : 3.4831839082842735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6028th epoch : 3.4831671643618014  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6029th epoch : 3.4831503956049223  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6030th epoch : 3.483133601954026  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6031th epoch : 3.483116783349317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6032th epoch : 3.4830999397308133  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6033th epoch : 3.483083071038349  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6034th epoch : 3.4830661772115703  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6035th epoch : 3.4830492581899355  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6036th epoch : 3.4830323139127164  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6037th epoch : 3.483015344318995  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6038th epoch : 3.4829983493476653  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6039th epoch : 3.4829813289374303  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6040th epoch : 3.4829642830268037  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6041th epoch : 3.4829472115541082  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6042th epoch : 3.482930114457474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6043th epoch : 3.48291299167484  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6044th epoch : 3.482895843143952  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6045th epoch : 3.4828786688023623  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6046th epoch : 3.4828614685874286  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6047th epoch : 3.4828442424363155  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6048th epoch : 3.4828269902859903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6049th epoch : 3.4828097120732253  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6050th epoch : 3.4827924077345966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6051th epoch : 3.4827750772064827  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6052th epoch : 3.4827577204250635  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6053th epoch : 3.4827403373263217  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6054th epoch : 3.48272292784604  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6055th epoch : 3.482705491919801  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6056th epoch : 3.482688029482988  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6057th epoch : 3.482670540470783  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6058th epoch : 3.482653024818165  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6059th epoch : 3.4826354824599117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6060th epoch : 3.482617913330598  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6061th epoch : 3.482600317364595  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6062th epoch : 3.4825826944960685  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6063th epoch : 3.4825650446589806  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6064th epoch : 3.482547367787087  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6065th epoch : 3.482529663813937  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6066th epoch : 3.4825119326728737  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6067th epoch : 3.482494174297032  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6068th epoch : 3.482476388619338  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6069th epoch : 3.48245857557251  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6070th epoch : 3.4824407350890563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6071th epoch : 3.482422867101274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6072th epoch : 3.4824049715412504  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6073th epoch : 3.4823870483408603  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6074th epoch : 3.482369097431767  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6075th epoch : 3.4823511187454197  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6076th epoch : 3.482333112213055  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6077th epoch : 3.482315077765694  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6078th epoch : 3.4822970153341437  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6079th epoch : 3.482278924848995  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6080th epoch : 3.482260806240623  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6081th epoch : 3.4822426594391835  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6082th epoch : 3.482224484374617  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6083th epoch : 3.4822062809766443  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6084th epoch : 3.4821880491747668  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6085th epoch : 3.4821697888982666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6086th epoch : 3.482151500076205  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6087th epoch : 3.4821331826374213  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6088th epoch : 3.4821148365105334  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6089th epoch : 3.4820964616239367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6090th epoch : 3.482078057905803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6091th epoch : 3.4820596252840788  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6092th epoch : 3.4820411636864876  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6093th epoch : 3.4820226730405257  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6094th epoch : 3.4820041532734645  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6095th epoch : 3.4819856043123467  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6096th epoch : 3.4819670260839883  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6097th epoch : 3.4819484185149774  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6098th epoch : 3.4819297815316714  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6099th epoch : 3.4819111150601993  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6100th epoch : 3.4818924190264577  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6101th epoch : 3.4818736933561136  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6102th epoch : 3.4818549379746004  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6103th epoch : 3.48183615280712  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6104th epoch : 3.481817337778639  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6105th epoch : 3.481798492813892  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6106th epoch : 3.481779617837376  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6107th epoch : 3.481760712773353  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6108th epoch : 3.4817417775458503  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6109th epoch : 3.4817228120786545  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6110th epoch : 3.481703816295317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6111th epoch : 3.4816847901191488  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6112th epoch : 3.481665733473222  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6113th epoch : 3.481646646280368  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6114th epoch : 3.4816275284631772  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6115th epoch : 3.481608379943998  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6116th epoch : 3.4815892006449367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6117th epoch : 3.481569990487855  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6118th epoch : 3.4815507493943723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6119th epoch : 3.481531477285861  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6120th epoch : 3.4815121740834494  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6121th epoch : 3.481492839708018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6122th epoch : 3.4814734740802016  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6123th epoch : 3.481454077120385  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6124th epoch : 3.481434648748706  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6125th epoch : 3.4814151888850517  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6126th epoch : 3.481395697449059  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6127th epoch : 3.481376174360114  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6128th epoch : 3.48135661953735  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6129th epoch : 3.481337032899649  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6130th epoch : 3.4813174143656376  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6131th epoch : 3.481297763853689  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6132th epoch : 3.4812780812819213  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6133th epoch : 3.4812583665681966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6134th epoch : 3.4812386196301204  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6135th epoch : 3.4812188403850395  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6136th epoch : 3.4811990287500434  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6137th epoch : 3.481179184641962  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6138th epoch : 3.481159307977366  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6139th epoch : 3.4811393986725645  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6140th epoch : 3.4811194566436043  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6141th epoch : 3.481099481806271  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6142th epoch : 3.4810794740760858  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6143th epoch : 3.4810594333683067  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6144th epoch : 3.481039359597927  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6145th epoch : 3.4810192526796726  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6146th epoch : 3.4809991125280044  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6147th epoch : 3.4809789390571155  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6148th epoch : 3.48095873218093  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6149th epoch : 3.480938491813103  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6150th epoch : 3.4809182178670213  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6151th epoch : 3.4808979102557984  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6152th epoch : 3.4808775688922777  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6153th epoch : 3.48085719368903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6154th epoch : 3.480836784558352  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6155th epoch : 3.4808163414122673  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6156th epoch : 3.4807958641625234  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6157th epoch : 3.4807753527205922  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6158th epoch : 3.4807548069976693  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6159th epoch : 3.480734226904672  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6160th epoch : 3.4807136123522393  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6161th epoch : 3.4806929632507306  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6162th epoch : 3.4806722795102254  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6163th epoch : 3.4806515610405224  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6164th epoch : 3.480630807751137  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6165th epoch : 3.4806100195513037  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6166th epoch : 3.480589196349971  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6167th epoch : 3.480568338055804  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6168th epoch : 3.4805474445771827  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6169th epoch : 3.480526515822199  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6170th epoch : 3.4805055516986596  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6171th epoch : 3.4804845521140813  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6172th epoch : 3.4804635169756923  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6173th epoch : 3.480442446190431  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6174th epoch : 3.480421339664945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6175th epoch : 3.480400197305589  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6176th epoch : 3.4803790190184265  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6177th epoch : 3.4803578047092265  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6178th epoch : 3.480336554283463  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6179th epoch : 3.4803152676463163  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6180th epoch : 3.4802939447026677  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6181th epoch : 3.4802725853571035  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6182th epoch : 3.4802511895139103  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6183th epoch : 3.4802297570770766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6184th epoch : 3.48020828795029  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6185th epoch : 3.480186782036937  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6186th epoch : 3.4801652392401032  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6187th epoch : 3.48014365946257  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6188th epoch : 3.4801220426068156  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6189th epoch : 3.4801003885750132  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6190th epoch : 3.4800786972690307  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6191th epoch : 3.480056968590429  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6192th epoch : 3.4800352024404617  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6193th epoch : 3.4800133987200725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6194th epoch : 3.479991557329898  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6195th epoch : 3.479969678170261  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6196th epoch : 3.479947761141176  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6197th epoch : 3.4799258061423433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6198th epoch : 3.4799038130731503  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6199th epoch : 3.4798817818326695  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6200th epoch : 3.479859712319659  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6201th epoch : 3.4798376044325594  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6202th epoch : 3.479815458069495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6203th epoch : 3.4797932731282715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6204th epoch : 3.4797710495063745  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6205th epoch : 3.479748787100971  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6206th epoch : 3.4797264858089045  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6207th epoch : 3.479704145526698  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6208th epoch : 3.479681766150551  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6209th epoch : 3.4796593475763373  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6210th epoch : 3.4796368896996075  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6211th epoch : 3.4796143924155847  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6212th epoch : 3.4795918556191645  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6213th epoch : 3.4795692792049144  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6214th epoch : 3.479546663067073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6215th epoch : 3.4795240070995477  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6216th epoch : 3.4795013111959157  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6217th epoch : 3.479478575249421  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6218th epoch : 3.4794557991529733  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6219th epoch : 3.4794329827991493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6220th epoch : 3.4794101260801895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6221th epoch : 3.479387228887998  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6222th epoch : 3.479364291114141  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6223th epoch : 3.4793413126498463  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6224th epoch : 3.4793182933860014  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6225th epoch : 3.479295233213154  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6226th epoch : 3.479272132021509  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6227th epoch : 3.4792489897009293  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6228th epoch : 3.479225806140933  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6229th epoch : 3.4792025812306933  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6230th epoch : 3.4791793148590378  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6231th epoch : 3.479156006914446  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6232th epoch : 3.4791326572850503  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6233th epoch : 3.479109265858633  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6234th epoch : 3.4790858325226255  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6235th epoch : 3.479062357164109  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6236th epoch : 3.47903883966981  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6237th epoch : 3.479015279926104  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6238th epoch : 3.4789916778190095  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6239th epoch : 3.4789680332341897  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6240th epoch : 3.4789443460569505  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6241th epoch : 3.4789206161722404  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6242th epoch : 3.4788968434646477  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6243th epoch : 3.4788730278184006  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6244th epoch : 3.4788491691173657  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6245th epoch : 3.4788252672450475  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6246th epoch : 3.478801322084586  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6247th epoch : 3.478777333518756  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6248th epoch : 3.4787533014299674  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6249th epoch : 3.4787292257002616  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6250th epoch : 3.4787051062113123  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6251th epoch : 3.478680942844423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6252th epoch : 3.4786567354805276  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6253th epoch : 3.4786324840001868  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6254th epoch : 3.4786081882835895  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6255th epoch : 3.47858384821055  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6256th epoch : 3.478559463660506  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6257th epoch : 3.4785350345125208  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6258th epoch : 3.4785105606452777  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6259th epoch : 3.4784860419370833  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6260th epoch : 3.4784614782658623  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6261th epoch : 3.4784368695091588  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6262th epoch : 3.478412215544134  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6263th epoch : 3.478387516247566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6264th epoch : 3.4783627714958474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6265th epoch : 3.4783379811649846  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6266th epoch : 3.478313145130597  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6267th epoch : 3.4782882632679146  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6268th epoch : 3.478263335451779  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6269th epoch : 3.478238361556639  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6270th epoch : 3.478213341456552  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6271th epoch : 3.4781882750251825  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6272th epoch : 3.4781631621357985  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6273th epoch : 3.478138002661273  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6274th epoch : 3.4781127964740812  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6275th epoch : 3.4780875434463003  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6276th epoch : 3.478062243449607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6277th epoch : 3.478036896355278  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6278th epoch : 3.4780115020341853  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6279th epoch : 3.4779860603567996  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6280th epoch : 3.477960571193185  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6281th epoch : 3.477935034413  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6282th epoch : 3.4779094498854954  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6283th epoch : 3.4778838174795133  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6284th epoch : 3.477858137063485  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6285th epoch : 3.4778324085054306  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6286th epoch : 3.4778066316729572  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6287th epoch : 3.477780806433258  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6288th epoch : 3.4777549326531103  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6289th epoch : 3.477729010198875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6290th epoch : 3.4777030389364945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6291th epoch : 3.477677018731491  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6292th epoch : 3.477650949448967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6293th epoch : 3.4776248309536024  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6294th epoch : 3.4775986631096525  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6295th epoch : 3.477572445780948  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6296th epoch : 3.4775461788308943  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6297th epoch : 3.4775198621224677  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6298th epoch : 3.4774934955182157  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6299th epoch : 3.477467078880255  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6300th epoch : 3.477440612070271  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6301th epoch : 3.4774140949495145  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6302th epoch : 3.477387527378803  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6303th epoch : 3.477360909218516  Training Accuracy:0.5714285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 6304th epoch : 3.477334240328597  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6305th epoch : 3.4773075205685493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6306th epoch : 3.4772807497974356  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6307th epoch : 3.477253927873877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6308th epoch : 3.4772270546560513  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6309th epoch : 3.4772001300016906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6310th epoch : 3.477173153768081  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6311th epoch : 3.477146125812061  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6312th epoch : 3.4771190459900194  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6313th epoch : 3.477091914157894  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6314th epoch : 3.47706473017117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6315th epoch : 3.4770374938848794  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6316th epoch : 3.477010205153598  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6317th epoch : 3.4769828638314455  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6318th epoch : 3.476955469772083  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6319th epoch : 3.4769280228287096  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6320th epoch : 3.4769005228540664  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6321th epoch : 3.4768729697004286  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6322th epoch : 3.4768453632196077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6323th epoch : 3.4768177032629493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6324th epoch : 3.47678998968133  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6325th epoch : 3.476762222325158  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6326th epoch : 3.4767344010443715  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6327th epoch : 3.476706525688433  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6328th epoch : 3.476678596106334  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6329th epoch : 3.476650612146588  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6330th epoch : 3.4766225736572323  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6331th epoch : 3.4765944804858244  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6332th epoch : 3.476566332479442  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6333th epoch : 3.4765381294846787  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6334th epoch : 3.4765098713476457  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6335th epoch : 3.4764815579139676  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6336th epoch : 3.476453189028782  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6337th epoch : 3.4764247645367377  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6338th epoch : 3.4763962842819915  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6339th epoch : 3.4763677481082085  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6340th epoch : 3.4763391558585597  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6341th epoch : 3.4763105073757203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6342th epoch : 3.476281802501867  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6343th epoch : 3.4762530410786776  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6344th epoch : 3.476224222947329  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6345th epoch : 3.4761953479484937  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6346th epoch : 3.476166415922342  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6347th epoch : 3.4761374267085356  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6348th epoch : 3.4761083801462282  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6349th epoch : 3.4760792760740644  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6350th epoch : 3.476050114330176  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6351th epoch : 3.47602089475218  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6352th epoch : 3.4759916171771805  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6353th epoch : 3.475962281441762  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6354th epoch : 3.47593288738199  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6355th epoch : 3.4759034348334095  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6356th epoch : 3.4758739236310414  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6357th epoch : 3.475844353609383  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6358th epoch : 3.4758147246024036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6359th epoch : 3.4757850364435434  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6360th epoch : 3.4757552889657135  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6361th epoch : 3.475725482001291  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6362th epoch : 3.4756956153821186  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6363th epoch : 3.4756656889395026  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6364th epoch : 3.475635702504211  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6365th epoch : 3.47560565590647  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6366th epoch : 3.4755755489759643  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6367th epoch : 3.4755453815418345  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6368th epoch : 3.475515153432674  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6369th epoch : 3.475484864476526  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6370th epoch : 3.475454514500887  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6371th epoch : 3.4754241033326956  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6372th epoch : 3.47539363079834  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6373th epoch : 3.475363096723649  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6374th epoch : 3.475332500933893  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6375th epoch : 3.4753018432537806  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6376th epoch : 3.4752711235074587  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6377th epoch : 3.475240341518507  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6378th epoch : 3.475209497109939  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6379th epoch : 3.4751785901041967  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6380th epoch : 3.4751476203231517  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6381th epoch : 3.4751165875881007  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6382th epoch : 3.4750854917197636  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6383th epoch : 3.4750543325382828  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6384th epoch : 3.4750231098632187  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6385th epoch : 3.474991823513548  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6386th epoch : 3.4749604733076644  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6387th epoch : 3.474929059063371  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6388th epoch : 3.474897580597882  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6389th epoch : 3.4748660377278195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6390th epoch : 3.4748344302692105  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6391th epoch : 3.4748027580374843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6392th epoch : 3.474771020847472  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6393th epoch : 3.4747392185134007  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6394th epoch : 3.4747073508488953  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6395th epoch : 3.4746754176669725  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6396th epoch : 3.474643418780041  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6397th epoch : 3.4746113539998964  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6398th epoch : 3.4745792231377206  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6399th epoch : 3.4745470260040796  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6400th epoch : 3.4745147624089188  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6401th epoch : 3.474482432161563  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6402th epoch : 3.474450035070712  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6403th epoch : 3.4744175709444396  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6404th epoch : 3.4743850395901887  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6405th epoch : 3.4743524408147706  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6406th epoch : 3.474319774424363  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6407th epoch : 3.4742870402245036  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6408th epoch : 3.474254238020093  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6409th epoch : 3.474221367615387  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6410th epoch : 3.4741884288139966  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6411th epoch : 3.4741554214188843  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6412th epoch : 3.4741223452323617  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6413th epoch : 3.474089200056086  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6414th epoch : 3.4740559856910593  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6415th epoch : 3.474022701937623  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6416th epoch : 3.4739893485954556  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6417th epoch : 3.4739559254635726  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6418th epoch : 3.4739224323403195  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6419th epoch : 3.4738888690233716  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6420th epoch : 3.4738552353097303  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6421th epoch : 3.4738215309957203  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6422th epoch : 3.4737877558769856  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6423th epoch : 3.4737539097484884  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6424th epoch : 3.473719992404505  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6425th epoch : 3.473686003638621  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6426th epoch : 3.473651943243732  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6427th epoch : 3.473617811012038  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6428th epoch : 3.4735836067350396  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6429th epoch : 3.4735493302035376  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6430th epoch : 3.4735149812076274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6431th epoch : 3.473480559536696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6432th epoch : 3.47344606497942  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6433th epoch : 3.473411497323762  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6434th epoch : 3.4733768563569662  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6435th epoch : 3.4733421418655563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6436th epoch : 3.4733073536353314  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6437th epoch : 3.4732724914513637  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6438th epoch : 3.473237555097993  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6439th epoch : 3.4732025443588266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6440th epoch : 3.4731674590167314  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6441th epoch : 3.473132298853835  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6442th epoch : 3.4730970636515193  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6443th epoch : 3.473061753190417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6444th epoch : 3.4730263672504096  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6445th epoch : 3.472990905610623  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6446th epoch : 3.472955368049423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6447th epoch : 3.4729197543444132  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6448th epoch : 3.4728840642724297  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6449th epoch : 3.4728482976095387  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6450th epoch : 3.4728124541310326  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6451th epoch : 3.472776533611425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6452th epoch : 3.472740535824448  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6453th epoch : 3.4727044605430475  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6454th epoch : 3.472668307539381  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6455th epoch : 3.4726320765848118  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6456th epoch : 3.4725957674499055  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6457th epoch : 3.4725593799044256  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6458th epoch : 3.472522913717332  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6459th epoch : 3.472486368656773  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6460th epoch : 3.4724497444900844  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6461th epoch : 3.4724130409837834  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6462th epoch : 3.4723762579035657  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6463th epoch : 3.4723393950143002  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6464th epoch : 3.472302452080026  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6465th epoch : 3.472265428863946  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6466th epoch : 3.472228325128425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6467th epoch : 3.472191140634984  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6468th epoch : 3.472153875144296  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6469th epoch : 3.472116528416182  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6470th epoch : 3.472079100209605  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6471th epoch : 3.4720415902826676  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6472th epoch : 3.4720039983926054  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6473th epoch : 3.471966324295784  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6474th epoch : 3.4719285677476934  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6475th epoch : 3.471890728502944  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6476th epoch : 3.47185280631526  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6477th epoch : 3.471814800937478  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6478th epoch : 3.4717767121215384  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6479th epoch : 3.4717385396184834  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6480th epoch : 3.4717002831784503  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6481th epoch : 3.4716619425506674  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6482th epoch : 3.4716235174834487  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6483th epoch : 3.4715850077241885  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6484th epoch : 3.471546413019358  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6485th epoch : 3.471507733114497  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6486th epoch : 3.471468967754211  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6487th epoch : 3.471430116682167  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6488th epoch : 3.471391179641084  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6489th epoch : 3.471352156372732  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6490th epoch : 3.471313046617924  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6491th epoch : 3.471273850116512  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6492th epoch : 3.4712345666073805  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6493th epoch : 3.471195195828441  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6494th epoch : 3.4711557375166264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6495th epoch : 3.4711161914078867  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6496th epoch : 3.4710765572371813  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6497th epoch : 3.4710368347384737  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6498th epoch : 3.4709970236447267  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6499th epoch : 3.4709571236878958  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6500th epoch : 3.4709171345989223  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6501th epoch : 3.4708770561077293  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6502th epoch : 3.470836887943214  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6503th epoch : 3.4707966298332416  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6504th epoch : 3.470756281504641  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6505th epoch : 3.4707158426831968  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6506th epoch : 3.4706753130936416  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6507th epoch : 3.4706346924596536  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6508th epoch : 3.4705939805038466  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6509th epoch : 3.4705531769477656  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6510th epoch : 3.4705122815118794  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6511th epoch : 3.470471293915573  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6512th epoch : 3.470430213877144  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6513th epoch : 3.470389041113792  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6514th epoch : 3.470347775341614  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6515th epoch : 3.4703064162755974  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6516th epoch : 3.470264963629613  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6517th epoch : 3.4702234171164066  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6518th epoch : 3.470181776447595  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6519th epoch : 3.470140041333654  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6520th epoch : 3.470098211483917  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6521th epoch : 3.470056286606563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6522th epoch : 3.47001426640861  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6523th epoch : 3.469972150595911  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6524th epoch : 3.469929938873142  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6525th epoch : 3.4698876309437967  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6526th epoch : 3.469845226510179  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6527th epoch : 3.4698027252733934  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6528th epoch : 3.4697601269333402  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6529th epoch : 3.4697174311887045  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6530th epoch : 3.46967463773695  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6531th epoch : 3.46963174627431  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6532th epoch : 3.46958875649578  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6533th epoch : 3.4695456680951096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6534th epoch : 3.469502480764793  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6535th epoch : 3.4694591941960615  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6536th epoch : 3.4694158080788755  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6537th epoch : 3.4693723221019135  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6538th epoch : 3.4693287359525673  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6539th epoch : 3.46928504931693  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6540th epoch : 3.4692412618797883  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6541th epoch : 3.4691973733246138  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6542th epoch : 3.4691533833335533  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6543th epoch : 3.4691092915874213  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6544th epoch : 3.469065097765688  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6545th epoch : 3.469020801546473  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6546th epoch : 3.468976402606534  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6547th epoch : 3.468931900621257  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6548th epoch : 3.4688872952646492  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6549th epoch : 3.468842586209327  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6550th epoch : 3.4687977731265063  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6551th epoch : 3.4687528556859935  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6552th epoch : 3.468707833556176  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6553th epoch : 3.4686627064040096  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6554th epoch : 3.4686174738950126  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6555th epoch : 3.4685721356932504  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6556th epoch : 3.4685266914613297  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6557th epoch : 3.4684811408603844  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6558th epoch : 3.4684354835500675  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6559th epoch : 3.4683897191885387  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6560th epoch : 3.468343847432455  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6561th epoch : 3.468297867936958  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6562th epoch : 3.4682517803556654  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6563th epoch : 3.4682055843406574  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6564th epoch : 3.4681592795424656  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6565th epoch : 3.468112865610064  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6566th epoch : 3.468066342190854  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6567th epoch : 3.468019708930656  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6568th epoch : 3.4679729654736953  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6569th epoch : 3.4679261114625914  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6570th epoch : 3.4678791465383454  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6571th epoch : 3.4678320703403287  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6572th epoch : 3.46778488250627  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6573th epoch : 3.4677375826722425  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6574th epoch : 3.4676901704726526  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6575th epoch : 3.467642645540227  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6576th epoch : 3.4675950075059987  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6577th epoch : 3.4675472559992953  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6578th epoch : 3.4674993906477263  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6579th epoch : 3.467451411077168  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6580th epoch : 3.467403316911752  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6581th epoch : 3.467355107773852  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6582th epoch : 3.4673067832840685  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6583th epoch : 3.4672583430612156  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6584th epoch : 3.467209786722308  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6585th epoch : 3.467161113882547  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6586th epoch : 3.467112324155305  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6587th epoch : 3.467063417152112  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6588th epoch : 3.467014392482641  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6589th epoch : 3.466965249754694  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6590th epoch : 3.4669159885741863  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6591th epoch : 3.4668666085451325  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6592th epoch : 3.4668171092696296  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6593th epoch : 3.466767490347845  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6594th epoch : 3.4667177513779968  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6595th epoch : 3.4666678919563423  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6596th epoch : 3.4666179116771603  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6597th epoch : 3.466567810132735  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6598th epoch : 3.46651758691334  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6599th epoch : 3.4664672416072246  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6600th epoch : 3.466416773800592  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6601th epoch : 3.466366183077589  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6602th epoch : 3.466315469020284  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6603th epoch : 3.466264631208654  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6604th epoch : 3.466213669220565  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6605th epoch : 3.4661625826317555  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6606th epoch : 3.46611137101582  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6607th epoch : 3.466060033944189  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6608th epoch : 3.4660085709861144  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6609th epoch : 3.4659569817086475  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6610th epoch : 3.4659052656766254  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6611th epoch : 3.4658534224526485  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6612th epoch : 3.4658014515970645  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6613th epoch : 3.465749352667948  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6614th epoch : 3.4656971252210833  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6615th epoch : 3.465644768809943  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6616th epoch : 3.4655922829856705  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6617th epoch : 3.46553966729706  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6618th epoch : 3.465486921290535  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6619th epoch : 3.465434044510131  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6620th epoch : 3.465381036497473  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6621th epoch : 3.4653278967917567  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6622th epoch : 3.4652746249297275  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6623th epoch : 3.4652212204456583  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6624th epoch : 3.46516768287133  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6625th epoch : 3.465114011736009  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6626th epoch : 3.465060206566427  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6627th epoch : 3.4650062668867574  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6628th epoch : 3.4649521922185964  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6629th epoch : 3.4648979820809367  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6630th epoch : 3.464843635990148  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6631th epoch : 3.4647891534599538  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6632th epoch : 3.464734534001407  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6633th epoch : 3.464679777122868  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6634th epoch : 3.464624882329982  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6635th epoch : 3.4645698491256534  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6636th epoch : 3.464514677010023  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6637th epoch : 3.4644593654804443  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6638th epoch : 3.464403914031457  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6639th epoch : 3.4643483221547653  Training Accuracy:0.5357142857142857\n",
      "The training loss at 6640th epoch : 3.4642925893392107  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6641th epoch : 3.4642367150707467  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6642th epoch : 3.4641806988324153  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6643th epoch : 3.464124540104319  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6644th epoch : 3.4640682383635966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6645th epoch : 3.4640117930843948  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6646th epoch : 3.463955203737844  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6647th epoch : 3.4638984697920296  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6648th epoch : 3.463841590711966  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6649th epoch : 3.4637845659595676  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6650th epoch : 3.463727394993624  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6651th epoch : 3.463670077269768  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6652th epoch : 3.4636126122404507  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6653th epoch : 3.463554999354911  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6654th epoch : 3.4634972380591478  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6655th epoch : 3.463439327795889  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6656th epoch : 3.463381268004564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6657th epoch : 3.4633230581212726  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6658th epoch : 3.4632646975787553  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6659th epoch : 3.463206185806363  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6660th epoch : 3.4631475222300248  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6661th epoch : 3.4630887062722193  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6662th epoch : 3.4630297373519396  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6663th epoch : 3.462970614884666  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6664th epoch : 3.4629113382823298  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6665th epoch : 3.462851906953283  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6666th epoch : 3.462792320302264  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6667th epoch : 3.462732577730367  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6668th epoch : 3.462672678635005  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6669th epoch : 3.4626126224098783  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6670th epoch : 3.46255240844494  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6671th epoch : 3.4624920361263603  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6672th epoch : 3.462431504836492  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6673th epoch : 3.4623708139538363  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6674th epoch : 3.4623099628530047  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6675th epoch : 3.462248950904685  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6676th epoch : 3.462187777475604  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6677th epoch : 3.4621264419284903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6678th epoch : 3.462064943622038  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6679th epoch : 3.4620032819108673  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6680th epoch : 3.461941456145488  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6681th epoch : 3.461879465672261  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6682th epoch : 3.461817309833358  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6683th epoch : 3.4617549879667235  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6684th epoch : 3.461692499406035  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6685th epoch : 3.4616298434806616  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6686th epoch : 3.4615670195156256  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6687th epoch : 3.461504026831559  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6688th epoch : 3.4614408647446635  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6689th epoch : 3.4613775325666696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6690th epoch : 3.4613140296047917  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6691th epoch : 3.4612503551616873  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6692th epoch : 3.4611865085354134  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6693th epoch : 3.461122489019383  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6694th epoch : 3.461058295902318  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6695th epoch : 3.4609939284682114  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6696th epoch : 3.460929385996274  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6697th epoch : 3.460864667760896  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6698th epoch : 3.4607997730315945  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6699th epoch : 3.460734701072973  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6700th epoch : 3.4606694511446703  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6701th epoch : 3.460604022501314  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6702th epoch : 3.460538414392474  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6703th epoch : 3.4604726260626104  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6704th epoch : 3.4604066567510285  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6705th epoch : 3.4603405056918275  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6706th epoch : 3.4602741721138495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6707th epoch : 3.46020765524063  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6708th epoch : 3.4601409542903454  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6709th epoch : 3.460074068475764  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6710th epoch : 3.460006997004191  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6711th epoch : 3.459939739077417  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6712th epoch : 3.4598722938916637  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6713th epoch : 3.4598046606375314  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6714th epoch : 3.4597368384999436  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6715th epoch : 3.4596688266580915  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6716th epoch : 3.459600624285379  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6717th epoch : 3.459532230549366  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6718th epoch : 3.459463644611713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6719th epoch : 3.459394865628121  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6720th epoch : 3.459325892748275  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6721th epoch : 3.4592567251157864  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6722th epoch : 3.459187361868132  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6723th epoch : 3.4591178021365936  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6724th epoch : 3.4590480450461993  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6725th epoch : 3.4589780897156626  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6726th epoch : 3.458907935257317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6727th epoch : 3.4588375807770575  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6728th epoch : 3.4587670253742755  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6729th epoch : 3.458696268141796  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6730th epoch : 3.4586253081658116  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6731th epoch : 3.4585541445258188  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6732th epoch : 3.458482776294551  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6733th epoch : 3.4584112025379126  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6734th epoch : 3.458339422314913  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6735th epoch : 3.4582674346775955  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6736th epoch : 3.458195238670972  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6737th epoch : 3.4581228333329506  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6738th epoch : 3.4580502176942685  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6739th epoch : 3.4579773907784186  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6740th epoch : 3.4579043516015795  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6741th epoch : 3.4578310991725423  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6742th epoch : 3.4577576324926382  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6743th epoch : 3.457683950555663  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6744th epoch : 3.457610052347805  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6745th epoch : 3.4575359368475684  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6746th epoch : 3.4574616030256955  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6747th epoch : 3.4573870498450923  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6748th epoch : 3.4573122762607493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6749th epoch : 3.457237281219663  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6750th epoch : 3.457162063660756  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6751th epoch : 3.4570866225147983  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6752th epoch : 3.4570109567043237  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6753th epoch : 3.456935065143551  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6754th epoch : 3.4568589467382984  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6755th epoch : 3.4567826003859  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6756th epoch : 3.4567060249751247  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6757th epoch : 3.4566292193860852  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6758th epoch : 3.4565521824901566  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6759th epoch : 3.4564749131498864  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6760th epoch : 3.4563974102189077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6761th epoch : 3.4563196725418495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6762th epoch : 3.4562416989542464  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6763th epoch : 3.456163488282449  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6764th epoch : 3.45608503934353  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6765th epoch : 3.456006350945195  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6766th epoch : 3.455927421885684  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6767th epoch : 3.4558482509536805  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6768th epoch : 3.4557688369282147  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6769th epoch : 3.4556891785785653  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6770th epoch : 3.455609274664164  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6771th epoch : 3.455529123934495  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6772th epoch : 3.4554487251289983  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6773th epoch : 3.4553680769769644  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6774th epoch : 3.455287178197436  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6775th epoch : 3.4552060274991057  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6776th epoch : 3.455124623580208  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6777th epoch : 3.4550429651284187  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6778th epoch : 3.454961050820747  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6779th epoch : 3.454878879323429  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6780th epoch : 3.454796449291819  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6781th epoch : 3.4547137593702795  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6782th epoch : 3.4546308081920727  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6783th epoch : 3.454547594379248  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6784th epoch : 3.4544641165425296  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6785th epoch : 3.4543803732812015  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6786th epoch : 3.454296363182995  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6787th epoch : 3.4542120848239697  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6788th epoch : 3.454127536768398  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6789th epoch : 3.454042717568647  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6790th epoch : 3.453957625765057  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6791th epoch : 3.453872259885823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6792th epoch : 3.45378661844687  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6793th epoch : 3.4537006999517317  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6794th epoch : 3.4536145028914245  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6795th epoch : 3.453528025744323  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6796th epoch : 3.453441266976032  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6797th epoch : 3.453354225039259  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6798th epoch : 3.4532668983736823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6799th epoch : 3.4531792854058234  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6800th epoch : 3.453091384548913  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6801th epoch : 3.453003194202756  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6802th epoch : 3.4529147127536  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6803th epoch : 3.4528259385739952  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6804th epoch : 3.452736870022661  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6805th epoch : 3.4526475054443426  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6806th epoch : 3.4525578431696746  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6807th epoch : 3.452467881515037  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6808th epoch : 3.4523776187824122  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6809th epoch : 3.4522870532592425  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6810th epoch : 3.452196183218281  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6811th epoch : 3.452105006917446  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6812th epoch : 3.452013522599674  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6813th epoch : 3.451921728492766  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6814th epoch : 3.451829622809237  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6815th epoch : 3.4517372037461644  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6816th epoch : 3.4516444694850303  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6817th epoch : 3.4515514181915696  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6818th epoch : 3.451458048015607  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6819th epoch : 3.4513643570909025  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6820th epoch : 3.4512703435349876  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6821th epoch : 3.451176005449005  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6822th epoch : 3.451081340917543  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6823th epoch : 3.4509863480084713  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6824th epoch : 3.4508910247727727  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6825th epoch : 3.450795369244377  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6826th epoch : 3.4506993794399885  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6827th epoch : 3.450603053358914  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6828th epoch : 3.4505063889828906  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6829th epoch : 3.450409384275911  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6830th epoch : 3.4503120371840454  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6831th epoch : 3.4502143456352634  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6832th epoch : 3.4501163075392545  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6833th epoch : 3.450017920787246  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6834th epoch : 3.44991918325182  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6835th epoch : 3.4498200927867266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6836th epoch : 3.4497206472266995  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6837th epoch : 3.449620844387266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6838th epoch : 3.449520682064556  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6839th epoch : 3.4494201580351116  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6840th epoch : 3.449319270055692  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6841th epoch : 3.4492180158630785  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6842th epoch : 3.4491163931738757  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6843th epoch : 3.4490143996843154  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6844th epoch : 3.4489120330700516  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6845th epoch : 3.448809290985961  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6846th epoch : 3.448706171065936  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6847th epoch : 3.448602670922681  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6848th epoch : 3.4484987881475004  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6849th epoch : 3.4483945203100914  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6850th epoch : 3.4482898649583302  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6851th epoch : 3.4481848196180596  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6852th epoch : 3.4480793817928714  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6853th epoch : 3.4479735489638905  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6854th epoch : 3.447867318589554  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6855th epoch : 3.4477606881053897  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6856th epoch : 3.4476536549237946  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6857th epoch : 3.447546216433806  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6858th epoch : 3.447438370000877  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6859th epoch : 3.447330112966647  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6860th epoch : 3.4472214426487096  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6861th epoch : 3.4471123563403787  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6862th epoch : 3.4470028513104554  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6863th epoch : 3.4468929248029903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6864th epoch : 3.4467825740370426  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6865th epoch : 3.446671796206441  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6866th epoch : 3.4465605884795396  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6867th epoch : 3.446448947998974  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6868th epoch : 3.446336871881412  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6869th epoch : 3.446224357217306  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6870th epoch : 3.446111401070642  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6871th epoch : 3.4459980004786854  Training Accuracy:0.5714285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 6872th epoch : 3.4458841524517267  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6873th epoch : 3.445769853972823  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6874th epoch : 3.44565510199754  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6875th epoch : 3.4455398934536903  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6876th epoch : 3.445424225241069  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6877th epoch : 3.4453080942311893  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6878th epoch : 3.445191497267014  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6879th epoch : 3.4450744311626873  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6880th epoch : 3.4449568927032614  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6881th epoch : 3.444838878644424  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6882th epoch : 3.4447203857122224  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6883th epoch : 3.444601410602784  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6884th epoch : 3.444481949982039  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6885th epoch : 3.4443620004854356  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6886th epoch : 3.4442415587176587  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6887th epoch : 3.444120621252341  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6888th epoch : 3.443999184631776  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6889th epoch : 3.443877245366629  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6890th epoch : 3.443754799935641  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6891th epoch : 3.443631844785339  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6892th epoch : 3.4435083763297354  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6893th epoch : 3.4433843909500323  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6894th epoch : 3.443259884994318  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6895th epoch : 3.4431348547772678  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6896th epoch : 3.4430092965798362  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6897th epoch : 3.4428832066489523  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6898th epoch : 3.4427565811972083  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6899th epoch : 3.442629416402553  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6900th epoch : 3.4425017084079745  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6901th epoch : 3.4423734533211876  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6902th epoch : 3.4422446472143178  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6903th epoch : 3.4421152861235793  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6904th epoch : 3.441985366048958  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6905th epoch : 3.4418548829538858  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6906th epoch : 3.4417238327649176  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6907th epoch : 3.4415922113714035  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6908th epoch : 3.4414600146251613  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6909th epoch : 3.4413272383401448  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6910th epoch : 3.4411938782921117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6911th epoch : 3.441059930218291  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6912th epoch : 3.4409253898170435  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6913th epoch : 3.440790252747527  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6914th epoch : 3.440654514629355  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6915th epoch : 3.440518171042254  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6916th epoch : 3.440381217525723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6917th epoch : 3.4402436495786852  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6918th epoch : 3.440105462659142  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6919th epoch : 3.4399666521838266  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6920th epoch : 3.4398272135278494  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6921th epoch : 3.4396871420243498  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6922th epoch : 3.4395464329641396  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6923th epoch : 3.43940508159535  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6924th epoch : 3.4392630831230724  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6925th epoch : 3.4391204327090024  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6926th epoch : 3.438977125471078  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6927th epoch : 3.438833156483118  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6928th epoch : 3.4386885207744595  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6929th epoch : 3.4385432133295946  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6930th epoch : 3.4383972290878018  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6931th epoch : 3.438250562942782  Training Accuracy:0.5714285714285714\n",
      "The training loss at 6932th epoch : 3.4381032097422874  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6933th epoch : 3.437955164287753  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6934th epoch : 3.437806421333924  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6935th epoch : 3.437656975588487  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6936th epoch : 3.437506821711692  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6937th epoch : 3.437355954315981  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6938th epoch : 3.4372043679656117  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6939th epoch : 3.4370520571762793  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6940th epoch : 3.4368990164147406  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6941th epoch : 3.4367452400984346  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6942th epoch : 3.436590722595103  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6943th epoch : 3.436435458222411  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6944th epoch : 3.4362794412475632  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6945th epoch : 3.436122665886925  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6946th epoch : 3.4359651263056383  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6947th epoch : 3.4358068166172386  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6948th epoch : 3.4356477308832716  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6949th epoch : 3.435487863112909  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6950th epoch : 3.435327207262563  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6951th epoch : 3.435165757235503  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6952th epoch : 3.4350035068814684  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6953th epoch : 3.434840449996284  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6954th epoch : 3.4346765803214736  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6955th epoch : 3.4345118915438757  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6956th epoch : 3.434346377295256  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6957th epoch : 3.4341800311519215  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6958th epoch : 3.434012846634337  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6959th epoch : 3.4338448172067357  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6960th epoch : 3.433675936276738  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6961th epoch : 3.433506197194964  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6962th epoch : 3.433335593254649  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6963th epoch : 3.433164117691262  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6964th epoch : 3.4329917636821197  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6965th epoch : 3.432818524346003  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6966th epoch : 3.4326443927427794  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6967th epoch : 3.432469361873017  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6968th epoch : 3.4322934246776082  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6969th epoch : 3.4321165740373876  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6970th epoch : 3.4319388027727555  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6971th epoch : 3.431760103643302  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6972th epoch : 3.43158046934743  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6973th epoch : 3.431399892521982  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6974th epoch : 3.431218365741867  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6975th epoch : 3.431035881519691  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6976th epoch : 3.4308524323053877  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6977th epoch : 3.4306680104858494  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6978th epoch : 3.430482608384564  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6979th epoch : 3.430296218261252  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6980th epoch : 3.4301088323115025  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6981th epoch : 3.4299204426664187  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6982th epoch : 3.4297310413922584  Training Accuracy:0.6071428571428571\n",
      "The training loss at 6983th epoch : 3.429540620490082  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6984th epoch : 3.4293491718954003  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6985th epoch : 3.4291566874778274  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6986th epoch : 3.4289631590407352  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6987th epoch : 3.428768578320909  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6988th epoch : 3.4285729369882123  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6989th epoch : 3.428376226645246  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6990th epoch : 3.428178438827021  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6991th epoch : 3.4279795650006246  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6992th epoch : 3.427779596564898  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6993th epoch : 3.427578524850115  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6994th epoch : 3.4273763411176628  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6995th epoch : 3.4271730365597306  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6996th epoch : 3.4269686022989982  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6997th epoch : 3.4267630293883338  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6998th epoch : 3.426556308810492  Training Accuracy:0.6428571428571429\n",
      "The training loss at 6999th epoch : 3.4263484314778188  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7000th epoch : 3.426139388231961  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7001th epoch : 3.42592916984358  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7002th epoch : 3.4257177670120726  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7003th epoch : 3.4255051703652937  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7004th epoch : 3.4252913704592878  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7005th epoch : 3.425076357778025  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7006th epoch : 3.424860122733141  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7007th epoch : 3.424642655663686  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7008th epoch : 3.4244239468358773  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7009th epoch : 3.424203986442859  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7010th epoch : 3.4239827646044687  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7011th epoch : 3.4237602713670103  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7012th epoch : 3.423536496703033  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7013th epoch : 3.4233114305111165  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7014th epoch : 3.4230850626156677  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7015th epoch : 3.4228573827667175  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7016th epoch : 3.422628380639732  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7017th epoch : 3.4223980458354264  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7018th epoch : 3.4221663678795884  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7019th epoch : 3.4219333362229114  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7020th epoch : 3.421698940240832  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7021th epoch : 3.421463169233379  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7022th epoch : 3.4212260124250293  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7023th epoch : 3.4209874589645737  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7024th epoch : 3.4207474979249883  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7025th epoch : 3.4205061183033214  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7026th epoch : 3.4202633090205814  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7027th epoch : 3.4200190589216413  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7028th epoch : 3.4197733567751483  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7029th epoch : 3.419526191273445  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7030th epoch : 3.4192775510324998  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7031th epoch : 3.4190274245918486  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7032th epoch : 3.4187758004145445  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7033th epoch : 3.4185226668871227  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7034th epoch : 3.418268012319568  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7035th epoch : 3.418011824945303  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7036th epoch : 3.41775409292118  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7037th epoch : 3.4174948043274864  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7038th epoch : 3.417233947167963  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7039th epoch : 3.4169715093698327  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7040th epoch : 3.4167074787838394  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7041th epoch : 3.4164418431843027  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7042th epoch : 3.4161745902691814  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7043th epoch : 3.415905707660152  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7044th epoch : 3.415635182902696  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7045th epoch : 3.4153630034662057  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7046th epoch : 3.4150891567440964  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7047th epoch : 3.414813630053938  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7048th epoch : 3.4145364106375946  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7049th epoch : 3.4142574856613814  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7050th epoch : 3.413976842216234  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7051th epoch : 3.4136944673178897  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7052th epoch : 3.413410347907086  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7053th epoch : 3.4131244708497728  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7054th epoch : 3.412836822937335  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7055th epoch : 3.412547390886837  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7056th epoch : 3.4122561613412743  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7057th epoch : 3.411963120869845  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7058th epoch : 3.4116682559682356  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7059th epoch : 3.41137155305892  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7060th epoch : 3.411072998491476  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7061th epoch : 3.410772578542919  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7062th epoch : 3.4104702794180444  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7063th epoch : 3.4101660872497965  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7064th epoch : 3.409859988099644  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7065th epoch : 3.4095519679579773  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7066th epoch : 3.4092420127445204  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7067th epoch : 3.40893010830876  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7068th epoch : 3.4086162404303906  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7069th epoch : 3.408300394819776  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7070th epoch : 3.4079825571184306  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7071th epoch : 3.407662712899515  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7072th epoch : 3.4073408476683498  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7073th epoch : 3.4070169468629463  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7074th epoch : 3.4066909958545573  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7075th epoch : 3.4063629799482418  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7076th epoch : 3.406032884383452  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7077th epoch : 3.405700694334632  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7078th epoch : 3.4053663949118422  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7079th epoch : 3.405029971161396  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7080th epoch : 3.404691408066517  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7081th epoch : 3.4043506905480156  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7082th epoch : 3.4040078034649808  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7083th epoch : 3.4036627316154955  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7084th epoch : 3.403315459737366  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7085th epoch : 3.4029659725088726  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7086th epoch : 3.4026142545495386  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7087th epoch : 3.4022602904209185  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7088th epoch : 3.401904064627404  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7089th epoch : 3.401545561617051  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7090th epoch : 3.4011847657824257  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7091th epoch : 3.4008216614614657  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7092th epoch : 3.4004562329383674  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7093th epoch : 3.4000884644444866  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7094th epoch : 3.3997183401592626  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7095th epoch : 3.399345844211157  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7096th epoch : 3.3989709606786183  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7097th epoch : 3.39859367359106  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7098th epoch : 3.398213966929861  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7099th epoch : 3.3978318246293866  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7100th epoch : 3.3974472305780243  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7101th epoch : 3.3970601686192445  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7102th epoch : 3.396670622552678  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7103th epoch : 3.3962785761352117  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7104th epoch : 3.395884013082106  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7105th epoch : 3.3954869170681308  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7106th epoch : 3.3950872717287206  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7107th epoch : 3.394685060661147  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7108th epoch : 3.394280267425716  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7109th epoch : 3.393872875546977  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7110th epoch : 3.3934628685149564  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7111th epoch : 3.3930502297864074  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7112th epoch : 3.3926349427860814  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7113th epoch : 3.3922169909080133  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7114th epoch : 3.391796357516832  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7115th epoch : 3.391373025949083  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7116th epoch : 3.3909469795145752  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7117th epoch : 3.390518201497741  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7118th epoch : 3.3900866751590173  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7119th epoch : 3.3896523837362467  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7120th epoch : 3.38921531044609  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7121th epoch : 3.388775438485463  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7122th epoch : 3.3883327510329884  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7123th epoch : 3.3878872312504638  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7124th epoch : 3.3874388622843483  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7125th epoch : 3.3869876272672665  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7126th epoch : 3.386533509319527  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7127th epoch : 3.3860764915506607  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7128th epoch : 3.3856165570609735  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7129th epoch : 3.3851536889431144  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7130th epoch : 3.3846878702836607  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7131th epoch : 3.384219084164719  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7132th epoch : 3.3837473136655407  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7133th epoch : 3.3832725418641525  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7134th epoch : 3.382794751839003  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7135th epoch : 3.382313926670622  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7136th epoch : 3.3818300494432947  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7137th epoch : 3.381343103246751  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7138th epoch : 3.3808530711778673  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7139th epoch : 3.3803599363423795  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7140th epoch : 3.3798636818566137  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7141th epoch : 3.3793642908492263  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7142th epoch : 3.378861746462955  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7143th epoch : 3.3783560318563857  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7144th epoch : 3.3778471302057276  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7145th epoch : 3.3773350247066016  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7146th epoch : 3.3768196985758365  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7147th epoch : 3.3763011350532808  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7148th epoch : 3.3757793174036177  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7149th epoch : 3.3752542289181955  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7150th epoch : 3.374725852916865  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7151th epoch : 3.374194172749823  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7152th epoch : 3.3736591717994706  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7153th epoch : 3.3731208334822713  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7154th epoch : 3.372579141250624  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7155th epoch : 3.3720340785947376  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7156th epoch : 3.3714856290445145  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7157th epoch : 3.3709337761714404  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7158th epoch : 3.37037850359048  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7159th epoch : 3.369819794961974  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7160th epoch : 3.369257633993547  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7161th epoch : 3.368692004442015  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7162th epoch : 3.368122890115297  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7163th epoch : 3.367550274874333  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7164th epoch : 3.3669741426349997  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7165th epoch : 3.366394477370033  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7166th epoch : 3.365811263110949  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7167th epoch : 3.365224483949968  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7168th epoch : 3.364634124041939  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7169th epoch : 3.364040167606262  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7170th epoch : 3.3634425989288137  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7171th epoch : 3.362841402363869  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7172th epoch : 3.362236562336022  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7173th epoch : 3.3616280633421067  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7174th epoch : 3.361015889953112  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7175th epoch : 3.3604000268160967  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7176th epoch : 3.3597804586560973  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7177th epoch : 3.359157170278036  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7178th epoch : 3.358530146568621  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7179th epoch : 3.3578993724982404  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7180th epoch : 3.357264833122855  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7181th epoch : 3.356626513585879  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7182th epoch : 3.3559843991200586  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7183th epoch : 3.3553384750493387  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7184th epoch : 3.3546887267907266  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7185th epoch : 3.3540351398561414  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7186th epoch : 3.353377699854259  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7187th epoch : 3.3527163924923444  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7188th epoch : 3.352051203578075  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7189th epoch : 3.3513821190213546  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7190th epoch : 3.3507091248361105  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7191th epoch : 3.350032207142086  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7192th epoch : 3.3493513521666136  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7193th epoch : 3.348666546246382  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7194th epoch : 3.347977775829182  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7195th epoch : 3.3472850274756447  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7196th epoch : 3.346588287860961  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7197th epoch : 3.3458875437765867  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7198th epoch : 3.3451827821319338  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7199th epoch : 3.3444739899560436  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7200th epoch : 3.343761154399241  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7201th epoch : 3.343044262734777  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7202th epoch : 3.342323302360446  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7203th epoch : 3.3415982608001924  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7204th epoch : 3.340869125705691  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7205th epoch : 3.3401358848579115  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7206th epoch : 3.3393985261686643  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7207th epoch : 3.3386570376821205  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7208th epoch : 3.3379114075763177  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7209th epoch : 3.337161624164636  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7210th epoch : 3.3364076758972603  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7211th epoch : 3.335649551362613  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7212th epoch : 3.3348872392887667  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7213th epoch : 3.3341207285448324  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7214th epoch : 3.3333500081423244  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7215th epoch : 3.332575067236499  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7216th epoch : 3.3317958951276667  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7217th epoch : 3.3310124812624835  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7218th epoch : 3.33022481523521  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7219th epoch : 3.3294328867889456  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7220th epoch : 3.3286366858168397  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7221th epoch : 3.327836202363266  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7222th epoch : 3.3270314266249783  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7223th epoch : 3.3262223489522285  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7224th epoch : 3.3254089598498617  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7225th epoch : 3.324591249978379  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7226th epoch : 3.3237692101549685  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7227th epoch : 3.3229428313545064  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7228th epoch : 3.322112104710529  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7229th epoch : 3.3212770215161664  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7230th epoch : 3.320437573225052  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7231th epoch : 3.3195937514521914  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7232th epoch : 3.3187455479748023  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7233th epoch : 3.317892954733118  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7234th epoch : 3.3170359638311577  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7235th epoch : 3.3161745675374603  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7236th epoch : 3.315308758285784  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7237th epoch : 3.314438528675767  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7238th epoch : 3.313563871473556  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7239th epoch : 3.3126847796123893  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7240th epoch : 3.3118012461931534  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7241th epoch : 3.3109132644848898  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7242th epoch : 3.3100208279252685  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7243th epoch : 3.309123930121022  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7244th epoch : 3.3082225648483377  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7245th epoch : 3.307316726053209  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7246th epoch : 3.3064064078517443  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7247th epoch : 3.3054916045304386  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7248th epoch : 3.304572310546395  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7249th epoch : 3.303648520527511  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7250th epoch : 3.3027202292726114  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7251th epoch : 3.301787431751548  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7252th epoch : 3.3008501231052416  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7253th epoch : 3.2999082986456902  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7254th epoch : 3.2989619538559194  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7255th epoch : 3.2980110843898958  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7256th epoch : 3.2970556860723823  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7257th epoch : 3.296095754898754  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7258th epoch : 3.2951312870347587  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7259th epoch : 3.2941622788162275  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7260th epoch : 3.293188726748739  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7261th epoch : 3.2922106275072265  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7262th epoch : 3.2912279779355336  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7263th epoch : 3.2902407750459206  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7264th epoch : 3.2892490160185135  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7265th epoch : 3.2882526982006963  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7266th epoch : 3.2872518191064515  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7267th epoch : 3.286246376415642  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7268th epoch : 3.2852363679732357  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7269th epoch : 3.2842217917884713  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7270th epoch : 3.283202646033966  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7271th epoch : 3.282178929044762  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7272th epoch : 3.2811506393173113  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7273th epoch : 3.280117775508401  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7274th epoch : 3.279080336434011  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7275th epoch : 3.2780383210681134  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7276th epoch : 3.2769917285414025  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7277th epoch : 3.275940558139959  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7278th epoch : 3.27488480930385  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7279th epoch : 3.2738244816256565  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7280th epoch : 3.2727595748489366  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7281th epoch : 3.2716900888666127  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7282th epoch : 3.2706160237192927  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7283th epoch : 3.2695373795935136  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7284th epoch : 3.268454156819915  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7285th epoch : 3.2673663558713346  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7286th epoch : 3.266273977360831  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7287th epoch : 3.2651770220396235  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7288th epoch : 3.26407549079496  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7289th epoch : 3.262969384647898  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7290th epoch : 3.2618587047510106  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7291th epoch : 3.2607434523860035  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7292th epoch : 3.259623628961254  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7293th epoch : 3.25849923600926  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7294th epoch : 3.2573702751840057  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7295th epoch : 3.256236748258234  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7296th epoch : 3.255098657120636  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7297th epoch : 3.2539560037729442  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7298th epoch : 3.2528087903269354  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7299th epoch : 3.2516570190013376  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7300th epoch : 3.250500692118643  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7301th epoch : 3.2493398121018218  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7302th epoch : 3.2481743814709403  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7303th epoch : 3.2470044028396736  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7304th epoch : 3.2458298789117204  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7305th epoch : 3.24465081247711  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7306th epoch : 3.243467206408408  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7307th epoch : 3.24227906365681  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7308th epoch : 3.2410863872481293  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7309th epoch : 3.239889180278671  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7310th epoch : 3.238687445910995  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7311th epoch : 3.2374811873695637  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7312th epoch : 3.2362704079362716  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7313th epoch : 3.235055110945858  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7314th epoch : 3.2338352997811963  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7315th epoch : 3.2326109778684637  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7316th epoch : 3.231382148672183  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7317th epoch : 3.2301488156901397  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7318th epoch : 3.228910982448166  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7319th epoch : 3.227668652494799  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7320th epoch : 3.2264218293958  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7321th epoch : 3.22517051672854  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7322th epoch : 3.223914718076247  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7323th epoch : 3.222654437022112  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7324th epoch : 3.2213896771432515  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7325th epoch : 3.220120442004524  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7326th epoch : 3.2188467351521997  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7327th epoch : 3.2175685601074773  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7328th epoch : 3.216285920359849  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7329th epoch : 3.2149988193603076  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7330th epoch : 3.213707260514398  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7331th epoch : 3.212411247175101  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7332th epoch : 3.2111107826355583  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7333th epoch : 3.209805870121625  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7334th epoch : 3.208496512784258  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7335th epoch : 3.2071827136917213  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7336th epoch : 3.2058644758216235  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7337th epoch : 3.2045418020527716  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7338th epoch : 3.2032146951568388  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7339th epoch : 3.201883157789851  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7340th epoch : 3.2005471924834805  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7341th epoch : 3.199206801636146  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7342th epoch : 3.1978619875039165  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7343th epoch : 3.1965127521912144  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7344th epoch : 3.1951590976413153  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7345th epoch : 3.193801025626639  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7346th epoch : 3.192438537738828  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7347th epoch : 3.1910716353786106  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7348th epoch : 3.1897003197454477  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7349th epoch : 3.1883245918269507  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7350th epoch : 3.186944452388075  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7351th epoch : 3.1855599019600795  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7352th epoch : 3.184170940829253  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7353th epoch : 3.182777569025397  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7354th epoch : 3.1813797863100635  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7355th epoch : 3.179977592164544  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7356th epoch : 3.1785709857776077  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7357th epoch : 3.1771599660329737  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7358th epoch : 3.175744531496526  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7359th epoch : 3.174324680403258  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7360th epoch : 3.1729004106439436  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7361th epoch : 3.1714717197515316  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7362th epoch : 3.1700386048872544  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7363th epoch : 3.1686010628264523  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7364th epoch : 3.1671590899441022  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7365th epoch : 3.16571268220005  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7366th epoch : 3.1642618351239364  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7367th epoch : 3.162806543799819  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7368th epoch : 3.1613468028504763  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7369th epoch : 3.1598826064213945  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7370th epoch : 3.15841394816443  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7371th epoch : 3.1569408212211436  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7372th epoch : 3.1554632182057962  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7373th epoch : 3.1539811311880097  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7374th epoch : 3.1524945516750766  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7375th epoch : 3.1510034705939267  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7376th epoch : 3.1495078782727304  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7377th epoch : 3.1480077644221467  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7378th epoch : 3.1465031181162053  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7379th epoch : 3.144993927772816  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7380th epoch : 3.143480181133904  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7381th epoch : 3.1419618652451704  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7382th epoch : 3.1404389664354584  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7383th epoch : 3.138911470295742  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7384th epoch : 3.1373793616577186  Training Accuracy:0.6428571428571429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 7385th epoch : 3.135842624572002  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7386th epoch : 3.1343012422859227  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7387th epoch : 3.1327551972209227  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7388th epoch : 3.131204470949544  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7389th epoch : 3.1296490441720124  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7390th epoch : 3.128088896692411  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7391th epoch : 3.1265240073944405  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7392th epoch : 3.1249543542167726  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7393th epoch : 3.1233799141279857  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7394th epoch : 3.121800663101092  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7395th epoch : 3.120216576087654  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7396th epoch : 3.1186276269914877  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7397th epoch : 3.1170337886419626  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7398th epoch : 3.1154350327668947  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7399th epoch : 3.113831329965044  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7400th epoch : 3.1122226496782117  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7401th epoch : 3.1106089601629527  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7402th epoch : 3.1089902284619066  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7403th epoch : 3.1073664203747566  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7404th epoch : 3.105737500428823  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7405th epoch : 3.1041034318493064  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7406th epoch : 3.1024641765291983  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7407th epoch : 3.100819694998856  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7408th epoch : 3.0991699463952784  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7409th epoch : 3.0975148884310912  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7410th epoch : 3.0958544773632544  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7411th epoch : 3.09418866796153  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7412th epoch : 3.0925174134767186  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7413th epoch : 3.0908406656087015  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7414th epoch : 3.0891583744743127  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7415th epoch : 3.08747048857507  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7416th epoch : 3.0857769547648037  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7417th epoch : 3.0840777182172197  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7418th epoch : 3.0823727223934294  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7419th epoch : 3.0806619090094998  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7420th epoch : 3.078945218004062  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7421th epoch : 3.07722258750603  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7422th epoch : 3.0754939538024852  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7423th epoch : 3.073759251306779  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7424th epoch : 3.0720184125269183  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7425th epoch : 3.070271368034297  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7426th epoch : 3.0685180464328385  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7427th epoch : 3.066758374328634  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7428th epoch : 3.064992276300136  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7429th epoch : 3.0632196748690084  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7430th epoch : 3.0614404904717065  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7431th epoch : 3.0596546414318837  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7432th epoch : 3.057862043933723  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7433th epoch : 3.056062611996292  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7434th epoch : 3.0542562574490315  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7435th epoch : 3.052442889908483  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7436th epoch : 3.0506224167563856  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7437th epoch : 3.0487947431192493  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7438th epoch : 3.0469597718495436  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7439th epoch : 3.0451174035086326  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7440th epoch : 3.043267536351589  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7441th epoch : 3.041410066314043  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7442th epoch : 3.039544887001199  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7443th epoch : 3.037671889679188  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7444th epoch : 3.0357909632689086  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7445th epoch : 3.0339019943425143  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7446th epoch : 3.032004867122725  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7447th epoch : 3.030099463485125  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7448th epoch : 3.0281856629636295  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7449th epoch : 3.0262633427592887  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7450th epoch : 3.024332377752619  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7451th epoch : 3.0223926405196395  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7452th epoch : 3.0204440013517986  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7453th epoch : 3.018486328279976  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7454th epoch : 3.0165194871027468  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7455th epoch : 3.0145433414190896  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7456th epoch : 3.012557752665724  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7457th epoch : 3.0105625801592564  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7458th epoch : 3.0085576811433135  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7459th epoch : 3.006542910840831  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7460th epoch : 3.00451812251167  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7461th epoch : 3.0024831675157193  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7462th epoch : 3.000437895381626  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7463th epoch : 2.9983821538813125  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7464th epoch : 2.996315789110394  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7465th epoch : 2.994238645574627  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7466th epoch : 2.9921505662824828  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7467th epoch : 2.990051392843942  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7468th epoch : 2.987940965575578  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7469th epoch : 2.9858191236119787  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7470th epoch : 2.983685705023547  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7471th epoch : 2.9815405469406837  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7472th epoch : 2.979383485684341  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7473th epoch : 2.977214356902913  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7474th epoch : 2.975032995715394  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7475th epoch : 2.9728392368607173  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7476th epoch : 2.970632914853154  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7477th epoch : 2.9684138641436184  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7478th epoch : 2.9661819192867065  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7479th epoch : 2.9639369151132446  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7480th epoch : 2.9616786869081166  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7481th epoch : 2.9594070705930813  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7482th epoch : 2.957121902914278  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7483th epoch : 2.954823021634073  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7484th epoch : 2.952510265726875  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7485th epoch : 2.9501834755785117  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7486th epoch : 2.9478424931887304  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7487th epoch : 2.9454871623763563  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7488th epoch : 2.9431173289866135  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7489th epoch : 2.9407328411000866  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7490th epoch : 2.938333549242778  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7491th epoch : 2.935919306596698  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7492th epoch : 2.9334899692103957  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7493th epoch : 2.9310453962088365  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7494th epoch : 2.9285854500020077  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7495th epoch : 2.9261099964916357  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7496th epoch : 2.9236189052753874  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7497th epoch : 2.9211120498479226  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7498th epoch : 2.9185893077981873  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7499th epoch : 2.91605056100232  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7500th epoch : 2.9134956958115787  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7501th epoch : 2.9109246032346947  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7502th epoch : 2.9083371791141004  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7503th epoch : 2.905733324295479  Training Accuracy:0.5714285714285714\n",
      "The training loss at 7504th epoch : 2.9031129447901445  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7505th epoch : 2.900475951929766  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7506th epoch : 2.8978222625130075  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7507th epoch : 2.895151798943691  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7508th epoch : 2.892464489360128  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7509th epoch : 2.889760267755327  Training Accuracy:0.6071428571428571\n",
      "The training loss at 7510th epoch : 2.8870390740878227  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7511th epoch : 2.8843008543829267  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7512th epoch : 2.8815455608242604  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7513th epoch : 2.8787731518354764  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7514th epoch : 2.8759835921521333  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7515th epoch : 2.8731768528837454  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7516th epoch : 2.870352911566078  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7517th epoch : 2.867511752203819  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7518th epoch : 2.8646533653037953  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7519th epoch : 2.861777747898969  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7520th epoch : 2.858884903563479  Training Accuracy:0.6428571428571429\n",
      "The training loss at 7521th epoch : 2.8559748424190405  Training Accuracy:0.6785714285714286\n",
      "The training loss at 7522th epoch : 2.8530475811330587  Training Accuracy:0.6785714285714286\n",
      "The training loss at 7523th epoch : 2.850103142908841  Training Accuracy:0.6785714285714286\n",
      "The training loss at 7524th epoch : 2.84714155746833  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7525th epoch : 2.844162861027793  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7526th epoch : 2.841167096266947  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7527th epoch : 2.83815431229199  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7528th epoch : 2.835124564593044  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7529th epoch : 2.8320779149965047  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7530th epoch : 2.829014431612814  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7531th epoch : 2.82593418878015  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7532th epoch : 2.8228372670045445  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7533th epoch : 2.819723752896909  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7534th epoch : 2.8165937391074554  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7535th epoch : 2.813447324257964  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7536th epoch : 2.810284612872346  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7537th epoch : 2.8071057153059153  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7538th epoch : 2.8039107476737666  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7539th epoch : 2.8006998317786245  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7540th epoch : 2.7974730950385065  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7541th epoch : 2.794230670414509  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7542th epoch : 2.7909726963389936  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7543th epoch : 2.7876993166444284  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7544th epoch : 2.7844106804930964  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7545th epoch : 2.7811069423078667  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7546th epoch : 2.7777882617041763  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7547th epoch : 2.7744548034233567  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7548th epoch : 2.7711067372674  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7549th epoch : 2.7677442380352364  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7550th epoch : 2.7643674854605598  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7551th epoch : 2.760976664151228  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7552th epoch : 2.757571963530216  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7553th epoch : 2.7541535777781028  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7554th epoch : 2.7507217057770315  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7555th epoch : 2.747276551056065  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7556th epoch : 2.7438183217378556  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7557th epoch : 2.7403472304865004  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7558th epoch : 2.73686349445647  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7559th epoch : 2.73336733524246  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7560th epoch : 2.729858978830006  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7561th epoch : 2.7263386555467046  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7562th epoch : 2.722806600013849  Training Accuracy:0.7142857142857143\n",
      "The training loss at 7563th epoch : 2.719263051098297  Training Accuracy:0.75\n",
      "The training loss at 7564th epoch : 2.7157082518643723  Training Accuracy:0.75\n",
      "The training loss at 7565th epoch : 2.712142449525595  Training Accuracy:0.75\n",
      "The training loss at 7566th epoch : 2.7085658953960308  Training Accuracy:0.75\n",
      "The training loss at 7567th epoch : 2.7049788448410403  Training Accuracy:0.75\n",
      "The training loss at 7568th epoch : 2.7013815572272204  Training Accuracy:0.75\n",
      "The training loss at 7569th epoch : 2.6977742958713  Training Accuracy:0.75\n",
      "The training loss at 7570th epoch : 2.694157327987787  Training Accuracy:0.75\n",
      "The training loss at 7571th epoch : 2.690530924635128  Training Accuracy:0.75\n",
      "The training loss at 7572th epoch : 2.686895360660172  Training Accuracy:0.75\n",
      "The training loss at 7573th epoch : 2.6832509146407144  Training Accuracy:0.75\n",
      "The training loss at 7574th epoch : 2.6795978688259003  Training Accuracy:0.75\n",
      "The training loss at 7575th epoch : 2.675936509074294  Training Accuracy:0.75\n",
      "The training loss at 7576th epoch : 2.672267124789388  Training Accuracy:0.75\n",
      "The training loss at 7577th epoch : 2.668590008852372  Training Accuracy:0.75\n",
      "The training loss at 7578th epoch : 2.6649054575519626  Training Accuracy:0.75\n",
      "The training loss at 7579th epoch : 2.6612137705111114  Training Accuracy:0.75\n",
      "The training loss at 7580th epoch : 2.657515250610428  Training Accuracy:0.75\n",
      "The training loss at 7581th epoch : 2.6538102039081513  Training Accuracy:0.75\n",
      "The training loss at 7582th epoch : 2.650098939556526  Training Accuracy:0.75\n",
      "The training loss at 7583th epoch : 2.646381769714446  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7584th epoch : 2.642659009456244  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7585th epoch : 2.6389309766765243  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7586th epoch : 2.6351979919909456  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7587th epoch : 2.631460378632878  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7588th epoch : 2.627718462345878  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7589th epoch : 2.6239725712719415  Training Accuracy:0.7857142857142857\n",
      "The training loss at 7590th epoch : 2.62022303583551  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7591th epoch : 2.616470188623225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7592th epoch : 2.612714364259447  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7593th epoch : 2.608955899277568  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7594th epoch : 2.6051951319871676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7595th epoch : 2.601432402337087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7596th epoch : 2.597668051774502  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7597th epoch : 2.5939024231001033  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7598th epoch : 2.590135860319511  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7599th epoch : 2.5863687084910567  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7600th epoch : 2.5826013135701014  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7601th epoch : 2.5788340222500534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7602th epoch : 2.5750671818002835  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7603th epoch : 2.5713011399011396  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7604th epoch : 2.5675362444762793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7605th epoch : 2.563772843522556  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7606th epoch : 2.5600112849376977  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7607th epoch : 2.5562519163460387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7608th epoch : 2.5524950849225707  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7609th epoch : 2.5487411372155835  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7610th epoch : 2.5449904189681822  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7611th epoch : 2.541243274938971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7612th epoch : 2.537500048722194  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7613th epoch : 2.5337610825676395  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7614th epoch : 2.5300267172006055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7615th epoch : 2.5262972916422344  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7616th epoch : 2.5225731430305176  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7617th epoch : 2.5188546064422854  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7618th epoch : 2.5151420147164716  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7619th epoch : 2.5114356982789676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7620th epoch : 2.507735984969357  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7621th epoch : 2.5040431998698196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7622th epoch : 2.500357665136502  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7623th epoch : 2.496679699833622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7624th epoch : 2.4930096197705933  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7625th epoch : 2.489347737342419  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7626th epoch : 2.485694361373621  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7627th epoch : 2.482049796965943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7628th epoch : 2.4784143453500604  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7629th epoch : 2.4747883037415224  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7630th epoch : 2.471171965201132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7631th epoch : 2.4675656184999655  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7632th epoch : 2.463969547989212  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7633th epoch : 2.4603840334750067  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7634th epoch : 2.4568093500984136  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7635th epoch : 2.453245768220701  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7636th epoch : 2.449693553314043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7637th epoch : 2.446152965857753  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7638th epoch : 2.4426242612401636  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7639th epoch : 2.439107689666226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7640th epoch : 2.4356034960709088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7641th epoch : 2.4321119200384547  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7642th epoch : 2.4286331957275373  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7643th epoch : 2.425167551802344  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7644th epoch : 2.4217152113696137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7645th epoch : 2.418276391921622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7646th epoch : 2.414851305285108  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7647th epoch : 2.411440157576125  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7648th epoch : 2.408043149160774  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7649th epoch : 2.404660474621785  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7650th epoch : 2.401292322730872  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7651th epoch : 2.3979388764268177  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7652th epoch : 2.394600312799186  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7653th epoch : 2.3912768030775946  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7654th epoch : 2.3879685126264345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7655th epoch : 2.3846756009449472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7656th epoch : 2.3813982216725296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7657th epoch : 2.3781365225991595  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7658th epoch : 2.3748906456808028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7659th epoch : 2.3716607270596786  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7660th epoch : 2.368446897089229  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7661th epoch : 2.3652492803636633  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7662th epoch : 2.36206799575191  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7663th epoch : 2.358903156435838  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7664th epoch : 2.3557548699525754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7665th epoch : 2.3526232382407763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7666th epoch : 2.349508357690664  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7667th epoch : 2.3464103191976853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7668th epoch : 2.3433292082196173  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7669th epoch : 2.340265104836948  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7670th epoch : 2.3372180838163668  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7671th epoch : 2.3341882146771944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7672th epoch : 2.3311755617605896  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7673th epoch : 2.328180184301351  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7674th epoch : 2.325202136502164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7675th epoch : 2.3222414676101106  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7676th epoch : 2.319298221995294  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7677th epoch : 2.3163724392314005  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7678th epoch : 2.3134641541780523  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7679th epoch : 2.310573397064789  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7680th epoch : 2.307700193576519  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7681th epoch : 2.3048445649403013  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7682th epoch : 2.3020065280132993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7683th epoch : 2.2991860953717675  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7684th epoch : 2.2963832754009337  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7685th epoch : 2.2935980723856333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7686th epoch : 2.2908304866015685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7687th epoch : 2.288080514407064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7688th epoch : 2.285348148335192  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7689th epoch : 2.2826333771861513  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7690th epoch : 2.279936186119778  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7691th epoch : 2.277256556748087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7692th epoch : 2.2745944672277294  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7693th epoch : 2.2719498923522656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7694th epoch : 2.2693228036441613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7695th epoch : 2.2667131694464064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7696th epoch : 2.2641209550136727  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7697th epoch : 2.2615461226029274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7698th epoch : 2.258988631563418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7699th epoch : 2.256448438425958  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7700th epoch : 2.2539254969914375  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7701th epoch : 2.2514197584184994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7702th epoch : 2.2489311713103097  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7703th epoch : 2.24645968180037  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7704th epoch : 2.2440052336373157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7705th epoch : 2.2415677682686477  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7706th epoch : 2.239147224923352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7707th epoch : 2.2367435406933676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7708th epoch : 2.2343566506138566  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7709th epoch : 2.2319864877422453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7710th epoch : 2.2296329832360025  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7711th epoch : 2.2272960664291257  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7712th epoch : 2.2249756649073107  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7713th epoch : 2.2226717045817783  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7714th epoch : 2.2203841097617407  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7715th epoch : 2.2181128032254893  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7716th epoch : 2.2158577062900906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7717th epoch : 2.2136187388796773  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7718th epoch : 2.2113958195923247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7719th epoch : 2.2091888657655057  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7720th epoch : 2.206997793540122  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7721th epoch : 2.2048225179231036  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7722th epoch : 2.202662952848581  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7723th epoch : 2.2005190112376307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7724th epoch : 2.198390605056593  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7725th epoch : 2.1962776453739714  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7726th epoch : 2.194180042415919  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7727th epoch : 2.1920977056203195  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7728th epoch : 2.19003054368947  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7729th epoch : 2.1879784646413816  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7730th epoch : 2.1859413758597026  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7731th epoch : 2.1839191841422863  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7732th epoch : 2.1819117957484093  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7733th epoch : 2.1799191164446583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7734th epoch : 2.177941051549504  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7735th epoch : 2.1759775059765762  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7736th epoch : 2.174028384276658  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7737th epoch : 2.172093590678419  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7738th epoch : 2.1701730291279016  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7739th epoch : 2.1682666033267903  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7740th epoch : 2.16637421676947  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7741th epoch : 2.1644957727789045  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7742th epoch : 2.162631174541352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7743th epoch : 2.1607803251399393  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7744th epoch : 2.1589431275871145  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7745th epoch : 2.157119484856  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7746th epoch : 2.155309299910673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7747th epoch : 2.153512475735386  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7748th epoch : 2.151728915362754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7749th epoch : 2.149958521900937  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7750th epoch : 2.1482011985598257  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7751th epoch : 2.1464568486762627  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7752th epoch : 2.1447253757383216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7753th epoch : 2.1430066834086574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7754th epoch : 2.14130067554696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7755th epoch : 2.1396072562315256  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7756th epoch : 2.13792632977997  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7757th epoch : 2.1362578007691058  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7758th epoch : 2.134601574054002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7759th epoch : 2.1329575547862505  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7760th epoch : 2.1313256484314573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7761th epoch : 2.1297057607859804  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7762th epoch : 2.128097797992933  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7763th epoch : 2.126501666557475  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7764th epoch : 2.124917273361408  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7765th epoch : 2.1233445256770986  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7766th epoch : 2.121783331180741  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7767th epoch : 2.120233597964989  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7768th epoch : 2.1186952345509646  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7769th epoch : 2.117168149899668  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7770th epoch : 2.115652253422805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7771th epoch : 2.1141474549930463  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7772th epoch : 2.112653664953745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7773th epoch : 2.111170794128115  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7774th epoch : 2.1096987538278995  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7775th epoch : 2.1082374558615387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7776th epoch : 2.1067868125418534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7777th epoch : 2.1053467366932637  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7778th epoch : 2.10391714165855  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7779th epoch : 2.102497941305182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7780th epoch : 2.101089050031217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7781th epoch : 2.0996903827707962  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7782th epoch : 2.098301854999237  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7783th epoch : 2.096923382737749  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7784th epoch : 2.095554882557777  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7785th epoch : 2.094196271584987  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7786th epoch : 2.092847467502911  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7787th epoch : 2.091508388556255  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7788th epoch : 2.0901789535538873  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7789th epoch : 2.0888590818715227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7790th epoch : 2.0875486934540994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7791th epoch : 2.0862477088178775  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7792th epoch : 2.0849560490522543  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7793th epoch : 2.0836736358213193  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7794th epoch : 2.082400391365145  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7795th epoch : 2.0811362385008403  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7796th epoch : 2.079881100623357  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7797th epoch : 2.078634901706077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7798th epoch : 2.077397566301174  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7799th epoch : 2.076169019539767  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7800th epoch : 2.074949187131871  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7801th epoch : 2.073737995366157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7802th epoch : 2.0725353711095185  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7803th epoch : 2.0713412418064667  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7804th epoch : 2.0701555354783525  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7805th epoch : 2.068978180722421  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7806th epoch : 2.0678091067107154  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7807th epoch : 2.0666482431888236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7808th epoch : 2.06549552047449  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7809th epoch : 2.0643508694560806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7810th epoch : 2.0632142215909237  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7811th epoch : 2.0620855089035235  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7812th epoch : 2.0609646639836536  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7813th epoch : 2.059851619984337  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7814th epoch : 2.0587463106197186  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7815th epoch : 2.0576486701628327  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7816th epoch : 2.0565586334432755  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7817th epoch : 2.055476135844781  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7818th epoch : 2.05440111330271  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7819th epoch : 2.053333502301453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7820th epoch : 2.052273239871761  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7821th epoch : 2.0512202635879877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7822th epoch : 2.050174511565274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7823th epoch : 2.0491359224566565  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7824th epoch : 2.048104435450117  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7825th epoch : 2.0470799902655683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7826th epoch : 2.0460625271517894  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7827th epoch : 2.045051986883303  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7828th epoch : 2.044048310757206  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7829th epoch : 2.0430514405899514  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7830th epoch : 2.0420613187140932  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7831th epoch : 2.0410778879749825  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7832th epoch : 2.0401010917274336  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7833th epoch : 2.0391308738323506  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7834th epoch : 2.0381671786533273  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7835th epoch : 2.037209951053212  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7836th epoch : 2.0362591363906493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7837th epoch : 2.0353146805165974  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7838th epoch : 2.034376529770821  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7839th epoch : 2.0334446309783663  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7840th epoch : 2.0325189314460177  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7841th epoch : 2.031599378958737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7842th epoch : 2.0306859217760933  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7843th epoch : 2.0297785086286733  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7844th epoch : 2.028877088714489  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7845th epoch : 2.027981611695374  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7846th epoch : 2.02709202769337  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7847th epoch : 2.0262082872871137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7848th epoch : 2.0253303415082162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7849th epoch : 2.024458141837641  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7850th epoch : 2.02359164020208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7851th epoch : 2.022730788970334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7852th epoch : 2.021875540949692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7853th epoch : 2.02102584938231  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7854th epoch : 2.020181667941604  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7855th epoch : 2.019342950728636  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7856th epoch : 2.0185096522685178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7857th epoch : 2.017681727506814  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7858th epoch : 2.0168591318059583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7859th epoch : 2.0160418209416755  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7860th epoch : 2.015229751099417  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7861th epoch : 2.014422878870807  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7862th epoch : 2.013621161250096  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7863th epoch : 2.0128245556306354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7864th epoch : 2.012033019801358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7865th epoch : 2.011246511943275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7866th epoch : 2.010464990625991  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7867th epoch : 2.0096884148042284  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7868th epoch : 2.0089167438143734  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7869th epoch : 2.0081499373710354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7870th epoch : 2.0073879555636247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7871th epoch : 2.0066307588529475  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7872th epoch : 2.0058783080678184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7873th epoch : 2.0051305644016937  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7874th epoch : 2.0043874894093197  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7875th epoch : 2.003649045003406  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7876th epoch : 2.002915193451312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7877th epoch : 2.0021858973717594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7878th epoch : 2.001461119731561  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7879th epoch : 2.0007408238423734  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7880th epoch : 2.0000249733574673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7881th epoch : 1.9993135322685223  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7882th epoch : 1.9986064649024418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7883th epoch : 1.9979037359181897  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7884th epoch : 1.9972053103036491  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7885th epoch : 1.9965111533725028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7886th epoch : 1.9958212307611383  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7887th epoch : 1.995135508425571  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7888th epoch : 1.9944539526383955  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7889th epoch : 1.993776529985755  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7890th epoch : 1.9931032073643362  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7891th epoch : 1.9924339519783865  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7892th epoch : 1.991768731336754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7893th epoch : 1.9911075132499516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7894th epoch : 1.990450265827243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7895th epoch : 1.9897969574737533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7896th epoch : 1.989147556887602  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7897th epoch : 1.98850203305706  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7898th epoch : 1.9878603552577296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7899th epoch : 1.9872224930497477  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7900th epoch : 1.9865884162750134  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7901th epoch : 1.9859580950544375  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7902th epoch : 1.9853314997852172  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7903th epoch : 1.984708601138132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7904th epoch : 1.9840893700548654  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7905th epoch : 1.983473777745347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7906th epoch : 1.9828617956851213  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7907th epoch : 1.982253395612736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7908th epoch : 1.9816485495271567  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7909th epoch : 1.9810472296852026  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7910th epoch : 1.9804494085990059  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7911th epoch : 1.9798550590334936  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7912th epoch : 1.9792641540038935  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7913th epoch : 1.978676666773262  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7914th epoch : 1.9780925708500339  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7915th epoch : 1.9775118399855955  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7916th epoch : 1.9769344481718818  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7917th epoch : 1.9763603696389918  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7918th epoch : 1.9757895788528315  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7919th epoch : 1.9752220505127738  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7920th epoch : 1.9746577595493446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7921th epoch : 1.9740966811219285  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7922th epoch : 1.973538790616497  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7923th epoch : 1.9729840636433573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7924th epoch : 1.9724324760349259  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7925th epoch : 1.9718840038435184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7926th epoch : 1.971338623339166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7927th epoch : 1.9707963110074493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7928th epoch : 1.9702570435473548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7929th epoch : 1.9697207978691516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7930th epoch : 1.9691875510922896  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7931th epoch : 1.9686572805433178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7932th epoch : 1.9681299637538225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7933th epoch : 1.9676055784583875  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 7934th epoch : 1.9670841025925716  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7935th epoch : 1.9665655142909095  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7936th epoch : 1.9660497918849305  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7937th epoch : 1.965536913901196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7938th epoch : 1.96502685905936  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7939th epoch : 1.9645196062702446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7940th epoch : 1.9640151346339392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7941th epoch : 1.9635134234379141  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7942th epoch : 1.9630144521551587  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7943th epoch : 1.9625182004423318  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7944th epoch : 1.962024648137937  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7945th epoch : 1.9615337752605122  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7946th epoch : 1.9610455620068392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7947th epoch : 1.9605599887501708  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7948th epoch : 1.9600770360384774  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7949th epoch : 1.9595966845927089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7950th epoch : 1.9591189153050768  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7951th epoch : 1.958643709237352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7952th epoch : 1.9581710476191823  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7953th epoch : 1.9577009118464237  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7954th epoch : 1.9572332834794919  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7955th epoch : 1.9567681442417295  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7956th epoch : 1.9563054760177903  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7957th epoch : 1.9558452608520391  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7958th epoch : 1.9553874809469698  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7959th epoch : 1.9549321186616389  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7960th epoch : 1.9544791565101145  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7961th epoch : 1.9540285771599424  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7962th epoch : 1.953580363430628  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7963th epoch : 1.9531344982921333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7964th epoch : 1.95269096486339  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7965th epoch : 1.9522497464108275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7966th epoch : 1.9518108263469165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7967th epoch : 1.9513741882287285  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7968th epoch : 1.9509398157565088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7969th epoch : 1.9505076927722647  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7970th epoch : 1.95007780325837  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7971th epoch : 1.9496501313361823  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7972th epoch : 1.9492246612646738  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7973th epoch : 1.9488013774390804  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7974th epoch : 1.9483802643895605  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7975th epoch : 1.9479613067798696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7976th epoch : 1.9475444894060496  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7977th epoch : 1.947129797195131  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7978th epoch : 1.9467172152038474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7979th epoch : 1.9463067286173656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7980th epoch : 1.9458983227480284  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7981th epoch : 1.9454919830341089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7982th epoch : 1.9450876950385807  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7983th epoch : 1.944685444447898  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7984th epoch : 1.9442852170707914  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7985th epoch : 1.9438869988370726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7986th epoch : 1.9434907757964568  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7987th epoch : 1.9430965341173918  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7988th epoch : 1.9427042600859035  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7989th epoch : 1.9423139401044518  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7990th epoch : 1.9419255606907988  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7991th epoch : 1.9415391084768883  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7992th epoch : 1.9411545702077382  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7993th epoch : 1.9407719327403437  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7994th epoch : 1.9403911830425924  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7995th epoch : 1.9400123081921896  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7996th epoch : 1.9396352953755973  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7997th epoch : 1.939260131886982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7998th epoch : 1.9388868051271742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 7999th epoch : 1.9385153026026392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8000th epoch : 1.9381456119244596  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8001th epoch : 1.937777720807325  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8002th epoch : 1.9374116170685372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8003th epoch : 1.9370472886270216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8004th epoch : 1.936684723502351  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8005th epoch : 1.9363239098137799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8006th epoch : 1.9359648357792874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8007th epoch : 1.9356074897146311  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8008th epoch : 1.935251860032412  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8009th epoch : 1.9348979352411462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8010th epoch : 1.9345457039443492  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8011th epoch : 1.9341951548396288  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8012th epoch : 1.9338462767177866  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8013th epoch : 1.9334990584619303  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8014th epoch : 1.9331534890465942  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8015th epoch : 1.9328095575368698  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8016th epoch : 1.9324672530875449  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8017th epoch : 1.932126564942251  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8018th epoch : 1.931787482432622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8019th epoch : 1.9314499949774584  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8020th epoch : 1.9311140920819028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8021th epoch : 1.930779763336623  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8022th epoch : 1.930446998417004  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8023th epoch : 1.9301157870823469  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8024th epoch : 1.9297861191750787  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8025th epoch : 1.9294579846199682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8026th epoch : 1.9291313734233517  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8027th epoch : 1.9288062756723643  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8028th epoch : 1.9284826815341827  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8029th epoch : 1.9281605812552722  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8030th epoch : 1.9278399651606446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8031th epoch : 1.9275208236531216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8032th epoch : 1.9272031472126072  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8033th epoch : 1.9268869263953665  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8034th epoch : 1.9265721518333134  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8035th epoch : 1.9262588142333044  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8036th epoch : 1.9259469043764401  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8037th epoch : 1.9256364131173744  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8038th epoch : 1.9253273313836303  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8039th epoch : 1.9250196501749226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8040th epoch : 1.9247133605624884  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8041th epoch : 1.9244084536884234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8042th epoch : 1.9241049207650263  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8043th epoch : 1.9238027530741493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8044th epoch : 1.9235019419665544  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8045th epoch : 1.9232024788612785  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8046th epoch : 1.9229043552450027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8047th epoch : 1.9226075626714298  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8048th epoch : 1.9223120927606674  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8049th epoch : 1.9220179371986166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8050th epoch : 1.9217250877363694  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8051th epoch : 1.9214335361896095  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8052th epoch : 1.9211432744380212  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8053th epoch : 1.920854294424703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8054th epoch : 1.9205665881555871  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8055th epoch : 1.9202801476988682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8056th epoch : 1.9199949651844324  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8057th epoch : 1.9197110328032967  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8058th epoch : 1.9194283428070518  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8059th epoch : 1.919146887507312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8060th epoch : 1.9188666592751693  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8061th epoch : 1.918587650540654  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8062th epoch : 1.9183098537922003  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8063th epoch : 1.918033261576118  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8064th epoch : 1.9177578664960688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8065th epoch : 1.917483661212548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8066th epoch : 1.9172106384423726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8067th epoch : 1.9169387909581725  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8068th epoch : 1.9166681115878885  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8069th epoch : 1.916398593214275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8070th epoch : 1.9161302287744078  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8071th epoch : 1.9158630112591961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8072th epoch : 1.9155969337129006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8073th epoch : 1.9153319892326552  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8074th epoch : 1.9150681709679949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8075th epoch : 1.914805472120387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8076th epoch : 1.9145438859427688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8077th epoch : 1.9142834057390874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8078th epoch : 1.914024024863847  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8079th epoch : 1.9137657367216583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8080th epoch : 1.9135085347667944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8081th epoch : 1.9132524125027495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8082th epoch : 1.9129973634818027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8083th epoch : 1.912743381304587  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8084th epoch : 1.9124904596196606  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8085th epoch : 1.912238592123085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8086th epoch : 1.911987772558004  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8087th epoch : 1.9117379947142312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8088th epoch : 1.9114892524278382  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8089th epoch : 1.911241539580747  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8090th epoch : 1.910994850100329  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8091th epoch : 1.9107491779590058  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8092th epoch : 1.9105045171738537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8093th epoch : 1.9102608618062147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8094th epoch : 1.9100182059613076  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8095th epoch : 1.9097765437878467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8096th epoch : 1.9095358694776616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8097th epoch : 1.9092961772653219  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8098th epoch : 1.909057461427765  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8099th epoch : 1.9088197162839287  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8100th epoch : 1.9085829361943862  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8101th epoch : 1.9083471155609848  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8102th epoch : 1.9081122488264897  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8103th epoch : 1.9078783304742282  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8104th epoch : 1.9076453550277412  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8105th epoch : 1.9074133170504355  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8106th epoch : 1.907182211145239  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8107th epoch : 1.9069520319542625  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8108th epoch : 1.9067227741584616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8109th epoch : 1.9064944324773032  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8110th epoch : 1.906267001668435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8111th epoch : 1.9060404765273593  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8112th epoch : 1.9058148518871072  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8113th epoch : 1.90559012261792  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8114th epoch : 1.9053662836269292  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8115th epoch : 1.905143329857844  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8116th epoch : 1.9049212562906384  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8117th epoch : 1.904700057941243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8118th epoch : 1.9044797298612393  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8119th epoch : 1.9042602671375575  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8120th epoch : 1.9040416648921763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8121th epoch : 1.9038239182818264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8122th epoch : 1.9036070224976964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8123th epoch : 1.9033909727651421  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8124th epoch : 1.9031757643433973  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8125th epoch : 1.9029613925252895  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8126th epoch : 1.9027478526369557  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8127th epoch : 1.9025351400375632  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8128th epoch : 1.9023232501190324  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8129th epoch : 1.9021121783057613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8130th epoch : 1.9019019200543539  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8131th epoch : 1.9016924708533502  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8132th epoch : 1.9014838262229603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8133th epoch : 1.9012759817147982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8134th epoch : 1.9010689329116217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8135th epoch : 1.9008626754270723  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8136th epoch : 1.9006572049054176  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8137th epoch : 1.900452517021298  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8138th epoch : 1.900248607479474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8139th epoch : 1.900045472014576  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8140th epoch : 1.8998431063908585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8141th epoch : 1.8996415064019532  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8142th epoch : 1.8994406678706277  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8143th epoch : 1.899240586648545  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8144th epoch : 1.8990412586160241  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8145th epoch : 1.898842679681806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8146th epoch : 1.8986448457828191  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8147th epoch : 1.898447752883947  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8148th epoch : 1.8982513969778003  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8149th epoch : 1.8980557740844897  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8150th epoch : 1.8978608802513999  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8151th epoch : 1.897666711552967  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8152th epoch : 1.8974732640904584  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8153th epoch : 1.8972805339917533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8154th epoch : 1.8970885174111265  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8155th epoch : 1.8968972105290327  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8156th epoch : 1.8967066095518954  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8157th epoch : 1.8965167107118948  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8158th epoch : 1.8963275102667594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8159th epoch : 1.8961390044995599  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8160th epoch : 1.8959511897185033  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8161th epoch : 1.8957640622567304  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8162th epoch : 1.8955776184721147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8163th epoch : 1.8953918547470625  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8164th epoch : 1.8952067674883168  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8165th epoch : 1.8950223531267603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8166th epoch : 1.8948386081172222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8167th epoch : 1.8946555289382865  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8168th epoch : 1.8944731120921008  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8169th epoch : 1.8942913541041888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8170th epoch : 1.894110251523263  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8171th epoch : 1.89392980092104  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8172th epoch : 1.893749998892056  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8173th epoch : 1.8935708420534874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8174th epoch : 1.8933923270449677  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8175th epoch : 1.8932144505284119  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8176th epoch : 1.8930372091878382  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8177th epoch : 1.892860599729193  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8178th epoch : 1.8926846188801778  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8179th epoch : 1.892509263390077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8180th epoch : 1.8923345300295875  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8181th epoch : 1.8921604155906497  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8182th epoch : 1.89198691688628  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8183th epoch : 1.8918140307504052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8184th epoch : 1.8916417540376989  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8185th epoch : 1.8914700836234168  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8186th epoch : 1.8912990164032377  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8187th epoch : 1.8911285492931014  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8188th epoch : 1.8909586792290511  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8189th epoch : 1.8907894031670769  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8190th epoch : 1.8906207180829597  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8191th epoch : 1.8904526209721162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8192th epoch : 1.8902851088494472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8193th epoch : 1.8901181787491859  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8194th epoch : 1.8899518277247467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8195th epoch : 1.889786052848578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8196th epoch : 1.8896208512120132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8197th epoch : 1.8894562199251257  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8198th epoch : 1.8892921561165834  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8199th epoch : 1.8891286569335055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8200th epoch : 1.88896571954132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8201th epoch : 1.8888033411236227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8202th epoch : 1.8886415188820371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8203th epoch : 1.888480250036077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8204th epoch : 1.8883195318230073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8205th epoch : 1.88815936149771  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8206th epoch : 1.8879997363325478  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8207th epoch : 1.8878406536172312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8208th epoch : 1.8876821106586852  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8209th epoch : 1.8875241047809188  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8210th epoch : 1.8873666333248946  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8211th epoch : 1.887209693648399  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8212th epoch : 1.8870532831259152  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8213th epoch : 1.8868973991484959  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8214th epoch : 1.886742039123638  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8215th epoch : 1.8865872004751574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8216th epoch : 1.886432880643066  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8217th epoch : 1.8862790770834488  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8218th epoch : 1.8861257872683435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8219th epoch : 1.885973008685619  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8220th epoch : 1.885820738838857  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8221th epoch : 1.8856689752472333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8222th epoch : 1.8855177154454006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8223th epoch : 1.885366956983373  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8224th epoch : 1.88521669742641  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8225th epoch : 1.8850669343549025  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8226th epoch : 1.8849176653642603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8227th epoch : 1.884768888064799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8228th epoch : 1.8846206000816292  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8229th epoch : 1.8844727990545462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8230th epoch : 1.8843254826379205  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8231th epoch : 1.8841786485005896  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8232th epoch : 1.8840322943257506  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8233th epoch : 1.8838864178108534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8234th epoch : 1.8837410166674953  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8235th epoch : 1.8835960886213161  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8236th epoch : 1.883451631411894  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8237th epoch : 1.883307642792644  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8238th epoch : 1.8831641205307144  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8239th epoch : 1.8830210624068853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8240th epoch : 1.8828784662154703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8241th epoch : 1.8827363297642148  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8242th epoch : 1.8825946508741993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8243th epoch : 1.88245342737974  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8244th epoch : 1.8823126571282927  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8245th epoch : 1.882172337980356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8246th epoch : 1.8820324678093778  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8247th epoch : 1.8818930445016582  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8248th epoch : 1.881754065956257  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8249th epoch : 1.8816155300849016  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8250th epoch : 1.8814774348118934  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8251th epoch : 1.8813397780740175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8252th epoch : 1.8812025578204512  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8253th epoch : 1.8810657720126749  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8254th epoch : 1.8809294186243828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8255th epoch : 1.8807934956413943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8256th epoch : 1.8806580010615668  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8257th epoch : 1.8805229328947084  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8258th epoch : 1.8803882891624923  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8259th epoch : 1.880254067898371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8260th epoch : 1.8801202671474913  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8261th epoch : 1.879986884966611  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8262th epoch : 1.8798539194240151  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8263th epoch : 1.8797213685994334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8264th epoch : 1.8795892305839585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8265th epoch : 1.8794575034799648  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8266th epoch : 1.879326185401027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8267th epoch : 1.8791952744718416  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8268th epoch : 1.8790647688281465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8269th epoch : 1.878934666616643  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8270th epoch : 1.8788049659949178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8271th epoch : 1.8786756651313652  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8272th epoch : 1.8785467622051113  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8273th epoch : 1.8784182554059372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8274th epoch : 1.8782901429342038  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8275th epoch : 1.8781624230007774  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8276th epoch : 1.8780350938269552  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8277th epoch : 1.8779081536443911  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8278th epoch : 1.877781600695024  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8279th epoch : 1.8776554332310051  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8280th epoch : 1.8775296495146248  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8281th epoch : 1.8774042478182433  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8282th epoch : 1.8772792264242188  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8283th epoch : 1.8771545836248384  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8284th epoch : 1.8770303177222474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8285th epoch : 1.8769064270283813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8286th epoch : 1.8767829098648976  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8287th epoch : 1.8766597645631071  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8288th epoch : 1.8765369894639077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8289th epoch : 1.8764145829177166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8290th epoch : 1.876292543284405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8291th epoch : 1.8761708689332326  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8292th epoch : 1.8760495582427816  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8293th epoch : 1.8759286096008922  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8294th epoch : 1.8758080214046002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8295th epoch : 1.8756877920600707  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8296th epoch : 1.875567919982538  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8297th epoch : 1.8754484035962404  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8298th epoch : 1.8753292413343603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8299th epoch : 1.8752104316389615  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8300th epoch : 1.875091972960928  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8301th epoch : 1.8749738637599047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8302th epoch : 1.874856102504236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8303th epoch : 1.8747386876709071  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8304th epoch : 1.8746216177454837  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8305th epoch : 1.8745048912220552  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8306th epoch : 1.8743885066031751  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8307th epoch : 1.8742724623998033  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8308th epoch : 1.8741567571312499  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8309th epoch : 1.8740413893251169  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8310th epoch : 1.8739263575172431  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8311th epoch : 1.8738116602516484  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8312th epoch : 1.873697296080476  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8313th epoch : 1.873583263563941  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8314th epoch : 1.873469561270272  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8315th epoch : 1.87335618777566  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8316th epoch : 1.873243141664203  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8317th epoch : 1.8731304215278528  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8318th epoch : 1.8730180259663631  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8319th epoch : 1.8729059535872354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8320th epoch : 1.8727942030056686  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8321th epoch : 1.872682772844506  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8322th epoch : 1.8725716617341848  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8323th epoch : 1.8724608683126849  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8324th epoch : 1.8723503912254789  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8325th epoch : 1.8722402291254807  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8326th epoch : 1.872130380672998  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8327th epoch : 1.872020844535681  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8328th epoch : 1.8719116193884742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8329th epoch : 1.871802703913568  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8330th epoch : 1.8716940968003506  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8331th epoch : 1.87158579674536  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8332th epoch : 1.8714778024522363  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8333th epoch : 1.8713701126316753  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8334th epoch : 1.8712627260013812  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8335th epoch : 1.8711556412860204  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8336th epoch : 1.8710488572171764  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8337th epoch : 1.8709423725333023  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8338th epoch : 1.8708361859796776  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8339th epoch : 1.8707302963083616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8340th epoch : 1.8706247022781501  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8341th epoch : 1.8705194026545304  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8342th epoch : 1.8704143962096371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8343th epoch : 1.8703096817222098  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8344th epoch : 1.8702052579775483  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8345th epoch : 1.8701011237674716  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8346th epoch : 1.8699972778902727  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8347th epoch : 1.8698937191506793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8348th epoch : 1.8697904463598094  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8349th epoch : 1.869687458335131  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8350th epoch : 1.8695847539004207  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8351th epoch : 1.8694823318857225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8352th epoch : 1.869380191127307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8353th epoch : 1.8692783304676308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8354th epoch : 1.8691767487552977  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8355th epoch : 1.8690754448450175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8356th epoch : 1.8689744175975669  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8357th epoch : 1.868873665879751  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8358th epoch : 1.8687731885643635  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8359th epoch : 1.868672984530149  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8360th epoch : 1.8685730526617643  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8361th epoch : 1.86847339184974  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8362th epoch : 1.8683740009904435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8363th epoch : 1.868274878986041  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8364th epoch : 1.8681760247444612  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8365th epoch : 1.8680774371793574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8366th epoch : 1.8679791152100707  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8367th epoch : 1.8678810577615956  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8368th epoch : 1.8677832637645417  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8369th epoch : 1.8676857321550993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8370th epoch : 1.8675884618750032  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8371th epoch : 1.8674914518714978  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8372th epoch : 1.8673947010973018  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8373th epoch : 1.8672982085105743  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8374th epoch : 1.8672019730748786  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8375th epoch : 1.86710599375915  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8376th epoch : 1.8670102695376605  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8377th epoch : 1.8669147993899855  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8378th epoch : 1.86681958230097  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8379th epoch : 1.866724617260696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8380th epoch : 1.866629903264449  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8381th epoch : 1.866535439312686  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8382th epoch : 1.8664412244110016  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8383th epoch : 1.8663472575700968  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8384th epoch : 1.866253537805747  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8385th epoch : 1.8661600641387701  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8386th epoch : 1.8660668355949943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8387th epoch : 1.8659738512052275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8388th epoch : 1.8658811100052264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8389th epoch : 1.8657886110356645  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8390th epoch : 1.8656963533421027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8391th epoch : 1.8656043359749583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8392th epoch : 1.8655125579894745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8393th epoch : 1.8654210184456912  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8394th epoch : 1.8653297164084144  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8395th epoch : 1.8652386509471874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8396th epoch : 1.865147821136261  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8397th epoch : 1.8650572260545644  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8398th epoch : 1.8649668647856765  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8399th epoch : 1.8648767364177972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8400th epoch : 1.8647868400437182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8401th epoch : 1.8646971747607959  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8402th epoch : 1.8646077396709226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8403th epoch : 1.8645185338804986  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8404th epoch : 1.8644295565004048  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8405th epoch : 1.8643408066459748  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8406th epoch : 1.864252283436968  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8407th epoch : 1.8641639859975423  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8408th epoch : 1.8640759134562273  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8409th epoch : 1.8639880649458975  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8410th epoch : 1.8639004396037462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8411th epoch : 1.8638130365712582  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8412th epoch : 1.8637258549941849  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8413th epoch : 1.863638894022517  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8414th epoch : 1.8635521528104604  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8415th epoch : 1.8634656305164086  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8416th epoch : 1.863379326302919  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8417th epoch : 1.863293239336687  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8418th epoch : 1.863207368788521  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8419th epoch : 1.863121713833317  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8420th epoch : 1.8630362736500352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8421th epoch : 1.8629510474216742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8422th epoch : 1.8628660343352472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8423th epoch : 1.8627812335817577  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8424th epoch : 1.862696644356176  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8425th epoch : 1.862612265857415  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8426th epoch : 1.8625280972883054  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8427th epoch : 1.8624441378555745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8428th epoch : 1.8623603867698209  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8429th epoch : 1.8622768432454926  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8430th epoch : 1.862193506500863  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8431th epoch : 1.8621103757580086  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8432th epoch : 1.8620274502427867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8433th epoch : 1.8619447291848115  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8434th epoch : 1.8618622118174333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8435th epoch : 1.8617798973777155  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8436th epoch : 1.8616977851064123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8437th epoch : 1.8616158742479472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8438th epoch : 1.8615341640503913  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8439th epoch : 1.8614526537654417  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8440th epoch : 1.8613713426483995  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8441th epoch : 1.861290229958149  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8442th epoch : 1.861209314957137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8443th epoch : 1.8611285969113498  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8444th epoch : 1.8610480750902951  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8445th epoch : 1.8609677487669796  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8446th epoch : 1.860887617217888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8447th epoch : 1.8608076797229642  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8448th epoch : 1.8607279355655895  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8449th epoch : 1.8606483840325632  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8450th epoch : 1.8605690244140822  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8451th epoch : 1.860489856003722  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8452th epoch : 1.860410878098415  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8453th epoch : 1.8603320899984332  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8454th epoch : 1.8602534910073674  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8455th epoch : 1.8601750804321078  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8456th epoch : 1.8600968575828252  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8457th epoch : 1.8600188217729523  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8458th epoch : 1.8599409723191638  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8459th epoch : 1.8598633085413576  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8460th epoch : 1.8597858297626375  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8461th epoch : 1.859708535309293  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8462th epoch : 1.859631424510782  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8463th epoch : 1.8595544966997108  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8464th epoch : 1.859477751211819  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8465th epoch : 1.8594011873859577  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8466th epoch : 1.8593248045640747  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8467th epoch : 1.8592486020911945  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8468th epoch : 1.859172579315402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8469th epoch : 1.8590967355878236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8470th epoch : 1.8590210702626115  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8471th epoch : 1.8589455826969248  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8472th epoch : 1.8588702722509123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8473th epoch : 1.8587951382876964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8474th epoch : 1.858720180173356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8475th epoch : 1.858645397276908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8476th epoch : 1.8585707889702927  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8477th epoch : 1.8584963546283555  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8478th epoch : 1.8584220936288316  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8479th epoch : 1.858348005352328  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8480th epoch : 1.8582740891823089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8481th epoch : 1.8582003445050783  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8482th epoch : 1.8581267707097642  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8483th epoch : 1.8580533671883028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8484th epoch : 1.857980133335422  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8485th epoch : 1.8579070685486268  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8486th epoch : 1.857834172228182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8487th epoch : 1.8577614437770977  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8488th epoch : 1.8576888826011138  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8489th epoch : 1.857616488108684  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8490th epoch : 1.857544259710961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8491th epoch : 1.8574721968217816  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8492th epoch : 1.8574002988576503  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8493th epoch : 1.857328565237726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8494th epoch : 1.857256995383806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8495th epoch : 1.8571855887203115  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8496th epoch : 1.8571143446742733  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8497th epoch : 1.8570432626753166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8498th epoch : 1.8569723421556465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8499th epoch : 1.8569015825500343  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8500th epoch : 1.856830983295803  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8501th epoch : 1.8567605438328119  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8502th epoch : 1.8566902636034441  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8503th epoch : 1.8566201420525916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8504th epoch : 1.856550178627642  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8505th epoch : 1.8564803727784631  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8506th epoch : 1.8564107239573917  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8507th epoch : 1.856341231619217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8508th epoch : 1.8562718952211694  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 8509th epoch : 1.856202714222906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8510th epoch : 1.8561336880864971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8511th epoch : 1.8560648162764133  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8512th epoch : 1.8559960982595116  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8513th epoch : 1.855927533505023  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8514th epoch : 1.8558591214845392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8515th epoch : 1.8557908616719996  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8516th epoch : 1.855722753543678  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8517th epoch : 1.8556547965781707  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8518th epoch : 1.8555869902563826  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8519th epoch : 1.8555193340615157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8520th epoch : 1.855451827479056  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8521th epoch : 1.8553844699967603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8522th epoch : 1.8553172611046456  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8523th epoch : 1.855250200294975  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8524th epoch : 1.8551832870622462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8525th epoch : 1.8551165209031795  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8526th epoch : 1.8550499013167057  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8527th epoch : 1.8549834278039532  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8528th epoch : 1.8549170998682376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8529th epoch : 1.8548509170150482  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8530th epoch : 1.8547848787520376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8531th epoch : 1.8547189845890089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8532th epoch : 1.8546532340379047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8533th epoch : 1.854587626612796  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8534th epoch : 1.8545221618298693  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8535th epoch : 1.8544568392074163  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8536th epoch : 1.8543916582658224  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8537th epoch : 1.8543266185275549  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8538th epoch : 1.8542617195171525  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8539th epoch : 1.8541969607612139  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8540th epoch : 1.8541323417883862  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8541th epoch : 1.854067862129355  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8542th epoch : 1.8540035213168322  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8543th epoch : 1.8539393188855469  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8544th epoch : 1.853875254372232  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8545th epoch : 1.8538113273156165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8546th epoch : 1.8537475372564125  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8547th epoch : 1.8536838837373057  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8548th epoch : 1.853620366302945  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8549th epoch : 1.8535569844999307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8550th epoch : 1.8534937378768062  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8551th epoch : 1.8534306259840465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8552th epoch : 1.8533676483740473  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8553th epoch : 1.8533048046011165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8554th epoch : 1.8532420942214622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8555th epoch : 1.8531795167931846  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8556th epoch : 1.853117071876264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8557th epoch : 1.8530547590325521  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8558th epoch : 1.8529925778257623  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8559th epoch : 1.852930527821459  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8560th epoch : 1.8528686085870483  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8561th epoch : 1.852806819691768  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8562th epoch : 1.852745160706679  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8563th epoch : 1.852683631204654  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8564th epoch : 1.8526222307603697  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8565th epoch : 1.852560958950296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8566th epoch : 1.8524998153526877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8567th epoch : 1.8524387995475742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8568th epoch : 1.8523779111167504  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8569th epoch : 1.8523171496437685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8570th epoch : 1.8522565147139274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8571th epoch : 1.8521960059142641  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8572th epoch : 1.8521356228335453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8573th epoch : 1.8520753650622575  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8574th epoch : 1.8520152321925982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8575th epoch : 1.8519552238184678  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8576th epoch : 1.8518953395354594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8577th epoch : 1.8518355789408514  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8578th epoch : 1.8517759416335973  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8579th epoch : 1.851716427214319  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8580th epoch : 1.8516570352852957  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8581th epoch : 1.8515977654504578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8582th epoch : 1.8515386173153765  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8583th epoch : 1.851479590487256  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8584th epoch : 1.851420684574926  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8585th epoch : 1.8513618991888308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8586th epoch : 1.8513032339410243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8587th epoch : 1.851244688445159  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8588th epoch : 1.8511862623164792  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8589th epoch : 1.8511279551718125  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8590th epoch : 1.8510697666295612  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8591th epoch : 1.8510116963096954  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8592th epoch : 1.8509537438337436  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8593th epoch : 1.8508959088247852  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8594th epoch : 1.8508381909074436  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8595th epoch : 1.8507805897078768  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8596th epoch : 1.8507231048537702  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8597th epoch : 1.850665735974329  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8598th epoch : 1.8506084827002705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8599th epoch : 1.8505513446638155  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8600th epoch : 1.850494321498682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8601th epoch : 1.8504374128400767  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8602th epoch : 1.8503806183246876  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8603th epoch : 1.8503239375906766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8604th epoch : 1.8502673702776722  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8605th epoch : 1.8502109160267617  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8606th epoch : 1.850154574480484  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8607th epoch : 1.8500983452828221  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8608th epoch : 1.8500422280791966  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8609th epoch : 1.8499862225164567  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8610th epoch : 1.8499303282428754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8611th epoch : 1.84987454490814  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8612th epoch : 1.8498188721633464  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8613th epoch : 1.849763309660992  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8614th epoch : 1.8497078570549679  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8615th epoch : 1.8496525140005522  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8616th epoch : 1.8495972801544034  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8617th epoch : 1.8495421551745534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8618th epoch : 1.8494871387204  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8619th epoch : 1.849432230452701  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8620th epoch : 1.8493774300335666  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8621th epoch : 1.8493227371264533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8622th epoch : 1.8492681513961564  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8623th epoch : 1.8492136725088044  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8624th epoch : 1.8491593001318511  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8625th epoch : 1.8491050339340704  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8626th epoch : 1.8490508735855484  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8627th epoch : 1.8489968187576775  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8628th epoch : 1.8489428691231504  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8629th epoch : 1.8488890243559528  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8630th epoch : 1.8488352841313573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8631th epoch : 1.8487816481259172  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8632th epoch : 1.84872811601746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8633th epoch : 1.8486746874850812  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8634th epoch : 1.848621362209138  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8635th epoch : 1.8485681398712428  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8636th epoch : 1.8485150201542577  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8637th epoch : 1.8484620027422878  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8638th epoch : 1.8484090873206747  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8639th epoch : 1.8483562735759915  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8640th epoch : 1.8483035611960361  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8641th epoch : 1.8482509498698252  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8642th epoch : 1.848198439287588  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8643th epoch : 1.8481460291407614  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8644th epoch : 1.8480937191219828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8645th epoch : 1.8480415089250848  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8646th epoch : 1.8479893982450892  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8647th epoch : 1.8479373867782019  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8648th epoch : 1.8478854742218058  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8649th epoch : 1.8478336602744563  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8650th epoch : 1.8477819446358748  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8651th epoch : 1.8477303270069434  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8652th epoch : 1.847678807089699  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8653th epoch : 1.8476273845873283  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8654th epoch : 1.8475760592041612  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8655th epoch : 1.8475248306456664  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8656th epoch : 1.8474736986184446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8657th epoch : 1.8474226628302244  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8658th epoch : 1.8473717229898556  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8659th epoch : 1.8473208788073046  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8660th epoch : 1.847270129993649  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8661th epoch : 1.8472194762610712  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8662th epoch : 1.847168917322855  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8663th epoch : 1.847118452893378  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8664th epoch : 1.8470680826881078  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8665th epoch : 1.8470178064235971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8666th epoch : 1.846967623817477  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8667th epoch : 1.8469175345884532  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8668th epoch : 1.8468675384562994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8669th epoch : 1.8468176351418542  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8670th epoch : 1.846767824367014  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8671th epoch : 1.8467181058547293  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8672th epoch : 1.8466684793289987  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8673th epoch : 1.8466189445148644  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8674th epoch : 1.8465695011384076  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8675th epoch : 1.8465201489267427  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8676th epoch : 1.8464708876080127  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8677th epoch : 1.8464217169113843  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8678th epoch : 1.8463726365670439  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8679th epoch : 1.8463236463061905  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8680th epoch : 1.8462747458610338  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8681th epoch : 1.8462259349647865  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8682th epoch : 1.8461772133516623  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8683th epoch : 1.846128580756869  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8684th epoch : 1.8460800369166046  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8685th epoch : 1.846031581568053  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8686th epoch : 1.8459832144493786  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8687th epoch : 1.8459349352997223  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8688th epoch : 1.8458867438591964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8689th epoch : 1.8458386398688802  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8690th epoch : 1.8457906230708154  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8691th epoch : 1.845742693208002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8692th epoch : 1.8456948500243933  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8693th epoch : 1.845647093264891  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8694th epoch : 1.8455994226753416  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8695th epoch : 1.845551838002532  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8696th epoch : 1.845504338994184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8697th epoch : 1.8454569253989515  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8698th epoch : 1.8454095969664144  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8699th epoch : 1.8453623534470756  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8700th epoch : 1.8453151945923558  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8701th epoch : 1.8452681201545902  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8702th epoch : 1.8452211298870234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8703th epoch : 1.8451742235438051  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8704th epoch : 1.8451274008799867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8705th epoch : 1.845080661651516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8706th epoch : 1.845034005615234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8707th epoch : 1.8449874325288702  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8708th epoch : 1.8449409421510388  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8709th epoch : 1.8448945342412337  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8710th epoch : 1.8448482085598263  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8711th epoch : 1.8448019648680591  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8712th epoch : 1.8447558029280438  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8713th epoch : 1.8447097225027551  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8714th epoch : 1.844663723356029  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8715th epoch : 1.844617805252557  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8716th epoch : 1.8445719679578834  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8717th epoch : 1.8445262112384  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8718th epoch : 1.844480534861344  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8719th epoch : 1.8444349385947922  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8720th epoch : 1.844389422207659  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8721th epoch : 1.84434398546969  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8722th epoch : 1.8442986281514615  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8723th epoch : 1.844253350024374  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8724th epoch : 1.8442081508606494  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8725th epoch : 1.8441630304333274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8726th epoch : 1.8441179885162613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8727th epoch : 1.8440730248841144  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8728th epoch : 1.844028139312357  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8729th epoch : 1.8439833315772614  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8730th epoch : 1.8439386014558992  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8731th epoch : 1.8438939487261372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8732th epoch : 1.8438493731666343  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8733th epoch : 1.8438048745568372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8734th epoch : 1.8437604526769773  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8735th epoch : 1.8437161073080666  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8736th epoch : 1.8436718382318953  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8737th epoch : 1.8436276452310263  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8738th epoch : 1.843583528088794  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8739th epoch : 1.843539486589299  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8740th epoch : 1.843495520517405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8741th epoch : 1.8434516296587367  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8742th epoch : 1.8434078137996737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8743th epoch : 1.8433640727273501  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8744th epoch : 1.8433204062296489  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8745th epoch : 1.843276814095199  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8746th epoch : 1.8432332961133728  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8747th epoch : 1.8431898520742822  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8748th epoch : 1.8431464817687746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8749th epoch : 1.843103184988431  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8750th epoch : 1.8430599615255614  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8751th epoch : 1.8430168111732022  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8752th epoch : 1.842973733725113  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8753th epoch : 1.8429307289757728  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8754th epoch : 1.8428877967203774  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8755th epoch : 1.8428449367548356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8756th epoch : 1.8428021488757664  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8757th epoch : 1.842759432880496  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8758th epoch : 1.8427167885670537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8759th epoch : 1.8426742157341698  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8760th epoch : 1.8426317141812718  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8761th epoch : 1.842589283708482  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8762th epoch : 1.8425469241166132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8763th epoch : 1.842504635207167  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8764th epoch : 1.8424624167823296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8765th epoch : 1.842420268644969  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8766th epoch : 1.8423781905986334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8767th epoch : 1.8423361824475453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8768th epoch : 1.8422942439966012  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8769th epoch : 1.8422523750513673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8770th epoch : 1.8422105754180764  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8771th epoch : 1.8421688449036258  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8772th epoch : 1.8421271833155735  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8773th epoch : 1.8420855904621358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8774th epoch : 1.8420440661521844  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8775th epoch : 1.8420026101952427  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8776th epoch : 1.841961222401484  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8777th epoch : 1.841919902581728  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8778th epoch : 1.8418786505474383  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8779th epoch : 1.8418374661107186  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8780th epoch : 1.841796349084312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8781th epoch : 1.8417552992815949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8782th epoch : 1.841714316516578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8783th epoch : 1.8416734006039002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8784th epoch : 1.8416325513588279  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8785th epoch : 1.8415917685972516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8786th epoch : 1.8415510521356828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8787th epoch : 1.841510401791252  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8788th epoch : 1.8414698173817052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8789th epoch : 1.841429298725402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8790th epoch : 1.8413888456413119  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8791th epoch : 1.841348457949013  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8792th epoch : 1.8413081354686875  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8793th epoch : 1.8412678780211216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8794th epoch : 1.8412276854277  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8795th epoch : 1.8411875575104055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8796th epoch : 1.8411474940918149  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8797th epoch : 1.8411074949950976  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8798th epoch : 1.841067560044012  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8799th epoch : 1.841027689062904  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8800th epoch : 1.8409878818767034  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8801th epoch : 1.8409481383109216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8802th epoch : 1.84090845819165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8803th epoch : 1.8408688413455558  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8804th epoch : 1.8408292875998813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8805th epoch : 1.84078979678244  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8806th epoch : 1.8407503687216147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8807th epoch : 1.8407110032463554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8808th epoch : 1.840671700186176  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8809th epoch : 1.8406324593711527  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8810th epoch : 1.8405932806319205  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8811th epoch : 1.840554163799672  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8812th epoch : 1.8405151087061544  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8813th epoch : 1.840476115183667  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8814th epoch : 1.8404371830650588  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8815th epoch : 1.8403983121837266  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8816th epoch : 1.840359502373612  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8817th epoch : 1.8403207534691994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8818th epoch : 1.8402820653055139  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8819th epoch : 1.8402434377181185  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8820th epoch : 1.840204870543112  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8821th epoch : 1.8401663636171266  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8822th epoch : 1.840127916777326  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8823th epoch : 1.840089529861402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8824th epoch : 1.840051202707574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8825th epoch : 1.8400129351545853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8826th epoch : 1.8399747270417015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8827th epoch : 1.8399365782087078  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8828th epoch : 1.8398984884959073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8829th epoch : 1.8398604577441182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8830th epoch : 1.8398224857946726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8831th epoch : 1.839784572489413  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8832th epoch : 1.839746717670691  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8833th epoch : 1.839708921181365  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8834th epoch : 1.8396711828647978  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8835th epoch : 1.8396335025648547  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8836th epoch : 1.8395958801259007  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8837th epoch : 1.8395583153927997  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8838th epoch : 1.8395208082109111  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8839th epoch : 1.8394833584260881  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8840th epoch : 1.839445965884676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8841th epoch : 1.8394086304335096  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8842th epoch : 1.839371351919911  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8843th epoch : 1.8393341301916886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8844th epoch : 1.8392969650971334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8845th epoch : 1.8392598564850182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8846th epoch : 1.8392228042045955  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8847th epoch : 1.8391858081055943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8848th epoch : 1.8391488680382198  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8849th epoch : 1.8391119838531498  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8850th epoch : 1.839075155401534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8851th epoch : 1.8390383825349912  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8852th epoch : 1.8390016651056071  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8853th epoch : 1.8389650029659335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8854th epoch : 1.8389283959689848  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8855th epoch : 1.8388918439682376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8856th epoch : 1.8388553468176276  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8857th epoch : 1.838818904371548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8858th epoch : 1.8387825164848475  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8859th epoch : 1.838746183012829  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8860th epoch : 1.8387099038112469  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8861th epoch : 1.8386736787363054  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8862th epoch : 1.8386375076446568  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8863th epoch : 1.8386013903933998  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8864th epoch : 1.8385653268400766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8865th epoch : 1.8385293168426726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8866th epoch : 1.8384933602596134  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8867th epoch : 1.8384574569497634  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8868th epoch : 1.8384216067724233  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8869th epoch : 1.8383858095873296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8870th epoch : 1.8383500652546516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8871th epoch : 1.8383143736349898  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8872th epoch : 1.8382787345893747  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8873th epoch : 1.838243147979264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8874th epoch : 1.8382076136665424  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8875th epoch : 1.8381721315135175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8876th epoch : 1.8381367013829204  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8877th epoch : 1.8381013231379022  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8878th epoch : 1.8380659966420334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8879th epoch : 1.8380307217593015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8880th epoch : 1.8379954983541091  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8881th epoch : 1.8379603262912734  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8882th epoch : 1.8379252054360222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8883th epoch : 1.837890135653995  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8884th epoch : 1.8378551168112391  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8885th epoch : 1.8378201487742085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8886th epoch : 1.8377852314097631  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8887th epoch : 1.8377503645851656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8888th epoch : 1.837715548168081  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8889th epoch : 1.8376807820265737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8890th epoch : 1.8376460660291076  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8891th epoch : 1.837611400044543  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8892th epoch : 1.8375767839421349  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8893th epoch : 1.8375422175915324  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8894th epoch : 1.8375077008627767  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8895th epoch : 1.8374732336262987  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8896th epoch : 1.8374388157529187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8897th epoch : 1.837404447113843  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8898th epoch : 1.8373701275806646  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8899th epoch : 1.8373358570253597  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8900th epoch : 1.837301635320287  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8901th epoch : 1.8372674623381857  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8902th epoch : 1.8372333379521741  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8903th epoch : 1.8371992620357487  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8904th epoch : 1.8371652344627813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8905th epoch : 1.8371312551075187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8906th epoch : 1.8370973238445805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8907th epoch : 1.8370634405489572  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8908th epoch : 1.8370296050960098  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8909th epoch : 1.8369958173614673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8910th epoch : 1.836962077221426  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8911th epoch : 1.8369283845523465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8912th epoch : 1.8368947392310546  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8913th epoch : 1.8368611411347373  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8914th epoch : 1.836827590140943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8915th epoch : 1.836794086127579  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8916th epoch : 1.836760628972911  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8917th epoch : 1.836727218555561  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8918th epoch : 1.8366938547545055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8919th epoch : 1.836660537449075  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8920th epoch : 1.8366272665189516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8921th epoch : 1.8365940418441686  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8922th epoch : 1.8365608633051076  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8923th epoch : 1.836527730782499  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8924th epoch : 1.8364946441574184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8925th epoch : 1.8364616033112868  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8926th epoch : 1.8364286081258692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8927th epoch : 1.8363956584832717  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8928th epoch : 1.8363627542659415  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8929th epoch : 1.8363298953566654  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8930th epoch : 1.8362970816385675  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8931th epoch : 1.8362643129951088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8932th epoch : 1.8362315893100853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8933th epoch : 1.836198910467627  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8934th epoch : 1.836166276352196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8935th epoch : 1.8361336868485854  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8936th epoch : 1.8361011418419182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8937th epoch : 1.8360686412176457  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8938th epoch : 1.8360361848615465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8939th epoch : 1.8360037726597243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8940th epoch : 1.8359714044986073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8941th epoch : 1.8359390802649473  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8942th epoch : 1.8359067998458172  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8943th epoch : 1.8358745631286106  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8944th epoch : 1.8358423700010398  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8945th epoch : 1.8358102203511357  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8946th epoch : 1.8357781140672447  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8947th epoch : 1.8357460510380292  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8948th epoch : 1.8357140311524656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8949th epoch : 1.835682054299842  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8950th epoch : 1.8356501203697588  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8951th epoch : 1.8356182292521264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8952th epoch : 1.835586380837164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8953th epoch : 1.8355545750153979  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8954th epoch : 1.8355228116776616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8955th epoch : 1.8354910907150932  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8956th epoch : 1.8354594120191345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8957th epoch : 1.8354277754815307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8958th epoch : 1.8353961809943278  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8959th epoch : 1.8353646284498721  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8960th epoch : 1.8353331177408088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8961th epoch : 1.8353016487600813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8962th epoch : 1.8352702214009289  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8963th epoch : 1.8352388355568867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8964th epoch : 1.835207491121784  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8965th epoch : 1.8351761879897426  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8966th epoch : 1.8351449260551767  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8967th epoch : 1.8351137052127906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8968th epoch : 1.8350825253575782  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8969th epoch : 1.8350513863848217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8970th epoch : 1.83502028819009  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8971th epoch : 1.834989230669239  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8972th epoch : 1.8349582137184077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8973th epoch : 1.83492723723402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8974th epoch : 1.8348963011127817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8975th epoch : 1.8348654052516802  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8976th epoch : 1.8348345495479828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8977th epoch : 1.8348037338992358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8978th epoch : 1.8347729582032637  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8979th epoch : 1.8347422223581675  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8980th epoch : 1.8347115262623244  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8981th epoch : 1.8346808698143853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8982th epoch : 1.834650252913275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8983th epoch : 1.834619675458191  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8984th epoch : 1.8345891373486012  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8985th epoch : 1.8345586384842443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8986th epoch : 1.834528178765128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8987th epoch : 1.8344977580915272  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8988th epoch : 1.8344673763639847  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8989th epoch : 1.8344370334833084  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8990th epoch : 1.8344067293505713  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8991th epoch : 1.8343764638671098  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8992th epoch : 1.834346236934523  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8993th epoch : 1.8343160484546714  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8994th epoch : 1.834285898329676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8995th epoch : 1.8342557864619173  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8996th epoch : 1.834225712754034  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8997th epoch : 1.8341956771089223  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8998th epoch : 1.8341656794297347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 8999th epoch : 1.8341357196198784  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9000th epoch : 1.8341057975830157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9001th epoch : 1.8340759132230613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9002th epoch : 1.8340460664441824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9003th epoch : 1.8340162571507972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9004th epoch : 1.833986485247574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9005th epoch : 1.8339567506394308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9006th epoch : 1.8339270532315326  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9007th epoch : 1.833897392929292  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9008th epoch : 1.8338677696383685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9009th epoch : 1.8338381832646653  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9010th epoch : 1.833808633714331  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9011th epoch : 1.8337791208937557  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9012th epoch : 1.8337496447095736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9013th epoch : 1.8337202050686585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9014th epoch : 1.8336908018781255  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9015th epoch : 1.8336614350453277  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9016th epoch : 1.8336321044778576  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9017th epoch : 1.8336028100835444  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9018th epoch : 1.8335735517704537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9019th epoch : 1.8335443294468863  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9020th epoch : 1.8335151430213776  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9021th epoch : 1.8334859924026965  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9022th epoch : 1.8334568774998443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9023th epoch : 1.8334277982220537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9024th epoch : 1.8333987544787884  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9025th epoch : 1.8333697461797418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9026th epoch : 1.8333407732348355  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9027th epoch : 1.8333118355542193  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9028th epoch : 1.83328293304827  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9029th epoch : 1.8332540656275904  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9030th epoch : 1.8332252332030081  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9031th epoch : 1.833196435685575  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9032th epoch : 1.8331676729865665  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9033th epoch : 1.8331389450174798  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9034th epoch : 1.8331102516900342  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9035th epoch : 1.8330815929161688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9036th epoch : 1.8330529686080428  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9037th epoch : 1.8330243786780342  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9038th epoch : 1.8329958230387389  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9039th epoch : 1.832967301602969  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9040th epoch : 1.8329388142837542  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9041th epoch : 1.8329103609943376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9042th epoch : 1.832881941648178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9043th epoch : 1.8328535561589472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9044th epoch : 1.8328252044405295  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9045th epoch : 1.8327968864070212  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9046th epoch : 1.832768601972729  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9047th epoch : 1.83274035105217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9048th epoch : 1.8327121335600705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9049th epoch : 1.8326839494113647  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9050th epoch : 1.8326557985211946  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9051th epoch : 1.832627680804909  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9052th epoch : 1.8325995961780612  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9053th epoch : 1.8325715445564115  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9054th epoch : 1.8325435258559222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9055th epoch : 1.83251553999276  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9056th epoch : 1.8324875868832942  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9057th epoch : 1.8324596664440944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9058th epoch : 1.8324317785919326  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9059th epoch : 1.8324039232437797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9060th epoch : 1.8323761003168055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9061th epoch : 1.832348309728379  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9062th epoch : 1.8323205513960663  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9063th epoch : 1.8322928252376296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9064th epoch : 1.8322651311710278  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9065th epoch : 1.8322374691144143  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9066th epoch : 1.8322098389861372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9067th epoch : 1.8321822407047377  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9068th epoch : 1.8321546741889496  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9069th epoch : 1.832127139357699  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9070th epoch : 1.8320996361301027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9071th epoch : 1.832072164425468  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9072th epoch : 1.8320447241632916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9073th epoch : 1.8320173152632588  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9074th epoch : 1.8319899376452433  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9075th epoch : 1.8319625912293054  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9076th epoch : 1.831935275935692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9077th epoch : 1.8319079916848358  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 9078th epoch : 1.831880738397354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9079th epoch : 1.8318535159940488  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9080th epoch : 1.8318263243959043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9081th epoch : 1.831799163524088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9082th epoch : 1.8317720332999494  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9083th epoch : 1.8317449336450187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9084th epoch : 1.8317178644810064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9085th epoch : 1.8316908257298026  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9086th epoch : 1.831663817313476  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9087th epoch : 1.831636839154274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9088th epoch : 1.8316098911746208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9089th epoch : 1.831582973297117  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9090th epoch : 1.8315560854445394  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9091th epoch : 1.8315292275398398  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9092th epoch : 1.8315023995061448  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9093th epoch : 1.8314756012667537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9094th epoch : 1.8314488327451393  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9095th epoch : 1.8314220938649468  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9096th epoch : 1.8313953845499924  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9097th epoch : 1.8313687047242633  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9098th epoch : 1.8313420543119168  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9099th epoch : 1.8313154332372792  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9100th epoch : 1.8312888414248456  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9101th epoch : 1.8312622787992794  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9102th epoch : 1.8312357452854104  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9103th epoch : 1.8312092408082352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9104th epoch : 1.8311827652929167  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9105th epoch : 1.831156318664782  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9106th epoch : 1.8311299008493231  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9107th epoch : 1.8311035117721959  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9108th epoch : 1.8310771513592183  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9109th epoch : 1.831050819536372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9110th epoch : 1.831024516229799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9111th epoch : 1.8309982413658026  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9112th epoch : 1.8309719948708467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9113th epoch : 1.8309457766715542  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9114th epoch : 1.8309195866947077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9115th epoch : 1.830893424867247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9116th epoch : 1.83086729111627  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9117th epoch : 1.8308411853690312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9118th epoch : 1.8308151075529415  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9119th epoch : 1.8307890575955672  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9120th epoch : 1.8307630354246296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9121th epoch : 1.8307370409680037  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9122th epoch : 1.8307110741537183  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9123th epoch : 1.830685134909955  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9124th epoch : 1.830659223165048  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9125th epoch : 1.8306333388474825  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9126th epoch : 1.8306074818858944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9127th epoch : 1.8305816522090705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9128th epoch : 1.8305558497459467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9129th epoch : 1.830530074425608  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9130th epoch : 1.8305043261772873  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9131th epoch : 1.8304786049303658  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9132th epoch : 1.8304529106143712  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9133th epoch : 1.8304272431589774  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9134th epoch : 1.8304016024940046  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9135th epoch : 1.8303759885494177  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9136th epoch : 1.8303504012553258  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9137th epoch : 1.8303248405419823  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9138th epoch : 1.8302993063397832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9139th epoch : 1.8302737985792676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9140th epoch : 1.8302483171911164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9141th epoch : 1.8302228621061514  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9142th epoch : 1.830197433255335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9143th epoch : 1.8301720305697706  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9144th epoch : 1.8301466539806999  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9145th epoch : 1.8301213034195039  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9146th epoch : 1.8300959788177016  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9147th epoch : 1.83007068010695  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9148th epoch : 1.8300454072190426  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9149th epoch : 1.8300201600859092  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9150th epoch : 1.8299949386396157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9151th epoch : 1.829969742812363  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9152th epoch : 1.829944572536486  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9153th epoch : 1.8299194277444542  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9154th epoch : 1.8298943083688703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9155th epoch : 1.8298692143424695  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9156th epoch : 1.8298441455981191  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9157th epoch : 1.829819102068818  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9158th epoch : 1.829794083687696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9159th epoch : 1.829769090388013  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9160th epoch : 1.8297441221031594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9161th epoch : 1.8297191787666536  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9162th epoch : 1.829694260312143  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9163th epoch : 1.8296693666734039  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9164th epoch : 1.8296444977843385  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9165th epoch : 1.8296196535789766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9166th epoch : 1.829594833991474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9167th epoch : 1.8295700389561123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9168th epoch : 1.8295452684072977  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9169th epoch : 1.8295205222795616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9170th epoch : 1.8294958005075586  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9171th epoch : 1.8294711030260669  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9172th epoch : 1.8294464297699873  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9173th epoch : 1.8294217806743431  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9174th epoch : 1.8293971556742787  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9175th epoch : 1.8293725547050603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9176th epoch : 1.8293479777020734  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9177th epoch : 1.8293234246008245  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9178th epoch : 1.829298895336939  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9179th epoch : 1.8292743898461608  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9180th epoch : 1.829249908064352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9181th epoch : 1.8292254499274934  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9182th epoch : 1.8292010153716813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9183th epoch : 1.8291766043331297  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9184th epoch : 1.8291522167481677  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9185th epoch : 1.8291278525532408  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9186th epoch : 1.8291035116849088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9187th epoch : 1.8290791940798454  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9188th epoch : 1.8290548996748388  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9189th epoch : 1.8290306284067903  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9190th epoch : 1.8290063802127132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9191th epoch : 1.8289821550297336  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9192th epoch : 1.8289579527950888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9193th epoch : 1.8289337734461275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9194th epoch : 1.8289096169203085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9195th epoch : 1.8288854831552006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9196th epoch : 1.8288613720884823  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9197th epoch : 1.8288372836579405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9198th epoch : 1.8288132178014709  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9199th epoch : 1.8287891744570763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9200th epoch : 1.8287651535628677  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9201th epoch : 1.828741155057062  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9202th epoch : 1.8287171788779826  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9203th epoch : 1.8286932249640586  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9204th epoch : 1.828669293253824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9205th epoch : 1.8286453836859178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9206th epoch : 1.8286214961990825  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9207th epoch : 1.8285976307321647  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9208th epoch : 1.8285737872241137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9209th epoch : 1.8285499656139812  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9210th epoch : 1.828526165840921  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9211th epoch : 1.8285023878441886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9212th epoch : 1.8284786315631398  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9213th epoch : 1.8284548969372312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9214th epoch : 1.8284311839060194  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9215th epoch : 1.82840749240916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9216th epoch : 1.8283838223864077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9217th epoch : 1.8283601737776154  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9218th epoch : 1.8283365465227341  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9219th epoch : 1.8283129405618117  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9220th epoch : 1.8282893558349929  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9221th epoch : 1.828265792282519  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9222th epoch : 1.8282422498447268  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9223th epoch : 1.8282187284620486  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9224th epoch : 1.8281952280750113  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9225th epoch : 1.828171748624236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9226th epoch : 1.8281482900504373  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9227th epoch : 1.8281248522944236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9228th epoch : 1.8281014352970957  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9229th epoch : 1.8280780389994467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9230th epoch : 1.828054663342561  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9231th epoch : 1.828031308267615  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9232th epoch : 1.8280079737158752  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9233th epoch : 1.8279846596286984  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9234th epoch : 1.8279613659475316  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9235th epoch : 1.8279380926139102  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9236th epoch : 1.8279148395694589  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9237th epoch : 1.8278916067558908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9238th epoch : 1.827868394115006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9239th epoch : 1.8278452015886923  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9240th epoch : 1.8278220291189247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9241th epoch : 1.827798876647763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9242th epoch : 1.8277757441173548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9243th epoch : 1.827752631469931  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9244th epoch : 1.8277295386478087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9245th epoch : 1.8277064655933886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9246th epoch : 1.8276834122491552  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9247th epoch : 1.8276603785576766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9248th epoch : 1.8276373644616035  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9249th epoch : 1.8276143699036689  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9250th epoch : 1.8275913948266882  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9251th epoch : 1.8275684391735572  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9252th epoch : 1.8275455028872534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9253th epoch : 1.8275225859108346  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9254th epoch : 1.827499688187438  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9255th epoch : 1.8274768096602807  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9256th epoch : 1.8274539502726588  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9257th epoch : 1.8274311099679468  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9258th epoch : 1.8274082886895968  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9259th epoch : 1.827385486381139  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9260th epoch : 1.8273627029861803  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9261th epoch : 1.8273399384484041  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9262th epoch : 1.8273171927115706  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9263th epoch : 1.8272944657195143  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9264th epoch : 1.8272717574161461  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9265th epoch : 1.8272490677454511  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9266th epoch : 1.8272263966514883  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9267th epoch : 1.8272037440783908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9268th epoch : 1.827181109970365  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9269th epoch : 1.8271584942716894  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9270th epoch : 1.8271358969267157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9271th epoch : 1.827113317879867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9272th epoch : 1.8270907570756376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9273th epoch : 1.827068214458593  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9274th epoch : 1.827045689973369  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9275th epoch : 1.8270231835646709  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9276th epoch : 1.8270006951772746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9277th epoch : 1.826978224756024  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9278th epoch : 1.826955772245832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9279th epoch : 1.8269333375916794  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9280th epoch : 1.8269109207386147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9281th epoch : 1.8268885216317536  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9282th epoch : 1.8268661402162787  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9283th epoch : 1.826843776437438  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9284th epoch : 1.826821430240546  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9285th epoch : 1.8267991015709826  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9286th epoch : 1.826776790374192  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9287th epoch : 1.8267544965956832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9288th epoch : 1.826732220181029  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9289th epoch : 1.8267099610758653  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9290th epoch : 1.8266877192258915  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9291th epoch : 1.826665494576869  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9292th epoch : 1.8266432870746219  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9293th epoch : 1.8266210966650356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9294th epoch : 1.8265989232940563  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9295th epoch : 1.8265767669076916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9296th epoch : 1.8265546274520086  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9297th epoch : 1.8265325048731347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9298th epoch : 1.8265103991172564  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9299th epoch : 1.8264883101306193  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9300th epoch : 1.8264662378595267  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9301th epoch : 1.8264441822503408  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9302th epoch : 1.8264221432494805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9303th epoch : 1.8264001208034224  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9304th epoch : 1.826378114858699  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9305th epoch : 1.8263561253618994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9306th epoch : 1.826334152259668  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9307th epoch : 1.8263121954987052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9308th epoch : 1.826290255025765  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9309th epoch : 1.8262683307876564  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9310th epoch : 1.826246422731242  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9311th epoch : 1.8262245308034384  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9312th epoch : 1.8262026549512143  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9313th epoch : 1.8261807951215914  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9314th epoch : 1.8261589512616432  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9315th epoch : 1.8261371233184946  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9316th epoch : 1.8261153112393225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9317th epoch : 1.8260935149713533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9318th epoch : 1.8260717344618647  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9319th epoch : 1.8260499696581831  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9320th epoch : 1.8260282205076852  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9321th epoch : 1.826006486957796  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9322th epoch : 1.8259847689559894  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9323th epoch : 1.8259630664497863  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9324th epoch : 1.8259413793867563  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9325th epoch : 1.8259197077145153  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9326th epoch : 1.825898051380726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9327th epoch : 1.8258764103330973  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9328th epoch : 1.825854784519384  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9329th epoch : 1.8258331738873856  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9330th epoch : 1.8258115783849473  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9331th epoch : 1.8257899979599579  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9332th epoch : 1.8257684325603503  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9333th epoch : 1.8257468821341007  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9334th epoch : 1.8257253466292291  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9335th epoch : 1.825703825993797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9336th epoch : 1.8256823201759087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9337th epoch : 1.82566082912371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9338th epoch : 1.8256393527853878  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9339th epoch : 1.8256178911091698  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9340th epoch : 1.825596444043324  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9341th epoch : 1.8255750115361586  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9342th epoch : 1.8255535935360205  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9343th epoch : 1.8255321899912964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9344th epoch : 1.8255108008504108  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9345th epoch : 1.8254894260618266  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9346th epoch : 1.8254680655740443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9347th epoch : 1.8254467193356017  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9348th epoch : 1.825425387295073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9349th epoch : 1.8254040694010687  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9350th epoch : 1.8253827656022354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9351th epoch : 1.8253614758472547  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9352th epoch : 1.8253402000848435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9353th epoch : 1.825318938263753  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9354th epoch : 1.825297690332768  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9355th epoch : 1.8252764562407073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9356th epoch : 1.8252552359364231  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9357th epoch : 1.8252340293687996  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9358th epoch : 1.8252128364867535  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9359th epoch : 1.8251916572392333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9360th epoch : 1.8251704915752187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9361th epoch : 1.8251493394437206  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9362th epoch : 1.8251282007937795  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9363th epoch : 1.8251070755744667  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9364th epoch : 1.8250859637348824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9365th epoch : 1.8250648652241566  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9366th epoch : 1.8250437799914467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9367th epoch : 1.8250227079859394  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9368th epoch : 1.8250016491568484  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9369th epoch : 1.8249806034534148  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9370th epoch : 1.8249595708249067  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9371th epoch : 1.8249385512206182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9372th epoch : 1.8249175445898695  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9373th epoch : 1.824896550882006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9374th epoch : 1.8248755700463983  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9375th epoch : 1.8248546020324414  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9376th epoch : 1.824833646789554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9377th epoch : 1.8248127042671793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9378th epoch : 1.8247917744147828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9379th epoch : 1.8247708571818528  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9380th epoch : 1.8247499525179  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9381th epoch : 1.824729060372457  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9382th epoch : 1.8247081806950778  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9383th epoch : 1.8246873134353363  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9384th epoch : 1.824666458542828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9385th epoch : 1.8246456159671678  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9386th epoch : 1.82462478565799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9387th epoch : 1.8246039675649481  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9388th epoch : 1.8245831616377142  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9389th epoch : 1.8245623678259781  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9390th epoch : 1.8245415860794478  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9391th epoch : 1.824520816347848  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9392th epoch : 1.8245000585809203  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9393th epoch : 1.8244793127284227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9394th epoch : 1.8244585787401286  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9395th epoch : 1.8244378565658272  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9396th epoch : 1.8244171461553222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9397th epoch : 1.824396447458432  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9398th epoch : 1.8243757604249886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9399th epoch : 1.8243550850048378  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9400th epoch : 1.8243344211478378  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9401th epoch : 1.8243137688038602  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9402th epoch : 1.824293127922788  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9403th epoch : 1.8242724984545164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9404th epoch : 1.8242518803489507  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9405th epoch : 1.824231273556008  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9406th epoch : 1.824210678025615  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9407th epoch : 1.8241900937077082  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9408th epoch : 1.8241695205522335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9409th epoch : 1.8241489585091455  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9410th epoch : 1.8241284075284068  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9411th epoch : 1.8241078675599882  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9412th epoch : 1.8240873385538678  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9413th epoch : 1.8240668204600308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9414th epoch : 1.8240463132284683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9415th epoch : 1.8240258168091779  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9416th epoch : 1.8240053311521622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9417th epoch : 1.823984856207429  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9418th epoch : 1.8239643919249906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9419th epoch : 1.8239439382548632  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9420th epoch : 1.8239234951470666  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9421th epoch : 1.8239030625516242  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9422th epoch : 1.8238826404185613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9423th epoch : 1.8238622286979052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9424th epoch : 1.8238418273396857  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9425th epoch : 1.8238214362939327  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9426th epoch : 1.8238010555106776  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9427th epoch : 1.8237806849399516  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9428th epoch : 1.8237603245317857  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9429th epoch : 1.82373997423621  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9430th epoch : 1.823719634003253  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9431th epoch : 1.8236993037829425  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9432th epoch : 1.8236789835253027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9433th epoch : 1.823658673180356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9434th epoch : 1.8236383726981211  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9435th epoch : 1.8236180820286132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9436th epoch : 1.823597801121843  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9437th epoch : 1.823577529927817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9438th epoch : 1.8235572683965358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9439th epoch : 1.8235370164779947  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9440th epoch : 1.823516774122183  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9441th epoch : 1.8234965412790825  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9442th epoch : 1.8234763178986688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9443th epoch : 1.8234561039309092  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9444th epoch : 1.8234358993257629  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9445th epoch : 1.8234157040331802  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9446th epoch : 1.8233955180031027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9447th epoch : 1.8233753411854619  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9448th epoch : 1.8233551735301792  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9449th epoch : 1.823335014987165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9450th epoch : 1.823314865506319  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9451th epoch : 1.8232947250375289  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9452th epoch : 1.8232745935306698  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9453th epoch : 1.8232544709356047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9454th epoch : 1.8232343572021827  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9455th epoch : 1.82321425228024  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9456th epoch : 1.8231941561195972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9457th epoch : 1.8231740686700613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9458th epoch : 1.8231539898814233  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9459th epoch : 1.8231339197034586  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9460th epoch : 1.823113858085926  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9461th epoch : 1.8230938049785679  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9462th epoch : 1.8230737603311085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9463th epoch : 1.823053724093255  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9464th epoch : 1.8230336962146956  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9465th epoch : 1.8230136766450993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9466th epoch : 1.822993665334116  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9467th epoch : 1.822973662231376  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9468th epoch : 1.8229536672864877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9469th epoch : 1.8229336804490397  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9470th epoch : 1.8229137016685981  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9471th epoch : 1.8228937308947077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9472th epoch : 1.8228737680768898  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9473th epoch : 1.822853813164643  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9474th epoch : 1.8228338661074415  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9475th epoch : 1.822813926854736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9476th epoch : 1.822793995355952  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9477th epoch : 1.8227740715604892  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9478th epoch : 1.8227541554177218  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9479th epoch : 1.8227342468769978  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9480th epoch : 1.8227143458876374  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9481th epoch : 1.822694452398934  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9482th epoch : 1.822674566360152  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9483th epoch : 1.8226546877205283  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9484th epoch : 1.8226348164292694  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9485th epoch : 1.8226149524355528  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9486th epoch : 1.8225950956885253  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9487th epoch : 1.8225752461373028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9488th epoch : 1.8225554037309701  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9489th epoch : 1.8225355684185793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9490th epoch : 1.8225157401491507  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9491th epoch : 1.8224959188716707  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9492th epoch : 1.8224761045350928  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9493th epoch : 1.8224562970883356  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9494th epoch : 1.822436496480283  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9495th epoch : 1.8224167026597837  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9496th epoch : 1.8223969155756499  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9497th epoch : 1.822377135176658  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9498th epoch : 1.8223573614115465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9499th epoch : 1.8223375942290165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9500th epoch : 1.822317833577731  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9501th epoch : 1.8222980794063137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9502th epoch : 1.8222783316633493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9503th epoch : 1.8222585902973822  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9504th epoch : 1.8222388552569158  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9505th epoch : 1.8222191264904128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9506th epoch : 1.8221994039462943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9507th epoch : 1.822179687572938  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9508th epoch : 1.8221599773186794  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9509th epoch : 1.8221402731318104  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9510th epoch : 1.822120574960578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9511th epoch : 1.8221008827531853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9512th epoch : 1.8220811964577892  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9513th epoch : 1.822061516022501  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9514th epoch : 1.8220418413953856  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9515th epoch : 1.82202217252446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9516th epoch : 1.8220025093576941  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9517th epoch : 1.8219828518430088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9518th epoch : 1.8219631999282757  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9519th epoch : 1.8219435535613178  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9520th epoch : 1.8219239126899065  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9521th epoch : 1.8219042772617633  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9522th epoch : 1.8218846472245573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9523th epoch : 1.821865022525906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9524th epoch : 1.8218454031133742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9525th epoch : 1.8218257889344724  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9526th epoch : 1.821806179936658  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9527th epoch : 1.8217865760673329  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9528th epoch : 1.8217669772738443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9529th epoch : 1.821747383503483  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9530th epoch : 1.8217277947034833  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9531th epoch : 1.821708210821022  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9532th epoch : 1.8216886318032186  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9533th epoch : 1.8216690575971333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9534th epoch : 1.8216494881497673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9535th epoch : 1.8216299234080622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9536th epoch : 1.8216103633188985  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9537th epoch : 1.821590807829096  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9538th epoch : 1.8215712568854128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9539th epoch : 1.8215517104345436  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9540th epoch : 1.8215321684231207  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9541th epoch : 1.8215126307977123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9542th epoch : 1.8214930975048218  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9543th epoch : 1.8214735684908878  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9544th epoch : 1.8214540437022828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9545th epoch : 1.8214345230853128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9546th epoch : 1.8214150065862165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9547th epoch : 1.8213954941511645  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9548th epoch : 1.821375985726259  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9549th epoch : 1.821356481257533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9550th epoch : 1.821336980690949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9551th epoch : 1.8213174839723991  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9552th epoch : 1.8212979910477043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9553th epoch : 1.8212785018626128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9554th epoch : 1.8212590163628002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9555th epoch : 1.8212395344938692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9556th epoch : 1.8212200562013474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9557th epoch : 1.821200581430688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9558th epoch : 1.821181110127268  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9559th epoch : 1.8211616422363888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9560th epoch : 1.821142177703274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9561th epoch : 1.8211227164730694  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9562th epoch : 1.821103258490843  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9563th epoch : 1.8210838037015824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9564th epoch : 1.8210643520501961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9565th epoch : 1.821044903481511  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9566th epoch : 1.8210254579402734  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9567th epoch : 1.8210060153711463  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9568th epoch : 1.8209865757187107  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9569th epoch : 1.820967138927463  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9570th epoch : 1.820947704941816  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9571th epoch : 1.8209282737060961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9572th epoch : 1.8209088451645448  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9573th epoch : 1.8208894192613159  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9574th epoch : 1.8208699959404762  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9575th epoch : 1.8208505751460038  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9576th epoch : 1.8208311568217883  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9577th epoch : 1.8208117409116287  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9578th epoch : 1.8207923273592335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9579th epoch : 1.8207729161082202  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9580th epoch : 1.8207535071021135  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9581th epoch : 1.8207341002843456  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9582th epoch : 1.820714695598254  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9583th epoch : 1.820695292987083  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9584th epoch : 1.82067589239398  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9585th epoch : 1.8206564937619971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9586th epoch : 1.820637097034089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9587th epoch : 1.820617702153113  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9588th epoch : 1.8205983090618265  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9589th epoch : 1.8205789177028888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9590th epoch : 1.8205595280188585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9591th epoch : 1.8205401399521928  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9592th epoch : 1.8205207534452466  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9593th epoch : 1.8205013684402729  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9594th epoch : 1.8204819848794205  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9595th epoch : 1.8204626027047335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9596th epoch : 1.8204432218581512  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9597th epoch : 1.8204238422815064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9598th epoch : 1.8204044639165249  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9599th epoch : 1.8203850867048244  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9600th epoch : 1.8203657105879139  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9601th epoch : 1.8203463355071932  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9602th epoch : 1.820326961403951  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9603th epoch : 1.8203075882193651  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9604th epoch : 1.8202882158945004  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9605th epoch : 1.8202688443703094  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9606th epoch : 1.82024947358763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9607th epoch : 1.8202301034871853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9608th epoch : 1.8202107340095828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9609th epoch : 1.820191365095313  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9610th epoch : 1.8201719966847485  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 9611th epoch : 1.8201526287181442  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9612th epoch : 1.8201332611356347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9613th epoch : 1.8201138938772343  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9614th epoch : 1.8200945268828368  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9615th epoch : 1.8200751600922127  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9616th epoch : 1.82005579344501  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9617th epoch : 1.820036426880752  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9618th epoch : 1.820017060338838  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9619th epoch : 1.81999769375854  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9620th epoch : 1.8199783270790038  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9621th epoch : 1.8199589602392474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9622th epoch : 1.8199395931781592  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9623th epoch : 1.8199202258344986  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9624th epoch : 1.8199008581468938  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9625th epoch : 1.8198814900538411  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9626th epoch : 1.8198621214937043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9627th epoch : 1.8198427524047132  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9628th epoch : 1.8198233827249626  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9629th epoch : 1.8198040123924124  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9630th epoch : 1.8197846413448853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9631th epoch : 1.8197652695200657  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9632th epoch : 1.8197458968555  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9633th epoch : 1.8197265232885949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9634th epoch : 1.8197071487566152  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9635th epoch : 1.8196877731966854  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9636th epoch : 1.8196683965457858  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9637th epoch : 1.8196490187407537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9638th epoch : 1.8196296397182807  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9639th epoch : 1.819610259414913  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9640th epoch : 1.8195908777670498  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9641th epoch : 1.8195714947109416  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9642th epoch : 1.8195521101826901  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9643th epoch : 1.8195327241182468  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9644th epoch : 1.819513336453412  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9645th epoch : 1.8194939471238327  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9646th epoch : 1.8194745560650036  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9647th epoch : 1.8194551632122642  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9648th epoch : 1.819435768500798  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9649th epoch : 1.8194163718656327  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9650th epoch : 1.8193969732416369  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9651th epoch : 1.8193775725635208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9652th epoch : 1.8193581697658345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9653th epoch : 1.8193387647829669  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9654th epoch : 1.8193193575491435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9655th epoch : 1.8192999479984278  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9656th epoch : 1.8192805360647173  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9657th epoch : 1.8192611216817443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9658th epoch : 1.8192417047830736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9659th epoch : 1.819222285302102  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9660th epoch : 1.8192028631720574  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9661th epoch : 1.8191834383259964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9662th epoch : 1.8191640106968043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9663th epoch : 1.819144580217193  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9664th epoch : 1.819125146819701  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9665th epoch : 1.8191057104366908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9666th epoch : 1.8190862710003488  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9667th epoch : 1.819066828442683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9668th epoch : 1.8190473826955231  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9669th epoch : 1.8190279336905182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9670th epoch : 1.8190084813591358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9671th epoch : 1.818989025632661  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9672th epoch : 1.8189695664421948  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9673th epoch : 1.8189501037186524  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9674th epoch : 1.8189306373927634  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9675th epoch : 1.818911167395069  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9676th epoch : 1.8188916936559216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9677th epoch : 1.818872216105483  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9678th epoch : 1.8188527346737233  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9679th epoch : 1.81883324929042  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9680th epoch : 1.8188137598851557  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9681th epoch : 1.8187942663873182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9682th epoch : 1.8187747687260976  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9683th epoch : 1.8187552668304858  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9684th epoch : 1.818735760629276  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9685th epoch : 1.818716250051059  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9686th epoch : 1.8186967350242242  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9687th epoch : 1.8186772154769573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9688th epoch : 1.8186576913372385  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9689th epoch : 1.818638162532842  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9690th epoch : 1.8186186289913335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9691th epoch : 1.8185990906400702  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9692th epoch : 1.818579547406198  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9693th epoch : 1.8185599992166512  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9694th epoch : 1.8185404459981505  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9695th epoch : 1.8185208876772012  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9696th epoch : 1.818501324180093  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9697th epoch : 1.8184817554328971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9698th epoch : 1.8184621813614659  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9699th epoch : 1.8184426018914306  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9700th epoch : 1.8184230169482007  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9701th epoch : 1.8184034264569617  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9702th epoch : 1.8183838303426738  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9703th epoch : 1.8183642285300705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9704th epoch : 1.8183446209436576  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9705th epoch : 1.8183250075077102  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9706th epoch : 1.8183053881462732  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9707th epoch : 1.818285762783158  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9708th epoch : 1.818266131341942  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9709th epoch : 1.8182464937459661  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9710th epoch : 1.8182268499183345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9711th epoch : 1.818207199781912  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9712th epoch : 1.818187543259323  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9713th epoch : 1.818167880272949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9714th epoch : 1.8181482107449285  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9715th epoch : 1.8181285345971538  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9716th epoch : 1.818108851751271  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9717th epoch : 1.8180891621286766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9718th epoch : 1.8180694656505172  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9719th epoch : 1.8180497622376874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9720th epoch : 1.818030051810828  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9721th epoch : 1.8180103342903249  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9722th epoch : 1.817990609596306  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9723th epoch : 1.8179708776486414  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9724th epoch : 1.8179511383669404  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9725th epoch : 1.8179313916705502  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9726th epoch : 1.817911637478554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9727th epoch : 1.8178918757097697  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9728th epoch : 1.8178721062827474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9729th epoch : 1.8178523291157687  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9730th epoch : 1.8178325441268435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9731th epoch : 1.8178127512337097  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9732th epoch : 1.8177929503538304  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9733th epoch : 1.8177731414043925  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9734th epoch : 1.8177533243023047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9735th epoch : 1.8177334989641964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9736th epoch : 1.8177136653064145  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9737th epoch : 1.8176938232450226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9738th epoch : 1.817673972695799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9739th epoch : 1.817654113574234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9740th epoch : 1.8176342457955295  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9741th epoch : 1.817614369274596  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9742th epoch : 1.817594483926051  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9743th epoch : 1.8175745896642166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9744th epoch : 1.8175546864031187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9745th epoch : 1.8175347740564842  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9746th epoch : 1.817514852537739  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9747th epoch : 1.817494921760006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9748th epoch : 1.8174749816361042  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9749th epoch : 1.817455032078545  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9750th epoch : 1.8174350729995317  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9751th epoch : 1.8174151043109565  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9752th epoch : 1.8173951259243988  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9753th epoch : 1.8173751377511231  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9754th epoch : 1.8173551397020773  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9755th epoch : 1.8173351316878903  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9756th epoch : 1.8173151136188692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9757th epoch : 1.817295085404999  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9758th epoch : 1.8172750469559387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9759th epoch : 1.81725499818102  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9760th epoch : 1.8172349389892453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9761th epoch : 1.8172148692892847  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9762th epoch : 1.817194788989475  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9763th epoch : 1.817174697997817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9764th epoch : 1.8171545962219726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9765th epoch : 1.8171344835692635  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9766th epoch : 1.817114359946669  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9767th epoch : 1.817094225260823  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9768th epoch : 1.8170740794180125  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9769th epoch : 1.8170539223241746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9770th epoch : 1.8170337538848949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9771th epoch : 1.817013574005405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9772th epoch : 1.8169933825905797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9773th epoch : 1.8169731795449358  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9774th epoch : 1.816952964772628  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9775th epoch : 1.8169327381774483  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9776th epoch : 1.8169124996628225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9777th epoch : 1.8168922491318087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9778th epoch : 1.8168719864870935  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9779th epoch : 1.8168517116309908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9780th epoch : 1.8168314244654395  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9781th epoch : 1.8168111248919996  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9782th epoch : 1.8167908128118513  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9783th epoch : 1.8167704881257916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9784th epoch : 1.8167501507342319  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9785th epoch : 1.8167298005371957  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9786th epoch : 1.816709437434316  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9787th epoch : 1.8166890613248328  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9788th epoch : 1.81666867210759  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9789th epoch : 1.8166482696810338  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9790th epoch : 1.8166278539432088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9791th epoch : 1.8166074247917565  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9792th epoch : 1.816586982123912  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9793th epoch : 1.8165665258365018  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9794th epoch : 1.8165460558259405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9795th epoch : 1.8165255719882285  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9796th epoch : 1.8165050742189495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9797th epoch : 1.8164845624132668  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9798th epoch : 1.8164640364659221  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9799th epoch : 1.8164434962712313  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9800th epoch : 1.8164229417230817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9801th epoch : 1.8164023727149308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9802th epoch : 1.8163817891398015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9803th epoch : 1.8163611908902806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9804th epoch : 1.8163405778585149  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9805th epoch : 1.816319949936209  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9806th epoch : 1.8162993070146227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9807th epoch : 1.8162786489845666  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9808th epoch : 1.8162579757364008  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9809th epoch : 1.816237287160031  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9810th epoch : 1.8162165831449053  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9811th epoch : 1.8161958635800126  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9812th epoch : 1.8161751283538772  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9813th epoch : 1.816154377354558  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9814th epoch : 1.8161336104696442  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9815th epoch : 1.8161128275862524  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9816th epoch : 1.8160920285910234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9817th epoch : 1.8160712133701196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9818th epoch : 1.8160503818092208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9819th epoch : 1.8160295337935222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9820th epoch : 1.8160086692077302  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9821th epoch : 1.8159877879360595  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9822th epoch : 1.8159668898622303  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9823th epoch : 1.8159459748694637  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9824th epoch : 1.8159250428404803  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9825th epoch : 1.815904093657495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9826th epoch : 1.815883127202215  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9827th epoch : 1.8158621433558353  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9828th epoch : 1.8158411419990366  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9829th epoch : 1.8158201230119804  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9830th epoch : 1.8157990862743065  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9831th epoch : 1.8157780316651297  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9832th epoch : 1.8157569590630351  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9833th epoch : 1.8157358683460763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9834th epoch : 1.8157147593917697  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9835th epoch : 1.8156936320770931  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9836th epoch : 1.8156724862784803  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9837th epoch : 1.815651321871819  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9838th epoch : 1.8156301387324458  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9839th epoch : 1.8156089367351433  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9840th epoch : 1.815587715754136  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9841th epoch : 1.8155664756630872  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9842th epoch : 1.8155452163350938  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9843th epoch : 1.8155239376426842  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9844th epoch : 1.8155026394578138  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9845th epoch : 1.8154813216518604  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9846th epoch : 1.8154599840956216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9847th epoch : 1.81543862665931  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9848th epoch : 1.8154172492125495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9849th epoch : 1.8153958516243711  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9850th epoch : 1.8153744337632098  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9851th epoch : 1.8153529954968994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9852th epoch : 1.8153315366926692  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9853th epoch : 1.8153100572171392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9854th epoch : 1.8152885569363173  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9855th epoch : 1.8152670357155933  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9856th epoch : 1.8152454934197366  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9857th epoch : 1.8152239299128907  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9858th epoch : 1.8152023450585693  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9859th epoch : 1.815180738719652  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9860th epoch : 1.8151591107583804  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9861th epoch : 1.8151374610363535  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9862th epoch : 1.815115789414523  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9863th epoch : 1.815094095753189  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9864th epoch : 1.815072379911996  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9865th epoch : 1.8150506417499284  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9866th epoch : 1.815028881125305  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9867th epoch : 1.8150070978957762  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9868th epoch : 1.8149852919183174  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9869th epoch : 1.8149634630492264  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9870th epoch : 1.814941611144117  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9871th epoch : 1.8149197360579157  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9872th epoch : 1.8148978376448561  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9873th epoch : 1.8148759157584744  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9874th epoch : 1.8148539702516049  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9875th epoch : 1.8148320009763745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9876th epoch : 1.8148100077841993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9877th epoch : 1.8147879905257773  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9878th epoch : 1.8147659490510861  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9879th epoch : 1.8147438832093759  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9880th epoch : 1.8147217928491655  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9881th epoch : 1.8146996778182374  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9882th epoch : 1.814677537963632  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9883th epoch : 1.8146553731316426  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9884th epoch : 1.814633183167811  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9885th epoch : 1.8146109679169216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9886th epoch : 1.8145887272229964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9887th epoch : 1.814566460929289  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9888th epoch : 1.8145441688782808  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9889th epoch : 1.8145218509116745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9890th epoch : 1.8144995068703886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9891th epoch : 1.8144771365945527  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9892th epoch : 1.8144547399235011  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9893th epoch : 1.8144323166957685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9894th epoch : 1.8144098667490833  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9895th epoch : 1.814387389920362  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9896th epoch : 1.8143648860457047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9897th epoch : 1.8143423549603879  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9898th epoch : 1.81431979649886  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9899th epoch : 1.8142972104947346  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9900th epoch : 1.8142745967807852  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9901th epoch : 1.8142519551889387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9902th epoch : 1.8142292855502706  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9903th epoch : 1.8142065876949978  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9904th epoch : 1.814183861452473  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9905th epoch : 1.8141611066511791  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9906th epoch : 1.8141383231187227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9907th epoch : 1.814115510681827  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9908th epoch : 1.8140926691663277  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9909th epoch : 1.8140697983971645  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9910th epoch : 1.8140468981983766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9911th epoch : 1.814023968393095  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9912th epoch : 1.8140010088035365  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9913th epoch : 1.8139780192509976  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9914th epoch : 1.8139549995558477  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9915th epoch : 1.8139319495375226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9916th epoch : 1.813908869014517  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9917th epoch : 1.8138857578043797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9918th epoch : 1.813862615723705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9919th epoch : 1.8138394425881272  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9920th epoch : 1.8138162382123126  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9921th epoch : 1.8137930024099538  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9922th epoch : 1.8137697349937618  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9923th epoch : 1.8137464357754596  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9924th epoch : 1.8137231045657745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9925th epoch : 1.813699741174432  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9926th epoch : 1.8136763454101474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9927th epoch : 1.8136529170806195  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9928th epoch : 1.8136294559925228  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9929th epoch : 1.8136059619515001  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9930th epoch : 1.8135824347621554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9931th epoch : 1.8135588742280466  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9932th epoch : 1.813535280151677  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9933th epoch : 1.813511652334489  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9934th epoch : 1.813487990576855  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9935th epoch : 1.8134642946780712  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9936th epoch : 1.813440564436349  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9937th epoch : 1.8134167996488064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9938th epoch : 1.8133930001114618  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9939th epoch : 1.8133691656192243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9940th epoch : 1.8133452959658873  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9941th epoch : 1.813321390944119  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9942th epoch : 1.8132974503454546  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9943th epoch : 1.8132734739602887  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9944th epoch : 1.813249461577866  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9945th epoch : 1.813225412986274  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9946th epoch : 1.8132013279724328  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9947th epoch : 1.8131772063220892  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9948th epoch : 1.8131530478198055  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9949th epoch : 1.8131288522489521  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9950th epoch : 1.8131046193916993  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9951th epoch : 1.8130803490290066  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9952th epoch : 1.8130560409406162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9953th epoch : 1.813031694905042  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9954th epoch : 1.813007310699562  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9955th epoch : 1.8129828881002077  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9956th epoch : 1.8129584268817567  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9957th epoch : 1.8129339268177223  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9958th epoch : 1.812909387680344  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9959th epoch : 1.8128848092405785  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9960th epoch : 1.8128601912680906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9961th epoch : 1.8128355335312432  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9962th epoch : 1.8128108357970867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9963th epoch : 1.812786097831351  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9964th epoch : 1.8127613193984347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9965th epoch : 1.812736500261395  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9966th epoch : 1.8127116401819385  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9967th epoch : 1.81268673892041  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9968th epoch : 1.8126617962357836  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9969th epoch : 1.8126368118856513  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9970th epoch : 1.8126117856262136  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9971th epoch : 1.8125867172122683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9972th epoch : 1.8125616063972005  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9973th epoch : 1.8125364529329717  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9974th epoch : 1.8125112565701096  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9975th epoch : 1.8124860170576964  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9976th epoch : 1.8124607341433587  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9977th epoch : 1.8124354075732563  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9978th epoch : 1.8124100370920708  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9979th epoch : 1.8123846224429951  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9980th epoch : 1.8123591633677216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9981th epoch : 1.812333659606431  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9982th epoch : 1.8123081108977805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9983th epoch : 1.8122825169788934  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9984th epoch : 1.812256877585346  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9985th epoch : 1.8122311924511563  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9986th epoch : 1.8122054613087726  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9987th epoch : 1.8121796838890611  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9988th epoch : 1.8121538599212943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9989th epoch : 1.812127989133138  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9990th epoch : 1.81210207125064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9991th epoch : 1.8120761059982162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9992th epoch : 1.8120500930986405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9993th epoch : 1.8120240322730297  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9994th epoch : 1.811997923240832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9995th epoch : 1.811971765719815  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9996th epoch : 1.8119455594260505  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9997th epoch : 1.8119193040739037  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9998th epoch : 1.8118929993760184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 9999th epoch : 1.8118666450433047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10000th epoch : 1.8118402407849254  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10001th epoch : 1.8118137863082822  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10002th epoch : 1.811787281319002  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10003th epoch : 1.8117607255209236  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10004th epoch : 1.8117341186160834  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10005th epoch : 1.8117074603047014  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10006th epoch : 1.811680750285168  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10007th epoch : 1.8116539882540275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10008th epoch : 1.8116271739059664  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10009th epoch : 1.811600306933797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10010th epoch : 1.8115733870284434  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10011th epoch : 1.811546413878927  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10012th epoch : 1.8115193871723507  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10013th epoch : 1.8114923065938853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10014th epoch : 1.8114651718267525  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10015th epoch : 1.811437982552211  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10016th epoch : 1.8114107384495401  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10017th epoch : 1.8113834391960257  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10018th epoch : 1.8113560844669423  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10019th epoch : 1.8113286739355385  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10020th epoch : 1.8113012072730208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10021th epoch : 1.8112736841485375  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10022th epoch : 1.811246104229162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10023th epoch : 1.811218467179877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10024th epoch : 1.8111907726635568  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10025th epoch : 1.8111630203409514  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10026th epoch : 1.8111352098706694  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10027th epoch : 1.8111073409091614  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10028th epoch : 1.8110794131107015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10029th epoch : 1.811051426127371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10030th epoch : 1.8110233796090405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10031th epoch : 1.8109952732033523  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10032th epoch : 1.810967106555702  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10033th epoch : 1.8109388793092218  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10034th epoch : 1.8109105911047607  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10035th epoch : 1.810882241580867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10036th epoch : 1.8108538303737693  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10037th epoch : 1.810825357117359  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10038th epoch : 1.8107968214431693  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10039th epoch : 1.8107682229803583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10040th epoch : 1.8107395613556885  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10041th epoch : 1.8107108361935074  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10042th epoch : 1.8106820471157288  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10043th epoch : 1.8106531937418118  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10044th epoch : 1.8106242756887418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10045th epoch : 1.8105952925710103  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10046th epoch : 1.8105662440005936  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10047th epoch : 1.8105371295869335  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10048th epoch : 1.8105079489369158  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10049th epoch : 1.8104787016548496  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10050th epoch : 1.8104493873424463  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10051th epoch : 1.8104200055987982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10052th epoch : 1.8103905560203573  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10053th epoch : 1.8103610382009128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10054th epoch : 1.8103314517315696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10055th epoch : 1.8103017962007268  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10056th epoch : 1.8102720711940548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10057th epoch : 1.810242276294472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10058th epoch : 1.810212411082124  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10059th epoch : 1.8101824751343583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10060th epoch : 1.810152468025703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10061th epoch : 1.8101223893278424  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10062th epoch : 1.810092238609594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10063th epoch : 1.8100620154368832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10064th epoch : 1.8100317193727218  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10065th epoch : 1.8100013499771808  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10066th epoch : 1.8099709068073682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10067th epoch : 1.8099403894174027  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10068th epoch : 1.809909797358389  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10069th epoch : 1.8098791301783936  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10070th epoch : 1.8098483874224176  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10071th epoch : 1.809817568632372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10072th epoch : 1.809786673347052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10073th epoch : 1.8097557011021097  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10074th epoch : 1.809724651430028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10075th epoch : 1.8096935238600946  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10076th epoch : 1.8096623179183737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10077th epoch : 1.8096310331276801  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10078th epoch : 1.8095996690075504  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10079th epoch : 1.809568225074216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10080th epoch : 1.8095367008405745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10081th epoch : 1.809505095816162  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10082th epoch : 1.8094734095071234  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10083th epoch : 1.8094416414161851  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10084th epoch : 1.8094097910426241  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10085th epoch : 1.8093778578822397  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10086th epoch : 1.809345841427323  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10087th epoch : 1.8093137411666271  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10088th epoch : 1.8092815565853375  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10089th epoch : 1.8092492871650399  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10090th epoch : 1.8092169323836906  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10091th epoch : 1.809184491715585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10092th epoch : 1.8091519646313248  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10093th epoch : 1.809119350597788  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10094th epoch : 1.8090866490780957  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10095th epoch : 1.8090538595315793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10096th epoch : 1.8090209814137481  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10097th epoch : 1.8089880141762567  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10098th epoch : 1.8089549572668702  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10099th epoch : 1.8089218101294313  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10100th epoch : 1.8088885722038266  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10101th epoch : 1.8088552429259501  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10102th epoch : 1.8088218217276713  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10103th epoch : 1.808788308036797  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10104th epoch : 1.808754701277038  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10105th epoch : 1.808721000867972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10106th epoch : 1.8086872062250081  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10107th epoch : 1.8086533167593493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10108th epoch : 1.8086193318779564  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10109th epoch : 1.8085852509835103  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10110th epoch : 1.8085510734743737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10111th epoch : 1.808516798744554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10112th epoch : 1.8084824261836645  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10113th epoch : 1.8084479551768844  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10114th epoch : 1.8084133851049213  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10115th epoch : 1.8083787153439703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10116th epoch : 1.8083439452656744  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10117th epoch : 1.8083090742370838  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10118th epoch : 1.8082741016206152  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10119th epoch : 1.8082390267740103  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10120th epoch : 1.8082038490502939  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10121th epoch : 1.8081685677977324  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10122th epoch : 1.8081331823597908  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10123th epoch : 1.808097692075089  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10124th epoch : 1.8080620962773601  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10125th epoch : 1.8080263942954047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10126th epoch : 1.807990585453047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10127th epoch : 1.8079546690690904  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10128th epoch : 1.807918644457273  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10129th epoch : 1.8078825109262195  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10130th epoch : 1.8078462677793972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10131th epoch : 1.8078099143150685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10132th epoch : 1.8077734498262437  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10133th epoch : 1.807736873600633  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10134th epoch : 1.8077001849205994  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10135th epoch : 1.8076633830631088  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10136th epoch : 1.807626467299682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10137th epoch : 1.8075894368963443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10138th epoch : 1.8075522911135755  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10139th epoch : 1.8075150292062592  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10140th epoch : 1.8074776504236318  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10141th epoch : 1.8074401540092304  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10142th epoch : 1.8074025392008406  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10143th epoch : 1.8073648052304443  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10144th epoch : 1.807326951324165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10145th epoch : 1.807288976702215  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 10146th epoch : 1.8072508805788408  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10147th epoch : 1.807212662162267  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10148th epoch : 1.8071743206546418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10149th epoch : 1.8071358552519803  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10150th epoch : 1.8070972651441075  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10151th epoch : 1.807058549514601  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10152th epoch : 1.8070197075407333  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10153th epoch : 1.8069807383934124  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10154th epoch : 1.8069416412371235  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10155th epoch : 1.8069024152298683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10156th epoch : 1.8068630595231043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10157th epoch : 1.8068235732616849  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10158th epoch : 1.8067839555837961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10159th epoch : 1.8067442056208949  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10160th epoch : 1.8067043224976462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10161th epoch : 1.8066643053318585  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10162th epoch : 1.8066241532344196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10163th epoch : 1.8065838653092312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10164th epoch : 1.8065434406531442  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10165th epoch : 1.80650287835589  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10166th epoch : 1.8064621775000156  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10167th epoch : 1.8064213371608138  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10168th epoch : 1.8063803564062553  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10169th epoch : 1.806339234296919  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10170th epoch : 1.8062979698859216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10171th epoch : 1.8062565622188476  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10172th epoch : 1.806215010333676  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10173th epoch : 1.8061733132607092  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10174th epoch : 1.806131470022499  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10175th epoch : 1.8060894796337728  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10176th epoch : 1.8060473411013582  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10177th epoch : 1.8060050534241086  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10178th epoch : 1.8059626155928252  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10179th epoch : 1.8059200265901805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10180th epoch : 1.8058772853906402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10181th epoch : 1.8058343909603836  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10182th epoch : 1.8057913422572245  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10183th epoch : 1.80574813823053  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10184th epoch : 1.8057047778211393  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10185th epoch : 1.80566125996128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10186th epoch : 1.8056175835744868  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10187th epoch : 1.8055737475755154  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10188th epoch : 1.8055297508702577  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10189th epoch : 1.8054855923556565  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10190th epoch : 1.8054412709196175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10191th epoch : 1.8053967854409212  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10192th epoch : 1.805352134789135  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10193th epoch : 1.8053073178245216  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10194th epoch : 1.8052623333979498  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10195th epoch : 1.805217180350801  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10196th epoch : 1.805171857514877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10197th epoch : 1.8051263637123063  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10198th epoch : 1.805080697755448  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10199th epoch : 1.8050348584467972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10200th epoch : 1.8049888445788864  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10201th epoch : 1.8049426549341885  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10202th epoch : 1.8048962882850166  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10203th epoch : 1.804849743393424  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10204th epoch : 1.8048030190111033  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10205th epoch : 1.8047561138792827  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10206th epoch : 1.804709026728623  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10207th epoch : 1.8046617562791123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10208th epoch : 1.8046143012399607  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10209th epoch : 1.8045666603094916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10210th epoch : 1.8045188321750354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10211th epoch : 1.8044708155128175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10212th epoch : 1.8044226089878492  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10213th epoch : 1.8043742112538155  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10214th epoch : 1.8043256209529603  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10215th epoch : 1.8042768367159738  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10216th epoch : 1.8042278571618753  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10217th epoch : 1.8041786808978961  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10218th epoch : 1.8041293065193624  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10219th epoch : 1.8040797326095732  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10220th epoch : 1.8040299577396817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10221th epoch : 1.8039799804685708  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10222th epoch : 1.8039297993427303  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10223th epoch : 1.8038794128961315  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10224th epoch : 1.8038288196501004  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10225th epoch : 1.80377801811319  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10226th epoch : 1.8037270067810498  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10227th epoch : 1.8036757841362967  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10228th epoch : 1.8036243486483805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10229th epoch : 1.8035726987734517  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10230th epoch : 1.803520832954225  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10231th epoch : 1.8034687496198425  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10232th epoch : 1.8034164471857361  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10233th epoch : 1.8033639240534867  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10234th epoch : 1.8033111786106821  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10235th epoch : 1.8032582092307754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10236th epoch : 1.8032050142729386  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10237th epoch : 1.8031515920819168  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10238th epoch : 1.8030979409878802  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10239th epoch : 1.8030440593062742  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10240th epoch : 1.8029899453376677  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10241th epoch : 1.8029355973676005  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10242th epoch : 1.8028810136664277  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10243th epoch : 1.8028261924891635  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10244th epoch : 1.8027711320753226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10245th epoch : 1.8027158306487598  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10246th epoch : 1.8026602864175085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10247th epoch : 1.8026044975736164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10248th epoch : 1.8025484622929795  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10249th epoch : 1.802492178735175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10250th epoch : 1.802435645043292  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10251th epoch : 1.8023788593437589  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10252th epoch : 1.8023218197461712  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10253th epoch : 1.802264524343116  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10254th epoch : 1.8022069712099937  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10255th epoch : 1.8021491584048401  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10256th epoch : 1.8020910839681439  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10257th epoch : 1.8020327459226635  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10258th epoch : 1.8019741422732418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10259th epoch : 1.801915271006618  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10260th epoch : 1.8018561300912388  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10261th epoch : 1.8017967174770655  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10262th epoch : 1.80173703109538  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10263th epoch : 1.8016770688585888  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10264th epoch : 1.8016168286600251  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10265th epoch : 1.8015563083737467  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10266th epoch : 1.8014955058543334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10267th epoch : 1.8014344189366818  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10268th epoch : 1.8013730454357981  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10269th epoch : 1.8013113831465868  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10270th epoch : 1.8012494298436392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10271th epoch : 1.8011871832810182  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10272th epoch : 1.8011246411920405  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10273th epoch : 1.801061801289058  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10274th epoch : 1.8009986612632345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10275th epoch : 1.8009352187843208  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10276th epoch : 1.8008714715004286  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10277th epoch : 1.800807417037799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10278th epoch : 1.8007430530005708  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10279th epoch : 1.8006783769705454  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10280th epoch : 1.8006133865069485  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10281th epoch : 1.8005480791461896  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10282th epoch : 1.8004824524016194  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10283th epoch : 1.8004165037632829  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10284th epoch : 1.800350230697671  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10285th epoch : 1.800283630647469  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10286th epoch : 1.800216701031302  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10287th epoch : 1.8001494392434767  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10288th epoch : 1.800081842653723  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10289th epoch : 1.8000139086069296  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10290th epoch : 1.7999456344228772  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10291th epoch : 1.799877017395971  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10292th epoch : 1.7998080547949673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10293th epoch : 1.7997387438626982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10294th epoch : 1.7996690818157939  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10295th epoch : 1.799599065844401  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10296th epoch : 1.799528693111898  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10297th epoch : 1.799457960754606  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10298th epoch : 1.7993868658815  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10299th epoch : 1.7993154055739131  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10300th epoch : 1.7992435768852388  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10301th epoch : 1.7991713768406308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10302th epoch : 1.7990988024366974  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10303th epoch : 1.7990258506411958  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10304th epoch : 1.7989525183927186  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10305th epoch : 1.7988788026003812  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10306th epoch : 1.7988047001435024  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10307th epoch : 1.7987302078712832  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10308th epoch : 1.7986553226024817  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10309th epoch : 1.7985800411250839  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10310th epoch : 1.7985043601959718  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10311th epoch : 1.7984282765405866  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10312th epoch : 1.7983517868525893  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10313th epoch : 1.7982748877935175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10314th epoch : 1.798197575992437  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10315th epoch : 1.7981198480455913  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10316th epoch : 1.7980417005160472  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10317th epoch : 1.797963129933334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10318th epoch : 1.7978841327930835  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10319th epoch : 1.7978047055566602  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10320th epoch : 1.7977248446507927  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10321th epoch : 1.7976445464671982  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10322th epoch : 1.7975638073622038  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10323th epoch : 1.7974826236563632  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10324th epoch : 1.7974009916340703  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10325th epoch : 1.7973189075431673  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10326th epoch : 1.7972363675945495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10327th epoch : 1.7971533679617664  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10328th epoch : 1.7970699047806165  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10329th epoch : 1.7969859741487402  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10330th epoch : 1.7969015721252066  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10331th epoch : 1.796816694730097  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10332th epoch : 1.796731337944083  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10333th epoch : 1.7966454977080015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10334th epoch : 1.7965591699224241  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10335th epoch : 1.7964723504472222  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10336th epoch : 1.7963850351011281  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10337th epoch : 1.796297219661291  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10338th epoch : 1.7962088998628283  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10339th epoch : 1.7961200713983736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10340th epoch : 1.7960307299176173  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10341th epoch : 1.795940871026846  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10342th epoch : 1.795850490288474  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10343th epoch : 1.7957595832205722  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10344th epoch : 1.7956681452963912  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10345th epoch : 1.7955761719438799  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10346th epoch : 1.7954836585451992  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10347th epoch : 1.7953906004362308  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10348th epoch : 1.7952969929060811  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10349th epoch : 1.7952028311965806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10350th epoch : 1.7951081105017783  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10351th epoch : 1.7950128259674294  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10352th epoch : 1.794916972690481  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10353th epoch : 1.7948205457185509  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10354th epoch : 1.7947235400494015  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10355th epoch : 1.7946259506304092  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10356th epoch : 1.794527772358028  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10357th epoch : 1.794429000077249  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10358th epoch : 1.7943296285810544  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10359th epoch : 1.7942296526098653  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10360th epoch : 1.7941290668509868  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10361th epoch : 1.7940278659380455  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10362th epoch : 1.7939260444504228  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10363th epoch : 1.7938235969126841  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10364th epoch : 1.793720517794001  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10365th epoch : 1.793616801507569  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10366th epoch : 1.7935124424100217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10367th epoch : 1.7934074348008366  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10368th epoch : 1.7933017729217389  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10369th epoch : 1.7931954509560972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10370th epoch : 1.7930884630283175  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10371th epoch : 1.7929808032032284  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10372th epoch : 1.7928724654854635  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10373th epoch : 1.7927634438188387  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10374th epoch : 1.792653732085722  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10375th epoch : 1.7925433241064017  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10376th epoch : 1.7924322136384463  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10377th epoch : 1.7923203943760613  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10378th epoch : 1.7922078599494407  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10379th epoch : 1.7920946039241121  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10380th epoch : 1.791980619800279  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10381th epoch : 1.7918659010121554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10382th epoch : 1.791750440927299  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10383th epoch : 1.7916342328459363  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10384th epoch : 1.7915172700002835  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10385th epoch : 1.791399545553865  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10386th epoch : 1.791281052600824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10387th epoch : 1.7911617841652299  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10388th epoch : 1.791041733200381  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10389th epoch : 1.790920892588103  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10390th epoch : 1.7907992551380418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10391th epoch : 1.790676813586953  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10392th epoch : 1.790553560597986  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10393th epoch : 1.7904294887599652  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10394th epoch : 1.7903045905866655  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10395th epoch : 1.7901788585160847  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10396th epoch : 1.7900522849097116  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10397th epoch : 1.7899248620517898  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10398th epoch : 1.789796582148578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10399th epoch : 1.789667437327607  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10400th epoch : 1.7895374196369314  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10401th epoch : 1.7894065210443815  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10402th epoch : 1.7892747334368064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10403th epoch : 1.7891420486193195  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10404th epoch : 1.7890084583145367  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10405th epoch : 1.7888739541618137  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10406th epoch : 1.788738527716481  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10407th epoch : 1.7886021704490735  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10408th epoch : 1.7884648737445616  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10409th epoch : 1.7883266289015771  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10410th epoch : 1.7881874271316371  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10411th epoch : 1.7880472595583683  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10412th epoch : 1.787906117216727  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10413th epoch : 1.7877639910522187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10414th epoch : 1.7876208719201174  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10415th epoch : 1.7874767505846814  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10416th epoch : 1.7873316177183711  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10417th epoch : 1.787185463901064  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10418th epoch : 1.7870382796192705  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10419th epoch : 1.786890055265349  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10420th epoch : 1.7867407811367226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10421th epoch : 1.7865904474350935  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10422th epoch : 1.786439044265662  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10423th epoch : 1.7862865616363428  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10424th epoch : 1.786132989456985  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10425th epoch : 1.7859783175385942  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10426th epoch : 1.7858225355925534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10427th epoch : 1.7856656332298513  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10428th epoch : 1.7855075999603085  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10429th epoch : 1.7853484251918101  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10430th epoch : 1.7851880982295407  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10431th epoch : 1.7850266082752229  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10432th epoch : 1.7848639444263605  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10433th epoch : 1.7847000956754873  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10434th epoch : 1.7845350509094196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10435th epoch : 1.7843687989085153  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10436th epoch : 1.7842013283459393  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10437th epoch : 1.7840326277869343  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10438th epoch : 1.7838626856881001  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10439th epoch : 1.7836914903966796  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10440th epoch : 1.7835190301498538  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10441th epoch : 1.7833452930740434  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10442th epoch : 1.7831702671842233  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10443th epoch : 1.7829939403832424  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10444th epoch : 1.7828163004611581  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10445th epoch : 1.7826373350945788  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10446th epoch : 1.7824570318460184  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10447th epoch : 1.782275378163266  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10448th epoch : 1.7820923613787638  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10449th epoch : 1.7819079687090018  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10450th epoch : 1.7817221872539268  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10451th epoch : 1.7815350039963656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10452th epoch : 1.7813464058014623  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10453th epoch : 1.7811563794161362  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10454th epoch : 1.7809649114685533  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10455th epoch : 1.7807719884676174  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10456th epoch : 1.7805775968024795  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10457th epoch : 1.7803817227420682  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10458th epoch : 1.7801843524346392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10459th epoch : 1.7799854719073462  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10460th epoch : 1.779785067065836  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10461th epoch : 1.7795831236938642  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10462th epoch : 1.7793796274529372  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10463th epoch : 1.779174563881979  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10464th epoch : 1.7789679183970217  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10465th epoch : 1.7787596762909275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10466th epoch : 1.7785498227331347  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10467th epoch : 1.778338342769435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10468th epoch : 1.778125221321781  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10469th epoch : 1.7779104431881239  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10470th epoch : 1.7776939930422841  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10471th epoch : 1.7774758554338572  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10472th epoch : 1.7772560147881504  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10473th epoch : 1.7770344554061597  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10474th epoch : 1.7768111614645805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10475th epoch : 1.7765861170158583  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10476th epoch : 1.7763593059882787  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10477th epoch : 1.7761307121860972  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10478th epoch : 1.775900319289712  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10479th epoch : 1.7756681108558805  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10480th epoch : 1.7754340703179787  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10481th epoch : 1.7751981809863087  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10482th epoch : 1.7749604260484526  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10483th epoch : 1.7747207885696745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10484th epoch : 1.774479251493374  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10485th epoch : 1.774235797641591  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10486th epoch : 1.7739904097155617  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10487th epoch : 1.773743070296332  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10488th epoch : 1.7734937618454247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10489th epoch : 1.7732424667055653  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10490th epoch : 1.7729891671014657  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10491th epoch : 1.7727338451406696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10492th epoch : 1.772476482814459  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10493th epoch : 1.7722170619988247  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10494th epoch : 1.7719555644555023  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10495th epoch : 1.7716919718330737  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10496th epoch : 1.7714262656681388  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10497th epoch : 1.771158427386555  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10498th epoch : 1.770888438304751  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10499th epoch : 1.7706162796311107  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10500th epoch : 1.7703419324674339  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10501th epoch : 1.7700653778104738  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10502th epoch : 1.7697865965535509  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10503th epoch : 1.769505569488248  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10504th epoch : 1.7692222773061868  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10505th epoch : 1.7689367006008856  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10506th epoch : 1.7686488198697048  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10507th epoch : 1.768358615515877  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10508th epoch : 1.768066067850624  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10509th epoch : 1.7677711570953665  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10510th epoch : 1.7674738633840226  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10511th epoch : 1.7671741667654006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10512th epoch : 1.7668720472056856  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10513th epoch : 1.7665674845910229  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10514th epoch : 1.7662604587301995  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10515th epoch : 1.7659509493574237  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10516th epoch : 1.765638936135206  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10517th epoch : 1.765324398657345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10518th epoch : 1.7650073164520128  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10519th epoch : 1.7646876689849493  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10520th epoch : 1.764365435662763  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10521th epoch : 1.764040595836338  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10522th epoch : 1.7637131288043546  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10523th epoch : 1.7633830138169164  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10524th epoch : 1.7630502300792943  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10525th epoch : 1.7627147567557813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10526th epoch : 1.7623765729736631  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10527th epoch : 1.7620356578273053  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10528th epoch : 1.7616919903823578  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10529th epoch : 1.7613455496800772  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10530th epoch : 1.7609963147417689  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10531th epoch : 1.7606442645733495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10532th epoch : 1.7602893781700313  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10533th epoch : 1.759931634521127  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10534th epoch : 1.7595710126149804  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10535th epoch : 1.7592074914440174  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10536th epoch : 1.7588410500099243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10537th epoch : 1.7584716673289489  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10538th epoch : 1.7580993224373276  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10539th epoch : 1.7577239943968381  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10540th epoch : 1.7573456623004793  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10541th epoch : 1.7569643052782746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10542th epoch : 1.7565799025032047  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10543th epoch : 1.7561924331972654  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10544th epoch : 1.7558018766376495  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10545th epoch : 1.7554082121630596  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10546th epoch : 1.7550114191801418  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10547th epoch : 1.7546114771700478  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10548th epoch : 1.7542083656951202  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10549th epoch : 1.7538020644057029  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10550th epoch : 1.7533925530470744  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10551th epoch : 1.7529798114665034  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10552th epoch : 1.7525638196204267  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10553th epoch : 1.7521445575817465  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10554th epoch : 1.7517220055472469  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10555th epoch : 1.7512961438451287  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10556th epoch : 1.7508669529426595  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10557th epoch : 1.7504344134539382  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10558th epoch : 1.7499985061477723  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10559th epoch : 1.7495592119556653  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10560th epoch : 1.7491165119799135  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10561th epoch : 1.7486703875018066  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10562th epoch : 1.748220819989935  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10563th epoch : 1.7477677911085956  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10564th epoch : 1.7473112827262969  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10565th epoch : 1.7468512769243592  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10566th epoch : 1.7463877560056074  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10567th epoch : 1.7459207025031527  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10568th epoch : 1.7454500991892596  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10569th epoch : 1.7449759290842963  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10570th epoch : 1.744498175465761  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10571th epoch : 1.7440168218773853  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10572th epoch : 1.7435318521383067  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10573th epoch : 1.7430432503523086  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10574th epoch : 1.7425510009171201  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10575th epoch : 1.7420550885337753  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10576th epoch : 1.7415554982160248  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10577th epoch : 1.7410522152997945  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10578th epoch : 1.7405452254526879  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10579th epoch : 1.740034514683526  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10580th epoch : 1.7395200693519206  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10581th epoch : 1.7390018761778725  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10582th epoch : 1.7384799222513938  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10583th epoch : 1.7379541950421438  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10584th epoch : 1.7374246824090769  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10585th epoch : 1.7368913726100916  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10586th epoch : 1.7363542543116806  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10587th epoch : 1.7358133165985687  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10588th epoch : 1.73526854898334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10589th epoch : 1.734719941416039  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10590th epoch : 1.7341674842937485  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10591th epoch : 1.7336111684701276  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10592th epoch : 1.7330509852649136  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10593th epoch : 1.7324869264733704  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10594th epoch : 1.7319189843756846  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10595th epoch : 1.731347151746297  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10596th epoch : 1.7307714218631667  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10597th epoch : 1.730191788516954  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10598th epoch : 1.7296082460201239  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10599th epoch : 1.7290207892159537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10600th epoch : 1.7284294134874432  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10601th epoch : 1.7278341147661187  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10602th epoch : 1.7272348895407215  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10603th epoch : 1.7266317348657751  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10604th epoch : 1.7260246483700241  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10605th epoch : 1.7254136282647354  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10606th epoch : 1.7247986733518552  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10607th epoch : 1.7241797830320145  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10608th epoch : 1.7235569573123746  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10609th epoch : 1.722930196814307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10610th epoch : 1.7222995027808976  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10611th epoch : 1.7216648770842709  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10612th epoch : 1.721026322232723  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10613th epoch : 1.72038384137766  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10614th epoch : 1.7197374383203334  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10615th epoch : 1.7190871175183622  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10616th epoch : 1.718432884092041  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10617th epoch : 1.7177747438304205  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10618th epoch : 1.7171127031971587  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10619th epoch : 1.716446769336133  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10620th epoch : 1.7157769500768076  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10621th epoch : 1.715103253939352  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10622th epoch : 1.7144256901394987  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10623th epoch : 1.713744268593141  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10624th epoch : 1.7130589999206598  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10625th epoch : 1.7123698954509745  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10626th epoch : 1.7116769672253167  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10627th epoch : 1.7109802280007134  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10628th epoch : 1.7102796912531824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10629th epoch : 1.7095753711806305  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10630th epoch : 1.7088672827054505  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10631th epoch : 1.7081554414768123  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10632th epoch : 1.7074398638726453  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10633th epoch : 1.7067205670013068  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10634th epoch : 1.705997568702931  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10635th epoch : 1.7052708875504592  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10636th epoch : 1.7045405428503437  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10637th epoch : 1.7038065546429233  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10638th epoch : 1.7030689437024709  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10639th epoch : 1.7023277315369043  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10640th epoch : 1.7015829403871656  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10641th epoch : 1.7008345932262594  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10642th epoch : 1.7000827137579535  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10643th epoch : 1.69932732641514  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10644th epoch : 1.6985684563578531  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10645th epoch : 1.697806129470944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10646th epoch : 1.6970403723614127  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10647th epoch : 1.6962712123553991  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10648th epoch : 1.6954986774948244  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10649th epoch : 1.694722796533696  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10650th epoch : 1.6939435989340639  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10651th epoch : 1.693161114861639  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10652th epoch : 1.6923753751810688  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10653th epoch : 1.6915864114508743  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10654th epoch : 1.690794255918049  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10655th epoch : 1.6899989415123229  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10656th epoch : 1.6892005018400924  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10657th epoch : 1.6883989711780203  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10658th epoch : 1.6875943844663073  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10659th epoch : 1.6867867773016392  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10660th epoch : 1.685976185929813  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10661th epoch : 1.685162647238044  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10662th epoch : 1.6843461987469621  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10663th epoch : 1.683526878602295  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10664th epoch : 1.68270472556625  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10665th epoch : 1.6818797790085924  Training Accuracy:0.8214285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 10666th epoch : 1.6810520788974315  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10667th epoch : 1.680221665789714  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10668th epoch : 1.6793885808214346  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10669th epoch : 1.6785528656975666  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10670th epoch : 1.6777145626817196  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10671th epoch : 1.6768737145855312  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10672th epoch : 1.6760303647577965  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10673th epoch : 1.6751845570733446  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10674th epoch : 1.6743363359216665  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10675th epoch : 1.6734857461953054  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10676th epoch : 1.6726328332780092  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10677th epoch : 1.671777643032661  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10678th epoch : 1.6709202217889874  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10679th epoch : 1.6700606163310587  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10680th epoch : 1.6691988738845833  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10681th epoch : 1.6683350421040082  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10682th epoch : 1.6674691690594297  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10683th epoch : 1.6666013032233271  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10684th epoch : 1.6657314934571243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10685th epoch : 1.6648597889975876  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10686th epoch : 1.663986239443069  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10687th epoch : 1.6631108947396052  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10688th epoch : 1.662233805166878  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10689th epoch : 1.661355021324046  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10690th epoch : 1.6604745941154555  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10691th epoch : 1.659592574736243  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10692th epoch : 1.6587090146578316  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10693th epoch : 1.657823965613337  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10694th epoch : 1.6569374795828864  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10695th epoch : 1.6560496087788645  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10696th epoch : 1.65516040563109  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10697th epoch : 1.6542699227719353  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10698th epoch : 1.6533782130213979  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10699th epoch : 1.6524853293721307  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10700th epoch : 1.6515913249744414  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10701th epoch : 1.6506962531212706  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10702th epoch : 1.6498001672331548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10703th epoch : 1.6489031208431852  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10704th epoch : 1.6480051675819716  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10705th epoch : 1.647106361162617  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10706th epoch : 1.6462067553657151  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10707th epoch : 1.6453064040243768  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10708th epoch : 1.6444053610092937  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10709th epoch : 1.6435036802138505  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10710th epoch : 1.6426014155392907  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10711th epoch : 1.641698620879944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10712th epoch : 1.6407953501085275  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10713th epoch : 1.6398916570615227  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10714th epoch : 1.6389875955246407  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10715th epoch : 1.6380832192183814  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10716th epoch : 1.6371785817836944  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10717th epoch : 1.6362737367677491  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10718th epoch : 1.635368737609821  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10719th epoch : 1.6344636376273014  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10720th epoch : 1.6335584900018385  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10721th epoch : 1.6326533477656147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10722th epoch : 1.6317482637877685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10723th epoch : 1.6308432907609665  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10724th epoch : 1.6299384811881321  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10725th epoch : 1.6290338873693373  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10726th epoch : 1.6281295613888633  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10727th epoch : 1.627225555102435  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10728th epoch : 1.6263219201246362  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10729th epoch : 1.6254187078165112  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10730th epoch : 1.624515969273355  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10731th epoch : 1.6236137553127026  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10732th epoch : 1.6227121164625147  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10733th epoch : 1.6218111029495736  Training Accuracy:0.8214285714285714\n",
      "The training loss at 10734th epoch : 1.6209107646880851  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10735th epoch : 1.6200111512684963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10736th epoch : 1.619112311946531  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10737th epoch : 1.6182142956324472  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10738th epoch : 1.617317150880521  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10739th epoch : 1.6164209258787579  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10740th epoch : 1.6155256684388386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10741th epoch : 1.6146314259862986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10742th epoch : 1.6137382455509472  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10743th epoch : 1.6128461737575277  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10744th epoch : 1.611955256816619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10745th epoch : 1.6110655405157872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10746th epoch : 1.6101770702109792  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10747th epoch : 1.609289890818172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10748th epoch : 1.6084040468052694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10749th epoch : 1.607519582184252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10750th epoch : 1.6066365405035847  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10751th epoch : 1.6057549648408738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10752th epoch : 1.6048748977957856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10753th epoch : 1.6039963814832192  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10754th epoch : 1.6031194575267367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10755th epoch : 1.6022441670522525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10756th epoch : 1.6013705506819789  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10757th epoch : 1.6004986485286312  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10758th epoch : 1.5996285001898896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10759th epoch : 1.5987601447431181  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10760th epoch : 1.5978936207403422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10761th epoch : 1.5970289662034807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10762th epoch : 1.5961662186198327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10763th epoch : 1.5953054149378219  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10764th epoch : 1.5944465915629893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10765th epoch : 1.5935897843542424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10766th epoch : 1.5927350286203512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10767th epoch : 1.5918823591166944  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10768th epoch : 1.5910318100422522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10769th epoch : 1.5901834150368448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10770th epoch : 1.5893372071786118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10771th epoch : 1.5884932189817351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10772th epoch : 1.5876514823943975  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10773th epoch : 1.5868120287969794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10774th epoch : 1.5859748890004883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10775th epoch : 1.5851400932452184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10776th epoch : 1.5843076711996393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10777th epoch : 1.583477651959509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10778th epoch : 1.5826500640472099  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10779th epoch : 1.5818249354113028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10780th epoch : 1.581002293426298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10781th epoch : 1.5801821648926384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10782th epoch : 1.579364576036892  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10783th epoch : 1.5785495525121502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10784th epoch : 1.5777371193986292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10785th epoch : 1.5769273012044684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10786th epoch : 1.5761201218667273  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10787th epoch : 1.5753156047525698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10788th epoch : 1.5745137726606393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10789th epoch : 1.5737146478226165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10790th epoch : 1.5729182519049576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10791th epoch : 1.572124606010808  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10792th epoch : 1.5713337306820894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10793th epoch : 1.5705456459017533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10794th epoch : 1.5697603710962007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10795th epoch : 1.5689779251378608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10796th epoch : 1.5681983263479249  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10797th epoch : 1.5674215924992345  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10798th epoch : 1.5666477408193156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10799th epoch : 1.5658767879935565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10800th epoch : 1.5651087501685264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10801th epoch : 1.5643436429554285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10802th epoch : 1.5635814814336841  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10803th epoch : 1.5628222801546454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10804th epoch : 1.5620660531454291  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10805th epoch : 1.5613128139128702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10806th epoch : 1.5605625754475903  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10807th epoch : 1.5598153502281762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10808th epoch : 1.5590711502254648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10809th epoch : 1.5583299869069311  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10810th epoch : 1.5575918712411738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10811th epoch : 1.5568568137024958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10812th epoch : 1.556124824275574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10813th epoch : 1.5553959124602168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10814th epoch : 1.554670087276202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10815th epoch : 1.5539473572681963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10816th epoch : 1.5532277305107454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10817th epoch : 1.552511214613338  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10818th epoch : 1.5517978167255353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10819th epoch : 1.5510875435421638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10820th epoch : 1.5503804013085682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10821th epoch : 1.5496763958259194  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10822th epoch : 1.548975532456575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10823th epoch : 1.5482778161294888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10824th epoch : 1.5475832513456647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10825th epoch : 1.5468918421836535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10826th epoch : 1.546203592305087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10827th epoch : 1.545518504960247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10828th epoch : 1.5448365829936668  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10829th epoch : 1.544157828849761  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10830th epoch : 1.54348224457848  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10831th epoch : 1.5428098318409873  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10832th epoch : 1.5421405919153552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10833th epoch : 1.5414745257022784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10834th epoch : 1.5408116337307987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10835th epoch : 1.5401519161640411  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10836th epoch : 1.5394953728049583  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10837th epoch : 1.5388420031020782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10838th epoch : 1.538191806155256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10839th epoch : 1.5375447807214235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10840th epoch : 1.536900925220337  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10841th epoch : 1.5362602377403196  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10842th epoch : 1.5356227160439953  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10843th epoch : 1.5349883575740138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10844th epoch : 1.5343571594587608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10845th epoch : 1.5337291185180573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10846th epoch : 1.5331042312688383  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10847th epoch : 1.5324824939308153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10848th epoch : 1.5318639024321161  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10849th epoch : 1.5312484524149041  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10850th epoch : 1.5306361392409706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10851th epoch : 1.5300269579973016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10852th epoch : 1.529420903501616  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10853th epoch : 1.5288179703078744  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10854th epoch : 1.5282181527117558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10855th epoch : 1.5276214447561014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10856th epoch : 1.5270278402363227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10857th epoch : 1.5264373327057748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10858th epoch : 1.5258499154810912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10859th epoch : 1.5252655816474805  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10860th epoch : 1.5246843240639811  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10861th epoch : 1.524106135368677  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10862th epoch : 1.5235310079838689  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10863th epoch : 1.5229589341212026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10864th epoch : 1.5223899057867527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10865th epoch : 1.5218239147860588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10866th epoch : 1.5212609527291185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10867th epoch : 1.5207010110353285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10868th epoch : 1.5201440809383802  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10869th epoch : 1.5195901534911052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10870th epoch : 1.5190392195702695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10871th epoch : 1.5184912698813195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10872th epoch : 1.5179462949630733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10873th epoch : 1.5174042851923626  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10874th epoch : 1.516865230788621  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10875th epoch : 1.5163291218184187  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10876th epoch : 1.5157959481999443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10877th epoch : 1.515265699707432  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10878th epoch : 1.514738365975535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10879th epoch : 1.5142139365036418  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10880th epoch : 1.513692400660142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10881th epoch : 1.513173747686631  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10882th epoch : 1.512657966702063  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10883th epoch : 1.5121450467068462  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10884th epoch : 1.5116349765868837  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10885th epoch : 1.5111277451175547  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10886th epoch : 1.5106233409676433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10887th epoch : 1.510121752703209  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10888th epoch : 1.5096229687913996  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10889th epoch : 1.5091269776042102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10890th epoch : 1.5086337674221835  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10891th epoch : 1.5081433264380548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10892th epoch : 1.50765564276034  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10893th epoch : 1.5071707044168683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10894th epoch : 1.5066884993582565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10895th epoch : 1.5062090154613306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10896th epoch : 1.5057322405324882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10897th epoch : 1.5052581623110075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10898th epoch : 1.5047867684722998  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10899th epoch : 1.504318046631107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10900th epoch : 1.5038519843446443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10901th epoch : 1.5033885691156872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10902th epoch : 1.502927788395606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10903th epoch : 1.502469629587344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10904th epoch : 1.502014080048344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10905th epoch : 1.5015611270934188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10906th epoch : 1.5011107579975713  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10907th epoch : 1.5006629599987606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10908th epoch : 1.5002177203006148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10909th epoch : 1.499775026075094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10910th epoch : 1.4993348644651  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10911th epoch : 1.498897222587035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10912th epoch : 1.4984620875333117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10913th epoch : 1.49802944637481  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10914th epoch : 1.497599286163287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10915th epoch : 1.4971715939337342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10916th epoch : 1.49674635670669  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10917th epoch : 1.4963235614905008  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10918th epoch : 1.4959031952835347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10919th epoch : 1.4954852450763494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10920th epoch : 1.4950696978538112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10921th epoch : 1.4946565405971692  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10922th epoch : 1.4942457602860832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10923th epoch : 1.4938373439006054  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10924th epoch : 1.4934312784231185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10925th epoch : 1.4930275508402298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10926th epoch : 1.4926261481446197  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10927th epoch : 1.4922270573368492  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10928th epoch : 1.4918302654271238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10929th epoch : 1.4914357594370145  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10930th epoch : 1.4910435264011386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10931th epoch : 1.4906535533687992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10932th epoch : 1.490265827405584  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10933th epoch : 1.4898803355949233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10934th epoch : 1.4894970650396109  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10935th epoch : 1.4891160028632837  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10936th epoch : 1.488737136211865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10937th epoch : 1.4883604522549692  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10938th epoch : 1.487985938187269  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10939th epoch : 1.4876135812298272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10940th epoch : 1.487243368631391  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10941th epoch : 1.486875287669652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10942th epoch : 1.486509325652471  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10943th epoch : 1.486145469919067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10944th epoch : 1.4857837078411753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10945th epoch : 1.4854240268241692  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10946th epoch : 1.4850664143081498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10947th epoch : 1.4847108577690058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10948th epoch : 1.4843573447194376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10949th epoch : 1.4840058627099537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10950th epoch : 1.4836563993298346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10951th epoch : 1.4833089422080667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10952th epoch : 1.4829634790142474  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10953th epoch : 1.4826199974594598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10954th epoch : 1.4822784852971205  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10955th epoch : 1.4819389303237978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10956th epoch : 1.4816013203800025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10957th epoch : 1.4812656433509528  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10958th epoch : 1.4809318871673107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10959th epoch : 1.480600039805895  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10960th epoch : 1.4802700892903644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10961th epoch : 1.4799420236918808  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10962th epoch : 1.4796158311297436  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10963th epoch : 1.4792914997720017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10964th epoch : 1.4789690178360415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10965th epoch : 1.4786483735891518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10966th epoch : 1.4783295553490652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10967th epoch : 1.4780125514844782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10968th epoch : 1.4776973504155482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10969th epoch : 1.4773839406143698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10970th epoch : 1.4770723106054304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10971th epoch : 1.4767624489660438  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10972th epoch : 1.476454344326765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10973th epoch : 1.4761479853717845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10974th epoch : 1.4758433608393036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10975th epoch : 1.4755404595218904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10976th epoch : 1.4752392702668178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10977th epoch : 1.4749397819763828  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10978th epoch : 1.474641983608208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10979th epoch : 1.474345864175527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10980th epoch : 1.4740514127474504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10981th epoch : 1.473758618449218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10982th epoch : 1.4734674704624329  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10983th epoch : 1.4731779580252797  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10984th epoch : 1.4728900704327292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10985th epoch : 1.472603797036725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10986th epoch : 1.4723191272463574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10987th epoch : 1.4720360505280228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10988th epoch : 1.471754556405568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10989th epoch : 1.471474634460421  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10990th epoch : 1.4711962743317089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10991th epoch : 1.4709194657163625  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10992th epoch : 1.4706441983692071  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10993th epoch : 1.470370462103043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10994th epoch : 1.470098246788711  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10995th epoch : 1.469827542355149  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10996th epoch : 1.4695583387894342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10997th epoch : 1.4692906261368162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10998th epoch : 1.469024394500738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 10999th epoch : 1.468759634042846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11000th epoch : 1.4684963349829911  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11001th epoch : 1.4682344875992184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11002th epoch : 1.4679740822277467  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11003th epoch : 1.4677151092629392  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11004th epoch : 1.4674575591572654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11005th epoch : 1.4672014224212515  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11006th epoch : 1.466946689623425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11007th epoch : 1.4666933513902485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11008th epoch : 1.466441398406046  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11009th epoch : 1.466190821412921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11010th epoch : 1.4659416112106662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11011th epoch : 1.4656937586566667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11012th epoch : 1.4654472546657944  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11013th epoch : 1.4652020902102958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11014th epoch : 1.464958256319673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11015th epoch : 1.4647157440805576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11016th epoch : 1.464474544636578  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11017th epoch : 1.46423464918822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11018th epoch : 1.4639960489926833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11019th epoch : 1.4637587353637274  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11020th epoch : 1.463522699671517  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11021th epoch : 1.4632879333424582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11022th epoch : 1.4630544278590312  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11023th epoch : 1.462822174759616  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11024th epoch : 1.462591165638315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11025th epoch : 1.462361392144769  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11026th epoch : 1.462132845983969  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11027th epoch : 1.4619055189160652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11028th epoch : 1.4616794027561673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11029th epoch : 1.4614544893741457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11030th epoch : 1.4612307706944245  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11031th epoch : 1.4610082386957737  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11032th epoch : 1.460786885411094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11033th epoch : 1.460566702927202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11034th epoch : 1.4603476833846094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11035th epoch : 1.4601298189772987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11036th epoch : 1.4599131019524967  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11037th epoch : 1.459697524610445  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11038th epoch : 1.4594830793041667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11039th epoch : 1.4592697584392302  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11040th epoch : 1.4590575544735118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11041th epoch : 1.458846459916953  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11042th epoch : 1.4586364673313186  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11043th epoch : 1.4584275693299498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11044th epoch : 1.458219758577516  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11045th epoch : 1.458013027789765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11046th epoch : 1.4578073697332699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11047th epoch : 1.4576027772251754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11048th epoch : 1.457399243132942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11049th epoch : 1.4571967603740865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11050th epoch : 1.4569953219159248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11051th epoch : 1.4567949207753093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11052th epoch : 1.4565955500183667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11053th epoch : 1.4563972027602348  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11054th epoch : 1.4561998721647968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11055th epoch : 1.4560035514444156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11056th epoch : 1.4558082338596658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11057th epoch : 1.4556139127190666  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11058th epoch : 1.4554205813788108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11059th epoch : 1.4552282332424962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11060th epoch : 1.455036861760854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11061th epoch : 1.4548464604314775  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11062th epoch : 1.45465702279855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11063th epoch : 1.4544685424525712  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11064th epoch : 1.4542810130300852  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11065th epoch : 1.4540944282134058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11066th epoch : 1.453908781730343  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11067th epoch : 1.4537240673539291  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11068th epoch : 1.4535402789021423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11069th epoch : 1.453357410237634  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11070th epoch : 1.4531754552674536  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11071th epoch : 1.4529944079427721  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11072th epoch : 1.4528142622586089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11073th epoch : 1.452635012253556  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11074th epoch : 1.4524566520095035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11075th epoch : 1.4522791756513647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11076th epoch : 1.4521025773468017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11077th epoch : 1.451926851305952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11078th epoch : 1.4517519917811532  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11079th epoch : 1.4515779930666703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11080th epoch : 1.4514048494984222  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11081th epoch : 1.4512325554537095  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11082th epoch : 1.451061105350941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11083th epoch : 1.450890493649363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11084th epoch : 1.4507207148487868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11085th epoch : 1.45055176348932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11086th epoch : 1.4503836341510934  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11087th epoch : 1.4502163214539947  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11088th epoch : 1.4500498200573968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11089th epoch : 1.449884124659892  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11090th epoch : 1.4497192299990231  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11091th epoch : 1.4495551308510177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11092th epoch : 1.4493918220305217  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11093th epoch : 1.449229298390335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11094th epoch : 1.4490675548211465  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11095th epoch : 1.4489065862512718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11096th epoch : 1.4487463876463904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11097th epoch : 1.4485869540092842  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11098th epoch : 1.448428280379577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11099th epoch : 1.448270361833475  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11100th epoch : 1.4481131934835085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11101th epoch : 1.4479567704782743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11102th epoch : 1.4478010880021794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11103th epoch : 1.4476461412751853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11104th epoch : 1.4474919255525531  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11105th epoch : 1.4473384361245922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11106th epoch : 1.4471856683164057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11107th epoch : 1.4470336174876413  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11108th epoch : 1.44688227903224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11109th epoch : 1.4467316483781887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11110th epoch : 1.446581720987272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11111th epoch : 1.446432492354825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11112th epoch : 1.4462839580094897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11113th epoch : 1.44613611351297  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11114th epoch : 1.445988954459789  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11115th epoch : 1.445842476477048  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11116th epoch : 1.4456966752241853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11117th epoch : 1.4455515463927382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11118th epoch : 1.4454070857061043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11119th epoch : 1.4452632889193053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11120th epoch : 1.4451201518187522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11121th epoch : 1.4449776702220105  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11122th epoch : 1.444835839977568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11123th epoch : 1.444694656964604  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11124th epoch : 1.4445541170927574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11125th epoch : 1.4444142163019  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11126th epoch : 1.444274950561908  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11127th epoch : 1.4441363158724352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11128th epoch : 1.4439983082626902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11129th epoch : 1.4438609237912106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11130th epoch : 1.4437241585456424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11131th epoch : 1.4435880086425186  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11132th epoch : 1.4434524702270397  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11133th epoch : 1.4433175394728561  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11134th epoch : 1.4431832125818498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11135th epoch : 1.443049485783921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11136th epoch : 1.4429163553367723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11137th epoch : 1.4427838175256968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11138th epoch : 1.4426518686633667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11139th epoch : 1.4425205050896224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11140th epoch : 1.4423897231712648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11141th epoch : 1.4422595193018473  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11142th epoch : 1.4421298899014698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11143th epoch : 1.4420008314165749  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11144th epoch : 1.4418723403197429  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11145th epoch : 1.4417444131094912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11146th epoch : 1.4416170463100733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11147th epoch : 1.4414902364712796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11148th epoch : 1.4413639801682387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11149th epoch : 1.4412382740012222  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11150th epoch : 1.4411131145954477  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11151th epoch : 1.4409884986008865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11152th epoch : 1.4408644226920704  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11153th epoch : 1.4407408835678994  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11154th epoch : 1.4406178779514538  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11155th epoch : 1.4404954025898038  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11156th epoch : 1.440373454253823  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11157th epoch : 1.4402520297380024  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11158th epoch : 1.4401311258602656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11159th epoch : 1.4400107394617854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11160th epoch : 1.4398908674068023  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11161th epoch : 1.4397715065824428  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11162th epoch : 1.4396526538985406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11163th epoch : 1.4395343062874586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11164th epoch : 1.4394164607039117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11165th epoch : 1.439299114124791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11166th epoch : 1.4391822635489901  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11167th epoch : 1.4390659059972322  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11168th epoch : 1.438950038511897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11169th epoch : 1.4388346581568516  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11170th epoch : 1.4387197620172818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11171th epoch : 1.4386053471995217  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11172th epoch : 1.4384914108308893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11173th epoch : 1.4383779500595204  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11174th epoch : 1.4382649620542036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11175th epoch : 1.4381524440042184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11176th epoch : 1.4380403931191725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11177th epoch : 1.4379288066288423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11178th epoch : 1.4378176817830122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11179th epoch : 1.4377070158513174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11180th epoch : 1.4375968061230875  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11181th epoch : 1.437487049907189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11182th epoch : 1.4373777445318723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11183th epoch : 1.4372688873446182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11184th epoch : 1.437160475711985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11185th epoch : 1.4370525070194577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11186th epoch : 1.4369449786712993  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11187th epoch : 1.4368378880904003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11188th epoch : 1.4367312327181323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11189th epoch : 1.4366250100142017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11190th epoch : 1.4365192174565042  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11191th epoch : 1.43641385254098  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 11192th epoch : 1.4363089127814723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11193th epoch : 1.4362043957095845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11194th epoch : 1.4361002988745393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11195th epoch : 1.4359966198430394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11196th epoch : 1.4358933561991298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11197th epoch : 1.4357905055440583  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11198th epoch : 1.4356880654961415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11199th epoch : 1.4355860336906274  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11200th epoch : 1.4354844077795632  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11201th epoch : 1.4353831854316603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11202th epoch : 1.4352823643321637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11203th epoch : 1.43518194218272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11204th epoch : 1.4350819167012487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11205th epoch : 1.4349822856218113  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11206th epoch : 1.4348830466944849  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11207th epoch : 1.4347841976852351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11208th epoch : 1.4346857363757903  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11209th epoch : 1.4345876605635155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11210th epoch : 1.4344899680612906  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11211th epoch : 1.434392656697386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11212th epoch : 1.4342957243153411  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11213th epoch : 1.4341991687738438  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11214th epoch : 1.4341029879466103  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11215th epoch : 1.4340071797222664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11216th epoch : 1.433911742004229  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11217th epoch : 1.4338166727105905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11218th epoch : 1.4337219697740007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11219th epoch : 1.4336276311415532  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11220th epoch : 1.4335336547746715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11221th epoch : 1.4334400386489945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11222th epoch : 1.4333467807542646  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11223th epoch : 1.4332538790942173  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11224th epoch : 1.4331613316864695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11225th epoch : 1.4330691365624106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11226th epoch : 1.4329772917670938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11227th epoch : 1.4328857953591279  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11228th epoch : 1.4327946454105707  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11229th epoch : 1.4327038400068233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11230th epoch : 1.4326133772465244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11231th epoch : 1.4325232552414464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11232th epoch : 1.4324334721163916  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11233th epoch : 1.43234402600909  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11234th epoch : 1.432254915070098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11235th epoch : 1.432166137462696  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11236th epoch : 1.43207769136279  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11237th epoch : 1.4319895749588114  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11238th epoch : 1.431901786451619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11239th epoch : 1.4318143240544015  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11240th epoch : 1.4317271859925804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11241th epoch : 1.431640370503714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11242th epoch : 1.4315538758374027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11243th epoch : 1.4314677002551939  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11244th epoch : 1.4313818420304887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11245th epoch : 1.43129629944845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11246th epoch : 1.4312110708059085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11247th epoch : 1.4311261544112728  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11248th epoch : 1.431041548584439  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11249th epoch : 1.4309572516566997  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11250th epoch : 1.4308732619706563  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11251th epoch : 1.4307895778801296  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11252th epoch : 1.430706197750073  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11253th epoch : 1.4306231199564854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11254th epoch : 1.4305403428863248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11255th epoch : 1.4304578649374236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11256th epoch : 1.430375684518403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11257th epoch : 1.4302938000485896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11258th epoch : 1.4302122099579324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11259th epoch : 1.4301309126869195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11260th epoch : 1.4300499066864962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11261th epoch : 1.429969190417985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11262th epoch : 1.4298887623530032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11263th epoch : 1.429808620973385  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11264th epoch : 1.4297287647711001  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11265th epoch : 1.4296491922481773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11266th epoch : 1.4295699019166257  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11267th epoch : 1.4294908922983571  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11268th epoch : 1.4294121619251097  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11269th epoch : 1.4293337093383722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11270th epoch : 1.429255533089309  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11271th epoch : 1.4291776317386848  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11272th epoch : 1.4291000038567907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11273th epoch : 1.4290226480233703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11274th epoch : 1.4289455628275485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11275th epoch : 1.4288687468677574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11276th epoch : 1.4287921987516654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11277th epoch : 1.428715917096107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11278th epoch : 1.4286399005270107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11279th epoch : 1.4285641476793305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11280th epoch : 1.4284886571969766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11281th epoch : 1.4284134277327458  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11282th epoch : 1.4283384579482543  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11283th epoch : 1.4282637465138694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11284th epoch : 1.4281892921086436  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11285th epoch : 1.4281150934202471  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11286th epoch : 1.4280411491449025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11287th epoch : 1.4279674579873196  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11288th epoch : 1.4278940186606301  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11289th epoch : 1.427820829886324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11290th epoch : 1.4277478903941856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11291th epoch : 1.4276751989222303  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11292th epoch : 1.427602754216642  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11293th epoch : 1.4275305550317117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11294th epoch : 1.4274586001297744  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11295th epoch : 1.4273868882811493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11296th epoch : 1.4273154182640795  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11297th epoch : 1.42724418886467  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11298th epoch : 1.427173198876831  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11299th epoch : 1.4271024471022158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11300th epoch : 1.427031932350165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11301th epoch : 1.4269616534376464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11302th epoch : 1.4268916091891986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11303th epoch : 1.4268217984368732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11304th epoch : 1.4267522200201785  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11305th epoch : 1.4266828727860235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11306th epoch : 1.4266137555886615  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11307th epoch : 1.426544867289636  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11308th epoch : 1.4264762067577244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11309th epoch : 1.4264077728688853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11310th epoch : 1.4263395645062036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11311th epoch : 1.4262715805598372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11312th epoch : 1.4262038199269644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11313th epoch : 1.4261362815117309  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11314th epoch : 1.4260689642251982  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11315th epoch : 1.4260018669852914  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11316th epoch : 1.4259349887167487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11317th epoch : 1.4258683283510694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11318th epoch : 1.4258018848264646  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11319th epoch : 1.425735657087807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11320th epoch : 1.4256696440865808  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11321th epoch : 1.4256038447808335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11322th epoch : 1.425538258135126  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11323th epoch : 1.4254728831204848  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11324th epoch : 1.4254077187143548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11325th epoch : 1.4253427639005503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11326th epoch : 1.4252780176692088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11327th epoch : 1.4252134790167446  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11328th epoch : 1.4251491469458009  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11329th epoch : 1.4250850204652055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11330th epoch : 1.425021098589924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11331th epoch : 1.4249573803410156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11332th epoch : 1.4248938647455869  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11333th epoch : 1.4248305508367485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11334th epoch : 1.4247674376535708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11335th epoch : 1.4247045242410397  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11336th epoch : 1.4246418096500129  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11337th epoch : 1.4245792929371783  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11338th epoch : 1.4245169731650102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11339th epoch : 1.4244548494017266  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11340th epoch : 1.4243929207212482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11341th epoch : 1.4243311862031565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11342th epoch : 1.4242696449326517  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11343th epoch : 1.4242082960005127  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11344th epoch : 1.4241471385030562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11345th epoch : 1.4240861715420958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11346th epoch : 1.4240253942249033  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11347th epoch : 1.4239648056641674  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11348th epoch : 1.4239044049779557  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11349th epoch : 1.423844191289675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11350th epoch : 1.4237841637280335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11351th epoch : 1.4237243214270008  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11352th epoch : 1.4236646635257715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11353th epoch : 1.4236051891687265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11354th epoch : 1.4235458975053963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11355th epoch : 1.4234867876904227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11356th epoch : 1.4234278588835232  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11357th epoch : 1.4233691102494541  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11358th epoch : 1.4233105409579736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11359th epoch : 1.4232521501838067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11360th epoch : 1.4231939371066094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11361th epoch : 1.4231359009109328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11362th epoch : 1.423078040786189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11363th epoch : 1.423020355926615  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11364th epoch : 1.4229628455312393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11365th epoch : 1.4229055088038478  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11366th epoch : 1.4228483449529483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11367th epoch : 1.4227913531917389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11368th epoch : 1.4227345327380732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11369th epoch : 1.422677882814427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11370th epoch : 1.4226214026478672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11371th epoch : 1.422565091470017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11372th epoch : 1.4225089485170248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11373th epoch : 1.4224529730295319  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11374th epoch : 1.4223971642526412  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11375th epoch : 1.4223415214358843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11376th epoch : 1.4222860438331915  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11377th epoch : 1.4222307307028599  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11378th epoch : 1.4221755813075234  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11379th epoch : 1.4221205949141213  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11380th epoch : 1.4220657707938684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11381th epoch : 1.4220111082222253  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11382th epoch : 1.4219566064788676  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11383th epoch : 1.4219022648476571  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11384th epoch : 1.4218480826166127  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11385th epoch : 1.42179405907788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11386th epoch : 1.4217401935277034  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11387th epoch : 1.4216864852663977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11388th epoch : 1.421632933598319  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11389th epoch : 1.4215795378318368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11390th epoch : 1.4215262972793057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11391th epoch : 1.4214732112570378  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11392th epoch : 1.421420279085276  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11393th epoch : 1.421367500088165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11394th epoch : 1.4213148735937258  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11395th epoch : 1.4212623989338278  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11396th epoch : 1.421210075444163  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11397th epoch : 1.4211579024642185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11398th epoch : 1.4211058793372509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11399th epoch : 1.42105400541026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11400th epoch : 1.4210022800339641  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11401th epoch : 1.420950702562772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11402th epoch : 1.4208992723547595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11403th epoch : 1.420847988771644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11404th epoch : 1.420796851178759  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11405th epoch : 1.4207458589450286  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11406th epoch : 1.4206950114429444  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11407th epoch : 1.42064430804854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11408th epoch : 1.4205937481413673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11409th epoch : 1.4205433311044715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11410th epoch : 1.4204930563243687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11411th epoch : 1.4204429231910212  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11412th epoch : 1.4203929310978136  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11413th epoch : 1.4203430794415308  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11414th epoch : 1.420293367622334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11415th epoch : 1.4202437950437374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11416th epoch : 1.4201943611125871  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11417th epoch : 1.4201450652390362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11418th epoch : 1.4200959068365242  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11419th epoch : 1.4200468853217534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11420th epoch : 1.4199980001146686  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11421th epoch : 1.4199492506384328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11422th epoch : 1.4199006363194082  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11423th epoch : 1.4198521565871318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11424th epoch : 1.4198038108742965  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11425th epoch : 1.4197555986167285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11426th epoch : 1.4197075192533664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11427th epoch : 1.4196595722262406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11428th epoch : 1.4196117569804523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11429th epoch : 1.4195640729641528  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11430th epoch : 1.4195165196285242  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11431th epoch : 1.4194690964277572  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11432th epoch : 1.4194218028190326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11433th epoch : 1.419374638262501  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11434th epoch : 1.4193276022212622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11435th epoch : 1.4192806941613467  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11436th epoch : 1.4192339135516954  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11437th epoch : 1.4191872598641406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11438th epoch : 1.419140732573387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11439th epoch : 1.4190943311569917  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11440th epoch : 1.4190480550953466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11441th epoch : 1.419001903871659  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11442th epoch : 1.418955876971933  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11443th epoch : 1.4189099738849507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11444th epoch : 1.4188641941022544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11445th epoch : 1.4188185371181286  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11446th epoch : 1.418773002429581  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11447th epoch : 1.4187275895363256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11448th epoch : 1.4186822979407645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11449th epoch : 1.4186371271479699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11450th epoch : 1.4185920766656672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11451th epoch : 1.4185471460042176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11452th epoch : 1.4185023346766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11453th epoch : 1.418457642198395  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11454th epoch : 1.4184130680877673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11455th epoch : 1.418368611865449  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11456th epoch : 1.418324273054723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11457th epoch : 1.418280051181406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11458th epoch : 1.4182359457738323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11459th epoch : 1.4181919563628376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11460th epoch : 1.4181480824817425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11461th epoch : 1.4181043236663367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11462th epoch : 1.4180606794548622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11463th epoch : 1.4180171493879987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11464th epoch : 1.417973733008847  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11465th epoch : 1.4179304298629138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11466th epoch : 1.4178872394980953  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11467th epoch : 1.417844161464663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11468th epoch : 1.417801195315248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11469th epoch : 1.4177583406048255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11470th epoch : 1.4177155968907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11471th epoch : 1.41767296373249  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11472th epoch : 1.4176304406921143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11473th epoch : 1.417588027333776  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11474th epoch : 1.4175457232239483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11475th epoch : 1.4175035279313604  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11476th epoch : 1.4174614410269828  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11477th epoch : 1.4174194620840124  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11478th epoch : 1.41737759067786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11479th epoch : 1.4173358263861342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11480th epoch : 1.4172941687886291  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11481th epoch : 1.4172526174673092  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11482th epoch : 1.4172111720062965  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11483th epoch : 1.4171698319918564  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11484th epoch : 1.4171285970123846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11485th epoch : 1.4170874666583924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11486th epoch : 1.4170464405224952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11487th epoch : 1.4170055181993977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11488th epoch : 1.4169646992858818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11489th epoch : 1.4169239833807923  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11490th epoch : 1.4168833700850252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11491th epoch : 1.4168428590015143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11492th epoch : 1.416802449735218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11493th epoch : 1.4167621418931076  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11494th epoch : 1.4167219350841536  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11495th epoch : 1.416681828919314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11496th epoch : 1.4166418230115214  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11497th epoch : 1.416601916975671  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11498th epoch : 1.4165621104286084  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11499th epoch : 1.4165224029891166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11500th epoch : 1.4164827942779057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11501th epoch : 1.416443283917599  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11502th epoch : 1.4164038715327225  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11503th epoch : 1.4163645567496923  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11504th epoch : 1.4163253391968036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11505th epoch : 1.4162862185042178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11506th epoch : 1.4162471943039527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11507th epoch : 1.41620826622987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11508th epoch : 1.4161694339176638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11509th epoch : 1.4161306970048497  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11510th epoch : 1.4160920551307536  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11511th epoch : 1.4160535079365002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11512th epoch : 1.4160150550650026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11513th epoch : 1.4159766961609508  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11514th epoch : 1.4159384308708005  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11515th epoch : 1.4159002588427634  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11516th epoch : 1.4158621797267952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11517th epoch : 1.4158241931745863  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11518th epoch : 1.4157862988395495  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11519th epoch : 1.4157484963768112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11520th epoch : 1.4157107854431998  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11521th epoch : 1.415673165697236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11522th epoch : 1.4156356367991219  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11523th epoch : 1.4155981984107315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11524th epoch : 1.4155608501956003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11525th epoch : 1.4155235918189146  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11526th epoch : 1.415486422947503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11527th epoch : 1.4154493432498245  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11528th epoch : 1.4154123523959603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11529th epoch : 1.4153754500576032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11530th epoch : 1.4153386359080482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11531th epoch : 1.4153019096221826  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11532th epoch : 1.4152652708764766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11533th epoch : 1.4152287193489739  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11534th epoch : 1.415192254719282  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11535th epoch : 1.4151558766685626  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11536th epoch : 1.4151195848795233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11537th epoch : 1.4150833790364072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11538th epoch : 1.415047258824984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11539th epoch : 1.415011223932542  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11540th epoch : 1.414975274047877  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11541th epoch : 1.4149394088612852  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11542th epoch : 1.414903628064553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11543th epoch : 1.4148679313509493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11544th epoch : 1.4148323184152154  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11545th epoch : 1.4147967889535573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11546th epoch : 1.4147613426636365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11547th epoch : 1.4147259792445617  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11548th epoch : 1.4146906983968794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11549th epoch : 1.414655499822567  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11550th epoch : 1.4146203832250228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11551th epoch : 1.4145853483090585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11552th epoch : 1.4145503947808904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11553th epoch : 1.4145155223481316  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11554th epoch : 1.4144807307197833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11555th epoch : 1.414446019606227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11556th epoch : 1.4144113887192162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11557th epoch : 1.414376837771869  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11558th epoch : 1.4143423664786587  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11559th epoch : 1.4143079745554072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11560th epoch : 1.414273661719277  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11561th epoch : 1.4142394276887622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11562th epoch : 1.4142052721836824  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11563th epoch : 1.4141711949251738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11564th epoch : 1.4141371956356819  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11565th epoch : 1.4141032740389539  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11566th epoch : 1.4140694298600314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11567th epoch : 1.4140356628252424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11568th epoch : 1.414001972662194  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11569th epoch : 1.4139683590997654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11570th epoch : 1.4139348218681  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11571th epoch : 1.4139013606985984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11572th epoch : 1.4138679753239112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11573th epoch : 1.4138346654779315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11574th epoch : 1.413801430895788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11575th epoch : 1.413768271313838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11576th epoch : 1.41373518646966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11577th epoch : 1.4137021761020465  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11578th epoch : 1.4136692399509982  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11579th epoch : 1.413636377757716  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11580th epoch : 1.4136035892645937  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11581th epoch : 1.4135708742152129  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11582th epoch : 1.4135382323543346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11583th epoch : 1.4135056634278935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11584th epoch : 1.4134731671829905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11585th epoch : 1.4134407433678868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11586th epoch : 1.4134083917319968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11587th epoch : 1.4133761120258816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11588th epoch : 1.4133439040012432  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11589th epoch : 1.4133117674109168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11590th epoch : 1.4132797020088652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11591th epoch : 1.4132477075501726  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11592th epoch : 1.4132157837910373  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11593th epoch : 1.4131839304887666  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11594th epoch : 1.4131521474017699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11595th epoch : 1.413120434289552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11596th epoch : 1.4130887909127086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11597th epoch : 1.4130572170329179  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11598th epoch : 1.4130257124129366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11599th epoch : 1.4129942768165924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11600th epoch : 1.4129629100087786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11601th epoch : 1.4129316117554485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11602th epoch : 1.4129003818236086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11603th epoch : 1.4128692199813135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11604th epoch : 1.4128381259976592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11605th epoch : 1.4128070996427786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11606th epoch : 1.4127761406878343  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11607th epoch : 1.4127452489050139  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11608th epoch : 1.4127144240675233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11609th epoch : 1.4126836659495825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11610th epoch : 1.4126529743264185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11611th epoch : 1.4126223489742609  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11612th epoch : 1.412591789670335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11613th epoch : 1.412561296192858  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11614th epoch : 1.412530868321032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11615th epoch : 1.4125005058350395  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11616th epoch : 1.4124702085160377  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11617th epoch : 1.4124399761461524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11618th epoch : 1.4124098085084746  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11619th epoch : 1.412379705387053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11620th epoch : 1.41234966656689  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11621th epoch : 1.4123196918339365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11622th epoch : 1.4122897809750858  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11623th epoch : 1.4122599337781696  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11624th epoch : 1.412230150031952  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 11625th epoch : 1.4122004295261248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11626th epoch : 1.4121707720513021  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11627th epoch : 1.412141177399016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11628th epoch : 1.4121116453617106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11629th epoch : 1.412082175732738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11630th epoch : 1.4120527683063524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11631th epoch : 1.4120234228777062  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11632th epoch : 1.4119941392428446  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11633th epoch : 1.4119649171987003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11634th epoch : 1.41193575654309  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11635th epoch : 1.411906657074708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11636th epoch : 1.4118776185931232  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11637th epoch : 1.4118486408987725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11638th epoch : 1.4118197237929577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11639th epoch : 1.4117908670778399  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11640th epoch : 1.4117620705564355  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11641th epoch : 1.4117333340326113  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11642th epoch : 1.4117046573110796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11643th epoch : 1.4116760401973942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11644th epoch : 1.4116474824979457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11645th epoch : 1.4116189840199571  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11646th epoch : 1.411590544571479  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11647th epoch : 1.4115621639613856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11648th epoch : 1.4115338419993702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11649th epoch : 1.4115055784959405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11650th epoch : 1.411477373262415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11651th epoch : 1.411449226110918  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11652th epoch : 1.4114211368543752  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11653th epoch : 1.41139310530651  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11654th epoch : 1.4113651312818396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11655th epoch : 1.4113372145956693  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11656th epoch : 1.4113093550640896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11657th epoch : 1.4112815525039724  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11658th epoch : 1.411253806732965  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11659th epoch : 1.411226117569488  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11660th epoch : 1.4111984848327304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11661th epoch : 1.411170908342645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11662th epoch : 1.4111433879199453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11663th epoch : 1.4111159233861015  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11664th epoch : 1.4110885145633354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11665th epoch : 1.4110611612746178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11666th epoch : 1.4110338633436637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11667th epoch : 1.4110066205949288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11668th epoch : 1.4109794328536054  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11669th epoch : 1.410952299945619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11670th epoch : 1.4109252216976236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11671th epoch : 1.410898197936999  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11672th epoch : 1.410871228491846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11673th epoch : 1.4108443131909838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11674th epoch : 1.4108174518639442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11675th epoch : 1.4107906443409706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11676th epoch : 1.4107638904530124  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11677th epoch : 1.410737190031722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11678th epoch : 1.410710542909451  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11679th epoch : 1.4106839489192469  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11680th epoch : 1.4106574078948484  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11681th epoch : 1.4106309196706837  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11682th epoch : 1.4106044840818655  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11683th epoch : 1.4105781009641878  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11684th epoch : 1.4105517701541226  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11685th epoch : 1.4105254914888161  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11686th epoch : 1.4104992648060855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11687th epoch : 1.4104730899444158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11688th epoch : 1.4104469667429553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11689th epoch : 1.4104208950415138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11690th epoch : 1.410394874680558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11691th epoch : 1.4103689055012079  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11692th epoch : 1.410342987345235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11693th epoch : 1.4103171200550577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11694th epoch : 1.410291303473738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11695th epoch : 1.410265537444979  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11696th epoch : 1.410239821813121  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11697th epoch : 1.410214156423138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11698th epoch : 1.410188541120636  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11699th epoch : 1.4101629757518477  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11700th epoch : 1.410137460163631  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11701th epoch : 1.4101119942034643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11702th epoch : 1.4100865777194453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11703th epoch : 1.410061210560286  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11704th epoch : 1.4100358925753111  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11705th epoch : 1.4100106236144534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11706th epoch : 1.4099854035282522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11707th epoch : 1.409960232167849  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11708th epoch : 1.4099351093849855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11709th epoch : 1.409910035032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11710th epoch : 1.4098850089618244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11711th epoch : 1.4098600310279816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11712th epoch : 1.409835101084582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11713th epoch : 1.4098102189863213  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11714th epoch : 1.4097853845884765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11715th epoch : 1.4097605977469039  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11716th epoch : 1.4097358583180362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11717th epoch : 1.409711166158879  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11718th epoch : 1.4096865211270084  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11719th epoch : 1.4096619230805678  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11720th epoch : 1.409637371878266  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11721th epoch : 1.4096128673793729  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11722th epoch : 1.409588409443718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11723th epoch : 1.4095639979316872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11724th epoch : 1.4095396327042198  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11725th epoch : 1.4095153136228056  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11726th epoch : 1.4094910405494834  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11727th epoch : 1.4094668133468369  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11728th epoch : 1.4094426318779922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11729th epoch : 1.4094184960066163  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11730th epoch : 1.4093944055969128  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11731th epoch : 1.4093703605136203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11732th epoch : 1.4093463606220098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11733th epoch : 1.4093224057878815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11734th epoch : 1.4092984958775625  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11735th epoch : 1.4092746307579043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11736th epoch : 1.40925081029628  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11737th epoch : 1.409227034360582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11738th epoch : 1.4092033028192195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11739th epoch : 1.4091796155411154  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11740th epoch : 1.4091559723957048  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11741th epoch : 1.4091323732529315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11742th epoch : 1.409108817983246  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11743th epoch : 1.409085306457603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11744th epoch : 1.409061838547459  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11745th epoch : 1.4090384141247696  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11746th epoch : 1.4090150330619875  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11747th epoch : 1.4089916952320596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11748th epoch : 1.408968400508425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11749th epoch : 1.4089451487650126  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11750th epoch : 1.4089219398762383  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11751th epoch : 1.4088987737170031  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11752th epoch : 1.4088756501626905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11753th epoch : 1.4088525690891647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11754th epoch : 1.4088295303727671  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11755th epoch : 1.4088065338903155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11756th epoch : 1.4087835795191006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11757th epoch : 1.4087606671368846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11758th epoch : 1.4087377966218981  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11759th epoch : 1.4087149678528386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11760th epoch : 1.408692180708868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11761th epoch : 1.4086694350696098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11762th epoch : 1.4086467308151482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11763th epoch : 1.4086240678260247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11764th epoch : 1.4086014459832363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11765th epoch : 1.4085788651682334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11766th epoch : 1.4085563252629176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11767th epoch : 1.4085338261496396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11768th epoch : 1.4085113677111973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11769th epoch : 1.4084889498308328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11770th epoch : 1.4084665723922314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11771th epoch : 1.4084442352795188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11772th epoch : 1.408421938377259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11773th epoch : 1.408399681570453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11774th epoch : 1.408377464744535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11775th epoch : 1.4083552877853731  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11776th epoch : 1.4083331505792647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11777th epoch : 1.408311053012935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11778th epoch : 1.4082889949735367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11779th epoch : 1.4082669763486453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11780th epoch : 1.4082449970262598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11781th epoch : 1.4082230568947987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11782th epoch : 1.4082011558430985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11783th epoch : 1.408179293760413  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11784th epoch : 1.408157470536409  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11785th epoch : 1.408135686061167  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11786th epoch : 1.4081139402251772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11787th epoch : 1.4080922329193384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11788th epoch : 1.4080705640349565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11789th epoch : 1.4080489334637414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11790th epoch : 1.4080273410978066  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11791th epoch : 1.4080057868296663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11792th epoch : 1.4079842705522334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11793th epoch : 1.407962792158819  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11794th epoch : 1.4079413515431285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11795th epoch : 1.407919948599262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11796th epoch : 1.4078985832217104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11797th epoch : 1.4078772553053551  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11798th epoch : 1.4078559647454654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11799th epoch : 1.407834711437697  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11800th epoch : 1.4078134952780905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11801th epoch : 1.4077923161630683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11802th epoch : 1.4077711739894352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11803th epoch : 1.4077500686543738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11804th epoch : 1.4077290000554457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11805th epoch : 1.4077079680905868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11806th epoch : 1.4076869726581083  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11807th epoch : 1.4076660136566927  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11808th epoch : 1.4076450909853941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11809th epoch : 1.407624204543635  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11810th epoch : 1.407603354231205  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11811th epoch : 1.4075825399482593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11812th epoch : 1.4075617615953175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11813th epoch : 1.407541019073261  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11814th epoch : 1.4075203122833313  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11815th epoch : 1.40749964112713  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11816th epoch : 1.4074790055066153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11817th epoch : 1.4074584053241006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11818th epoch : 1.4074378404822545  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11819th epoch : 1.4074173108840968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11820th epoch : 1.4073968164329993  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11821th epoch : 1.407376357032682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11822th epoch : 1.4073559325872134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11823th epoch : 1.4073355430010075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11824th epoch : 1.4073151881788235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11825th epoch : 1.4072948680257626  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11826th epoch : 1.4072745824472686  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11827th epoch : 1.4072543313491241  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11828th epoch : 1.4072341146374505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11829th epoch : 1.4072139322187065  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11830th epoch : 1.4071937839996853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11831th epoch : 1.4071736698875144  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11832th epoch : 1.4071535897896532  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11833th epoch : 1.4071335436138925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11834th epoch : 1.407113531268352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11835th epoch : 1.4070935526614796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11836th epoch : 1.4070736077020491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11837th epoch : 1.4070536962991596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11838th epoch : 1.4070338183622335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11839th epoch : 1.4070139738010152  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11840th epoch : 1.4069941625255702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11841th epoch : 1.4069743844462825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11842th epoch : 1.4069546394738544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11843th epoch : 1.406934927519304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11844th epoch : 1.4069152484939644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11845th epoch : 1.406895602309483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11846th epoch : 1.4068759888778184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11847th epoch : 1.4068564081112405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11848th epoch : 1.406836859922328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11849th epoch : 1.4068173442239686  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11850th epoch : 1.4067978609293557  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11851th epoch : 1.4067784099519884  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11852th epoch : 1.40675899120567  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11853th epoch : 1.4067396046045058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11854th epoch : 1.4067202500629026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11855th epoch : 1.4067009274955675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11856th epoch : 1.406681636817506  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11857th epoch : 1.4066623779440206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11858th epoch : 1.4066431507907102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11859th epoch : 1.4066239552734685  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11860th epoch : 1.4066047913084823  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11861th epoch : 1.4065856588122305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11862th epoch : 1.4065665577014832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11863th epoch : 1.4065474878933  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11864th epoch : 1.4065284493050283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11865th epoch : 1.4065094418543034  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11866th epoch : 1.4064904654590458  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11867th epoch : 1.4064715200374607  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11868th epoch : 1.4064526055080366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11869th epoch : 1.4064337217895444  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11870th epoch : 1.4064148688010354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11871th epoch : 1.406396046461841  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11872th epoch : 1.4063772546915707  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11873th epoch : 1.4063584934101114  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11874th epoch : 1.4063397625376257  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11875th epoch : 1.4063210619945514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11876th epoch : 1.4063023917016002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11877th epoch : 1.4062837515797553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11878th epoch : 1.406265141550272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11879th epoch : 1.4062465615346758  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11880th epoch : 1.4062280114547603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11881th epoch : 1.4062094912325878  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11882th epoch : 1.4061910007904865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11883th epoch : 1.4061725400510507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11884th epoch : 1.4061541089371388  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11885th epoch : 1.4061357073718725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11886th epoch : 1.4061173352786351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11887th epoch : 1.4060989925810718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11888th epoch : 1.4060806792030867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11889th epoch : 1.4060623950688433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11890th epoch : 1.4060441401027624  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11891th epoch : 1.4060259142295213  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11892th epoch : 1.406007717374053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11893th epoch : 1.4059895494615446  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11894th epoch : 1.4059714104174366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11895th epoch : 1.4059533001674216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11896th epoch : 1.4059352186374434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11897th epoch : 1.4059171657536957  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11898th epoch : 1.4058991414426216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11899th epoch : 1.4058811456309115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11900th epoch : 1.405863178245503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11901th epoch : 1.4058452392135796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11902th epoch : 1.4058273284625695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11903th epoch : 1.405809445920145  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11904th epoch : 1.40579159151422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11905th epoch : 1.4057737651729516  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11906th epoch : 1.4057559668247366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11907th epoch : 1.4057381963982116  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11908th epoch : 1.4057204538222525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11909th epoch : 1.405702739025972  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11910th epoch : 1.4056850519387196  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11911th epoch : 1.4056673924900813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11912th epoch : 1.4056497606098766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11913th epoch : 1.4056321562281595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11914th epoch : 1.4056145792752164  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11915th epoch : 1.4055970296815652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11916th epoch : 1.4055795073779553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11917th epoch : 1.4055620122953654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11918th epoch : 1.4055445443650028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11919th epoch : 1.4055271035183032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11920th epoch : 1.405509689686929  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11921th epoch : 1.4054923028027684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11922th epoch : 1.405474942797935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11923th epoch : 1.4054576096047664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11924th epoch : 1.4054403031558234  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11925th epoch : 1.4054230233838887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11926th epoch : 1.405405770221967  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11927th epoch : 1.405388543603283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11928th epoch : 1.4053713434612807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11929th epoch : 1.4053541697296232  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11930th epoch : 1.4053370223421908  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11931th epoch : 1.4053199012330813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11932th epoch : 1.4053028063366073  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11933th epoch : 1.4052857375872974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11934th epoch : 1.4052686949198938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11935th epoch : 1.4052516782693523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11936th epoch : 1.4052346875708406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11937th epoch : 1.4052177227597382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11938th epoch : 1.4052007837716354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11939th epoch : 1.4051838705423314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11940th epoch : 1.4051669830078353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11941th epoch : 1.4051501211043638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11942th epoch : 1.4051332847683407  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11943th epoch : 1.4051164739363962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11944th epoch : 1.4050996885453662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11945th epoch : 1.4050829285322908  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11946th epoch : 1.4050661938344142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11947th epoch : 1.4050494843891839  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11948th epoch : 1.4050328001342487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11949th epoch : 1.4050161410074598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11950th epoch : 1.4049995069468677  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11951th epoch : 1.404982897890724  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11952th epoch : 1.404966313777478  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11953th epoch : 1.4049497545457774  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11954th epoch : 1.4049332201344675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11955th epoch : 1.40491671048259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11956th epoch : 1.4049002255293819  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11957th epoch : 1.4048837652142754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11958th epoch : 1.4048673294768965  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11959th epoch : 1.4048509182570652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11960th epoch : 1.4048345314947932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11961th epoch : 1.4048181691302846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11962th epoch : 1.4048018311039339  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11963th epoch : 1.4047855173563262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11964th epoch : 1.404769227828236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11965th epoch : 1.4047529624606265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11966th epoch : 1.4047367211946489  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11967th epoch : 1.404720503971641  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11968th epoch : 1.4047043107331278  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11969th epoch : 1.4046881414208197  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11970th epoch : 1.4046719959766116  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11971th epoch : 1.4046558743425832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11972th epoch : 1.4046397764609975  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11973th epoch : 1.4046237022743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11974th epoch : 1.4046076517251183  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11975th epoch : 1.404591624756261  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11976th epoch : 1.404575621310718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11977th epoch : 1.4045596413316581  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11978th epoch : 1.40454368476243  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11979th epoch : 1.4045277515465602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11980th epoch : 1.404511841627753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11981th epoch : 1.40449595494989  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11982th epoch : 1.4044800914570288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11983th epoch : 1.4044642510934024  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11984th epoch : 1.4044484338034193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11985th epoch : 1.4044326395316613  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11986th epoch : 1.4044168682228846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11987th epoch : 1.4044011198220174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11988th epoch : 1.4043853942741606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11989th epoch : 1.4043696915245867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11990th epoch : 1.4043540115187378  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11991th epoch : 1.4043383542022276  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11992th epoch : 1.4043227195208385  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11993th epoch : 1.4043071074205213  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11994th epoch : 1.4042915178473956  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11995th epoch : 1.4042759507477482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11996th epoch : 1.4042604060680324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11997th epoch : 1.404244883754868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11998th epoch : 1.4042293837550401  Training Accuracy:0.8571428571428571\n",
      "The training loss at 11999th epoch : 1.4042139060154983  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12000th epoch : 1.4041984504833573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12001th epoch : 1.4041830171058942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12002th epoch : 1.40416760583055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12003th epoch : 1.404152216604927  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12004th epoch : 1.4041368493767898  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12005th epoch : 1.4041215040940642  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12006th epoch : 1.4041061807048354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12007th epoch : 1.4040908791573494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12008th epoch : 1.4040755994000105  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12009th epoch : 1.4040603413813821  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12010th epoch : 1.404045105050185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12011th epoch : 1.4040298903552977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12012th epoch : 1.4040146972457552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12013th epoch : 1.4039995256707483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12014th epoch : 1.4039843755796237  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12015th epoch : 1.4039692469218827  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12016th epoch : 1.4039541396471809  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12017th epoch : 1.4039390537053271  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12018th epoch : 1.4039239890462842  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12019th epoch : 1.4039089456201665  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12020th epoch : 1.4038939233772412  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12021th epoch : 1.4038789222679255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12022th epoch : 1.4038639422427885  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12023th epoch : 1.4038489832525491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12024th epoch : 1.4038340452480753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12025th epoch : 1.4038191281803845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12026th epoch : 1.4038042320006425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12027th epoch : 1.4037893566601627  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12028th epoch : 1.4037745021104062  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12029th epoch : 1.4037596683029805  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12030th epoch : 1.403744855189639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12031th epoch : 1.4037300627222813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12032th epoch : 1.4037152908529513  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12033th epoch : 1.4037005395338382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12034th epoch : 1.4036858087172746  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12035th epoch : 1.4036710983557366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12036th epoch : 1.4036564084018428  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12037th epoch : 1.4036417388083546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12038th epoch : 1.4036270895281753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12039th epoch : 1.4036124605143483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12040th epoch : 1.4035978517200591  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12041th epoch : 1.403583263098632  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12042th epoch : 1.4035686946035322  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12043th epoch : 1.403554146188363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12044th epoch : 1.4035396178068662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12045th epoch : 1.4035251094129226  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12046th epoch : 1.4035106209605495  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12047th epoch : 1.4034961524039016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12048th epoch : 1.4034817036972702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12049th epoch : 1.403467274795082  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 12050th epoch : 1.4034528656518999  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12051th epoch : 1.4034384762224208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12052th epoch : 1.4034241064614772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12053th epoch : 1.4034097563240342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12054th epoch : 1.4033954257651913  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12055th epoch : 1.4033811147401802  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12056th epoch : 1.4033668232043657  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12057th epoch : 1.403352551113244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12058th epoch : 1.4033382984224427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12059th epoch : 1.4033240650877208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12060th epoch : 1.403309851064967  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12061th epoch : 1.4032956563102006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12062th epoch : 1.40328148077957  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12063th epoch : 1.4032673244293525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12064th epoch : 1.4032531872159544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12065th epoch : 1.4032390690959093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12066th epoch : 1.4032249700258788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12067th epoch : 1.4032108899626514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12068th epoch : 1.4031968288631425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12069th epoch : 1.403182786684393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12070th epoch : 1.4031687633835694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12071th epoch : 1.4031547589179645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12072th epoch : 1.4031407732449945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12073th epoch : 1.4031268063222009  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12074th epoch : 1.4031128581072478  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12075th epoch : 1.4030989285579238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12076th epoch : 1.4030850176321399  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12077th epoch : 1.403071125287929  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12078th epoch : 1.4030572514834472  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12079th epoch : 1.4030433961769706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12080th epoch : 1.4030295593268975  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12081th epoch : 1.4030157408917463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12082th epoch : 1.4030019408301557  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12083th epoch : 1.4029881591008844  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12084th epoch : 1.4029743956628098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12085th epoch : 1.4029606504749288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12086th epoch : 1.402946923496356  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12087th epoch : 1.4029332146863245  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12088th epoch : 1.402919524004185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12089th epoch : 1.4029058514094048  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12090th epoch : 1.4028921968615682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12091th epoch : 1.4028785603203762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12092th epoch : 1.4028649417456445  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12093th epoch : 1.4028513410973054  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12094th epoch : 1.4028377583354052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12095th epoch : 1.4028241934201058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12096th epoch : 1.402810646311682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12097th epoch : 1.4027971169705236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12098th epoch : 1.4027836053571328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12099th epoch : 1.402770111432125  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12100th epoch : 1.402756635156228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12101th epoch : 1.4027431764902818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12102th epoch : 1.4027297353952382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12103th epoch : 1.40271631183216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12104th epoch : 1.402702905762221  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12105th epoch : 1.4026895171467053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12106th epoch : 1.4026761459470072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12107th epoch : 1.4026627921246306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12108th epoch : 1.4026494556411888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12109th epoch : 1.402636136458404  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12110th epoch : 1.4026228345381064  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12111th epoch : 1.4026095498422346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12112th epoch : 1.4025962823328353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12113th epoch : 1.4025830319720618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12114th epoch : 1.4025697987221746  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12115th epoch : 1.4025565825455406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12116th epoch : 1.4025433834046335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12117th epoch : 1.4025302012620318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12118th epoch : 1.4025170360804198  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12119th epoch : 1.4025038878225873  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12120th epoch : 1.4024907564514277  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12121th epoch : 1.4024776419299394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12122th epoch : 1.4024645442212247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12123th epoch : 1.402451463288489  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12124th epoch : 1.4024383990950409  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12125th epoch : 1.4024253516042922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12126th epoch : 1.4024123207797563  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12127th epoch : 1.4023993065850495  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12128th epoch : 1.4023863089838893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12129th epoch : 1.4023733279400945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12130th epoch : 1.402360363417585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12131th epoch : 1.402347415380381  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12132th epoch : 1.4023344837926033  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12133th epoch : 1.4023215686184722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12134th epoch : 1.4023086698223077  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12135th epoch : 1.4022957873685293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12136th epoch : 1.4022829212216545  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12137th epoch : 1.4022700713462999  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12138th epoch : 1.40225723770718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12139th epoch : 1.4022444202691071  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12140th epoch : 1.4022316189969906  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12141th epoch : 1.4022188338558375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12142th epoch : 1.402206064810751  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12143th epoch : 1.402193311826931  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12144th epoch : 1.4021805748696736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12145th epoch : 1.40216785390437  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12146th epoch : 1.4021551488965074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12147th epoch : 1.4021424598116674  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12148th epoch : 1.402129786615527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12149th epoch : 1.4021171292738568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12150th epoch : 1.402104487752522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12151th epoch : 1.4020918620174811  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12152th epoch : 1.4020792520347867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12153th epoch : 1.4020666577705831  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12154th epoch : 1.4020540791911085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12155th epoch : 1.4020415162626931  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12156th epoch : 1.4020289689517589  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12157th epoch : 1.40201643722482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12158th epoch : 1.4020039210484818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12159th epoch : 1.4019914203894408  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12160th epoch : 1.4019789352144838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12161th epoch : 1.401966465490489  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12162th epoch : 1.401954011184424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12163th epoch : 1.4019415722633466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12164th epoch : 1.4019291486944037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12165th epoch : 1.4019167404448318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12166th epoch : 1.4019043474819561  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12167th epoch : 1.4018919697731904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12168th epoch : 1.401879607286037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12169th epoch : 1.401867259988086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12170th epoch : 1.4018549278470147  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12171th epoch : 1.4018426108305884  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12172th epoch : 1.4018303089066593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12173th epoch : 1.4018180220431662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12174th epoch : 1.4018057502081345  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12175th epoch : 1.4017934933696756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12176th epoch : 1.4017812514959869  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12177th epoch : 1.401769024555351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12178th epoch : 1.4017568125161362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12179th epoch : 1.4017446153467956  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12180th epoch : 1.401732433015867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12181th epoch : 1.4017202654919725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12182th epoch : 1.401708112743818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12183th epoch : 1.401695974740194  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12184th epoch : 1.4016838514499739  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12185th epoch : 1.4016717428421142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12186th epoch : 1.4016596488856545  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12187th epoch : 1.4016475695497175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12188th epoch : 1.4016355048035074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12189th epoch : 1.4016234546163115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12190th epoch : 1.401611418957498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12191th epoch : 1.4015993977965169  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12192th epoch : 1.4015873911028998  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12193th epoch : 1.4015753988462585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12194th epoch : 1.4015634209962866  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12195th epoch : 1.4015514575227568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12196th epoch : 1.401539508395523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12197th epoch : 1.4015275735845185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12198th epoch : 1.4015156530597561  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12199th epoch : 1.401503746791328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12200th epoch : 1.4014918547494055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12201th epoch : 1.401479976904239  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12202th epoch : 1.4014681132261566  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12203th epoch : 1.4014562636855652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12204th epoch : 1.40144442825295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12205th epoch : 1.4014326068988727  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12206th epoch : 1.4014207995939738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12207th epoch : 1.4014090063089701  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12208th epoch : 1.401397227014656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12209th epoch : 1.401385461681902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12210th epoch : 1.4013737102816548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12211th epoch : 1.4013619727849378  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12212th epoch : 1.4013502491628504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12213th epoch : 1.401338539386567  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12214th epoch : 1.4013268434273376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12215th epoch : 1.4013151612564876  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12216th epoch : 1.401303492845417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12217th epoch : 1.4012918381656003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12218th epoch : 1.4012801971885869  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12219th epoch : 1.4012685698859992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12220th epoch : 1.4012569562295347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12221th epoch : 1.401245356190964  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12222th epoch : 1.4012337697421307  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12223th epoch : 1.4012221968549519  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12224th epoch : 1.4012106375014175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12225th epoch : 1.4011990916535901  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12226th epoch : 1.4011875592836047  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12227th epoch : 1.4011760403636682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12228th epoch : 1.4011645348660593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12229th epoch : 1.401153042763129  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12230th epoch : 1.4011415640272988  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12231th epoch : 1.4011300986310622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12232th epoch : 1.401118646546983  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12233th epoch : 1.4011072077476963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12234th epoch : 1.401095782205907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12235th epoch : 1.401084369894391  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12236th epoch : 1.401072970785993  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12237th epoch : 1.401061584853629  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12238th epoch : 1.4010502120702832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12239th epoch : 1.4010388524090098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12240th epoch : 1.401027505842932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12241th epoch : 1.4010161723452417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12242th epoch : 1.401004851889199  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12243th epoch : 1.4009935444481334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12244th epoch : 1.4009822499954416  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12245th epoch : 1.4009709685045886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12246th epoch : 1.400959699949107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12247th epoch : 1.400948444302597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12248th epoch : 1.400937201538726  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12249th epoch : 1.4009259716312283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12250th epoch : 1.4009147545539051  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12251th epoch : 1.4009035502806244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12252th epoch : 1.4008923587853201  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12253th epoch : 1.4008811800419925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12254th epoch : 1.4008700140247081  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12255th epoch : 1.4008588607075985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12256th epoch : 1.4008477200648612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12257th epoch : 1.4008365920707588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12258th epoch : 1.4008254766996193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12259th epoch : 1.4008143739258352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12260th epoch : 1.4008032837238638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12261th epoch : 1.4007922060682263  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12262th epoch : 1.4007811409335091  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12263th epoch : 1.4007700882943617  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12264th epoch : 1.4007590481254977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12265th epoch : 1.4007480204016947  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12266th epoch : 1.4007370050977928  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12267th epoch : 1.400726002188696  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12268th epoch : 1.400715011649371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12269th epoch : 1.400704033454847  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12270th epoch : 1.4006930675802163  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12271th epoch : 1.400682114000633  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12272th epoch : 1.4006711726913135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12273th epoch : 1.4006602436275362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12274th epoch : 1.4006493267846414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12275th epoch : 1.4006384221380306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12276th epoch : 1.4006275296631667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12277th epoch : 1.400616649335574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12278th epoch : 1.4006057811308374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12279th epoch : 1.4005949250246024  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12280th epoch : 1.4005840809925756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12281th epoch : 1.4005732490105236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12282th epoch : 1.4005624290542729  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12283th epoch : 1.4005516210997102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12284th epoch : 1.4005408251227822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12285th epoch : 1.4005300410994947  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12286th epoch : 1.4005192690059132  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12287th epoch : 1.4005085088181621  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12288th epoch : 1.400497760512425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12289th epoch : 1.4004870240649439  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12290th epoch : 1.40047629945202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12291th epoch : 1.4004655866500122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12292th epoch : 1.4004548856353385  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12293th epoch : 1.4004441963844743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12294th epoch : 1.4004335188739527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12295th epoch : 1.400422853080365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12296th epoch : 1.4004121989803595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12297th epoch : 1.4004015565506422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12298th epoch : 1.4003909257679759  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12299th epoch : 1.4003803066091804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12300th epoch : 1.400369699051132  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12301th epoch : 1.4003591030707643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12302th epoch : 1.4003485186450662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12303th epoch : 1.4003379457510836  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12304th epoch : 1.400327384365918  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12305th epoch : 1.4003168344667272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12306th epoch : 1.400306296030724  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12307th epoch : 1.4002957690351772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12308th epoch : 1.4002852534574104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12309th epoch : 1.4002747492748029  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12310th epoch : 1.4002642564647885  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12311th epoch : 1.4002537750048558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12312th epoch : 1.4002433048725482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12313th epoch : 1.4002328460454634  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12314th epoch : 1.4002223985012532  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12315th epoch : 1.4002119622176237  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12316th epoch : 1.4002015371723349  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12317th epoch : 1.4001911233432  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12318th epoch : 1.4001807207080867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12319th epoch : 1.4001703292449152  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12320th epoch : 1.4001599489316594  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12321th epoch : 1.400149579746346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12322th epoch : 1.4001392216670545  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12323th epoch : 1.4001288746719176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12324th epoch : 1.40011853873912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12325th epoch : 1.4001082138468992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12326th epoch : 1.4000978999735443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12327th epoch : 1.400087597097397  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12328th epoch : 1.4000773051968507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12329th epoch : 1.4000670242503503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12330th epoch : 1.4000567542363929  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12331th epoch : 1.4000464951335259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12332th epoch : 1.400036246920349  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12333th epoch : 1.4000260095755122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12334th epoch : 1.400015783077717  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12335th epoch : 1.4000055674057148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12336th epoch : 1.3999953625383084  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12337th epoch : 1.399985168454351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12338th epoch : 1.399974985132745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12339th epoch : 1.3999648125524442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12340th epoch : 1.3999546506924518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12341th epoch : 1.3999444995318207  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12342th epoch : 1.3999343590496531  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12343th epoch : 1.3999242292251017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12344th epoch : 1.3999141100373673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12345th epoch : 1.399904001465701  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12346th epoch : 1.3998939034894016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12347th epoch : 1.3998838160878182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12348th epoch : 1.3998737392403475  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12349th epoch : 1.399863672926435  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12350th epoch : 1.399853617125575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12351th epoch : 1.39984357181731  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12352th epoch : 1.3998335369812296  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12353th epoch : 1.3998235125969727  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12354th epoch : 1.399813498644225  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12355th epoch : 1.3998034951027203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12356th epoch : 1.3997935019522396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12357th epoch : 1.399783519172612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12358th epoch : 1.3997735467437127  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12359th epoch : 1.3997635846454646  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12360th epoch : 1.3997536328578373  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12361th epoch : 1.3997436913608474  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12362th epoch : 1.3997337601345579  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12363th epoch : 1.399723839159078  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12364th epoch : 1.3997139284145639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12365th epoch : 1.3997040278812172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12366th epoch : 1.399694137539286  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12367th epoch : 1.3996842573690644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12368th epoch : 1.3996743873508917  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12369th epoch : 1.3996645274651534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12370th epoch : 1.39965467769228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12371th epoch : 1.3996448380127477  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12372th epoch : 1.3996350084070774  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12373th epoch : 1.3996251888558358  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12374th epoch : 1.3996153793396333  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12375th epoch : 1.3996055798391263  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12376th epoch : 1.3995957903350151  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12377th epoch : 1.3995860108080447  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12378th epoch : 1.3995762412390045  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12379th epoch : 1.3995664816087279  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12380th epoch : 1.3995567318980926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12381th epoch : 1.39954699208802  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12382th epoch : 1.3995372621594755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12383th epoch : 1.3995275420934679  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12384th epoch : 1.3995178318710502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12385th epoch : 1.3995081314733178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12386th epoch : 1.39949844088141  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12387th epoch : 1.3994887600765094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12388th epoch : 1.3994790890398408  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12389th epoch : 1.3994694277526727  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12390th epoch : 1.399459776196316  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12391th epoch : 1.399450134352124  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12392th epoch : 1.3994405022014926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12393th epoch : 1.39943087972586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12394th epoch : 1.3994212669067072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12395th epoch : 1.3994116637255565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12396th epoch : 1.3994020701639722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12397th epoch : 1.3993924862035607  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12398th epoch : 1.3993829118259702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12399th epoch : 1.3993733470128904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12400th epoch : 1.399363791746052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12401th epoch : 1.3993542460072272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12402th epoch : 1.3993447097782301  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12403th epoch : 1.3993351830409149  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12404th epoch : 1.399325665777177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12405th epoch : 1.3993161579689533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12406th epoch : 1.39930665959822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12407th epoch : 1.3992971706469952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12408th epoch : 1.3992876910973366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12409th epoch : 1.3992782209313426  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12410th epoch : 1.3992687601311518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12411th epoch : 1.3992593086789424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12412th epoch : 1.3992498665569333  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12413th epoch : 1.3992404337473825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12414th epoch : 1.3992310102325882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12415th epoch : 1.399221595994888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12416th epoch : 1.3992121910166588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12417th epoch : 1.399202795280317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12418th epoch : 1.3991934087683184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12419th epoch : 1.3991840314631576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12420th epoch : 1.399174663347368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12421th epoch : 1.3991653044035226  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12422th epoch : 1.3991559546142325  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12423th epoch : 1.3991466139621476  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12424th epoch : 1.3991372824299562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12425th epoch : 1.3991279600003854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12426th epoch : 1.3991186466562002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12427th epoch : 1.3991093423802037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12428th epoch : 1.3991000471552375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12429th epoch : 1.3990907609641805  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12430th epoch : 1.39908148378995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12431th epoch : 1.3990722156155007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12432th epoch : 1.3990629564238248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12433th epoch : 1.3990537061979524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12434th epoch : 1.3990444649209506  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12435th epoch : 1.3990352325759234  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12436th epoch : 1.3990260091460132  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12437th epoch : 1.3990167946143977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12438th epoch : 1.399007588964293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12439th epoch : 1.398998392178951  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12440th epoch : 1.3989892042416612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12441th epoch : 1.3989800251357485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12442th epoch : 1.3989708548445756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12443th epoch : 1.3989616933515405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12444th epoch : 1.3989525406400778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12445th epoch : 1.3989433966936586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12446th epoch : 1.3989342614957896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12447th epoch : 1.3989251350300134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12448th epoch : 1.3989160172799087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12449th epoch : 1.3989069082290897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12450th epoch : 1.3988978078612064  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12451th epoch : 1.398888716159944  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12452th epoch : 1.3988796331090234  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12453th epoch : 1.3988705586922008  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12454th epoch : 1.398861492893267  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12455th epoch : 1.3988524356960486  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12456th epoch : 1.3988433870844068  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12457th epoch : 1.3988343470422375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12458th epoch : 1.398825315553472  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12459th epoch : 1.3988162926020757  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12460th epoch : 1.3988072781720484  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12461th epoch : 1.398798272247425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12462th epoch : 1.3987892748122743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12463th epoch : 1.398780285850699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12464th epoch : 1.3987713053468371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12465th epoch : 1.3987623332848593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12466th epoch : 1.398753369648971  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12467th epoch : 1.3987444144234114  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12468th epoch : 1.398735467592453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12469th epoch : 1.3987265291404025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12470th epoch : 1.3987175990515999  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12471th epoch : 1.3987086773104185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12472th epoch : 1.398699763901265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12473th epoch : 1.3986908588085794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12474th epoch : 1.3986819620168347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12475th epoch : 1.3986730735105375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12476th epoch : 1.3986641932742263  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12477th epoch : 1.3986553212924733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12478th epoch : 1.3986464575498831  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12479th epoch : 1.3986376020310933  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12480th epoch : 1.3986287547207734  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12481th epoch : 1.3986199156036259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12482th epoch : 1.3986110846643856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12483th epoch : 1.3986022618878189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12484th epoch : 1.3985934472587256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12485th epoch : 1.3985846407619364  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12486th epoch : 1.3985758423823147  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12487th epoch : 1.3985670521047555  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12488th epoch : 1.3985582699141856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12489th epoch : 1.3985494957955633  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12490th epoch : 1.398540729733879  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12491th epoch : 1.3985319717141542  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12492th epoch : 1.398523221721442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12493th epoch : 1.3985144797408267  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12494th epoch : 1.3985057457574237  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12495th epoch : 1.39849701975638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12496th epoch : 1.3984883017228733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12497th epoch : 1.398479591642112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12498th epoch : 1.3984708894993358  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12499th epoch : 1.3984621952798155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12500th epoch : 1.3984535089688515  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12501th epoch : 1.3984448305517756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12502th epoch : 1.3984361600139499  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12503th epoch : 1.3984274973407669  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12504th epoch : 1.3984188425176494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12505th epoch : 1.3984101955300503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12506th epoch : 1.3984015563634533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12507th epoch : 1.398392925003371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12508th epoch : 1.398384301435347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12509th epoch : 1.3983756856449543  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12510th epoch : 1.3983670776177957  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12511th epoch : 1.398358477339504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12512th epoch : 1.3983498847957407  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12513th epoch : 1.3983412999721982  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12514th epoch : 1.3983327228545974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12515th epoch : 1.398324153428689  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12516th epoch : 1.398315591680252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12517th epoch : 1.3983070375950963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12518th epoch : 1.3982984911590595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12519th epoch : 1.3982899523580086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12520th epoch : 1.3982814211778394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12521th epoch : 1.3982728976044771  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12522th epoch : 1.398264381623875  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12523th epoch : 1.3982558732220154  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12524th epoch : 1.398247372384909  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12525th epoch : 1.3982388790985953  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12526th epoch : 1.398230393349142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12527th epoch : 1.398221915122645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12528th epoch : 1.3982134444052288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12529th epoch : 1.398204981183046  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12530th epoch : 1.3981965254422768  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12531th epoch : 1.3981880771691302  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12532th epoch : 1.3981796363498424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12533th epoch : 1.398171202970678  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12534th epoch : 1.398162777017929  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12535th epoch : 1.3981543584779152  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12536th epoch : 1.3981459473369842  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12537th epoch : 1.3981375435815107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12538th epoch : 1.3981291471978972  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12539th epoch : 1.3981207581725732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12540th epoch : 1.398112376491996  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12541th epoch : 1.3981040021426496  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12542th epoch : 1.3980956351110454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12543th epoch : 1.3980872753837217  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12544th epoch : 1.398078922947244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12545th epoch : 1.3980705777882043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12546th epoch : 1.3980622398932216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12547th epoch : 1.3980539092489421  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12548th epoch : 1.3980455858420375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12549th epoch : 1.3980372696592074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12550th epoch : 1.398028960687177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12551th epoch : 1.398020658912698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12552th epoch : 1.3980123643225488  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12553th epoch : 1.398004076903534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12554th epoch : 1.3979957966424843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12555th epoch : 1.3979875235262562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12556th epoch : 1.3979792575417327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12557th epoch : 1.3979709986758226  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12558th epoch : 1.3979627469154607  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12559th epoch : 1.3979545022476074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12560th epoch : 1.3979462646592489  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12561th epoch : 1.397938034137397  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12562th epoch : 1.3979298106690892  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12563th epoch : 1.3979215942413887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12564th epoch : 1.3979133848413836  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12565th epoch : 1.397905182456188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12566th epoch : 1.3978969870729407  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12567th epoch : 1.3978887986788062  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12568th epoch : 1.3978806172609741  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12569th epoch : 1.3978724428066585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12570th epoch : 1.3978642753030992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12571th epoch : 1.3978561147375603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12572th epoch : 1.3978479610973318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12573th epoch : 1.397839814369727  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12574th epoch : 1.3978316745420851  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12575th epoch : 1.3978235416017695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12576th epoch : 1.3978154155361682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12577th epoch : 1.3978072963326937  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 12578th epoch : 1.3977991839787827  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12579th epoch : 1.3977910784618968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12580th epoch : 1.3977829797695214  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12581th epoch : 1.3977748878891665  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12582th epoch : 1.3977668028083656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12583th epoch : 1.397758724514677  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12584th epoch : 1.3977506529956827  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12585th epoch : 1.3977425882389887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12586th epoch : 1.3977345302322244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12587th epoch : 1.397726478963044  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12588th epoch : 1.3977184344191245  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12589th epoch : 1.3977103965881668  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12590th epoch : 1.397702365457896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12591th epoch : 1.3976943410160596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12592th epoch : 1.3976863232504295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12593th epoch : 1.3976783121488006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12594th epoch : 1.3976703076989911  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12595th epoch : 1.397662309888843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12596th epoch : 1.3976543187062205  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12597th epoch : 1.3976463341390115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12598th epoch : 1.397638356175127  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12599th epoch : 1.3976303848025011  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12600th epoch : 1.3976224200090905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12601th epoch : 1.3976144617828747  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12602th epoch : 1.3976065101118562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12603th epoch : 1.3975985649840605  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12604th epoch : 1.397590626387535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12605th epoch : 1.3975826943103504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12606th epoch : 1.3975747687405995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12607th epoch : 1.3975668496663978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12608th epoch : 1.3975589370758832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12609th epoch : 1.3975510309572157  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12610th epoch : 1.3975431312985778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12611th epoch : 1.397535238088174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12612th epoch : 1.3975273513142314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12613th epoch : 1.3975194709649987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12614th epoch : 1.3975115970287466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12615th epoch : 1.397503729493768  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12616th epoch : 1.3974958683483776  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12617th epoch : 1.397488013580912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12618th epoch : 1.3974801651797295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12619th epoch : 1.39747232313321  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12620th epoch : 1.397464487429755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12621th epoch : 1.3974566580577878  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12622th epoch : 1.3974488350057535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12623th epoch : 1.3974410182621175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12624th epoch : 1.397433207815368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12625th epoch : 1.3974254036540135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12626th epoch : 1.3974176057665844  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12627th epoch : 1.3974098141416318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12628th epoch : 1.3974020287677282  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12629th epoch : 1.3973942496334675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12630th epoch : 1.397386476727464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12631th epoch : 1.397378710038353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12632th epoch : 1.3973709495547917  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12633th epoch : 1.3973631952654568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12634th epoch : 1.3973554471590466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12635th epoch : 1.3973477052242798  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12636th epoch : 1.3973399694498958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12637th epoch : 1.3973322398246548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12638th epoch : 1.3973245163373376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12639th epoch : 1.397316798976745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12640th epoch : 1.3973090877316987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12641th epoch : 1.3973013825910403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12642th epoch : 1.3972936835436323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12643th epoch : 1.397285990578357  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12644th epoch : 1.3972783036841172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12645th epoch : 1.3972706228498355  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12646th epoch : 1.3972629480644547  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12647th epoch : 1.397255279316938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12648th epoch : 1.3972476165962677  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12649th epoch : 1.3972399598914471  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12650th epoch : 1.3972323091914982  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12651th epoch : 1.397224664485464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12652th epoch : 1.397217025762406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12653th epoch : 1.3972093930114065  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12654th epoch : 1.3972017662215663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12655th epoch : 1.397194145382007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12656th epoch : 1.3971865304818685  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12657th epoch : 1.397178921510311  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12658th epoch : 1.3971713184565138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12659th epoch : 1.3971637213096755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12660th epoch : 1.397156130059014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12661th epoch : 1.3971485446937666  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12662th epoch : 1.3971409652031894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12663th epoch : 1.397133391576558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12664th epoch : 1.3971258238031667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12665th epoch : 1.3971182618723295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12666th epoch : 1.3971107057733783  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12667th epoch : 1.3971031554956648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12668th epoch : 1.397095611028559  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12669th epoch : 1.39708807236145  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12670th epoch : 1.3970805394837458  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12671th epoch : 1.3970730123848722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12672th epoch : 1.3970654910542748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12673th epoch : 1.3970579754814172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12674th epoch : 1.397050465655781  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12675th epoch : 1.3970429615668674  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12676th epoch : 1.397035463204195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12677th epoch : 1.3970279705573017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12678th epoch : 1.3970204836157425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12679th epoch : 1.3970130023690919  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12680th epoch : 1.3970055268069417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12681th epoch : 1.3969980569189024  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12682th epoch : 1.3969905926946022  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12683th epoch : 1.396983134123688  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12684th epoch : 1.3969756811958238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12685th epoch : 1.3969682339006921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12686th epoch : 1.3969607922279932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12687th epoch : 1.3969533561674452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12688th epoch : 1.396945925708784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12689th epoch : 1.3969385008417632  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12690th epoch : 1.3969310815561544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12691th epoch : 1.396923667841746  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12692th epoch : 1.396916259688345  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12693th epoch : 1.3969088570857755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12694th epoch : 1.3969014600238787  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12695th epoch : 1.396894068492514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12696th epoch : 1.3968866824815573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12697th epoch : 1.396879301980903  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12698th epoch : 1.3968719269804613  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12699th epoch : 1.3968645574701608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12700th epoch : 1.396857193439947  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12701th epoch : 1.3968498348797824  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12702th epoch : 1.3968424817796463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12703th epoch : 1.3968351341295357  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12704th epoch : 1.3968277919194643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12705th epoch : 1.3968204551394623  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12706th epoch : 1.3968131237795773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12707th epoch : 1.3968057978298738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12708th epoch : 1.3967984772804325  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12709th epoch : 1.3967911621213516  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12710th epoch : 1.3967838523427456  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12711th epoch : 1.3967765479347454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12712th epoch : 1.3967692488874988  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12713th epoch : 1.3967619551911703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12714th epoch : 1.3967546668359405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12715th epoch : 1.3967473838120068  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12716th epoch : 1.3967401061095828  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12717th epoch : 1.3967328337188984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12718th epoch : 1.3967255666302003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12719th epoch : 1.3967183048337508  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12720th epoch : 1.3967110483198286  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12721th epoch : 1.3967037970787288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12722th epoch : 1.3966965511007627  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12723th epoch : 1.3966893103762572  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12724th epoch : 1.3966820748955555  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12725th epoch : 1.3966748446490167  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12726th epoch : 1.3966676196270162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12727th epoch : 1.396660399819945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12728th epoch : 1.3966531852182096  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12729th epoch : 1.396645975812233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12730th epoch : 1.3966387715924533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12731th epoch : 1.3966315725493246  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12732th epoch : 1.396624378673317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12733th epoch : 1.3966171899549156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12734th epoch : 1.3966100063846212  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12735th epoch : 1.3966028279529505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12736th epoch : 1.3965956546504354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12737th epoch : 1.3965884864676232  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12738th epoch : 1.3965813233950766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12739th epoch : 1.3965741654233739  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12740th epoch : 1.3965670125431082  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12741th epoch : 1.3965598647448885  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12742th epoch : 1.3965527220193386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12743th epoch : 1.396545584357097  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12744th epoch : 1.3965384517488186  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12745th epoch : 1.396531324185172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12746th epoch : 1.3965242016568418  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12747th epoch : 1.3965170841545271  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12748th epoch : 1.3965099716689422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12749th epoch : 1.3965028641908162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12750th epoch : 1.3964957617108926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12751th epoch : 1.3964886642199308  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12752th epoch : 1.396481571708704  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12753th epoch : 1.3964744841680004  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12754th epoch : 1.396467401588623  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12755th epoch : 1.3964603239613893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12756th epoch : 1.3964532512771317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12757th epoch : 1.3964461835266966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12758th epoch : 1.3964391207009454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12759th epoch : 1.396432062790754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12760th epoch : 1.3964250097870123  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12761th epoch : 1.396417961680625  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12762th epoch : 1.3964109184625106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12763th epoch : 1.3964038801236027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12764th epoch : 1.3963968466548484  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12765th epoch : 1.3963898180472094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12766th epoch : 1.3963827942916618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12767th epoch : 1.396375775379195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12768th epoch : 1.3963687613008136  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12769th epoch : 1.3963617520475353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12770th epoch : 1.3963547476103924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12771th epoch : 1.3963477479804307  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12772th epoch : 1.3963407531487106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12773th epoch : 1.3963337631063057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12774th epoch : 1.3963267778443036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12775th epoch : 1.3963197973538062  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12776th epoch : 1.3963128216259282  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12777th epoch : 1.3963058506517991  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12778th epoch : 1.3962988844225614  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12779th epoch : 1.3962919229293715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12780th epoch : 1.3962849661633991  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12781th epoch : 1.3962780141158277  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12782th epoch : 1.3962710667778546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12783th epoch : 1.3962641241406901  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12784th epoch : 1.396257186195558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12785th epoch : 1.3962502529336955  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12786th epoch : 1.3962433243463535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12787th epoch : 1.396236400424796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12788th epoch : 1.3962294811603002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12789th epoch : 1.3962225665441563  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12790th epoch : 1.3962156565676687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12791th epoch : 1.3962087512221535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12792th epoch : 1.396201850498941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12793th epoch : 1.3961949543893746  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12794th epoch : 1.3961880628848098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12795th epoch : 1.396181175976616  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12796th epoch : 1.3961742936561754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12797th epoch : 1.396167415914883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12798th epoch : 1.3961605427441464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12799th epoch : 1.3961536741353864  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12800th epoch : 1.3961468100800367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12801th epoch : 1.3961399505695435  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12802th epoch : 1.3961330955953661  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12803th epoch : 1.396126245148976  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12804th epoch : 1.3961193992218577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12805th epoch : 1.3961125578055082  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12806th epoch : 1.3961057208914371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12807th epoch : 1.3960988884711667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12808th epoch : 1.3960920605362312  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12809th epoch : 1.3960852370781784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12810th epoch : 1.3960784180885673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12811th epoch : 1.39607160355897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12812th epoch : 1.396064793480971  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12813th epoch : 1.3960579878461665  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12814th epoch : 1.3960511866461658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12815th epoch : 1.3960443898725898  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12816th epoch : 1.396037597517072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12817th epoch : 1.396030809571258  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12818th epoch : 1.396024026026805  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12819th epoch : 1.3960172468753833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12820th epoch : 1.3960104721086743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12821th epoch : 1.396003701718372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12822th epoch : 1.395996935696182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12823th epoch : 1.3959901740338223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12824th epoch : 1.3959834167230225  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12825th epoch : 1.3959766637555242  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12826th epoch : 1.3959699151230807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12827th epoch : 1.3959631708174571  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12828th epoch : 1.3959564308304304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12829th epoch : 1.3959496951537895  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12830th epoch : 1.3959429637793344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12831th epoch : 1.3959362366988775  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12832th epoch : 1.3959295139042422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12833th epoch : 1.3959227953872637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12834th epoch : 1.395916081139789  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12835th epoch : 1.3959093711536765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12836th epoch : 1.3959026654207958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12837th epoch : 1.395895963933028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12838th epoch : 1.395889266682266  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12839th epoch : 1.395882573660414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12840th epoch : 1.3958758848593866  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12841th epoch : 1.3958692002711113  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12842th epoch : 1.3958625198875259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12843th epoch : 1.395855843700579  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12844th epoch : 1.3958491717022317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12845th epoch : 1.3958425038844549  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12846th epoch : 1.3958358402392317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12847th epoch : 1.3958291807585559  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12848th epoch : 1.3958225254344319  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12849th epoch : 1.395815874258876  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12850th epoch : 1.3958092272239147  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12851th epoch : 1.395802584321586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12852th epoch : 1.3957959455439384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12853th epoch : 1.395789310883032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12854th epoch : 1.3957826803309368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12855th epoch : 1.3957760538797341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12856th epoch : 1.3957694315215161  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12857th epoch : 1.395762813248386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12858th epoch : 1.3957561990524565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12859th epoch : 1.3957495889258527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12860th epoch : 1.3957429828607089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12861th epoch : 1.395736380849171  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12862th epoch : 1.3957297828833948  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12863th epoch : 1.395723188955547  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12864th epoch : 1.3957165990578047  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12865th epoch : 1.3957100131823559  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12866th epoch : 1.395703431321398  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12867th epoch : 1.3956968534671403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12868th epoch : 1.3956902796118014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12869th epoch : 1.3956837097476102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12870th epoch : 1.3956771438668067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12871th epoch : 1.3956705819616406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12872th epoch : 1.395664024024372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12873th epoch : 1.3956574700472713  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12874th epoch : 1.3956509200226188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12875th epoch : 1.3956443739427054  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12876th epoch : 1.3956378317998317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12877th epoch : 1.3956312935863089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12878th epoch : 1.3956247592944575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12879th epoch : 1.3956182289166088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12880th epoch : 1.3956117024451036  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12881th epoch : 1.395605179872293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12882th epoch : 1.3955986611905375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12883th epoch : 1.395592146392208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12884th epoch : 1.3955856354696854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12885th epoch : 1.3955791284153598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12886th epoch : 1.3955726252216314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12887th epoch : 1.3955661258809102  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12888th epoch : 1.3955596303856164  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12889th epoch : 1.3955531387281788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12890th epoch : 1.395546650901037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12891th epoch : 1.3955401668966394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12892th epoch : 1.3955336867074446  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12893th epoch : 1.3955272103259206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12894th epoch : 1.3955207377445447  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12895th epoch : 1.395514268955804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12896th epoch : 1.3955078039521949  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12897th epoch : 1.3955013427262235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12898th epoch : 1.395494885270405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12899th epoch : 1.3954884315772644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12900th epoch : 1.3954819816393356  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12901th epoch : 1.395475535449162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12902th epoch : 1.3954690929992966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12903th epoch : 1.395462654282301  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12904th epoch : 1.3954562192907467  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12905th epoch : 1.3954497880172143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12906th epoch : 1.3954433604542933  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12907th epoch : 1.3954369365945822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12908th epoch : 1.3954305164306893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12909th epoch : 1.3954240999552312  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12910th epoch : 1.3954176871608341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12911th epoch : 1.395411278040133  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12912th epoch : 1.3954048725857722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12913th epoch : 1.3953984707904041  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12914th epoch : 1.3953920726466909  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12915th epoch : 1.3953856781473035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12916th epoch : 1.3953792872849216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12917th epoch : 1.3953729000522335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12918th epoch : 1.3953665164419367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12919th epoch : 1.3953601364467372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12920th epoch : 1.39535376005935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12921th epoch : 1.3953473872724986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12922th epoch : 1.3953410180789152  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12923th epoch : 1.395334652471341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12924th epoch : 1.3953282904425253  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12925th epoch : 1.3953219319852264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12926th epoch : 1.3953155770922108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12927th epoch : 1.395309225756254  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12928th epoch : 1.39530287797014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12929th epoch : 1.3952965337266605  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12930th epoch : 1.3952901930186166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12931th epoch : 1.3952838558388174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12932th epoch : 1.3952775221800804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12933th epoch : 1.3952711920352314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12934th epoch : 1.395264865397105  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12935th epoch : 1.3952585422585433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12936th epoch : 1.3952522226123973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12937th epoch : 1.3952459064515264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12938th epoch : 1.3952395937687974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12939th epoch : 1.3952332845570858  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12940th epoch : 1.3952269788092757  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12941th epoch : 1.3952206765182584  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12942th epoch : 1.3952143776769341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12943th epoch : 1.3952080822782105  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12944th epoch : 1.3952017903150038  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12945th epoch : 1.395195501780238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12946th epoch : 1.3951892166668451  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12947th epoch : 1.395182934967765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12948th epoch : 1.3951766566759456  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12949th epoch : 1.3951703817843428  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12950th epoch : 1.3951641102859202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12951th epoch : 1.3951578421736492  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12952th epoch : 1.3951515774405097  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12953th epoch : 1.395145316079488  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12954th epoch : 1.3951390580835796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12955th epoch : 1.395132803445787  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12956th epoch : 1.3951265521591207  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12957th epoch : 1.3951203042165983  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12958th epoch : 1.3951140596112457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12959th epoch : 1.395107818336096  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12960th epoch : 1.3951015803841906  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12961th epoch : 1.3950953457485773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12962th epoch : 1.3950891144223125  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12963th epoch : 1.3950828863984595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12964th epoch : 1.3950766616700891  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12965th epoch : 1.3950704402302803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12966th epoch : 1.3950642220721183  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12967th epoch : 1.3950580071886969  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12968th epoch : 1.3950517955731163  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12969th epoch : 1.3950455872184846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12970th epoch : 1.3950393821179172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12971th epoch : 1.3950331802645366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12972th epoch : 1.3950269816514724  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12973th epoch : 1.395020786271862  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12974th epoch : 1.3950145941188494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12975th epoch : 1.3950084051855862  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12976th epoch : 1.395002219465231  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12977th epoch : 1.3949960369509493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12978th epoch : 1.3949898576359143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12979th epoch : 1.3949836815133057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12980th epoch : 1.39497750857631  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12981th epoch : 1.394971338818122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12982th epoch : 1.394965172231942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12983th epoch : 1.394959008810978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12984th epoch : 1.3949528485484448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12985th epoch : 1.3949466914375643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12986th epoch : 1.394940537471565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12987th epoch : 1.3949343866436825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12988th epoch : 1.394928238947159  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12989th epoch : 1.3949220943752434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12990th epoch : 1.3949159529211916  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12991th epoch : 1.3949098145782666  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12992th epoch : 1.3949036793397374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12993th epoch : 1.39489754719888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12994th epoch : 1.394891418148977  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12995th epoch : 1.3948852921833181  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12996th epoch : 1.3948791692951992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12997th epoch : 1.3948730494779225  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12998th epoch : 1.3948669327247971  Training Accuracy:0.8571428571428571\n",
      "The training loss at 12999th epoch : 1.3948608190291387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13000th epoch : 1.3948547083842697  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13001th epoch : 1.3948486007835184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13002th epoch : 1.39484249622022  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13003th epoch : 1.3948363946877158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13004th epoch : 1.394830296179354  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13005th epoch : 1.3948242006884886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13006th epoch : 1.3948181082084803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13007th epoch : 1.3948120187326958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13008th epoch : 1.3948059322545088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13009th epoch : 1.3947998487672986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13010th epoch : 1.3947937682644507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13011th epoch : 1.3947876907393575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13012th epoch : 1.3947816161854167  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13013th epoch : 1.394775544596033  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13014th epoch : 1.3947694759646168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13015th epoch : 1.3947634102845845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13016th epoch : 1.3947573475493589  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13017th epoch : 1.3947512877523687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13018th epoch : 1.3947452308870487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13019th epoch : 1.3947391769468396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13020th epoch : 1.3947331259251883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13021th epoch : 1.3947270778155474  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13022th epoch : 1.3947210326113755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13023th epoch : 1.3947149903061375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13024th epoch : 1.3947089508933035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13025th epoch : 1.3947029143663499  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13026th epoch : 1.394696880718759  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13027th epoch : 1.3946908499440185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13028th epoch : 1.3946848220356223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13029th epoch : 1.3946787969870698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13030th epoch : 1.3946727747918661  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13031th epoch : 1.3946667554435224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13032th epoch : 1.3946607389355552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13033th epoch : 1.3946547252614865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13034th epoch : 1.3946487144148445  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13035th epoch : 1.3946427063891624  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13036th epoch : 1.3946367011779797  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13037th epoch : 1.3946306987748402  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13038th epoch : 1.394624699173295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13039th epoch : 1.394618702366899  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13040th epoch : 1.3946127083492137  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13041th epoch : 1.3946067171138052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13042th epoch : 1.3946007286542461  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13043th epoch : 1.3945947429641135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13044th epoch : 1.3945887600369902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13045th epoch : 1.394582779866464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13046th epoch : 1.394576802446129  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13047th epoch : 1.3945708277695832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13048th epoch : 1.394564855830431  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13049th epoch : 1.3945588866222818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13050th epoch : 1.3945529201387499  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13051th epoch : 1.394546956373455  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13052th epoch : 1.3945409953200218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13053th epoch : 1.3945350369720806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13054th epoch : 1.3945290813232665  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13055th epoch : 1.3945231283672197  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13056th epoch : 1.3945171780975854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13057th epoch : 1.394511230508014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13058th epoch : 1.3945052855921611  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13059th epoch : 1.394499343343687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13060th epoch : 1.3944934037562569  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13061th epoch : 1.3944874668235414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13062th epoch : 1.3944815325392157  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13063th epoch : 1.3944756008969597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13064th epoch : 1.3944696718904588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13065th epoch : 1.3944637455134026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13066th epoch : 1.394457821759486  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13067th epoch : 1.3944519006224085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13068th epoch : 1.3944459820958743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13069th epoch : 1.3944400661735927  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13070th epoch : 1.3944341528492772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13071th epoch : 1.3944282421166465  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13072th epoch : 1.3944223339694237  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13073th epoch : 1.3944164284013367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13074th epoch : 1.394410525406118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13075th epoch : 1.3944046249775046  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13076th epoch : 1.3943987271092382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13077th epoch : 1.3943928317950651  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13078th epoch : 1.3943869390287358  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13079th epoch : 1.3943810488040058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13080th epoch : 1.3943751611146349  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13081th epoch : 1.3943692759543873  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13082th epoch : 1.3943633933170316  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13083th epoch : 1.3943575131963408  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13084th epoch : 1.3943516355860923  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13085th epoch : 1.3943457604800684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13086th epoch : 1.3943398878720548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13087th epoch : 1.394334017755842  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13088th epoch : 1.3943281501252252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13089th epoch : 1.394322284974003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13090th epoch : 1.3943164222959787  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13091th epoch : 1.3943105620849603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13092th epoch : 1.3943047043347592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13093th epoch : 1.394298849039191  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13094th epoch : 1.3942929961920763  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13095th epoch : 1.3942871457872388  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13096th epoch : 1.394281297818507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13097th epoch : 1.3942754522797132  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13098th epoch : 1.3942696091646938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13099th epoch : 1.394263768467289  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13100th epoch : 1.3942579301813434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13101th epoch : 1.3942520943007055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13102th epoch : 1.3942462608192274  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13103th epoch : 1.3942404297307656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13104th epoch : 1.39423460102918  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13105th epoch : 1.394228774708335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13106th epoch : 1.3942229507620985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13107th epoch : 1.394217129184342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13108th epoch : 1.3942113099689413  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13109th epoch : 1.3942054931097756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13110th epoch : 1.3941996786007282  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13111th epoch : 1.394193866435686  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13112th epoch : 1.3941880566085396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13113th epoch : 1.394182249113183  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13114th epoch : 1.3941764439435145  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13115th epoch : 1.3941706410934356  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13116th epoch : 1.3941648405568514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13117th epoch : 1.3941590423276706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13118th epoch : 1.3941532463998059  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13119th epoch : 1.3941474527671731  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13120th epoch : 1.3941416614236917  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13121th epoch : 1.3941358723632846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13122th epoch : 1.3941300855798784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13123th epoch : 1.3941243010674027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13124th epoch : 1.3941185188197909  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13125th epoch : 1.39411273883098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13126th epoch : 1.39410696109491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13127th epoch : 1.394101185605524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13128th epoch : 1.3940954123567695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13129th epoch : 1.394089641342596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13130th epoch : 1.3940838725569575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13131th epoch : 1.39407810599381  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13132th epoch : 1.3940723416471141  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13133th epoch : 1.3940665795108325  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13134th epoch : 1.3940608195789315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13135th epoch : 1.3940550618453809  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13136th epoch : 1.394049306304153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13137th epoch : 1.3940435529492239  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13138th epoch : 1.3940378017745723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13139th epoch : 1.39403205277418  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13140th epoch : 1.3940263059420324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13141th epoch : 1.394020561272117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13142th epoch : 1.3940148187584254  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13143th epoch : 1.394009078394951  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13144th epoch : 1.3940033401756913  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13145th epoch : 1.3939976040946458  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13146th epoch : 1.3939918701458176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13147th epoch : 1.3939861383232122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13148th epoch : 1.3939804086208383  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13149th epoch : 1.3939746810327072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13150th epoch : 1.393968955552833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13151th epoch : 1.3939632321752329  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13152th epoch : 1.3939575108939264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13153th epoch : 1.3939517917029365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13154th epoch : 1.393946074596288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13155th epoch : 1.3939403595680089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13156th epoch : 1.3939346466121298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13157th epoch : 1.3939289357226843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13158th epoch : 1.3939232268937076  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13159th epoch : 1.3939175201192389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13160th epoch : 1.393911815393319  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13161th epoch : 1.3939061127099912  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 13162th epoch : 1.393900412063302  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13163th epoch : 1.3938947134473  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13164th epoch : 1.3938890168560365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13165th epoch : 1.3938833222835647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13166th epoch : 1.3938776297239408  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13167th epoch : 1.3938719391712235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13168th epoch : 1.3938662506194734  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13169th epoch : 1.393860564062754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13170th epoch : 1.3938548794951304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13171th epoch : 1.3938491969106708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13172th epoch : 1.3938435163034455  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13173th epoch : 1.3938378376675264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13174th epoch : 1.3938321609969888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13175th epoch : 1.3938264862859093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13176th epoch : 1.3938208135283672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13177th epoch : 1.3938151427184435  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13178th epoch : 1.393809473850222  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13179th epoch : 1.393803806917788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13180th epoch : 1.3937981419152294  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13181th epoch : 1.393792478836636  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13182th epoch : 1.3937868176760995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13183th epoch : 1.393781158427714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13184th epoch : 1.393775501085575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13185th epoch : 1.3937698456437806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13186th epoch : 1.3937641920964308  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13187th epoch : 1.3937585404376271  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13188th epoch : 1.3937528906614736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13189th epoch : 1.3937472427620754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13190th epoch : 1.3937415967335403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13191th epoch : 1.3937359525699775  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13192th epoch : 1.393730310265498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13193th epoch : 1.3937246698142152  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13194th epoch : 1.3937190312102434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13195th epoch : 1.3937133944476994  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13196th epoch : 1.393707759520701  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13197th epoch : 1.3937021264233684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13198th epoch : 1.393696495149823  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13199th epoch : 1.3936908656941882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13200th epoch : 1.3936852380505889  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13201th epoch : 1.3936796122131514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13202th epoch : 1.393673988176004  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13203th epoch : 1.3936683659332763  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13204th epoch : 1.3936627454790993  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13205th epoch : 1.393657126807606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13206th epoch : 1.39365150991293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13207th epoch : 1.3936458947892079  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13208th epoch : 1.393640281430576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13209th epoch : 1.393634669831173  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13210th epoch : 1.3936290599851389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13211th epoch : 1.393623451886615  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13212th epoch : 1.393617845529744  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13213th epoch : 1.39361224090867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13214th epoch : 1.3936066380175378  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13215th epoch : 1.3936010368504943  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13216th epoch : 1.3935954374016872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13217th epoch : 1.3935898396652655  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13218th epoch : 1.3935842436353794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13219th epoch : 1.3935786493061804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13220th epoch : 1.3935730566718212  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13221th epoch : 1.3935674657264552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13222th epoch : 1.3935618764642375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13223th epoch : 1.3935562888793236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13224th epoch : 1.393550702965871  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13225th epoch : 1.3935451187180374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13226th epoch : 1.3935395361299818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13227th epoch : 1.3935339551958643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13228th epoch : 1.393528375909846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13229th epoch : 1.3935227982660885  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13230th epoch : 1.3935172222587549  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13231th epoch : 1.3935116478820087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13232th epoch : 1.3935060751300146  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13233th epoch : 1.3935005039969381  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13234th epoch : 1.3934949344769456  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13235th epoch : 1.3934893665642039  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13236th epoch : 1.393483800252881  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13237th epoch : 1.3934782355371453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13238th epoch : 1.3934726724111663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13239th epoch : 1.3934671108691141  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13240th epoch : 1.3934615509051593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13241th epoch : 1.393455992513473  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13242th epoch : 1.3934504356882274  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13243th epoch : 1.393444880423595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13244th epoch : 1.3934393267137493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13245th epoch : 1.3934337745528633  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13246th epoch : 1.393428223935112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13247th epoch : 1.3934226748546696  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13248th epoch : 1.3934171273057117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13249th epoch : 1.3934115812824137  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13250th epoch : 1.393406036778952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13251th epoch : 1.3934004937895028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13252th epoch : 1.3933949523082434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13253th epoch : 1.3933894123293509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13254th epoch : 1.3933838738470028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13255th epoch : 1.3933783368553774  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13256th epoch : 1.3933728013486524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13257th epoch : 1.3933672673210067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13258th epoch : 1.3933617347666187  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13259th epoch : 1.3933562036796678  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13260th epoch : 1.3933506740543327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13261th epoch : 1.3933451458847925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13262th epoch : 1.3933396191652272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13263th epoch : 1.3933340938898162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13264th epoch : 1.3933285700527387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13265th epoch : 1.3933230476481748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13266th epoch : 1.3933175266703042  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13267th epoch : 1.3933120071133067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13268th epoch : 1.3933064889713618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13269th epoch : 1.3933009722386493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13270th epoch : 1.393295456909349  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13271th epoch : 1.3932899429776402  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13272th epoch : 1.3932844304377026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13273th epoch : 1.3932789192837156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13274th epoch : 1.3932734095098582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13275th epoch : 1.3932679011103093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13276th epoch : 1.393262394079248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13277th epoch : 1.3932568884108525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13278th epoch : 1.3932513840993015  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13279th epoch : 1.3932458811387725  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13280th epoch : 1.3932403795234436  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13281th epoch : 1.3932348792474922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13282th epoch : 1.393229380305095  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13283th epoch : 1.3932238826904288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13284th epoch : 1.39321838639767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13285th epoch : 1.393212891420994  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13286th epoch : 1.3932073977545765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13287th epoch : 1.3932019053925921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13288th epoch : 1.3931964143292155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13289th epoch : 1.39319092455862  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13290th epoch : 1.3931854360749791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13291th epoch : 1.3931799488724654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13292th epoch : 1.3931744629452512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13293th epoch : 1.3931689782875076  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13294th epoch : 1.3931634948934055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13295th epoch : 1.393158012757115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13296th epoch : 1.3931525318728053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13297th epoch : 1.3931470522346452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13298th epoch : 1.3931415738368025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13299th epoch : 1.393136096673444  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13300th epoch : 1.3931306207387366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13301th epoch : 1.393125146026845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13302th epoch : 1.3931196725319341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13303th epoch : 1.3931142002481676  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13304th epoch : 1.393108729169708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13305th epoch : 1.3931032592907173  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13306th epoch : 1.393097790605356  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13307th epoch : 1.3930923231077845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13308th epoch : 1.3930868567921613  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13309th epoch : 1.3930813916526439  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13310th epoch : 1.3930759276833893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13311th epoch : 1.393070464878553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13312th epoch : 1.3930650032322895  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13313th epoch : 1.3930595427387522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13314th epoch : 1.393054083392093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13315th epoch : 1.393048625186463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13316th epoch : 1.3930431681160118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13317th epoch : 1.393037712174888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13318th epoch : 1.3930322573572387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13319th epoch : 1.3930268036572098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13320th epoch : 1.3930213510689455  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13321th epoch : 1.3930158995865893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13322th epoch : 1.393010449204283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13323th epoch : 1.3930049999161667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13324th epoch : 1.3929995517163796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13325th epoch : 1.3929941045990588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13326th epoch : 1.3929886585583406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13327th epoch : 1.3929832135883593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13328th epoch : 1.392977769683248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13329th epoch : 1.3929723268371375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13330th epoch : 1.392966885044158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13331th epoch : 1.3929614442984375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13332th epoch : 1.3929560045941023  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13333th epoch : 1.3929505659252772  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13334th epoch : 1.3929451282860854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13335th epoch : 1.392939691670648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13336th epoch : 1.3929342560730846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13337th epoch : 1.3929288214875133  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13338th epoch : 1.3929233879080496  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13339th epoch : 1.3929179553288076  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13340th epoch : 1.3929125237439  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13341th epoch : 1.3929070931474368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13342th epoch : 1.3929016635335263  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13343th epoch : 1.3928962348962752  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13344th epoch : 1.392890807229788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13345th epoch : 1.3928853805281673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13346th epoch : 1.392879954785513  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13347th epoch : 1.3928745299959242  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13348th epoch : 1.3928691061534968  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13349th epoch : 1.392863683252325  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13350th epoch : 1.3928582612865006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13351th epoch : 1.3928528402501141  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13352th epoch : 1.3928474201372527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13353th epoch : 1.392842000942002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13354th epoch : 1.392836582658445  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13355th epoch : 1.3928311652806629  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13356th epoch : 1.392825748802734  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13357th epoch : 1.3928203332187348  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13358th epoch : 1.3928149185227392  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13359th epoch : 1.3928095047088185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13360th epoch : 1.392804091771042  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13361th epoch : 1.3927986797034762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13362th epoch : 1.392793268500185  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13363th epoch : 1.3927878581552304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13364th epoch : 1.3927824486626716  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13365th epoch : 1.3927770400165647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13366th epoch : 1.392771632210964  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13367th epoch : 1.3927662252399207  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13368th epoch : 1.3927608190974836  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13369th epoch : 1.3927554137776985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13370th epoch : 1.392750009274609  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13371th epoch : 1.3927446055822552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13372th epoch : 1.3927392026946754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13373th epoch : 1.3927338006059042  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13374th epoch : 1.3927283993099742  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13375th epoch : 1.3927229988009144  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13376th epoch : 1.3927175990727514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13377th epoch : 1.392712200119509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13378th epoch : 1.3927068019352071  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13379th epoch : 1.3927014045138641  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13380th epoch : 1.3926960078494943  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13381th epoch : 1.3926906119361093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13382th epoch : 1.392685216767718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13383th epoch : 1.3926798223383257  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13384th epoch : 1.3926744286419346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13385th epoch : 1.3926690356725442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13386th epoch : 1.3926636434241506  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13387th epoch : 1.3926582518907464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13388th epoch : 1.3926528610663216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13389th epoch : 1.3926474709448622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13390th epoch : 1.3926420815203517  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13391th epoch : 1.3926366927867695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13392th epoch : 1.3926313047380925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13393th epoch : 1.392625917368293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13394th epoch : 1.3926205306713415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13395th epoch : 1.3926151446412038  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13396th epoch : 1.3926097592718425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13397th epoch : 1.3926043745572172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13398th epoch : 1.3925989904912832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13399th epoch : 1.3925936070679927  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13400th epoch : 1.3925882242812946  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13401th epoch : 1.3925828421251336  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13402th epoch : 1.392577460593451  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13403th epoch : 1.3925720796801846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13404th epoch : 1.392566699379268  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13405th epoch : 1.3925613196846314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13406th epoch : 1.3925559405902013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13407th epoch : 1.3925505620899004  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13408th epoch : 1.3925451841776468  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13409th epoch : 1.3925398068473562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13410th epoch : 1.3925344300929392  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13411th epoch : 1.3925290539083028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13412th epoch : 1.3925236782873502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13413th epoch : 1.3925183032239803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13414th epoch : 1.3925129287120885  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13415th epoch : 1.3925075547455656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13416th epoch : 1.3925021813182987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13417th epoch : 1.3924968084241705  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13418th epoch : 1.3924914360570595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13419th epoch : 1.3924860642108405  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13420th epoch : 1.3924806928793838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13421th epoch : 1.3924753220565553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13422th epoch : 1.3924699517362167  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13423th epoch : 1.3924645819122257  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13424th epoch : 1.3924592125784352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13425th epoch : 1.392453843728694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13426th epoch : 1.3924484753568467  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13427th epoch : 1.392443107456733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13428th epoch : 1.3924377400221883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13429th epoch : 1.3924323730470436  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13430th epoch : 1.3924270065251254  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13431th epoch : 1.3924216404502556  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13432th epoch : 1.3924162748162514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13433th epoch : 1.3924109096169255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13434th epoch : 1.3924055448460855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13435th epoch : 1.3924001804975352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13436th epoch : 1.3923948165650728  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13437th epoch : 1.3923894530424923  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13438th epoch : 1.3923840899235824  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13439th epoch : 1.3923787272021277  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13440th epoch : 1.392373364871907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13441th epoch : 1.3923680029266952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13442th epoch : 1.3923626413602614  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13443th epoch : 1.3923572801663704  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13444th epoch : 1.3923519193387817  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13445th epoch : 1.3923465588712496  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13446th epoch : 1.3923411987575236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13447th epoch : 1.392335838991348  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13448th epoch : 1.3923304795664624  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13449th epoch : 1.3923251204766003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13450th epoch : 1.392319761715491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13451th epoch : 1.392314403276858  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13452th epoch : 1.3923090451544193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13453th epoch : 1.3923036873418886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13454th epoch : 1.3922983298329732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13455th epoch : 1.3922929726213755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13456th epoch : 1.3922876157007926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13457th epoch : 1.392282259064916  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13458th epoch : 1.3922769027074315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13459th epoch : 1.3922715466220201  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13460th epoch : 1.3922661908023561  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13461th epoch : 1.3922608352421098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13462th epoch : 1.3922554799349443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13463th epoch : 1.3922501248745178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13464th epoch : 1.392244770054483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13465th epoch : 1.392239415468487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13466th epoch : 1.3922340611101702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13467th epoch : 1.392228706973168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13468th epoch : 1.39222335305111  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13469th epoch : 1.3922179993376194  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13470th epoch : 1.392212645826314  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13471th epoch : 1.3922072925108055  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13472th epoch : 1.3922019393846996  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13473th epoch : 1.3921965864415962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13474th epoch : 1.3921912336750886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13475th epoch : 1.3921858810787648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13476th epoch : 1.3921805286462061  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13477th epoch : 1.392175176370988  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13478th epoch : 1.3921698242466793  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13479th epoch : 1.3921644722668434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13480th epoch : 1.3921591204250368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13481th epoch : 1.3921537687148096  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13482th epoch : 1.392148417129706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13483th epoch : 1.392143065663264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13484th epoch : 1.3921377143090146  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13485th epoch : 1.3921323630604825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13486th epoch : 1.3921270119111864  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13487th epoch : 1.3921216608546376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13488th epoch : 1.3921163098843417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13489th epoch : 1.3921109589937974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13490th epoch : 1.3921056081764964  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13491th epoch : 1.3921002574259245  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13492th epoch : 1.3920949067355601  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13493th epoch : 1.3920895560988749  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13494th epoch : 1.3920842055093345  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13495th epoch : 1.3920788549603966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13496th epoch : 1.3920735044455133  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13497th epoch : 1.3920681539581283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13498th epoch : 1.39206280349168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13499th epoch : 1.3920574530395984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13500th epoch : 1.3920521025953074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13501th epoch : 1.3920467521522235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13502th epoch : 1.392041401703756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13503th epoch : 1.3920360512433072  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13504th epoch : 1.3920307007642723  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13505th epoch : 1.3920253502600393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13506th epoch : 1.3920199997239886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13507th epoch : 1.3920146491494936  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13508th epoch : 1.3920092985299204  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13509th epoch : 1.392003947858628  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13510th epoch : 1.3919985971289668  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13511th epoch : 1.3919932463342812  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13512th epoch : 1.3919878954679075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13513th epoch : 1.3919825445231742  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13514th epoch : 1.3919771934934027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13515th epoch : 1.391971842371906  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13516th epoch : 1.391966491151991  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13517th epoch : 1.391961139826955  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13518th epoch : 1.3919557883900888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13519th epoch : 1.3919504368346753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13520th epoch : 1.3919450851539892  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13521th epoch : 1.3919397333412973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13522th epoch : 1.3919343813898588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13523th epoch : 1.3919290292929252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13524th epoch : 1.3919236770437393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13525th epoch : 1.3919183246355362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13526th epoch : 1.3919129720615433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13527th epoch : 1.3919076193149793  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13528th epoch : 1.3919022663890552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13529th epoch : 1.3918969132769734  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13530th epoch : 1.3918915599719284  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13531th epoch : 1.391886206467106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13532th epoch : 1.3918808527556843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13533th epoch : 1.3918754988308326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13534th epoch : 1.391870144685712  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13535th epoch : 1.3918647903134747  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13536th epoch : 1.391859435707265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13537th epoch : 1.391854080860218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13538th epoch : 1.391848725765461  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13539th epoch : 1.3918433704161124  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13540th epoch : 1.3918380148052811  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13541th epoch : 1.3918326589260688  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13542th epoch : 1.3918273027715669  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13543th epoch : 1.3918219463348591  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13544th epoch : 1.39181658960902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13545th epoch : 1.3918112325871148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13546th epoch : 1.3918058752622002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13547th epoch : 1.391800517627324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13548th epoch : 1.391795159675525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13549th epoch : 1.3917898013998322  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13550th epoch : 1.3917844427932664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13551th epoch : 1.3917790838488389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13552th epoch : 1.3917737245595514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13553th epoch : 1.3917683649183972  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13554th epoch : 1.3917630049183594  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13555th epoch : 1.3917576445524122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13556th epoch : 1.3917522838135206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13557th epoch : 1.3917469226946395  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13558th epoch : 1.391741561188715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13559th epoch : 1.3917361992886834  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13560th epoch : 1.3917308369874715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13561th epoch : 1.391725474277996  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13562th epoch : 1.391720111153165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13563th epoch : 1.3917147476058755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13564th epoch : 1.3917093836290158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13565th epoch : 1.3917040192154637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13566th epoch : 1.391698654358088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13567th epoch : 1.3916932890497464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13568th epoch : 1.3916879232832877  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13569th epoch : 1.3916825570515503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13570th epoch : 1.3916771903473621  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13571th epoch : 1.3916718231635419  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13572th epoch : 1.3916664554928972  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13573th epoch : 1.3916610873282262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13574th epoch : 1.3916557186623166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13575th epoch : 1.3916503494879453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13576th epoch : 1.3916449797978796  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13577th epoch : 1.391639609584876  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13578th epoch : 1.3916342388416807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13579th epoch : 1.391628867561029  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13580th epoch : 1.3916234957356464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13581th epoch : 1.391618123358247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13582th epoch : 1.391612750421535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13583th epoch : 1.3916073769182031  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13584th epoch : 1.3916020028409342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13585th epoch : 1.3915966281823995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13586th epoch : 1.3915912529352599  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13587th epoch : 1.391585877092165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13588th epoch : 1.391580500645754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13589th epoch : 1.3915751235886549  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13590th epoch : 1.391569745913484  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13591th epoch : 1.3915643676128475  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13592th epoch : 1.3915589886793396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13593th epoch : 1.391553609105544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13594th epoch : 1.3915482288840326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13595th epoch : 1.3915428480073662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13596th epoch : 1.3915374664680942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13597th epoch : 1.3915320842587546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13598th epoch : 1.3915267013718737  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13599th epoch : 1.3915213177999668  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13600th epoch : 1.3915159335355374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13601th epoch : 1.3915105485710766  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13602th epoch : 1.3915051628990651  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13603th epoch : 1.3914997765119712  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13604th epoch : 1.3914943894022511  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13605th epoch : 1.3914890015623496  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13606th epoch : 1.3914836129846997  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13607th epoch : 1.391478223661722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13608th epoch : 1.3914728335858253  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13609th epoch : 1.3914674427494065  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13610th epoch : 1.3914620511448499  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13611th epoch : 1.3914566587645283  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13612th epoch : 1.3914512656008016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13613th epoch : 1.3914458716460179  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13614th epoch : 1.3914404768925126  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13615th epoch : 1.3914350813326088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13616th epoch : 1.3914296849586174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13617th epoch : 1.3914242877628364  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13618th epoch : 1.3914188897375515  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13619th epoch : 1.3914134908750355  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13620th epoch : 1.3914080911675488  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13621th epoch : 1.3914026906073387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13622th epoch : 1.3913972891866402  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13623th epoch : 1.391391886897675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13624th epoch : 1.391386483732652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13625th epoch : 1.3913810796837671  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13626th epoch : 1.3913756747432033  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13627th epoch : 1.3913702689031304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13628th epoch : 1.3913648621557053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13629th epoch : 1.391359454493071  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13630th epoch : 1.3913540459073577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13631th epoch : 1.3913486363906826  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13632th epoch : 1.3913432259351488  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13633th epoch : 1.3913378145328463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13634th epoch : 1.3913324021758517  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13635th epoch : 1.391326988856228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13636th epoch : 1.3913215745660243  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13637th epoch : 1.391316159297276  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13638th epoch : 1.3913107430420053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13639th epoch : 1.3913053257922197  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13640th epoch : 1.3912999075399137  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13641th epoch : 1.3912944882770673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13642th epoch : 1.3912890679956464  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13643th epoch : 1.3912836466876035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13644th epoch : 1.3912782243448765  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13645th epoch : 1.391272800959389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13646th epoch : 1.3912673765230505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13647th epoch : 1.3912619510277564  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13648th epoch : 1.3912565244653872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13649th epoch : 1.3912510968278093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13650th epoch : 1.3912456681068748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13651th epoch : 1.391240238294421  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13652th epoch : 1.39123480738227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13653th epoch : 1.3912293753622302  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13654th epoch : 1.3912239422260948  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13655th epoch : 1.3912185079656418  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13656th epoch : 1.3912130725726348  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13657th epoch : 1.3912076360388224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13658th epoch : 1.391202198355938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13659th epoch : 1.3911967595156995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13660th epoch : 1.3911913195098107  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13661th epoch : 1.391185878329959  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13662th epoch : 1.3911804359678175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13663th epoch : 1.3911749924150432  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13664th epoch : 1.3911695476632782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13665th epoch : 1.3911641017041485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13666th epoch : 1.391158654529265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13667th epoch : 1.391153206130223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13668th epoch : 1.3911477564986017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13669th epoch : 1.391142305625965  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13670th epoch : 1.3911368535038608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13671th epoch : 1.3911314001238206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13672th epoch : 1.3911259454773608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13673th epoch : 1.391120489555981  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13674th epoch : 1.3911150323511652  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13675th epoch : 1.3911095738543806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13676th epoch : 1.3911041140570788  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13677th epoch : 1.3910986529506948  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13678th epoch : 1.391093190526647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13679th epoch : 1.3910877267763375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13680th epoch : 1.3910822616911522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13681th epoch : 1.3910767952624596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13682th epoch : 1.3910713274816122  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13683th epoch : 1.3910658583399453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13684th epoch : 1.3910603878287777  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13685th epoch : 1.3910549159394112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13686th epoch : 1.3910494426631304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13687th epoch : 1.391043967991203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13688th epoch : 1.3910384919148797  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13689th epoch : 1.3910330144253937  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13690th epoch : 1.391027535513961  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13691th epoch : 1.3910220551717807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13692th epoch : 1.3910165733900337  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13693th epoch : 1.391011090159884  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13694th epoch : 1.3910056054724778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13695th epoch : 1.3910001193189434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13696th epoch : 1.390994631690392  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13697th epoch : 1.3909891425779166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13698th epoch : 1.390983651972592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13699th epoch : 1.3909781598654753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13700th epoch : 1.390972666247606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13701th epoch : 1.3909671711100051  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13702th epoch : 1.390961674443675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13703th epoch : 1.3909561762396006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13704th epoch : 1.3909506764887478  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13705th epoch : 1.3909451751820643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13706th epoch : 1.3909396723104797  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13707th epoch : 1.390934167864904  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13708th epoch : 1.3909286618362298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13709th epoch : 1.39092315421533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13710th epoch : 1.390917644993059  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13711th epoch : 1.390912134160252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13712th epoch : 1.3909066217077255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13713th epoch : 1.3909011076262772  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 13714th epoch : 1.390895591906685  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13715th epoch : 1.390890074539708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13716th epoch : 1.3908845555160856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13717th epoch : 1.3908790348265383  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13718th epoch : 1.3908735124617668  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13719th epoch : 1.390867988412452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13720th epoch : 1.3908624626692556  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13721th epoch : 1.390856935222819  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13722th epoch : 1.3908514060637647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13723th epoch : 1.3908458751826942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13724th epoch : 1.3908403425701896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13725th epoch : 1.390834808216813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13726th epoch : 1.3908292721131057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13727th epoch : 1.3908237342495897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13728th epoch : 1.3908181946167657  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13729th epoch : 1.3908126532051144  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13730th epoch : 1.3908071100050963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13731th epoch : 1.3908015650071506  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13732th epoch : 1.3907960182016963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13733th epoch : 1.3907904695791313  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13734th epoch : 1.3907849191298332  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13735th epoch : 1.3907793668441577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13736th epoch : 1.3907738127124403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13737th epoch : 1.390768256724995  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13738th epoch : 1.3907626988721145  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13739th epoch : 1.39075713914407  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13740th epoch : 1.390751577531112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13741th epoch : 1.3907460140234686  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13742th epoch : 1.3907404486113473  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13743th epoch : 1.3907348812849325  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13744th epoch : 1.3907293120343884  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13745th epoch : 1.390723740849856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13746th epoch : 1.3907181677214553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13747th epoch : 1.3907125926392834  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13748th epoch : 1.3907070155934158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13749th epoch : 1.3907014365739057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13750th epoch : 1.3906958555707838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13751th epoch : 1.3906902725740582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13752th epoch : 1.3906846875737147  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13753th epoch : 1.3906791005597166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13754th epoch : 1.390673511522004  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13755th epoch : 1.3906679204504941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13756th epoch : 1.3906623273350822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13757th epoch : 1.3906567321656396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13758th epoch : 1.3906511349320143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13759th epoch : 1.3906455356240317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13760th epoch : 1.390639934231494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13761th epoch : 1.3906343307441789  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13762th epoch : 1.3906287251518419  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13763th epoch : 1.390623117444214  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13764th epoch : 1.3906175076110028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13765th epoch : 1.3906118956418918  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13766th epoch : 1.390606281526541  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13767th epoch : 1.390600665254586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13768th epoch : 1.390595046815638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13769th epoch : 1.390589426199285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13770th epoch : 1.3905838033950897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13771th epoch : 1.3905781783925903  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13772th epoch : 1.390572551181301  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13773th epoch : 1.3905669217507113  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13774th epoch : 1.3905612900902853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13775th epoch : 1.390555656189463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13776th epoch : 1.390550020037659  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13777th epoch : 1.3905443816242626  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13778th epoch : 1.3905387409386387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13779th epoch : 1.390533097970126  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13780th epoch : 1.3905274527080382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13781th epoch : 1.3905218051416635  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13782th epoch : 1.3905161552602643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13783th epoch : 1.3905105030530778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13784th epoch : 1.3905048485093143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13785th epoch : 1.3904991916181593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13786th epoch : 1.3904935323687713  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13787th epoch : 1.3904878707502832  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13788th epoch : 1.3904822067518012  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13789th epoch : 1.3904765403624058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13790th epoch : 1.39047087157115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13791th epoch : 1.3904652003670608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13792th epoch : 1.390459526739138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13793th epoch : 1.3904538506763553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13794th epoch : 1.3904481721676587  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13795th epoch : 1.3904424912019673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13796th epoch : 1.390436807768173  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13797th epoch : 1.3904311218551404  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13798th epoch : 1.3904254334517068  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13799th epoch : 1.3904197425466815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13800th epoch : 1.3904140491288466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13801th epoch : 1.3904083531869562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13802th epoch : 1.3904026547097363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13803th epoch : 1.3903969536858853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13804th epoch : 1.390391250104073  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13805th epoch : 1.390385543952941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13806th epoch : 1.3903798352211023  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13807th epoch : 1.3903741238971423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13808th epoch : 1.3903684099696165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13809th epoch : 1.3903626934270525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13810th epoch : 1.3903569742579487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13811th epoch : 1.3903512524507744  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13812th epoch : 1.3903455279939698  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13813th epoch : 1.390339800875946  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13814th epoch : 1.3903340710850847  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13815th epoch : 1.3903283386097374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13816th epoch : 1.390322603438227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13817th epoch : 1.3903168655588458  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13818th epoch : 1.3903111249598565  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13819th epoch : 1.3903053816294921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13820th epoch : 1.3902996355559547  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13821th epoch : 1.3902938867274166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13822th epoch : 1.3902881351320195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13823th epoch : 1.3902823807578748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13824th epoch : 1.3902766235930628  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13825th epoch : 1.3902708636256331  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13826th epoch : 1.3902651008436047  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13827th epoch : 1.3902593352349648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13828th epoch : 1.3902535667876703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13829th epoch : 1.3902477954896457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13830th epoch : 1.390242021328785  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13831th epoch : 1.3902362442929497  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13832th epoch : 1.3902304643699699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13833th epoch : 1.3902246815476442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13834th epoch : 1.3902188958137387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13835th epoch : 1.390213107155987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13836th epoch : 1.390207315562091  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13837th epoch : 1.3902015210197198  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13838th epoch : 1.3901957235165103  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13839th epoch : 1.3901899230400658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13840th epoch : 1.3901841195779576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13841th epoch : 1.3901783131177234  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13842th epoch : 1.3901725036468682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13843th epoch : 1.390166691152863  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13844th epoch : 1.390160875623146  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13845th epoch : 1.3901550570451215  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13846th epoch : 1.3901492354061602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13847th epoch : 1.3901434106935984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13848th epoch : 1.390137582894739  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13849th epoch : 1.3901317519968504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13850th epoch : 1.3901259179871666  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13851th epoch : 1.390120080852887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13852th epoch : 1.3901142405811768  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13853th epoch : 1.390108397159166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13854th epoch : 1.3901025505739497  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13855th epoch : 1.390096700812588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13856th epoch : 1.390090847862106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13857th epoch : 1.3900849917094924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13858th epoch : 1.3900791323417014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13859th epoch : 1.3900732697456515  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13860th epoch : 1.3900674039082241  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13861th epoch : 1.3900615348162662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13862th epoch : 1.3900556624565872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13863th epoch : 1.3900497868159611  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13864th epoch : 1.3900439078811249  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13865th epoch : 1.3900380256387792  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13866th epoch : 1.3900321400755873  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13867th epoch : 1.3900262511781762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13868th epoch : 1.3900203589331352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13869th epoch : 1.3900144633270166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13870th epoch : 1.3900085643463351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13871th epoch : 1.3900026619775676  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13872th epoch : 1.3899967562071534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13873th epoch : 1.3899908470214937  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13874th epoch : 1.389984934406952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13875th epoch : 1.3899790183498524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13876th epoch : 1.389973098836482  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13877th epoch : 1.389967175853088  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13878th epoch : 1.3899612493858795  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13879th epoch : 1.3899553194210261  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13880th epoch : 1.3899493859446588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13881th epoch : 1.3899434489428688  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13882th epoch : 1.389937508401708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13883th epoch : 1.3899315643071888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13884th epoch : 1.3899256166452831  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13885th epoch : 1.3899196654019237  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13886th epoch : 1.3899137105630024  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13887th epoch : 1.3899077521143708  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13888th epoch : 1.3899017900418402  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13889th epoch : 1.389895824331181  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13890th epoch : 1.3898898549681227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13891th epoch : 1.3898838819383534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13892th epoch : 1.3898779052275203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13893th epoch : 1.3898719248212292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13894th epoch : 1.3898659407050438  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13895th epoch : 1.3898599528644864  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13896th epoch : 1.3898539612850367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13897th epoch : 1.389847965952133  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13898th epoch : 1.3898419668511703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13899th epoch : 1.389835963967502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13900th epoch : 1.3898299572864377  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13901th epoch : 1.3898239467932445  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13902th epoch : 1.3898179324731468  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13903th epoch : 1.3898119143113248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13904th epoch : 1.3898058922929157  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13905th epoch : 1.389799866403013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13906th epoch : 1.3897938366266658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13907th epoch : 1.3897878029488793  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13908th epoch : 1.3897817653546147  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13909th epoch : 1.3897757238287882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13910th epoch : 1.3897696783562714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13911th epoch : 1.3897636289218913  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13912th epoch : 1.3897575755104294  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13913th epoch : 1.3897515181066218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13914th epoch : 1.3897454566951595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13915th epoch : 1.3897393912606872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13916th epoch : 1.3897333217878045  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13917th epoch : 1.3897272482610639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13918th epoch : 1.3897211706649721  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13919th epoch : 1.389715088983989  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13920th epoch : 1.389709003202528  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13921th epoch : 1.3897029133049554  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13922th epoch : 1.38969681927559  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13923th epoch : 1.3896907210987037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13924th epoch : 1.3896846187585206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13925th epoch : 1.3896785122392166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13926th epoch : 1.3896724015249202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13927th epoch : 1.389666286599711  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13928th epoch : 1.3896601674476206  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13929th epoch : 1.3896540440526315  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13930th epoch : 1.3896479163986777  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13931th epoch : 1.3896417844696438  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13932th epoch : 1.389635648249365  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13933th epoch : 1.389629507721627  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13934th epoch : 1.3896233628701657  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13935th epoch : 1.3896172136786669  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13936th epoch : 1.3896110601307663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13937th epoch : 1.3896049022100485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13938th epoch : 1.3895987399000485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13939th epoch : 1.3895925731842491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13940th epoch : 1.3895864020460829  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13941th epoch : 1.3895802264689305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13942th epoch : 1.389574046436121  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13943th epoch : 1.3895678619309317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13944th epoch : 1.3895616729365878  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13945th epoch : 1.389555479436262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13946th epoch : 1.3895492814130743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13947th epoch : 1.3895430788500922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13948th epoch : 1.3895368717303298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13949th epoch : 1.389530660036748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13950th epoch : 1.3895244437522543  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13951th epoch : 1.389518222859702  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13952th epoch : 1.389511997341891  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13953th epoch : 1.3895057671815658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13954th epoch : 1.3894995323614174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13955th epoch : 1.3894932928640817  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13956th epoch : 1.3894870486721391  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13957th epoch : 1.3894807997681153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13958th epoch : 1.38947454613448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13959th epoch : 1.389468287753647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13960th epoch : 1.389462024607975  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13961th epoch : 1.3894557566797647  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13962th epoch : 1.3894494839512619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13963th epoch : 1.3894432064046545  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13964th epoch : 1.3894369240220732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13965th epoch : 1.3894306367855922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13966th epoch : 1.3894243446772272  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13967th epoch : 1.3894180476789366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13968th epoch : 1.38941174577262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13969th epoch : 1.3894054389401191  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13970th epoch : 1.389399127163217  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13971th epoch : 1.3893928104236366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13972th epoch : 1.389386488703043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13973th epoch : 1.389380161983041  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13974th epoch : 1.389373830245176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13975th epoch : 1.3893674934709326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13976th epoch : 1.389361151641736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13977th epoch : 1.3893548047389497  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13978th epoch : 1.3893484527438773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13979th epoch : 1.3893420956377602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13980th epoch : 1.389335733401779  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13981th epoch : 1.3893293660170523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13982th epoch : 1.3893229934646363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13983th epoch : 1.3893166157255255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13984th epoch : 1.389310232780651  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13985th epoch : 1.3893038446108816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13986th epoch : 1.3892974511970224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13987th epoch : 1.389291052519815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13988th epoch : 1.3892846485599373  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13989th epoch : 1.389278239298003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13990th epoch : 1.3892718247145615  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13991th epoch : 1.389265404790097  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13992th epoch : 1.3892589795050292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13993th epoch : 1.3892525488397123  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13994th epoch : 1.3892461127744344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13995th epoch : 1.3892396712894182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13996th epoch : 1.3892332243648198  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13997th epoch : 1.3892267719807287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13998th epoch : 1.3892203141171677  Training Accuracy:0.8571428571428571\n",
      "The training loss at 13999th epoch : 1.389213850754092  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14000th epoch : 1.38920738187139  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14001th epoch : 1.3892009074488811  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14002th epoch : 1.3891944274663177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14003th epoch : 1.3891879419033826  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14004th epoch : 1.3891814507396907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14005th epoch : 1.389174953954787  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14006th epoch : 1.3891684515281475  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14007th epoch : 1.3891619434391782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14008th epoch : 1.3891554296672153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14009th epoch : 1.3891489101915235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14010th epoch : 1.389142384991298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14011th epoch : 1.3891358540456618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14012th epoch : 1.3891293173336672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14013th epoch : 1.3891227748342938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14014th epoch : 1.3891162265264498  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14015th epoch : 1.3891096723889707  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14016th epoch : 1.3891031124006188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14017th epoch : 1.3890965465400833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14018th epoch : 1.38908997478598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14019th epoch : 1.3890833971168508  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14020th epoch : 1.389076813511163  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14021th epoch : 1.3890702239473096  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14022th epoch : 1.3890636284036086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14023th epoch : 1.3890570268583025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14024th epoch : 1.3890504192895576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14025th epoch : 1.3890438056754655  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14026th epoch : 1.3890371859940398  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14027th epoch : 1.3890305602232182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14028th epoch : 1.389023928340861  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14029th epoch : 1.3890172903247509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14030th epoch : 1.3890106461525928  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14031th epoch : 1.389003995802013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14032th epoch : 1.3889973392505597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14033th epoch : 1.388990676475701  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14034th epoch : 1.3889840074548268  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14035th epoch : 1.388977332165246  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14036th epoch : 1.3889706505841883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14037th epoch : 1.3889639626888022  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14038th epoch : 1.388957268456155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14039th epoch : 1.388950567863233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14040th epoch : 1.3889438608869409  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14041th epoch : 1.3889371475041006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14042th epoch : 1.3889304276914518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14043th epoch : 1.3889237014256512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14044th epoch : 1.3889169686832719  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14045th epoch : 1.3889102294408031  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14046th epoch : 1.3889034836746503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14047th epoch : 1.388896731361134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14048th epoch : 1.3888899724764896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14049th epoch : 1.388883206996867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14050th epoch : 1.3888764348983305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14051th epoch : 1.3888696561568579  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14052th epoch : 1.3888628707483404  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14053th epoch : 1.3888560786485815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14054th epoch : 1.388849279833298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14055th epoch : 1.3888424742781182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14056th epoch : 1.388835661958582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14057th epoch : 1.38882884285014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14058th epoch : 1.3888220169281542  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14059th epoch : 1.3888151841678966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14060th epoch : 1.3888083445445485  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14061th epoch : 1.3888014980332013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14062th epoch : 1.3887946446088546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14063th epoch : 1.388787784246417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14064th epoch : 1.3887809169207046  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14065th epoch : 1.3887740426064414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14066th epoch : 1.3887671612782584  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14067th epoch : 1.388760272910693  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14068th epoch : 1.388753377478189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14069th epoch : 1.3887464749550955  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14070th epoch : 1.3887395653156673  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14071th epoch : 1.3887326485340636  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14072th epoch : 1.3887257245843478  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14073th epoch : 1.3887187934404874  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14074th epoch : 1.3887118550763529  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14075th epoch : 1.3887049094657178  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14076th epoch : 1.3886979565822577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14077th epoch : 1.3886909963995502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14078th epoch : 1.388684028891074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14079th epoch : 1.3886770540302091  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14080th epoch : 1.3886700717902358  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14081th epoch : 1.3886630821443335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14082th epoch : 1.3886560850655816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14083th epoch : 1.3886490805269585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14084th epoch : 1.3886420685013403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14085th epoch : 1.3886350489615011  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14086th epoch : 1.3886280218801128  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14087th epoch : 1.3886209872297435  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14088th epoch : 1.3886139449828576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14089th epoch : 1.3886068951118156  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14090th epoch : 1.3885998375888724  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14091th epoch : 1.3885927723861786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14092th epoch : 1.3885856994757784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14093th epoch : 1.3885786188296094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14094th epoch : 1.3885715304195025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14095th epoch : 1.388564434217181  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14096th epoch : 1.3885573301942602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14097th epoch : 1.388550218322247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14098th epoch : 1.3885430985725387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14099th epoch : 1.3885359709164231  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14100th epoch : 1.3885288353250778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14101th epoch : 1.3885216917695697  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14102th epoch : 1.3885145402208539  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14103th epoch : 1.3885073806497736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14104th epoch : 1.38850021302706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14105th epoch : 1.3884930373233304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14106th epoch : 1.388485853509089  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14107th epoch : 1.3884786615547249  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14108th epoch : 1.3884714614305134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14109th epoch : 1.3884642531066134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14110th epoch : 1.3884570365530682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14111th epoch : 1.3884498117398043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14112th epoch : 1.388442578636631  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14113th epoch : 1.3884353372132394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14114th epoch : 1.3884280874392025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14115th epoch : 1.388420829283974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14116th epoch : 1.3884135627168877  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14117th epoch : 1.3884062877071575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14118th epoch : 1.3883990042238759  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14119th epoch : 1.3883917122360139  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14120th epoch : 1.3883844117124204  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14121th epoch : 1.3883771026218212  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14122th epoch : 1.388369784932819  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14123th epoch : 1.3883624586138916  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14124th epoch : 1.3883551236333926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14125th epoch : 1.38834777995955  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14126th epoch : 1.3883404275604656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14127th epoch : 1.3883330664041142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14128th epoch : 1.388325696458344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14129th epoch : 1.3883183176908738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14130th epoch : 1.3883109300692944  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14131th epoch : 1.3883035335610672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14132th epoch : 1.3882961281335229  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14133th epoch : 1.3882887137538622  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14134th epoch : 1.3882812903891533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14135th epoch : 1.3882738580063327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14136th epoch : 1.3882664165722043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14137th epoch : 1.3882589660534375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14138th epoch : 1.388251506416568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14139th epoch : 1.3882440376279963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14140th epoch : 1.3882365596539872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14141th epoch : 1.3882290724606687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14142th epoch : 1.3882215760140322  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14143th epoch : 1.3882140702799306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14144th epoch : 1.3882065552240783  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14145th epoch : 1.3881990308120502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14146th epoch : 1.3881914970092812  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14147th epoch : 1.3881839537810654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14148th epoch : 1.388176401092555  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14149th epoch : 1.3881688389087596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14150th epoch : 1.388161267194546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14151th epoch : 1.388153685914637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14152th epoch : 1.3881460950336104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14153th epoch : 1.388138494515899  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14154th epoch : 1.3881308843257887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14155th epoch : 1.3881232644274188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14156th epoch : 1.3881156347847805  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14157th epoch : 1.3881079953617164  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14158th epoch : 1.3881003461219195  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14159th epoch : 1.388092687028933  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14160th epoch : 1.3880850180461486  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14161th epoch : 1.388077339136806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14162th epoch : 1.3880696502639924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14163th epoch : 1.3880619513906416  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14164th epoch : 1.3880542424795328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14165th epoch : 1.3880465234932897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14166th epoch : 1.3880387943943806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14167th epoch : 1.3880310551451165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14168th epoch : 1.3880233057076505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14169th epoch : 1.3880155460439771  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14170th epoch : 1.3880077761159317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14171th epoch : 1.387999995885189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14172th epoch : 1.387992205313262  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14173th epoch : 1.3879844043615026  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14174th epoch : 1.387976592991099  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14175th epoch : 1.3879687711630755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14176th epoch : 1.3879609388382916  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14177th epoch : 1.3879530959774413  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14178th epoch : 1.387945242541052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14179th epoch : 1.387937378489483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14180th epoch : 1.3879295037829258  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14181th epoch : 1.3879216183814018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14182th epoch : 1.387913722244763  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14183th epoch : 1.387905815332689  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14184th epoch : 1.3878978976046883  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14185th epoch : 1.387889969020095  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14186th epoch : 1.38788202953807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14187th epoch : 1.3878740791175987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14188th epoch : 1.3878661177174905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14189th epoch : 1.3878581452963776  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14190th epoch : 1.3878501618127144  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14191th epoch : 1.3878421672247758  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14192th epoch : 1.387834161490657  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14193th epoch : 1.3878261445682722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14194th epoch : 1.3878181164153534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14195th epoch : 1.3878100769894492  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14196th epoch : 1.387802026247925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14197th epoch : 1.3877939641479597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14198th epoch : 1.3877858906465472  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14199th epoch : 1.3877778057004935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14200th epoch : 1.3877697092664167  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14201th epoch : 1.3877616013007454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14202th epoch : 1.3877534817597175  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14203th epoch : 1.38774535059938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14204th epoch : 1.3877372077755865  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14205th epoch : 1.3877290532439979  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14206th epoch : 1.3877208869600794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14207th epoch : 1.3877127088791013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14208th epoch : 1.3877045189561361  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14209th epoch : 1.3876963171460586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14210th epoch : 1.3876881034035442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14211th epoch : 1.3876798776830683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14212th epoch : 1.3876716399389042  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14213th epoch : 1.387663390125123  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14214th epoch : 1.387655128195592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14215th epoch : 1.3876468541039735  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14216th epoch : 1.3876385678037233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14217th epoch : 1.3876302692480902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14218th epoch : 1.3876219583901146  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14219th epoch : 1.387613635182627  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14220th epoch : 1.387605299578247  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14221th epoch : 1.387596951529382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14222th epoch : 1.3875885909882264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14223th epoch : 1.3875802179067593  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14224th epoch : 1.387571832236745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14225th epoch : 1.3875634339297298  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 14226th epoch : 1.3875550229370424  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14227th epoch : 1.387546599209791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14228th epoch : 1.3875381626988643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14229th epoch : 1.3875297133549274  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14230th epoch : 1.3875212511284232  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14231th epoch : 1.3875127759695691  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14232th epoch : 1.3875042878283568  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14233th epoch : 1.3874957866545505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14234th epoch : 1.3874872723976857  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14235th epoch : 1.3874787450070682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14236th epoch : 1.3874702044317722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14237th epoch : 1.387461650620639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14238th epoch : 1.3874530835222763  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14239th epoch : 1.387444503085056  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14240th epoch : 1.3874359092571131  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14241th epoch : 1.3874273019863448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14242th epoch : 1.3874186812204086  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14243th epoch : 1.3874100469067203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14244th epoch : 1.3874013989924543  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14245th epoch : 1.3873927374245403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14246th epoch : 1.387384062149663  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14247th epoch : 1.3873753731142602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14248th epoch : 1.3873666702645218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14249th epoch : 1.3873579535463876  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14250th epoch : 1.3873492229055462  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14251th epoch : 1.387340478287434  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14252th epoch : 1.3873317196372323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14253th epoch : 1.3873229468998682  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14254th epoch : 1.38731416002001  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14255th epoch : 1.387305358942068  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14256th epoch : 1.3872965436101925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14257th epoch : 1.387287713968271  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14258th epoch : 1.3872788699599288  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14259th epoch : 1.387270011528525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14260th epoch : 1.3872611386171527  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14261th epoch : 1.3872522511686372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14262th epoch : 1.387243349125533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14263th epoch : 1.3872344324301238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14264th epoch : 1.3872255010244203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14265th epoch : 1.3872165548501583  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14266th epoch : 1.3872075938487973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14267th epoch : 1.3871986179615186  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14268th epoch : 1.387189627129224  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14269th epoch : 1.3871806212925333  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14270th epoch : 1.3871716003917842  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14271th epoch : 1.3871625643670287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14272th epoch : 1.3871535131580324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14273th epoch : 1.3871444467042728  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14274th epoch : 1.3871353649449372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14275th epoch : 1.387126267818921  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14276th epoch : 1.3871171552648256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14277th epoch : 1.3871080272209577  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14278th epoch : 1.3870988836253264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14279th epoch : 1.3870897244156415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14280th epoch : 1.3870805495293124  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14281th epoch : 1.3870713589034454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14282th epoch : 1.3870621524748419  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14283th epoch : 1.3870529301799976  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14284th epoch : 1.3870436919550992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14285th epoch : 1.3870344377360235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14286th epoch : 1.387025167458335  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14287th epoch : 1.3870158810572835  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14288th epoch : 1.3870065784678034  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14289th epoch : 1.3869972596245113  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14290th epoch : 1.3869879244617027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14291th epoch : 1.3869785729133526  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14292th epoch : 1.3869692049131104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14293th epoch : 1.3869598203943008  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14294th epoch : 1.3869504192899196  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14295th epoch : 1.386941001532633  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14296th epoch : 1.3869315670547748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14297th epoch : 1.3869221157883447  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14298th epoch : 1.3869126476650058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14299th epoch : 1.386903162616083  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14300th epoch : 1.3868936605725608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14301th epoch : 1.3868841414650803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14302th epoch : 1.3868746052239387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14303th epoch : 1.3868650517790853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14304th epoch : 1.3868554810601204  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14305th epoch : 1.3868458929962935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14306th epoch : 1.3868362875164992  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14307th epoch : 1.3868266645492777  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14308th epoch : 1.38681702402281  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14309th epoch : 1.3868073658649165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14310th epoch : 1.3867976900030559  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14311th epoch : 1.3867879963643208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14312th epoch : 1.3867782848754375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14313th epoch : 1.3867685554627618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14314th epoch : 1.3867588080522775  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14315th epoch : 1.3867490425695943  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14316th epoch : 1.3867392589399452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14317th epoch : 1.3867294570881834  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14318th epoch : 1.3867196369387806  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14319th epoch : 1.3867097984158252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14320th epoch : 1.3866999414430174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14321th epoch : 1.38669006594367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14322th epoch : 1.386680171840703  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14323th epoch : 1.3866702590566427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14324th epoch : 1.386660327513619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14325th epoch : 1.386650377133362  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14326th epoch : 1.3866404078372006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14327th epoch : 1.3866304195460588  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14328th epoch : 1.3866204121804537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14329th epoch : 1.386610385660493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14330th epoch : 1.3866003399058715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14331th epoch : 1.3865902748358692  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14332th epoch : 1.3865801903693487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14333th epoch : 1.3865700864247512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14334th epoch : 1.386559962920096  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14335th epoch : 1.3865498197729749  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14336th epoch : 1.3865396569005521  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14337th epoch : 1.3865294742195595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14338th epoch : 1.386519271646295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14339th epoch : 1.3865090490966188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14340th epoch : 1.3864988064859511  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14341th epoch : 1.3864885437292689  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14342th epoch : 1.3864782607411035  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14343th epoch : 1.386467957435537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14344th epoch : 1.3864576337261991  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14345th epoch : 1.3864472895262656  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14346th epoch : 1.3864369247484534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14347th epoch : 1.3864265393050188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14348th epoch : 1.386416133107754  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14349th epoch : 1.386405706067984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14350th epoch : 1.3863952580965637  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14351th epoch : 1.3863847891038743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14352th epoch : 1.3863742989998205  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14353th epoch : 1.3863637876938275  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14354th epoch : 1.3863532550948372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14355th epoch : 1.3863427011113052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14356th epoch : 1.3863321256511978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14357th epoch : 1.3863215286219888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14358th epoch : 1.386310909930655  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14359th epoch : 1.3863002694836748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14360th epoch : 1.3862896071870228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14361th epoch : 1.3862789229461683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14362th epoch : 1.38626821666607  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14363th epoch : 1.3862574882511742  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14364th epoch : 1.3862467376054106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14365th epoch : 1.386235964632188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14366th epoch : 1.3862251692343923  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14367th epoch : 1.386214351314382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14368th epoch : 1.386203510773985  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14369th epoch : 1.386192647514494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14370th epoch : 1.3861817614366643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14371th epoch : 1.3861708524407093  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14372th epoch : 1.3861599204262967  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14373th epoch : 1.3861489652925452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14374th epoch : 1.3861379869380202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14375th epoch : 1.3861269852607303  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14376th epoch : 1.3861159601581239  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14377th epoch : 1.3861049115270843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14378th epoch : 1.3860938392639264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14379th epoch : 1.386082743264393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14380th epoch : 1.3860716234236505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14381th epoch : 1.386060479636285  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14382th epoch : 1.3860493117962978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14383th epoch : 1.3860381197971023  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14384th epoch : 1.3860269035315194  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14385th epoch : 1.3860156628917726  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14386th epoch : 1.3860043977694854  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14387th epoch : 1.3859931080556755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14388th epoch : 1.3859817936407524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14389th epoch : 1.3859704544145108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14390th epoch : 1.3859590902661287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14391th epoch : 1.3859477010841608  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14392th epoch : 1.3859362867565361  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14393th epoch : 1.3859248471705523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14394th epoch : 1.3859133822128717  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14395th epoch : 1.3859018917695165  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14396th epoch : 1.3858903757258645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14397th epoch : 1.3858788339666448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14398th epoch : 1.3858672663759324  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14399th epoch : 1.3858556728371443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14400th epoch : 1.3858440532330345  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14401th epoch : 1.3858324074456894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14402th epoch : 1.3858207353565228  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14403th epoch : 1.3858090368462714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14404th epoch : 1.3857973117949896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14405th epoch : 1.385785560082045  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14406th epoch : 1.3857737815861135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14407th epoch : 1.3857619761851738  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14408th epoch : 1.3857501437565027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14409th epoch : 1.3857382841766706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14410th epoch : 1.3857263973215352  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14411th epoch : 1.3857144830662376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14412th epoch : 1.3857025412851962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14413th epoch : 1.3856905718521018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14414th epoch : 1.3856785746399127  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14415th epoch : 1.3856665495208491  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14416th epoch : 1.3856544963663868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14417th epoch : 1.3856424150472537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14418th epoch : 1.385630305433423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14419th epoch : 1.3856181673941075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14420th epoch : 1.385606000797755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14421th epoch : 1.3855938055120427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14422th epoch : 1.3855815814038699  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14423th epoch : 1.3855693283393546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14424th epoch : 1.385557046183826  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14425th epoch : 1.38554473480182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14426th epoch : 1.3855323940570718  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14427th epoch : 1.3855200238125118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14428th epoch : 1.3855076239302582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14429th epoch : 1.3854951942716116  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14430th epoch : 1.385482734697049  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14431th epoch : 1.385470245066218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14432th epoch : 1.3854577252379292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14433th epoch : 1.3854451750701522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14434th epoch : 1.385432594420007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14435th epoch : 1.3854199831437597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14436th epoch : 1.3854073410968148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14437th epoch : 1.385394668133709  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14438th epoch : 1.3853819641081053  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14439th epoch : 1.385369228872786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14440th epoch : 1.3853564622796455  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14441th epoch : 1.3853436641796848  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14442th epoch : 1.3853308344230044  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14443th epoch : 1.3853179728587963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14444th epoch : 1.3853050793353394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14445th epoch : 1.3852921536999905  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14446th epoch : 1.3852791957991786  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14447th epoch : 1.3852662054783966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14448th epoch : 1.3852531825821963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14449th epoch : 1.385240126954179  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14450th epoch : 1.3852270384369896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14451th epoch : 1.3852139168723085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14452th epoch : 1.385200762100845  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14453th epoch : 1.3851875739623298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14454th epoch : 1.3851743522955065  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14455th epoch : 1.3851610969381252  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14456th epoch : 1.3851478077269344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14457th epoch : 1.3851344844976732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14458th epoch : 1.3851211270850636  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14459th epoch : 1.3851077353228032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14460th epoch : 1.3850943090435557  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14461th epoch : 1.385080848078945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14462th epoch : 1.3850673522595454  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14463th epoch : 1.3850538214148749  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14464th epoch : 1.3850402553733856  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14465th epoch : 1.3850266539624563  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14466th epoch : 1.385013017008384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14467th epoch : 1.3849993443363753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14468th epoch : 1.384985635770538  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14469th epoch : 1.384971891133872  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14470th epoch : 1.3849581102482618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14471th epoch : 1.3849442929344664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14472th epoch : 1.3849304390121115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14473th epoch : 1.3849165482996797  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14474th epoch : 1.3849026206145019  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14475th epoch : 1.3848886557727487  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14476th epoch : 1.3848746535894205  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14477th epoch : 1.3848606138783384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14478th epoch : 1.3848465364521347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14479th epoch : 1.3848324211222443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14480th epoch : 1.384818267698894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14481th epoch : 1.3848040759910938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14482th epoch : 1.3847898458066268  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14483th epoch : 1.384775576952039  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14484th epoch : 1.3847612692326303  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14485th epoch : 1.3847469224524442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14486th epoch : 1.3847325364142569  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14487th epoch : 1.3847181109195683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14488th epoch : 1.384703645768591  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14489th epoch : 1.3846891407602404  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14490th epoch : 1.3846745956921236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14491th epoch : 1.3846600103605293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14492th epoch : 1.3846453845604172  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14493th epoch : 1.384630718085407  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14494th epoch : 1.384616010727767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14495th epoch : 1.3846012622784045  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14496th epoch : 1.3845864725268535  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14497th epoch : 1.3845716412612639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14498th epoch : 1.3845567682683897  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14499th epoch : 1.3845418533335792  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14500th epoch : 1.3845268962407609  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14501th epoch : 1.3845118967724346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14502th epoch : 1.3844968547096572  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14503th epoch : 1.3844817698320329  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14504th epoch : 1.3844666419176996  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14505th epoch : 1.3844514707433182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14506th epoch : 1.3844362560840586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14507th epoch : 1.3844209977135893  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14508th epoch : 1.3844056954040638  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14509th epoch : 1.3843903489261082  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14510th epoch : 1.3843749580488087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14511th epoch : 1.3843595225396987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14512th epoch : 1.3843440421647453  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14513th epoch : 1.3843285166883372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14514th epoch : 1.384312945873271  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14515th epoch : 1.3842973294807375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14516th epoch : 1.3842816672703087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14517th epoch : 1.3842659589999238  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14518th epoch : 1.3842502044258762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14519th epoch : 1.3842344033027987  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14520th epoch : 1.3842185553836501  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14521th epoch : 1.3842026604197006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14522th epoch : 1.3841867181605176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14523th epoch : 1.3841707283539517  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14524th epoch : 1.3841546907461215  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14525th epoch : 1.3841386050813993  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14526th epoch : 1.3841224711023956  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14527th epoch : 1.3841062885499449  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14528th epoch : 1.3840900571630899  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14529th epoch : 1.384073776679066  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14530th epoch : 1.384057446833287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14531th epoch : 1.3840410673593273  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14532th epoch : 1.3840246379889085  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14533th epoch : 1.3840081584518813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14534th epoch : 1.3839916284762108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14535th epoch : 1.3839750477879598  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14536th epoch : 1.3839584161112717  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14537th epoch : 1.3839417331683548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14538th epoch : 1.3839249986794646  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14539th epoch : 1.3839082123628879  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14540th epoch : 1.383891373934924  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14541th epoch : 1.383874483109869  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14542th epoch : 1.3838575395999975  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14543th epoch : 1.3838405431155452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14544th epoch : 1.3838234933646898  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14545th epoch : 1.3838063900535353  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14546th epoch : 1.3837892328860915  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14547th epoch : 1.3837720215642564  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14548th epoch : 1.3837547557877976  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14549th epoch : 1.3837374352543341  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14550th epoch : 1.3837200596593153  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14551th epoch : 1.3837026286960044  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14552th epoch : 1.3836851420554563  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14553th epoch : 1.3836675994265002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14554th epoch : 1.3836500004957184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14555th epoch : 1.3836323449474266  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14556th epoch : 1.3836146324636536  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14557th epoch : 1.3835968627241213  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14558th epoch : 1.383579035406223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14559th epoch : 1.383561150185003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14560th epoch : 1.3835432067331361  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14561th epoch : 1.3835252047209052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14562th epoch : 1.3835071438161801  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14563th epoch : 1.3834890236843957  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14564th epoch : 1.3834708439885297  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14565th epoch : 1.3834526043890811  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14566th epoch : 1.3834343045440465  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14567th epoch : 1.3834159441088978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14568th epoch : 1.3833975227365596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14569th epoch : 1.3833790400773855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14570th epoch : 1.3833604957791346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14571th epoch : 1.3833418894869476  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14572th epoch : 1.383323220843323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14573th epoch : 1.3833044894880928  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14574th epoch : 1.3832856950583974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14575th epoch : 1.3832668371886618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14576th epoch : 1.3832479155105695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14577th epoch : 1.3832289296530376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14578th epoch : 1.3832098792421907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14579th epoch : 1.383190763901336  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14580th epoch : 1.383171583250936  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14581th epoch : 1.3831523369085816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14582th epoch : 1.3831330244889675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14583th epoch : 1.3831136456038626  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14584th epoch : 1.383094199862084  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14585th epoch : 1.383074686869469  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14586th epoch : 1.3830551062288463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14587th epoch : 1.3830354575400097  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14588th epoch : 1.3830157403996868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14589th epoch : 1.3829959544015125  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14590th epoch : 1.3829760991359976  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14591th epoch : 1.3829561741905012  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14592th epoch : 1.382936179149199  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14593th epoch : 1.3829161135930539  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14594th epoch : 1.3828959770997857  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14595th epoch : 1.3828757692438391  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14596th epoch : 1.3828554895963534  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14597th epoch : 1.3828351377251304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14598th epoch : 1.382814713194602  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14599th epoch : 1.3827942155657986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14600th epoch : 1.382773644396316  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14601th epoch : 1.3827529992402816  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14602th epoch : 1.3827322796483223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14603th epoch : 1.3827114851675295  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14604th epoch : 1.3826906153414251  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14605th epoch : 1.3826696697099268  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14606th epoch : 1.3826486478093132  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14607th epoch : 1.3826275491721887  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14608th epoch : 1.3826063733274463  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14609th epoch : 1.382585119800233  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14610th epoch : 1.382563788111912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14611th epoch : 1.3825423777800256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14612th epoch : 1.3825208883182583  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14613th epoch : 1.3824993192363981  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14614th epoch : 1.3824776700402988  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14615th epoch : 1.3824559402318397  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14616th epoch : 1.3824341293088886  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14617th epoch : 1.3824122367652596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14618th epoch : 1.3823902620906743  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14619th epoch : 1.3823682047707202  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14620th epoch : 1.3823460642868106  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14621th epoch : 1.3823238401161417  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14622th epoch : 1.3823015317316512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14623th epoch : 1.3822791386019748  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14624th epoch : 1.3822566601914044  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14625th epoch : 1.382234095959843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14626th epoch : 1.382211445362761  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14627th epoch : 1.3821887078511514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14628th epoch : 1.3821658828714851  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14629th epoch : 1.382142969865664  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14630th epoch : 1.3821199682709753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14631th epoch : 1.3820968775200448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14632th epoch : 1.3820736970407888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14633th epoch : 1.3820504262563662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14634th epoch : 1.3820270645851302  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14635th epoch : 1.3820036114405791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14636th epoch : 1.3819800662313058  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14637th epoch : 1.381956428360948  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14638th epoch : 1.3819326972281374  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14639th epoch : 1.3819088722264468  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14640th epoch : 1.3818849527443395  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14641th epoch : 1.3818609381651155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14642th epoch : 1.3818368278668576  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14643th epoch : 1.3818126212223778  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14644th epoch : 1.3817883175991628  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14645th epoch : 1.381763916359317  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14646th epoch : 1.3817394168595079  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14647th epoch : 1.381714818450908  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14648th epoch : 1.381690120479138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14649th epoch : 1.381665322284208  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14650th epoch : 1.3816404232004584  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14651th epoch : 1.3816154225565005  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14652th epoch : 1.3815903196751558  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14653th epoch : 1.3815651138733942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14654th epoch : 1.381539804462273  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14655th epoch : 1.3815143907468732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14656th epoch : 1.3814888720262366  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14657th epoch : 1.3814632475933002  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14658th epoch : 1.381437516734833  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14659th epoch : 1.3814116787313675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14660th epoch : 1.381385732857135  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14661th epoch : 1.3813596783799973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14662th epoch : 1.3813335145613768  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14663th epoch : 1.381307240656189  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14664th epoch : 1.3812808559127714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14665th epoch : 1.3812543595728117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14666th epoch : 1.3812277508712767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14667th epoch : 1.381201029036339  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14668th epoch : 1.3811741932893025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14669th epoch : 1.381147242844528  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14670th epoch : 1.3811201769093575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14671th epoch : 1.3810929946840371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14672th epoch : 1.3810656953616387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14673th epoch : 1.3810382781279826  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14674th epoch : 1.381010742161556  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14675th epoch : 1.3809830866334334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14676th epoch : 1.3809553107071935  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14677th epoch : 1.3809274135388376  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14678th epoch : 1.3808993942767045  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14679th epoch : 1.3808712520613857  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14680th epoch : 1.380842986025639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14681th epoch : 1.3808145952943018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14682th epoch : 1.3807860789842012  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14683th epoch : 1.3807574362040655  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14684th epoch : 1.380728666054433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14685th epoch : 1.3806997676275596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14686th epoch : 1.380670740007326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14687th epoch : 1.3806415822691427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14688th epoch : 1.3806122934798548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14689th epoch : 1.3805828726976443  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14690th epoch : 1.3805533189719321  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14691th epoch : 1.3805236313432787  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14692th epoch : 1.3804938088432825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14693th epoch : 1.3804638504944782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14694th epoch : 1.3804337553102326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14695th epoch : 1.3804035222946398  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14696th epoch : 1.3803731504424144  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14697th epoch : 1.3803426387387843  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14698th epoch : 1.3803119861593804  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14699th epoch : 1.3802811916701263  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14700th epoch : 1.3802502542271258  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14701th epoch : 1.3802191727765494  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14702th epoch : 1.3801879462545177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14703th epoch : 1.3801565735869863  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14704th epoch : 1.3801250536896255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14705th epoch : 1.3800933854677007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14706th epoch : 1.3800615678159507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14707th epoch : 1.3800295996184644  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14708th epoch : 1.3799974797485546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14709th epoch : 1.3799652070686326  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14710th epoch : 1.3799327804300776  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14711th epoch : 1.379900198673108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14712th epoch : 1.3798674606266483  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14713th epoch : 1.3798345651081945  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14714th epoch : 1.3798015109236792  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14715th epoch : 1.379768296867333  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14716th epoch : 1.3797349217215455  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14717th epoch : 1.3797013842567223  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14718th epoch : 1.3796676832311423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14719th epoch : 1.3796338173908116  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14720th epoch : 1.3795997854693158  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14721th epoch : 1.3795655861876706  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14722th epoch : 1.3795312182541684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14723th epoch : 1.379496680364226  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14724th epoch : 1.379461971200227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14725th epoch : 1.379427089431364  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14726th epoch : 1.3793920337134773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14727th epoch : 1.3793568026888925  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14728th epoch : 1.3793213949862544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14729th epoch : 1.3792858092203597  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14730th epoch : 1.3792500439919868  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14731th epoch : 1.3792140978877234  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 14732th epoch : 1.379177969479791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14733th epoch : 1.3791416573258675  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14734th epoch : 1.3791051599689075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14735th epoch : 1.379068475936959  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14736th epoch : 1.3790316037429782  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14737th epoch : 1.3789945418846414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14738th epoch : 1.3789572888441548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14739th epoch : 1.3789198430880596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14740th epoch : 1.3788822030670371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14741th epoch : 1.3788443672157087  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14742th epoch : 1.378806333952433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14743th epoch : 1.3787681016791025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14744th epoch : 1.3787296687809338  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14745th epoch : 1.378691033626257  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14746th epoch : 1.3786521945663013  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14747th epoch : 1.3786131499349779  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14748th epoch : 1.3785738980486582  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14749th epoch : 1.3785344372059514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14750th epoch : 1.3784947656874755  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14751th epoch : 1.3784548817556281  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14752th epoch : 1.3784147836543512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14753th epoch : 1.3783744696088942  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14754th epoch : 1.378333937825572  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14755th epoch : 1.3782931864915207  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14756th epoch : 1.3782522137744495  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14757th epoch : 1.378211017822388  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14758th epoch : 1.3781695967634298  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14759th epoch : 1.378127948705473  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14760th epoch : 1.3780860717359567  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14761th epoch : 1.3780439639215927  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14762th epoch : 1.3780016233080936  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14763th epoch : 1.3779590479198973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14764th epoch : 1.3779162357598855  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14765th epoch : 1.377873184809101  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14766th epoch : 1.3778298930264574  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14767th epoch : 1.377786358348446  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14768th epoch : 1.3777425786888382  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14769th epoch : 1.377698551938384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14770th epoch : 1.3776542759645025  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14771th epoch : 1.3776097486109729  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14772th epoch : 1.377564967697616  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14773th epoch : 1.377519931019973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14774th epoch : 1.3774746363489798  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14775th epoch : 1.3774290814306343  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14776th epoch : 1.37738326398566  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14777th epoch : 1.3773371817091642  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14778th epoch : 1.37729083227029  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14779th epoch : 1.3772442133118643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14780th epoch : 1.3771973224500387  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14781th epoch : 1.3771501572739255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14782th epoch : 1.3771027153452282  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14783th epoch : 1.3770549941978654  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14784th epoch : 1.37700699133759  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14785th epoch : 1.376958704241601  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14786th epoch : 1.3769101303581497  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14787th epoch : 1.3768612671061398  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14788th epoch : 1.376812111874721  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14789th epoch : 1.3767626620228761  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14790th epoch : 1.3767129148790018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14791th epoch : 1.3766628677404813  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14792th epoch : 1.3766125178732522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14793th epoch : 1.376561862511367  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14794th epoch : 1.376510898856544  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14795th epoch : 1.376459624077715  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14796th epoch : 1.3764080353105619  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14797th epoch : 1.376356129657049  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14798th epoch : 1.3763039041849452  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14799th epoch : 1.3762513559273393  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14800th epoch : 1.376198481882148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14801th epoch : 1.376145279011616  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14802th epoch : 1.3760917442418052  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14803th epoch : 1.3760378744620803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14804th epoch : 1.3759836665245815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14805th epoch : 1.3759291172436907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14806th epoch : 1.375874223395489  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14807th epoch : 1.3758189817172048  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14808th epoch : 1.3757633889066518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14809th epoch : 1.37570744162166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14810th epoch : 1.375651136479495  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14811th epoch : 1.375594470056269  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14812th epoch : 1.375537438886342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14813th epoch : 1.375480039461711  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14814th epoch : 1.3754222682313932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14815th epoch : 1.375364121600794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14816th epoch : 1.3753055959310674  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14817th epoch : 1.375246687538466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14818th epoch : 1.3751873926936773  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14819th epoch : 1.3751277076211523  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14820th epoch : 1.3750676284984193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14821th epoch : 1.3750071514553899  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14822th epoch : 1.3749462725736492  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14823th epoch : 1.3748849878857372  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14824th epoch : 1.3748232933744162  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14825th epoch : 1.3747611849719275  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14826th epoch : 1.3746986585592318  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14827th epoch : 1.3746357099652422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14828th epoch : 1.374572334966038  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14829th epoch : 1.3745085292840704  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14830th epoch : 1.3744442885873511  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14831th epoch : 1.3743796084886275  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14832th epoch : 1.374314484544546  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14833th epoch : 1.3742489122547974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14834th epoch : 1.3741828870612505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14835th epoch : 1.374116404347069  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14836th epoch : 1.3740494594358141  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14837th epoch : 1.3739820475905304  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14838th epoch : 1.3739141640128176  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14839th epoch : 1.3738458038418846  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14840th epoch : 1.3737769621535871  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14841th epoch : 1.3737076339594503  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14842th epoch : 1.373637814205672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14843th epoch : 1.3735674977721104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14844th epoch : 1.3734966794712524  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14845th epoch : 1.3734253540471653  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14846th epoch : 1.373353516174429  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14847th epoch : 1.37328116045705  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14848th epoch : 1.373208281427357  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14849th epoch : 1.3731348735448745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14850th epoch : 1.3730609311951794  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14851th epoch : 1.372986448688736  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14852th epoch : 1.3729114202597104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14853th epoch : 1.372835840064764  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14854th epoch : 1.3727597021818259  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14855th epoch : 1.3726830006088426  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14856th epoch : 1.3726057292625067  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14857th epoch : 1.3725278819769624  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14858th epoch : 1.3724494525024866  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14859th epoch : 1.3723704345041499  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14860th epoch : 1.372290821560449  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14861th epoch : 1.3722106071619187  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14862th epoch : 1.3721297847097171  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14863th epoch : 1.3720483475141851  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14864th epoch : 1.3719662887933817  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14865th epoch : 1.3718836016715907  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14866th epoch : 1.3718002791778028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14867th epoch : 1.371716314244169  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14868th epoch : 1.3716316997044264  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14869th epoch : 1.3715464282922956  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14870th epoch : 1.3714604926398493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14871th epoch : 1.3713738852758512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14872th epoch : 1.3712865986240657  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14873th epoch : 1.3711986250015349  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14874th epoch : 1.3711099566168268  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14875th epoch : 1.3710205855682507  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14876th epoch : 1.3709305038420392  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14877th epoch : 1.3708397033104998  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14878th epoch : 1.3707481757301294  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14879th epoch : 1.3706559127396982  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14880th epoch : 1.3705629058582958  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14881th epoch : 1.3704691464833427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14882th epoch : 1.3703746258885672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14883th epoch : 1.3702793352219425  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14884th epoch : 1.3701832655035882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14885th epoch : 1.3700864076236332  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14886th epoch : 1.3699887523400396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14887th epoch : 1.3698902902763859  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14888th epoch : 1.3697910119196115  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14889th epoch : 1.3696909076177184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14890th epoch : 1.3695899675774321  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14891th epoch : 1.3694881818618188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14892th epoch : 1.3693855403878596  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14893th epoch : 1.3692820329239812  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14894th epoch : 1.3691776490875396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14895th epoch : 1.3690723783422591  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14896th epoch : 1.3689662099956248  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14897th epoch : 1.368859133196227  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14898th epoch : 1.368751136931056  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14899th epoch : 1.3686422100227509  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14900th epoch : 1.3685323411267938  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14901th epoch : 1.3684215187286557  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14902th epoch : 1.3683097311408912  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14903th epoch : 1.3681969665001767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14904th epoch : 1.3680832127642983  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14905th epoch : 1.367968457709083  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14906th epoch : 1.3678526889252742  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14907th epoch : 1.3677358938153519  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14908th epoch : 1.3676180595902934  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14909th epoch : 1.3674991732662762  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14910th epoch : 1.3673792216613216  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14911th epoch : 1.367258191391877  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14912th epoch : 1.3671360688693368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14913th epoch : 1.3670128402964994  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14914th epoch : 1.3668884916639639  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14915th epoch : 1.3667630087464575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14916th epoch : 1.3666363770991001  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14917th epoch : 1.3665085820536018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14918th epoch : 1.3663796087143902  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14919th epoch : 1.3662494419546722  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14920th epoch : 1.3661180664124222  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14921th epoch : 1.3659854664863014  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14922th epoch : 1.3658516263315046  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14923th epoch : 1.3657165298555323  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14924th epoch : 1.3655801607138898  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14925th epoch : 1.3654425023057104  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14926th epoch : 1.365303537769301  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14927th epoch : 1.3651632499776123  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14928th epoch : 1.3650216215336273  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14929th epoch : 1.3648786347656714  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14930th epoch : 1.364734271722643  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14931th epoch : 1.3645885141691587  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14932th epoch : 1.3644413435806184  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14933th epoch : 1.3642927411381847  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14934th epoch : 1.3641426877236775  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14935th epoch : 1.3639911639143825  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14936th epoch : 1.3638381499777719  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14937th epoch : 1.363683625866138  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14938th epoch : 1.3635275712111363  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14939th epoch : 1.3633699653182394  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14940th epoch : 1.3632107871610988  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14941th epoch : 1.3630500153758154  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14942th epoch : 1.3628876282551174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14943th epoch : 1.3627236037424437  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14944th epoch : 1.3625579194259327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14945th epoch : 1.3623905525323166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14946th epoch : 1.362221479920719  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14947th epoch : 1.3620506780763562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14948th epoch : 1.3618781231041406  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14949th epoch : 1.3617037907221867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14950th epoch : 1.361527656255218  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14951th epoch : 1.3613496946278767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14952th epoch : 1.361169880357931  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14953th epoch : 1.360988187549386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14954th epoch : 1.3608045898854932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14955th epoch : 1.36061906062166  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14956th epoch : 1.3604315725782592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14957th epoch : 1.360242098133339  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14958th epoch : 1.3600506092152327  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14959th epoch : 1.3598570772950684  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14960th epoch : 1.3596614733791799  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14961th epoch : 1.359463768001419  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14962th epoch : 1.359263931215368  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14963th epoch : 1.3590619325864575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14964th epoch : 1.3588577411839837  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14965th epoch : 1.3586513255730346  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14966th epoch : 1.3584426538063177  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14967th epoch : 1.3582316934158962  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14968th epoch : 1.3580184114048357  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14969th epoch : 1.3578027742387573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14970th epoch : 1.357584747837305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14971th epoch : 1.3573642975655287  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14972th epoch : 1.35714138822518  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14973th epoch : 1.3569159840459306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14974th epoch : 1.356688048676512  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14975th epoch : 1.3564575451757785  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14976th epoch : 1.3562244360037017  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14977th epoch : 1.3559886830122936  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14978th epoch : 1.3557502474364693  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14979th epoch : 1.3555090898848474  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14980th epoch : 1.3552651703304963  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14981th epoch : 1.3550184481016299  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14982th epoch : 1.3547688818722585  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14983th epoch : 1.3545164296528007  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14984th epoch : 1.3542610487806606  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14985th epoch : 1.354002695910779  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14986th epoch : 1.353741327006164  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14987th epoch : 1.35347689732841  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14988th epoch : 1.3532093614282075  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14989th epoch : 1.3529386731358615  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14990th epoch : 1.3526647855518155  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14991th epoch : 1.3523876510372006  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14992th epoch : 1.3521072212044123  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14993th epoch : 1.351823446907729  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14994th epoch : 1.351536278233981  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14995th epoch : 1.3512456644932815  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14996th epoch : 1.3509515542098338  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14997th epoch : 1.3506538951128235  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14998th epoch : 1.3503526341274117  Training Accuracy:0.8571428571428571\n",
      "The training loss at 14999th epoch : 1.350047717365841  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15000th epoch : 1.3497390901186719  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15001th epoch : 1.3494266968461592  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15002th epoch : 1.3491104811697914  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15003th epoch : 1.3487903858640018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15004th epoch : 1.3484663528480756  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15005th epoch : 1.3481383231782667  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15006th epoch : 1.3478062370401427  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15007th epoch : 1.347470033741183  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15008th epoch : 1.3471296517036409  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15009th epoch : 1.3467850284577003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15010th epoch : 1.3464361006349437  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15011th epoch : 1.3460828039621537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15012th epoch : 1.345725073255474  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15013th epoch : 1.3453628424149537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15014th epoch : 1.3449960444194986  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15015th epoch : 1.344624611322255  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15016th epoch : 1.344248474246457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15017th epoch : 1.3438675633817578  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15018th epoch : 1.34348180798108  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15019th epoch : 1.3430911363580094  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15020th epoch : 1.3426954758847645  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15021th epoch : 1.3422947529907712  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15022th epoch : 1.3418888931618735  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15023th epoch : 1.341477820940214  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15024th epoch : 1.3410614599248143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15025th epoch : 1.3406397327728896  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15026th epoch : 1.340212561201932  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15027th epoch : 1.3397798659925944  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15028th epoch : 1.3393415669924125  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15029th epoch : 1.3388975831203973  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15030th epoch : 1.3384478323725342  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15031th epoch : 1.3379922318282254  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15032th epoch : 1.337530697657709  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15033th epoch : 1.337063145130493  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15034th epoch : 1.3365894886248377  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15035th epoch : 1.3361096416383225  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15036th epoch : 1.3356235167995334  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15037th epoch : 1.3351310258809057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15038th epoch : 1.334632079812753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15039th epoch : 1.334126588698522  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15040th epoch : 1.3336144618313008  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15041th epoch : 1.3330956077116143  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15042th epoch : 1.332569934066537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15043th epoch : 1.3320373478701537  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15044th epoch : 1.331497755365395  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15045th epoch : 1.3309510620872709  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15046th epoch : 1.330397172887533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15047th epoch : 1.3298359919607807  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15048th epoch : 1.3292674228720351  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15049th epoch : 1.3286913685857966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15050th epoch : 1.3281077314966  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15051th epoch : 1.327516413461079  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15052th epoch : 1.326917315831548  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15053th epoch : 1.3263103394911049  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15054th epoch : 1.3256953848902575  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15055th epoch : 1.325072352085068  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15056th epoch : 1.324441140776809  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15057th epoch : 1.323801650353119  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15058th epoch : 1.32315377993064  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15059th epoch : 1.322497428399116  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15060th epoch : 1.3218324944669244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15061th epoch : 1.3211588767080065  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15062th epoch : 1.3204764736101624  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15063th epoch : 1.3197851836246612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15064th epoch : 1.319084905217118  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15065th epoch : 1.3183755369195818  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15066th epoch : 1.3176569773837672  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15067th epoch : 1.3169291254353648  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15068th epoch : 1.3161918801293466  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15069th epoch : 1.3154451408061882  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15070th epoch : 1.314688807148913  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15071th epoch : 1.3139227792408603  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15072th epoch : 1.313146957624074  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15073th epoch : 1.3123612433581957  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15074th epoch : 1.3115655380797457  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15075th epoch : 1.3107597440616612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15076th epoch : 1.3099437642729623  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15077th epoch : 1.3091175024384  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15078th epoch : 1.3082808630979414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15079th epoch : 1.3074337516659396  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15080th epoch : 1.306576074489823  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15081th epoch : 1.3057077389081435  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15082th epoch : 1.30482865330781  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15083th epoch : 1.303938727180328  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15084th epoch : 1.3030378711768695  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15085th epoch : 1.302125997161983  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15086th epoch : 1.3012030182657566  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15087th epoch : 1.3002688489342433  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15088th epoch : 1.2993234049779536  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15089th epoch : 1.2983666036182182  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15090th epoch : 1.2973983635312265  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15091th epoch : 1.2964186048895423  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15092th epoch : 1.2954272494009018  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15093th epoch : 1.2944242203440994  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15094th epoch : 1.293409442601767  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15095th epoch : 1.2923828426898605  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15096th epoch : 1.2913443487836687  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15097th epoch : 1.2902938907401633  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15098th epoch : 1.2892314001165188  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15099th epoch : 1.2881568101846337  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15100th epoch : 1.2870700559415  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15101th epoch : 1.2859710741152646  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15102th epoch : 1.2848598031668514  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15103th epoch : 1.283736183287011  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15104th epoch : 1.282600156388683  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15105th epoch : 1.2814516660945732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15106th epoch : 1.2802906577198456  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15107th epoch : 1.279117078249867  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15108th epoch : 1.2779308763129371  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15109th epoch : 1.2767320021479625  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15110th epoch : 1.2755204075670505  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15111th epoch : 1.274296045913016  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15112th epoch : 1.2730588720118028  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15113th epoch : 1.2718088421198612  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15114th epoch : 1.2705459138665174  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15115th epoch : 1.269270046191409  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15116th epoch : 1.2679811992770733  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15117th epoch : 1.2666793344767926  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15118th epoch : 1.2653644142378289  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15119th epoch : 1.2640364020201915  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15120th epoch : 1.2626952622111112  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15121th epoch : 1.2613409600354037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15122th epoch : 1.2599734614619378  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15123th epoch : 1.2585927331064297  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15124th epoch : 1.2571987421308197  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15125th epoch : 1.2557914561394894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15126th epoch : 1.2543708430726126  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15127th epoch : 1.2529368710969389  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15128th epoch : 1.2514895084943292  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15129th epoch : 1.2500287235483853  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15130th epoch : 1.24855448442952  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15131th epoch : 1.247066759078838  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15132th epoch : 1.2455655150912064  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15133th epoch : 1.2440507195979098  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15134th epoch : 1.2425223391492943  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15135th epoch : 1.2409803395978134  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15136th epoch : 1.2394246859819043  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15137th epoch : 1.2378553424111243  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15138th epoch : 1.2362722719529888  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15139th epoch : 1.2346754365219552  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15140th epoch : 1.233064796771003  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15141th epoch : 1.2314403119862618  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15142th epoch : 1.2298019399851468  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15143th epoch : 1.228149637018448  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15144th epoch : 1.2264833576768375  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15145th epoch : 1.2248030548022422  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15146th epoch : 1.223108679404533  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15147th epoch : 1.221400180583974  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15148th epoch : 1.2196775054598745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15149th epoch : 1.2179405991058732  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15150th epoch : 1.2161894044922803  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15151th epoch : 1.214423862435894  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15152th epoch : 1.2126439115576941  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15153th epoch : 1.210849488248808  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15154th epoch : 1.2090405266451307  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15155th epoch : 1.2072169586109658  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15156th epoch : 1.2053787137320386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15157th epoch : 1.2035257193182243  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15158th epoch : 1.201657900416306  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15159th epoch : 1.1997751798330705  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15160th epoch : 1.197877478169027  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15161th epoch : 1.1959647138630105  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15162th epoch : 1.194036803247922  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15163th epoch : 1.192093660617822  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15164th epoch : 1.1901351983065875  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15165th epoch : 1.1881613267783049  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15166th epoch : 1.1861719547295562  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15167th epoch : 1.1841669892037305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15168th epoch : 1.1821463357174595  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15169th epoch : 1.1801098983992573  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15170th epoch : 1.1780575801404114  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15171th epoch : 1.1759892827581442  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15172th epoch : 1.1739049071710321  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15173th epoch : 1.1718043535866414  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15174th epoch : 1.1696875217013032  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15175th epoch : 1.1675543109119193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15176th epoch : 1.1654046205396502  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15177th epoch : 1.1632383500653103  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15178th epoch : 1.161055399376244  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15179th epoch : 1.1588556690244305  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15180th epoch : 1.1566390604955148  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15181th epoch : 1.1544054764884293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15182th epoch : 1.152154821205221  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15183th epoch : 1.149887000650662  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15184th epoch : 1.1476019229411716  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15185th epoch : 1.1452994986225356  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15186th epoch : 1.1429796409958641  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15187th epoch : 1.1406422664511784  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15188th epoch : 1.1382872948079745  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15189th epoch : 1.1359146496620611  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15190th epoch : 1.1335242587379284  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15191th epoch : 1.131116054245848  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15192th epoch : 1.1286899732428717  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15193th epoch : 1.1262459579968385  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15194th epoch : 1.1237839563524694  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15195th epoch : 1.1213039220985779  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15196th epoch : 1.1188058153353908  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15197th epoch : 1.1162896028409344  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15198th epoch : 1.1137552584354142  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15199th epoch : 1.1112027633424753  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15200th epoch : 1.1086321065462168  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15201th epoch : 1.1060432851428057  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15202th epoch : 1.1034363046855193  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15203th epoch : 1.1008111795220386  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15204th epoch : 1.0981679331228045  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15205th epoch : 1.0955065983992531  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15206th epoch : 1.0928272180107534  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15207th epoch : 1.0901298446590824  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15208th epoch : 1.0874145413692948  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15209th epoch : 1.0846813817558754  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15210th epoch : 1.0819304502730902  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15211th epoch : 1.0791618424485063  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15212th epoch : 1.076375665098685  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15213th epoch : 1.0735720365261265  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15214th epoch : 1.0707510866965917  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15215th epoch : 1.0679129573960109  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15216th epoch : 1.0650578023662554  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15217th epoch : 1.0621857874191345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15218th epoch : 1.0592970905280648  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15219th epoch : 1.0563919018969548  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15220th epoch : 1.0534704240059345  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15221th epoch : 1.0505328716336657  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15222th epoch : 1.047579471856063  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15223th epoch : 1.0446104640213572  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15224th epoch : 1.041626099701537  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15225th epoch : 1.0386266426203006  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15226th epoch : 1.0356123685577487  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15227th epoch : 1.0325835652321491  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15228th epoch : 1.0295405321591915  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15229th epoch : 1.0264835804892407  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15230th epoch : 1.0234130328231796  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15231th epoch : 1.0203292230075105  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15232th epoch : 1.0172324959094508  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15233th epoch : 1.0141232071728263  Training Accuracy:0.8214285714285714\n",
      "The training loss at 15234th epoch : 1.0110017229556203  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15235th epoch : 1.0078684196500791  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15236th epoch : 1.0047236835863256  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15237th epoch : 1.0015679107204525  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15238th epoch : 0.9984015063080994  Training Accuracy:0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 15239th epoch : 0.9952248845645293  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15240th epoch : 0.9920384683122284  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15241th epoch : 0.9888426886170586  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15242th epoch : 0.9856379844139793  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15243th epoch : 0.9824248021233504  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15244th epoch : 0.9792035952588037  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15245th epoch : 0.9759748240276553  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15246th epoch : 0.9727389549247967  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15247th epoch : 0.969496460320978  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15248th epoch : 0.9662478180463632  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15249th epoch : 0.9629935109701984  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15250th epoch : 0.959734026577403  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15251th epoch : 0.9564698565428561  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15252th epoch : 0.953201496304109  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15253th epoch : 0.949929444633229  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15254th epoch : 0.9466542032084347  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15255th epoch : 0.9433762761861564  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15256th epoch : 0.9400961697741236  Training Accuracy:0.8571428571428571\n",
      "The training loss at 15257th epoch : 0.9368143918060517  Training Accuracy:0.8928571428571429\n",
      "The training loss at 15258th epoch : 0.933531451318475  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15259th epoch : 0.9302478581302486  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15260th epoch : 0.9269641224252229  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15261th epoch : 0.9236807543385754  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15262th epoch : 0.9203982635472662  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15263th epoch : 0.9171171588650737  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15264th epoch : 0.9138379478426545  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15265th epoch : 0.9105611363730578  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15266th epoch : 0.9072872283031218  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15267th epoch : 0.9040167250511671  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15268th epoch : 0.9007501252313985  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15269th epoch : 0.8974879242854166  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15270th epoch : 0.8942306141212366  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15271th epoch : 0.8909786827602035  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15272th epoch : 0.8877326139921838  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15273th epoch : 0.8844928870394051  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15274th epoch : 0.8812599762293057  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15275th epoch : 0.8780343506767437  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15276th epoch : 0.8748164739758992  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15277th epoch : 0.8716068039021915  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15278th epoch : 0.8684057921245127  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15279th epoch : 0.865213883928063  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15280th epoch : 0.8620315179480454  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15281th epoch : 0.8588591259144662  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15282th epoch : 0.8556971324082483  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15283th epoch : 0.8525459546288532  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15284th epoch : 0.8494060021735682  Training Accuracy:0.9285714285714286\n",
      "The training loss at 15285th epoch : 0.8462776768285959  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15286th epoch : 0.8431613723720475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15287th epoch : 0.840057474388917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15288th epoch : 0.8369663600980801  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15289th epoch : 0.8338883981913339  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15290th epoch : 0.8308239486844619  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15291th epoch : 0.8277733627802837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15292th epoch : 0.8247369827436167  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15293th epoch : 0.8217151417880536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15294th epoch : 0.8187081639744306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15295th epoch : 0.8157163641208418  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15296th epoch : 0.8127400477240285  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15297th epoch : 0.8097795108919541  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15298th epoch : 0.8068350402873558  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15299th epoch : 0.8039069130820474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15300th epoch : 0.8009953969217355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15301th epoch : 0.7981007499010923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15302th epoch : 0.7952232205488259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15303th epoch : 0.792363047822473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15304th epoch : 0.7895204611126365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15305th epoch : 0.7866956802563819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15306th epoch : 0.7838889155595057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15307th epoch : 0.7811003678273843  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15308th epoch : 0.778330228404113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15309th epoch : 0.7755786792196419  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15310th epoch : 0.7728458928446209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15311th epoch : 0.7701320325526648  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15312th epoch : 0.767437252389752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15313th epoch : 0.7647616972504763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15314th epoch : 0.7621055029608731  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15315th epoch : 0.7594687963675443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15316th epoch : 0.7568516954328114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15317th epoch : 0.7542543093356322  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15318th epoch : 0.7516767385780152  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15319th epoch : 0.7491190750966761  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15320th epoch : 0.7465814023796792  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15321th epoch : 0.7440637955878135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15322th epoch : 0.7415663216804551  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15323th epoch : 0.7390890395456698  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15324th epoch : 0.7366320001343141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15325th epoch : 0.7341952465978945  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15326th epoch : 0.7317788144299474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15327th epoch : 0.7293827316107034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15328th epoch : 0.7270070187548026  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15329th epoch : 0.7246516892618275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15330th epoch : 0.722316749469427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15331th epoch : 0.7200021988087968  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15332th epoch : 0.7177080299622944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15333th epoch : 0.7154342290229612  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15334th epoch : 0.7131807756557278  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15335th epoch : 0.7109476432600823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15336th epoch : 0.7087347991339821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15337th epoch : 0.7065422046387915  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15338th epoch : 0.7043698153650325  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15339th epoch : 0.702217581298737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15340th epoch : 0.7000854469881921  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15341th epoch : 0.6979733517108763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15342th epoch : 0.6958812296403837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15343th epoch : 0.6938090100131434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15344th epoch : 0.6917566172947409  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15345th epoch : 0.6897239713456561  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15346th epoch : 0.6877109875862368  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15347th epoch : 0.6857175771607341  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15348th epoch : 0.683743647100228  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15349th epoch : 0.681789100484282  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15350th epoch : 0.6798538366011709  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15351th epoch : 0.67793775110653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15352th epoch : 0.6760407361802839  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15353th epoch : 0.6741626806817216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15354th epoch : 0.6723034703025844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15355th epoch : 0.6704629877180508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15356th epoch : 0.6686411127355018  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15357th epoch : 0.6668377224409615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15358th epoch : 0.6650526913431142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15359th epoch : 0.6632858915148074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15360th epoch : 0.6615371927319573  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15361th epoch : 0.65980646260978  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15362th epoch : 0.6580935667362807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15363th epoch : 0.6563983688029391  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15364th epoch : 0.6547207307325368  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15365th epoch : 0.6530605128040787  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15366th epoch : 0.6514175737747704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15367th epoch : 0.6497917709990131  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15368th epoch : 0.6481829605443943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15369th epoch : 0.6465909973046485  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15370th epoch : 0.6450157351095746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15371th epoch : 0.6434570268319003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15372th epoch : 0.64191472449109  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15373th epoch : 0.6403886793540962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15374th epoch : 0.6388787420330613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15375th epoch : 0.6373847625799817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15376th epoch : 0.6359065905783483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15377th epoch : 0.634444075231784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15378th epoch : 0.6329970654497014  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15379th epoch : 0.6315654099300083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15380th epoch : 0.630148957238893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15381th epoch : 0.6287475558877207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15382th epoch : 0.6273610544070818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15383th epoch : 0.6259893014180282  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15384th epoch : 0.6246321457005432  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15385th epoch : 0.6232894362592863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15386th epoch : 0.6219610223866637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15387th epoch : 0.6206467537232679  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15388th epoch : 0.619346480315741  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15389th epoch : 0.6180600526721104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15390th epoch : 0.6167873218146513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15391th epoch : 0.615528139330329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15392th epoch : 0.6142823574188756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15393th epoch : 0.6130498289385574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15394th epoch : 0.6118304074496891  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15395th epoch : 0.6106239472559498  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15396th epoch : 0.6094303034435599  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15397th epoch : 0.6082493319183735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15398th epoch : 0.6070808894409455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15399th epoch : 0.605924833659629  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15400th epoch : 0.6047810231417597  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15401th epoch : 0.6036493174029856  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15402th epoch : 0.6025295769347945  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15403th epoch : 0.6014216632303003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15404th epoch : 0.6003254388083376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15405th epoch : 0.5992407672359235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15406th epoch : 0.598167513149138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15407th epoch : 0.5971055422724778  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15408th epoch : 0.5960547214367348  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15409th epoch : 0.595014918595451  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15410th epoch : 0.5939860028400011  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15411th epoch : 0.5929678444133529  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15412th epoch : 0.5919603147225527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15413th epoch : 0.5909632863499854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15414th epoch : 0.5899766330634558  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15415th epoch : 0.5890002298251361  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15416th epoch : 0.588033952799426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15417th epoch : 0.5870776793597682  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15418th epoch : 0.5861312880944612  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15419th epoch : 0.5851946588115148  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15420th epoch : 0.584267672542584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15421th epoch : 0.583350211546025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15422th epoch : 0.5824421593091089  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15423th epoch : 0.5815434005494341  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15424th epoch : 0.5806538212155689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15425th epoch : 0.5797733084869647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15426th epoch : 0.5789017507731711  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15427th epoch : 0.5780390377123862  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15428th epoch : 0.577185060169377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15429th epoch : 0.5763397102327973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15430th epoch : 0.5755028812119372  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15431th epoch : 0.5746744676329306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15432th epoch : 0.5738543652344503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15433th epoch : 0.5730424709629187  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15434th epoch : 0.5722386829672587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15435th epoch : 0.5714429005932121  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15436th epoch : 0.5706550243772497  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15437th epoch : 0.5698749560400955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15438th epoch : 0.5691025984798905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15439th epoch : 0.5683378557650155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15440th epoch : 0.567580633126596  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15441th epoch : 0.5668308369507088  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15442th epoch : 0.5660883747703099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15443th epoch : 0.5653531552569037  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15444th epoch : 0.5646250882119692  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15445th epoch : 0.5639040845581647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15446th epoch : 0.5631900563303227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15447th epoch : 0.5624829166662557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15448th epoch : 0.5617825797973851  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15449th epoch : 0.56108896103921  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15450th epoch : 0.5604019767816284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15451th epoch : 0.5597215444791257  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15452th epoch : 0.5590475826408426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15453th epoch : 0.5583800108205356  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15454th epoch : 0.5577187496064404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15455th epoch : 0.5570637206110517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15456th epoch : 0.556414846460828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15457th epoch : 0.5557720507858332  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15458th epoch : 0.5551352582093246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15459th epoch : 0.5545043943372956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15460th epoch : 0.5538793857479832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15461th epoch : 0.5532601599813488  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15462th epoch : 0.5526466455285388  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15463th epoch : 0.5520387718213351  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15464th epoch : 0.5514364692215997  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15465th epoch : 0.5508396690107242  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15466th epoch : 0.5502483033790866  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15467th epoch : 0.5496623054155243  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15468th epoch : 0.5490816090968289  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15469th epoch : 0.5485061492772672  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15470th epoch : 0.5479358616781337  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15471th epoch : 0.5473706828773421  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15472th epoch : 0.5468105502990562  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15473th epoch : 0.5462554022033678  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15474th epoch : 0.5457051776760252  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15475th epoch : 0.5451598166182151  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15476th epoch : 0.5446192597364021  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15477th epoch : 0.5440834485322295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15478th epoch : 0.5435523252924841  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15479th epoch : 0.5430258330791287  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15480th epoch : 0.5425039157194033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15481th epoch : 0.5419865177960005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15482th epoch : 0.5414735846373141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15483th epoch : 0.540965062307766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15484th epoch : 0.5404608975982111  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15485th epoch : 0.5399610380164247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15486th epoch : 0.5394654317776704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15487th epoch : 0.5389740277953544  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15488th epoch : 0.5384867756717646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15489th epoch : 0.5380036256888958  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15490th epoch : 0.5375245287993645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15491th epoch : 0.5370494366174119  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15492th epoch : 0.5365783014099972  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15493th epoch : 0.5361110760879819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15494th epoch : 0.5356477141974058  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15495th epoch : 0.5351881699108546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15496th epoch : 0.5347323980189213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15497th epoch : 0.5342803539217592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15498th epoch : 0.5338319936207301  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15499th epoch : 0.5333872737101448  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15500th epoch : 0.5329461513690982  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15501th epoch : 0.5325085843533982  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15502th epoch : 0.5320745309875891  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15503th epoch : 0.5316439501570677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15504th epoch : 0.5312168013002951  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15505th epoch : 0.530793044401101  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15506th epoch : 0.5303726399810814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15507th epoch : 0.5299555490920906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15508th epoch : 0.5295417333088258  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15509th epoch : 0.5291311547215033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15510th epoch : 0.5287237759286286  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15511th epoch : 0.5283195600298572  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15512th epoch : 0.5279184706189469  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15513th epoch : 0.5275204717768006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15514th epoch : 0.5271255280646004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15515th epoch : 0.5267336045170304  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15516th epoch : 0.5263446666355884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15517th epoch : 0.5259586803819872  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15518th epoch : 0.5255756121716425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15519th epoch : 0.5251954288672483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15520th epoch : 0.5248180977724393  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15521th epoch : 0.5244435866255375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15522th epoch : 0.5240718635933856  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15523th epoch : 0.5237028972652632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15524th epoch : 0.523336656646887  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15525th epoch : 0.5229731111544931  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15526th epoch : 0.5226122306090022  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15527th epoch : 0.5222539852302643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15528th epoch : 0.5218983456313855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15529th epoch : 0.521545282813132  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15530th epoch : 0.5211947681584145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15531th epoch : 0.5208467734268495  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15532th epoch : 0.5205012707493972  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15533th epoch : 0.520158232623076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15534th epoch : 0.519817631905752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15535th epoch : 0.5194794418110024  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15536th epoch : 0.5191436359030525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15537th epoch : 0.5188101880917859  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15538th epoch : 0.5184790726278257  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15539th epoch : 0.5181502640976863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15540th epoch : 0.5178237374189963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15541th epoch : 0.5174994678357897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15542th epoch : 0.5171774309138648  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15543th epoch : 0.5168576025362122  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15544th epoch : 0.5165399588985078  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15545th epoch : 0.5162244765046722  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15546th epoch : 0.5159111321624947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15547th epoch : 0.5155999029793219  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15548th epoch : 0.515290766357808  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15549th epoch : 0.5149836999917294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15550th epoch : 0.5146786818618592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15551th epoch : 0.5143756902319031  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15552th epoch : 0.5140747036444954  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15553th epoch : 0.5137757009172527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15554th epoch : 0.5134786611388877  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15555th epoch : 0.5131835636653793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15556th epoch : 0.5128903881161991  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15557th epoch : 0.5125991143705947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15558th epoch : 0.512309722563927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15559th epoch : 0.5120221930840627  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15560th epoch : 0.5117365065678199  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15561th epoch : 0.511452643897466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15562th epoch : 0.5111705861972689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15563th epoch : 0.5108903148300976  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15564th epoch : 0.5106118113940755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15565th epoch : 0.5103350577192813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15566th epoch : 0.5100600358645005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15567th epoch : 0.5097867281140248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15568th epoch : 0.5095151169744987  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15569th epoch : 0.5092451851718139  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15570th epoch : 0.5089769156480491  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15571th epoch : 0.5087102915584563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15572th epoch : 0.5084452962684904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15573th epoch : 0.5081819133508856  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15574th epoch : 0.5079201265827724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15575th epoch : 0.5076599199428398  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15576th epoch : 0.5074012776085389  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15577th epoch : 0.5071441839533282  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15578th epoch : 0.5068886235439594  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15579th epoch : 0.5066345811378049  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15580th epoch : 0.5063820416802242  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15581th epoch : 0.5061309903019688  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15582th epoch : 0.5058814123166279  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15583th epoch : 0.5056332932181092  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15584th epoch : 0.5053866186781601  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15585th epoch : 0.5051413745439234  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15586th epoch : 0.5048975468355306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15587th epoch : 0.5046551217437302  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15588th epoch : 0.5044140856275522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15589th epoch : 0.5041744250120064  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15590th epoch : 0.5039361265858145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15591th epoch : 0.5036991771991775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15592th epoch : 0.5034635638615738  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15593th epoch : 0.5032292737395923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15594th epoch : 0.5029962941547955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15595th epoch : 0.5027646125816159  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15596th epoch : 0.5025342166452818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15597th epoch : 0.5023050941197756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15598th epoch : 0.5020772329258206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15599th epoch : 0.5018506211288983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15600th epoch : 0.5016252469372948  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15601th epoch : 0.5014010987001758  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15602th epoch : 0.5011781649056902  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15603th epoch : 0.5009564341791013  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15604th epoch : 0.5007358952809456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15605th epoch : 0.5005165371052185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15606th epoch : 0.5002983486775867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15607th epoch : 0.5000813191536271  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15608th epoch : 0.49986543781709036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15609th epoch : 0.49965069407819146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15610th epoch : 0.499437077471924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15611th epoch : 0.49922457765639955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15612th epoch : 0.4990131844112112  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15613th epoch : 0.4988028876358208  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15614th epoch : 0.4985936773479702  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15615th epoch : 0.49838554368211463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15616th epoch : 0.4981784768878797  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15617th epoch : 0.4979724673285405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15618th epoch : 0.4977675054795226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15619th epoch : 0.4975635819269248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15620th epoch : 0.49736068736606337  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15621th epoch : 0.4971588126000374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15622th epoch : 0.4969579485383145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15623th epoch : 0.49675808619533707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15624th epoch : 0.4965592166891489  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15625th epoch : 0.49636133124004095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15626th epoch : 0.49616442116921716  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15627th epoch : 0.4959684778974791  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15628th epoch : 0.49577349294392953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15629th epoch : 0.49557945792469427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15630th epoch : 0.49538636455166296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15631th epoch : 0.4951942046312472  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15632th epoch : 0.4950029700631567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15633th epoch : 0.49481265283919273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15634th epoch : 0.4946232450420588  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15635th epoch : 0.4944347388441883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15636th epoch : 0.49424712650658886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15637th epoch : 0.49406040037770244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15638th epoch : 0.4938745528922827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15639th epoch : 0.49368957657028717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15640th epoch : 0.4935054640157857  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15641th epoch : 0.49332220791588405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15642th epoch : 0.4931398010396627  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15643th epoch : 0.49295823623713053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15644th epoch : 0.49277750643819346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15645th epoch : 0.4925976046516371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15646th epoch : 0.49241852396412406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15647th epoch : 0.49224025753920503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15648th epoch : 0.49206279861634405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15649th epoch : 0.4918861405099567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15650th epoch : 0.4917102766084626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15651th epoch : 0.49153520037335025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15652th epoch : 0.4913609053382553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15653th epoch : 0.4911873851080519  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15654th epoch : 0.49101463335795564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15655th epoch : 0.4908426438326403  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15656th epoch : 0.49067141034536554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15657th epoch : 0.4905009267771175  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15658th epoch : 0.4903311870757607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15659th epoch : 0.4901621852552019  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15660th epoch : 0.4899939153945656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15661th epoch : 0.48982637163738046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15662th epoch : 0.48965954819077706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15663th epoch : 0.4894934393246968  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15664th epoch : 0.4893280393711114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15665th epoch : 0.4891633427232531  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15666th epoch : 0.4889993438348556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15667th epoch : 0.48883603721940483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15668th epoch : 0.4886734174494006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15669th epoch : 0.4885114791556276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15670th epoch : 0.48835021702643655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15671th epoch : 0.48818962580703545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15672th epoch : 0.4880297002987898  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15673th epoch : 0.48787043535853264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15674th epoch : 0.48771182589788387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15675th epoch : 0.4875538668825786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15676th epoch : 0.48739655333180476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15677th epoch : 0.48723988031754917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15678th epoch : 0.4870838429639531  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15679th epoch : 0.4869284364466756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15680th epoch : 0.4867736559922663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15681th epoch : 0.4866194968775455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15682th epoch : 0.4864659544289936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15683th epoch : 0.4863130240221478  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15684th epoch : 0.4861607010810075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15685th epoch : 0.4860089810774472  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15686th epoch : 0.4858578595306371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15687th epoch : 0.4857073320064718  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15688th epoch : 0.4855573941170063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15689th epoch : 0.4854080415198994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15690th epoch : 0.4852592699178645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15691th epoch : 0.4851110750581277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15692th epoch : 0.4849634527318931  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15693th epoch : 0.4848163987738149  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15694th epoch : 0.4846699090614765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15695th epoch : 0.4845239795148766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15696th epoch : 0.48437860609592176  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15697th epoch : 0.48423378480792606  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15698th epoch : 0.48408951169511655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15699th epoch : 0.48394578284214584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15700th epoch : 0.4838025943736106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15701th epoch : 0.48365994245357674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15702th epoch : 0.4835178232851101  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15703th epoch : 0.4833762331098142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15704th epoch : 0.4832351682073728  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15705th epoch : 0.48309462489509936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15706th epoch : 0.4829545995274919  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15707th epoch : 0.4828150884957937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15708th epoch : 0.48267608822755925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15709th epoch : 0.48253759518622674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15710th epoch : 0.48239960587069497  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15711th epoch : 0.48226211681490644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15712th epoch : 0.4821251245874354  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15713th epoch : 0.48198862579108137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15714th epoch : 0.48185261706246774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15715th epoch : 0.4817170950716456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15716th epoch : 0.48158205652170266  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15717th epoch : 0.4814474981483768  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15718th epoch : 0.48131341671967504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15719th epoch : 0.481179809035497  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15720th epoch : 0.48104667192726347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15721th epoch : 0.4809140022575491  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15722th epoch : 0.4807817969197206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15723th epoch : 0.48065005283757867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15724th epoch : 0.4805187669650049  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15725th epoch : 0.4803879362856133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15726th epoch : 0.4802575578124057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15727th epoch : 0.4801276285874318  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15728th epoch : 0.47999814568145377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15729th epoch : 0.47986910619361434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15730th epoch : 0.4797405072511097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15731th epoch : 0.4796123460088665  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15732th epoch : 0.47948461964922207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15733th epoch : 0.4793573253816099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15734th epoch : 0.479230460442248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15735th epoch : 0.4791040220938317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15736th epoch : 0.4789780076252301  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15737th epoch : 0.4788524143511862  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15738th epoch : 0.4787272396120213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15739th epoch : 0.478602480773342  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15740th epoch : 0.4784781352257522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15741th epoch : 0.4783542003845676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15742th epoch : 0.478230673689534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15743th epoch : 0.47810755260454957  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15744th epoch : 0.47798483461738983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15745th epoch : 0.47786251723943673  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15746th epoch : 0.4777405980054104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15747th epoch : 0.4776190744731047  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15748th epoch : 0.4774979442231259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15749th epoch : 0.47737720485863444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15750th epoch : 0.47725685400509  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15751th epoch : 0.47713688930999965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15752th epoch : 0.47701730844266904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15753th epoch : 0.476898109093957  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15754th epoch : 0.47677928897603244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15755th epoch : 0.47666084582213486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15756th epoch : 0.4765427773863376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15757th epoch : 0.47642508144331375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15758th epoch : 0.4763077557881053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15759th epoch : 0.47619079823589494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15760th epoch : 0.47607420662178035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15761th epoch : 0.4759579788005518  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15762th epoch : 0.47584211264647197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15763th epoch : 0.4757266060530587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15764th epoch : 0.47561145693287044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15765th epoch : 0.4754966632172938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15766th epoch : 0.4753822228563344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15767th epoch : 0.4752681338184099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15768th epoch : 0.4751543940901453  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15769th epoch : 0.4750410016761712  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15770th epoch : 0.4749279545989239  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15771th epoch : 0.4748152508984487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15772th epoch : 0.47470288863220494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15773th epoch : 0.4745908658748734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15774th epoch : 0.4744791807181665  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15775th epoch : 0.47436783127064036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15776th epoch : 0.47425681565750916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15777th epoch : 0.4741461320204621  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15778th epoch : 0.47403577851748185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15779th epoch : 0.47392575332266607  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 15780th epoch : 0.4738160546260503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15781th epoch : 0.47370668063343346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15782th epoch : 0.47359762956620505  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15783th epoch : 0.4734888996611748  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15784th epoch : 0.4733804891704042  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15785th epoch : 0.4732723963610399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15786th epoch : 0.4731646195151494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15787th epoch : 0.47305715692955835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15788th epoch : 0.47295000691569006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15789th epoch : 0.47284316779940694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15790th epoch : 0.4727366379208535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15791th epoch : 0.4726304156343017  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15792th epoch : 0.4725244993079976  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15793th epoch : 0.47241888732401033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15794th epoch : 0.4723135780780826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15795th epoch : 0.4722085699794831  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15796th epoch : 0.4721038614508602  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15797th epoch : 0.4719994509280984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15798th epoch : 0.4718953368601754  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15799th epoch : 0.4717915177090212  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15800th epoch : 0.4716879919493796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15801th epoch : 0.4715847580686699  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15802th epoch : 0.47148181456685184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15803th epoch : 0.4713791599562907  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15804th epoch : 0.47127679276162515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15805th epoch : 0.47117471151963586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15806th epoch : 0.471072914779116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15807th epoch : 0.4709714011007434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15808th epoch : 0.4708701690569538  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15809th epoch : 0.47076921723181603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15810th epoch : 0.4706685442209083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15811th epoch : 0.4705681486311964  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15812th epoch : 0.4704680290809127  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15813th epoch : 0.4703681841994371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15814th epoch : 0.4702686126271793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15815th epoch : 0.47016931301546205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15816th epoch : 0.47007028402640655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15817th epoch : 0.4699715243328182  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15818th epoch : 0.4698730326180745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15819th epoch : 0.4697748075760141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15820th epoch : 0.46967684791082664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15821th epoch : 0.4695791523369447  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15822th epoch : 0.46948171957893625  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15823th epoch : 0.4693845483713988  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15824th epoch : 0.4692876374588549  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15825th epoch : 0.46919098559564815  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15826th epoch : 0.46909459154584154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15827th epoch : 0.46899845408311586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15828th epoch : 0.46890257199067004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15829th epoch : 0.4688069440611223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15830th epoch : 0.46871156909641265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15831th epoch : 0.46861644590770646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15832th epoch : 0.4685215733152989  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15833th epoch : 0.4684269501485212  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15834th epoch : 0.468332575245647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15835th epoch : 0.4682384474538005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15836th epoch : 0.46814456562886586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15837th epoch : 0.46805092863539677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15838th epoch : 0.46795753534652784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15839th epoch : 0.4678643846438868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15840th epoch : 0.46777147541750774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15841th epoch : 0.467678806565745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15842th epoch : 0.4675863769951889  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15843th epoch : 0.46749418562058137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15844th epoch : 0.46740223136473347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15845th epoch : 0.46731051315844346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15846th epoch : 0.46721902994041575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15847th epoch : 0.46712778065718097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15848th epoch : 0.4670367642630169  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15849th epoch : 0.4669459797198703  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15850th epoch : 0.4668554259972797  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15851th epoch : 0.4667651020722991  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15852th epoch : 0.4666750069294223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15853th epoch : 0.46658513956050846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15854th epoch : 0.4664954989647083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15855th epoch : 0.4664060841483913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15856th epoch : 0.46631689412507354  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15857th epoch : 0.46622792791534645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15858th epoch : 0.46613918454680664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15859th epoch : 0.4660506630539861  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15860th epoch : 0.4659623624782835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15861th epoch : 0.4658742818678961  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15862th epoch : 0.4657864202777528  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15863th epoch : 0.4656987767694474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15864th epoch : 0.4656113504111731  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15865th epoch : 0.46552414027765754  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15866th epoch : 0.4654371454500987  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15867th epoch : 0.4653503650161014  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15868th epoch : 0.46526379806961443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15869th epoch : 0.465177443710869  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15870th epoch : 0.46509130104631696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15871th epoch : 0.4650053691885706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15872th epoch : 0.4649196472563426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15873th epoch : 0.46483413437438686  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15874th epoch : 0.4647488296734399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15875th epoch : 0.4646637322901632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15876th epoch : 0.46457884136708605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15877th epoch : 0.46449415605254846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15878th epoch : 0.46440967550064616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15879th epoch : 0.4643253988711745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15880th epoch : 0.4642413253295745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15881th epoch : 0.4641574540468784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15882th epoch : 0.4640737841996564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15883th epoch : 0.46399031496996396  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15884th epoch : 0.4639070455452896  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15885th epoch : 0.4638239751185034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15886th epoch : 0.4637411028878056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15887th epoch : 0.46365842805667684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15888th epoch : 0.4635759498338277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15889th epoch : 0.4634936674331499  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15890th epoch : 0.46341158007366706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15891th epoch : 0.4633296869794871  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15892th epoch : 0.46324798737975426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15893th epoch : 0.4631664805086021  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15894th epoch : 0.4630851656051069  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15895th epoch : 0.46300404191324174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15896th epoch : 0.46292310868183095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15897th epoch : 0.46284236516450505  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15898th epoch : 0.4627618106196564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15899th epoch : 0.462681444310395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15900th epoch : 0.46260126550450525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15901th epoch : 0.46252127347440286  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15902th epoch : 0.46244146749709214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15903th epoch : 0.4623618468541243  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15904th epoch : 0.46228241083155563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15905th epoch : 0.4622031587199065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15906th epoch : 0.4621240898141207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15907th epoch : 0.46204520341352523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15908th epoch : 0.4619664988217906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15909th epoch : 0.46188797534689163  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15910th epoch : 0.4618096323010683  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15911th epoch : 0.46173146900078776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15912th epoch : 0.461653484766706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15913th epoch : 0.4615756789236303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15914th epoch : 0.4614980508004823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15915th epoch : 0.46142059973026117  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15916th epoch : 0.4613433250500072  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15917th epoch : 0.46126622610076595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15918th epoch : 0.4611893022275528  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15919th epoch : 0.46111255277931745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15920th epoch : 0.4610359771089098  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15921th epoch : 0.46095957457304515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15922th epoch : 0.46088334453227026  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15923th epoch : 0.4608072863509299  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15924th epoch : 0.46073139939713337  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15925th epoch : 0.46065568304272214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15926th epoch : 0.46058013666323666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15927th epoch : 0.46050475963788484  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15928th epoch : 0.46042955134950986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15929th epoch : 0.46035451118455883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15930th epoch : 0.46027963853305176  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15931th epoch : 0.46020493278855085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15932th epoch : 0.46013039334812983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15933th epoch : 0.46005601961234416  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15934th epoch : 0.459981810985201  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15935th epoch : 0.45990776687413015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15936th epoch : 0.4598338866899544  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15937th epoch : 0.4597601698468613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15938th epoch : 0.4596866157623742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15939th epoch : 0.4596132238573244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15940th epoch : 0.45953999355582326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15941th epoch : 0.4594669242852343  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15942th epoch : 0.45939401547614633  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15943th epoch : 0.4593212665623464  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15944th epoch : 0.4592486769807929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15945th epoch : 0.4591762461715893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15946th epoch : 0.4591039735779581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15947th epoch : 0.45903185864621504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15948th epoch : 0.45895990082574323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15949th epoch : 0.4588880995689682  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15950th epoch : 0.4588164543313329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15951th epoch : 0.4587449645712726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15952th epoch : 0.45867362975019094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15953th epoch : 0.4586024493324352  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15954th epoch : 0.45853142278527276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15955th epoch : 0.45846054957886706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15956th epoch : 0.45838982918625437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15957th epoch : 0.45831926108332066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15958th epoch : 0.4582488447487783  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15959th epoch : 0.45817857966414366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15960th epoch : 0.4581084653137145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15961th epoch : 0.45803850118454786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15962th epoch : 0.4579686867664379  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15963th epoch : 0.45789902155189427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15964th epoch : 0.4578295050361203  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15965th epoch : 0.45776013671699217  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15966th epoch : 0.4576909160950373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15967th epoch : 0.4576218426734139  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15968th epoch : 0.4575529159578899  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15969th epoch : 0.457484135456823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15970th epoch : 0.45741550068114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15971th epoch : 0.4573470111443171  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15972th epoch : 0.45727866636235975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15973th epoch : 0.45721046585378355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15974th epoch : 0.45714240913959436  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15975th epoch : 0.4570744957432693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15976th epoch : 0.4570067251907378  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15977th epoch : 0.4569390970103628  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15978th epoch : 0.45687161073292193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15979th epoch : 0.45680426589158935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15980th epoch : 0.4567370620219174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15981th epoch : 0.4566699986618184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15982th epoch : 0.4566030753515471  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15983th epoch : 0.4565362916336828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15984th epoch : 0.45646964705311194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15985th epoch : 0.45640314115701053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15986th epoch : 0.4563367734948273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15987th epoch : 0.4562705436182667  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15988th epoch : 0.4562044510812719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15989th epoch : 0.4561384954400083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15990th epoch : 0.4560726762528469  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15991th epoch : 0.4560069930803484  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15992th epoch : 0.4559414454852465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15993th epoch : 0.45587603303243246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15994th epoch : 0.4558107552889387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15995th epoch : 0.4557456118239238  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15996th epoch : 0.4556806022086564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15997th epoch : 0.4556157260165003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15998th epoch : 0.45555098282289896  Training Accuracy:0.9642857142857143\n",
      "The training loss at 15999th epoch : 0.4554863722053605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16000th epoch : 0.455421893743443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16001th epoch : 0.4553575470187395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16002th epoch : 0.45529333161486346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16003th epoch : 0.4552292471174345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16004th epoch : 0.4551652931140637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16005th epoch : 0.4551014691943396  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16006th epoch : 0.45503777494981434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16007th epoch : 0.4549742099739895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16008th epoch : 0.45491077386230233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16009th epoch : 0.45484746621211225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16010th epoch : 0.4547842866226872  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16011th epoch : 0.45472123469519043  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16012th epoch : 0.454658310032667  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16013th epoch : 0.4545955122400309  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16014th epoch : 0.454532840924052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16015th epoch : 0.45447029569334296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16016th epoch : 0.4544078761583467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16017th epoch : 0.4543455819313239  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16018th epoch : 0.45428341262634003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16019th epoch : 0.4542213678592534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16020th epoch : 0.45415944724770263  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16021th epoch : 0.4540976504110947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16022th epoch : 0.4540359769705926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16023th epoch : 0.4539744265491038  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16024th epoch : 0.45391299877126806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16025th epoch : 0.45385169326344593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16026th epoch : 0.45379050965370704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16027th epoch : 0.4537294475718188  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16028th epoch : 0.4536685066492347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16029th epoch : 0.45360768651908334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16030th epoch : 0.4535469868161571  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16031th epoch : 0.4534864071769011  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16032th epoch : 0.4534259472394021  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16033th epoch : 0.453365606643378  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16034th epoch : 0.45330538503016654  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16035th epoch : 0.4532452820427152  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16036th epoch : 0.45318529732557006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16037th epoch : 0.4531254305248658  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16038th epoch : 0.45306568128831504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16039th epoch : 0.45300604926519816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16040th epoch : 0.45294653410635305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16041th epoch : 0.45288713546416504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16042th epoch : 0.45282785299255685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16043th epoch : 0.45276868634697875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16044th epoch : 0.45270963518439855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16045th epoch : 0.4526506991632922  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16046th epoch : 0.45259187794363365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16047th epoch : 0.4525331711868857  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16048th epoch : 0.45247457855599016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16049th epoch : 0.4524160997153589  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16050th epoch : 0.452357734330864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16051th epoch : 0.4522994820698289  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16052th epoch : 0.45224134260101895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16053th epoch : 0.4521833155946327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16054th epoch : 0.4521254007222925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16055th epoch : 0.4520675976570359  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16056th epoch : 0.4520099060733065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16057th epoch : 0.45195232564694554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16058th epoch : 0.4518948560551828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16059th epoch : 0.45183749697662845  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16060th epoch : 0.45178024809126405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16061th epoch : 0.4517231090804344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16062th epoch : 0.451666079626839  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16063th epoch : 0.45160915941452384  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16064th epoch : 0.45155234812887285  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16065th epoch : 0.4514956454566002  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16066th epoch : 0.4514390510857417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16067th epoch : 0.45138256470564714  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16068th epoch : 0.45132618600697205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16069th epoch : 0.4512699146816699  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16070th epoch : 0.45121375042298417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16071th epoch : 0.4511576929254408  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16072th epoch : 0.4511017418848402  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16073th epoch : 0.45104589699824976  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16074th epoch : 0.4509901579639962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16075th epoch : 0.4509345244816581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16076th epoch : 0.4508789962520584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16077th epoch : 0.45082357297725695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16078th epoch : 0.45076825436054335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16079th epoch : 0.45071304010642943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16080th epoch : 0.45065792992064224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16081th epoch : 0.4506029235101168  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16082th epoch : 0.450548020582989  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16083th epoch : 0.4504932208485885  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16084th epoch : 0.45043852401743195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16085th epoch : 0.4503839298012157  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16086th epoch : 0.45032943791280944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16087th epoch : 0.45027504806624874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16088th epoch : 0.4502207599767289  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16089th epoch : 0.4501665733605979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16090th epoch : 0.45011248793534975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16091th epoch : 0.450058503419618  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16092th epoch : 0.45000461953316917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16093th epoch : 0.44995083599689617  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16094th epoch : 0.44989715253281193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16095th epoch : 0.44984356886404303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16096th epoch : 0.4497900847148232  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16097th epoch : 0.4497366998104872  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16098th epoch : 0.4496834138774645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16099th epoch : 0.4496302266432731  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16100th epoch : 0.4495771378365133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16101th epoch : 0.44952414718686173  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16102th epoch : 0.4494712544250652  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16103th epoch : 0.4494184592829346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16104th epoch : 0.44936576149333934  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16105th epoch : 0.4493131607902009  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16106th epoch : 0.44926065690848727  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16107th epoch : 0.4492082495842072  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16108th epoch : 0.44915593855440406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16109th epoch : 0.44910372355715056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16110th epoch : 0.4490516043315426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16111th epoch : 0.4489995806176941  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16112th epoch : 0.44894765215673094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16113th epoch : 0.4488958186907857  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16114th epoch : 0.4488440799629919  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16115th epoch : 0.44879243571747884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16116th epoch : 0.4487408856993658  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16117th epoch : 0.448689429654757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16118th epoch : 0.44863806733073586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16119th epoch : 0.4485867984753599  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16120th epoch : 0.4485356228376556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16121th epoch : 0.4484845401676128  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16122th epoch : 0.44843355021617975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16123th epoch : 0.44838265273525796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16124th epoch : 0.44833184747769683  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16125th epoch : 0.448281134197289  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16126th epoch : 0.44823051264876473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16127th epoch : 0.44817998258778735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16128th epoch : 0.4481295437709481  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16129th epoch : 0.44807919595576123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16130th epoch : 0.44802893890065904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16131th epoch : 0.44797877236498695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16132th epoch : 0.44792869610899894  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16133th epoch : 0.44787870989385237  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16134th epoch : 0.4478288134816036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16135th epoch : 0.4477790066352029  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16136th epoch : 0.44772928911849  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16137th epoch : 0.4476796606961895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16138th epoch : 0.44763012113390566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16139th epoch : 0.44758067019811865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16140th epoch : 0.4475313076561793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16141th epoch : 0.4474820332763051  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16142th epoch : 0.44743284682757506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16143th epoch : 0.4473837480799259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16144th epoch : 0.4473347368041472  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16145th epoch : 0.4472858127718771  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16146th epoch : 0.44723697575559795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16147th epoch : 0.447188225528632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16148th epoch : 0.447139561865137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16149th epoch : 0.4470909845401018  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16150th epoch : 0.44704249332934254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16151th epoch : 0.4469940880094979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16152th epoch : 0.44694576835802513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16153th epoch : 0.446897534153196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16154th epoch : 0.4468493851740924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16155th epoch : 0.4468013212006025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16156th epoch : 0.44675334201341643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16157th epoch : 0.44670544739402235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16158th epoch : 0.44665763712470247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16159th epoch : 0.44660991098852887  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16160th epoch : 0.44656226876935967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16161th epoch : 0.4465147102518351  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16162th epoch : 0.4464672352213735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16163th epoch : 0.44641984346416747  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16164th epoch : 0.44637253476717986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16165th epoch : 0.44632530891814026  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16166th epoch : 0.4462781657055408  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16167th epoch : 0.4462311049186327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16168th epoch : 0.4461841263474222  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16169th epoch : 0.44613722978266707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16170th epoch : 0.44609041501587277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16171th epoch : 0.44604368183928866  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16172th epoch : 0.44599703004590463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16173th epoch : 0.4459504594294472  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16174th epoch : 0.445903969784376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16175th epoch : 0.4458575609058801  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16176th epoch : 0.44581123258987454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16177th epoch : 0.4457649846329968  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16178th epoch : 0.4457188168326031  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16179th epoch : 0.4456727289867652  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16180th epoch : 0.44562672089426647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16181th epoch : 0.44558079235459896  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16182th epoch : 0.44553494316795955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16183th epoch : 0.44548917313524683  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16184th epoch : 0.4454434820580574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16185th epoch : 0.4453978697386828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16186th epoch : 0.4453523359801061  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16187th epoch : 0.4453068805859984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16188th epoch : 0.4452615033607157  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16189th epoch : 0.44521620410929563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16190th epoch : 0.445170982637454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16191th epoch : 0.4451258387515818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16192th epoch : 0.4450807722587419  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16193th epoch : 0.44503578296666557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16194th epoch : 0.4449908706837499  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16195th epoch : 0.444946035219054  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16196th epoch : 0.4449012763822963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16197th epoch : 0.4448565939838514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16198th epoch : 0.44481198783474657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16199th epoch : 0.4447674577466591  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16200th epoch : 0.4447230035319132  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16201th epoch : 0.44467862500347666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16202th epoch : 0.44463432197495817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16203th epoch : 0.44459009426060414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16204th epoch : 0.4445459416752956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16205th epoch : 0.44450186403454567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16206th epoch : 0.444457861154496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16207th epoch : 0.44441393285191433  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16208th epoch : 0.44437007894419145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16209th epoch : 0.4443262992493382  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16210th epoch : 0.44428259358598254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16211th epoch : 0.444238961773367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16212th epoch : 0.4441954036313457  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16213th epoch : 0.44415191898038114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16214th epoch : 0.444108507641542  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16215th epoch : 0.44406516943650015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16216th epoch : 0.4440219041875275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16217th epoch : 0.4439787117174939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16218th epoch : 0.4439355918498638  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16219th epoch : 0.4438925444086939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16220th epoch : 0.44384956921863034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16221th epoch : 0.4438066661049059  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16222th epoch : 0.4437638348933375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16223th epoch : 0.44372107541032346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16224th epoch : 0.44367838748284094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16225th epoch : 0.4436357709384431  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16226th epoch : 0.4435932256052567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16227th epoch : 0.4435507513119795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16228th epoch : 0.4435083478878776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16229th epoch : 0.4434660151627827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16230th epoch : 0.44342375296709013  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16231th epoch : 0.44338156113175564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16232th epoch : 0.44333943948829324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16233th epoch : 0.4432973878687727  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16234th epoch : 0.44325540610581704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16235th epoch : 0.44321349403259985  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16236th epoch : 0.44317165148284315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16237th epoch : 0.4431298782908148  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16238th epoch : 0.4430881742913259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16239th epoch : 0.44304653931972876  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16240th epoch : 0.4430049732119141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16241th epoch : 0.442963475804309  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16242th epoch : 0.44292204693387416  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16243th epoch : 0.442880686438102  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16244th epoch : 0.4428393941550139  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16245th epoch : 0.44279816992315796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16246th epoch : 0.442757013581607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16247th epoch : 0.44271592496995577  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16248th epoch : 0.44267490392831904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16249th epoch : 0.44263395029732905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16250th epoch : 0.44259306391813347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16251th epoch : 0.44255224463239307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16252th epoch : 0.4425114922822793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16253th epoch : 0.4424708067104724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16254th epoch : 0.44243018776015886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16255th epoch : 0.4423896352750295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16256th epoch : 0.44234914909927703  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16257th epoch : 0.442308729077594  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16258th epoch : 0.44226837505517075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16259th epoch : 0.44222808687769294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16260th epoch : 0.4421878643913397  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16261th epoch : 0.44214770744278153  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16262th epoch : 0.4421076158791778  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16263th epoch : 0.44206758954817504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16264th epoch : 0.4420276282979048  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16265th epoch : 0.4419877319769814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16266th epoch : 0.4419479004344999  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16267th epoch : 0.44190813352003405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16268th epoch : 0.44186843108363455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16269th epoch : 0.4418287929758264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16270th epoch : 0.4417892190476075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16271th epoch : 0.44174970915044626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16272th epoch : 0.44171026313627965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16273th epoch : 0.4416708808575113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16274th epoch : 0.4416315621670097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16275th epoch : 0.4415923069181057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16276th epoch : 0.4415531149645911  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16277th epoch : 0.4415139861607163  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16278th epoch : 0.44147492036118874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16279th epoch : 0.4414359174211707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16280th epoch : 0.4413969771962775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16281th epoch : 0.44135809954257554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16282th epoch : 0.4413192843165804  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16283th epoch : 0.44128053137525514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16284th epoch : 0.44124184057600807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16285th epoch : 0.4412032117766913  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 16286th epoch : 0.44116464483559864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16287th epoch : 0.44112613961146374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16288th epoch : 0.4410876959634584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16289th epoch : 0.4410493137511908  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16290th epoch : 0.44101099283470324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16291th epoch : 0.440972733074471  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16292th epoch : 0.4409345343314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16293th epoch : 0.44089639646682544  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16294th epoch : 0.44085831934250963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16295th epoch : 0.4408203028206405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16296th epoch : 0.4407823467638298  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16297th epoch : 0.4407444510351114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16298th epoch : 0.4407066154979392  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16299th epoch : 0.440668840016186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16300th epoch : 0.4406311244541413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16301th epoch : 0.44059346867650984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16302th epoch : 0.4405558725484098  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16303th epoch : 0.44051833593537104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16304th epoch : 0.44048085870333364  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16305th epoch : 0.4404434407186462  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16306th epoch : 0.4404060818480639  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16307th epoch : 0.44036878195874707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16308th epoch : 0.44033154091825966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16309th epoch : 0.4402943585945672  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16310th epoch : 0.44025723485603574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16311th epoch : 0.4402201695714297  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16312th epoch : 0.44018316260991047  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16313th epoch : 0.44014621384103503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16314th epoch : 0.44010932313475387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16315th epoch : 0.44007249036141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16316th epoch : 0.44003571539173675  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16317th epoch : 0.4399989980968568  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16318th epoch : 0.43996233834828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16319th epoch : 0.4399257360179025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16320th epoch : 0.43988919097800466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16321th epoch : 0.43985270310124974  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16322th epoch : 0.4398162722606823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16323th epoch : 0.4397798983297269  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16324th epoch : 0.4397435811821862  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16325th epoch : 0.4397073206922399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16326th epoch : 0.4396711167344427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16327th epoch : 0.43963496918372347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16328th epoch : 0.43959887791538327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16329th epoch : 0.43956284280509395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16330th epoch : 0.43952686372889693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16331th epoch : 0.43949094056320154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16332th epoch : 0.4394550731847835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16333th epoch : 0.43941926147078375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16334th epoch : 0.4393835052987068  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16335th epoch : 0.4393478045464193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16336th epoch : 0.4393121590921487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16337th epoch : 0.4392765688144819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16338th epoch : 0.43924103359236366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16339th epoch : 0.4392055533050953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16340th epoch : 0.4391701278323334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16341th epoch : 0.4391347570540882  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16342th epoch : 0.43909944085072244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16343th epoch : 0.4390641791029498  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16344th epoch : 0.43902897169183375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16345th epoch : 0.438993818498786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16346th epoch : 0.4389587194055652  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16347th epoch : 0.43892367429427565  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16348th epoch : 0.4388886830473659  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16349th epoch : 0.43885374554762757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16350th epoch : 0.4388188616781938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16351th epoch : 0.438784031322538  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16352th epoch : 0.4387492543644727  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16353th epoch : 0.43871453068814814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16354th epoch : 0.4386798601780508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16355th epoch : 0.4386452427190024  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16356th epoch : 0.4386106781961585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16357th epoch : 0.4385761664950072  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16358th epoch : 0.4385417075013678  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16359th epoch : 0.43850730110138963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16360th epoch : 0.43847294718155094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16361th epoch : 0.4384386456286573  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16362th epoch : 0.4384043963298406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16363th epoch : 0.4383701991725577  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16364th epoch : 0.43833605404458936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16365th epoch : 0.43830196083403883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16366th epoch : 0.43826791942933063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16367th epoch : 0.4382339297192095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16368th epoch : 0.4381999915927391  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16369th epoch : 0.4381661049393006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16370th epoch : 0.4381322696485919  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16371th epoch : 0.4380984856106262  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16372th epoch : 0.4380647527157307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16373th epoch : 0.4380310708545456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16374th epoch : 0.43799743991802287  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16375th epoch : 0.43796385979742514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16376th epoch : 0.43793033038432444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16377th epoch : 0.43789685157060104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16378th epoch : 0.43786342324844235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16379th epoch : 0.4378300453103419  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16380th epoch : 0.4377967176490979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16381th epoch : 0.4377634401578123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16382th epoch : 0.4377302127298897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16383th epoch : 0.4376970352590361  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16384th epoch : 0.4376639076392578  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16385th epoch : 0.43763082976486034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16386th epoch : 0.43759780153044747  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16387th epoch : 0.4375648228309199  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16388th epoch : 0.4375318935614741  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16389th epoch : 0.4374990136176016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16390th epoch : 0.43746618289508743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16391th epoch : 0.43743340129000946  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16392th epoch : 0.437400668698737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16393th epoch : 0.43736798501793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16394th epoch : 0.43733535014453767  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16395th epoch : 0.43730276397579776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16396th epoch : 0.43727022640923513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16397th epoch : 0.4372377373426612  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16398th epoch : 0.43720529667417224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16399th epoch : 0.43717290430214906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16400th epoch : 0.4371405601252554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16401th epoch : 0.437108264042437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16402th epoch : 0.43707601595292106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16403th epoch : 0.4370438157562144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16404th epoch : 0.43701166335210323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16405th epoch : 0.4369795586406516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16406th epoch : 0.4369475015222006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16407th epoch : 0.4369154918973673  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16408th epoch : 0.43688352966704397  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16409th epoch : 0.4368516147323967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16410th epoch : 0.4368197469948647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16411th epoch : 0.43678792635615926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16412th epoch : 0.43675615271826274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16413th epoch : 0.4367244259834275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16414th epoch : 0.4366927460541751  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16415th epoch : 0.43666111283329523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16416th epoch : 0.4366295262238449  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16417th epoch : 0.4365979861291471  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16418th epoch : 0.43656649245279033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16419th epoch : 0.4365350450986274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16420th epoch : 0.4365036439707744  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16421th epoch : 0.43647228897361  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16422th epoch : 0.43644098001177434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16423th epoch : 0.43640971699016806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16424th epoch : 0.4363784998139516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16425th epoch : 0.4363473283885441  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16426th epoch : 0.43631620261962245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16427th epoch : 0.43628512241312056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16428th epoch : 0.43625408767522816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16429th epoch : 0.43622309831239026  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16430th epoch : 0.4361921542313059  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16431th epoch : 0.4361612553389276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16432th epoch : 0.43613040154246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16433th epoch : 0.43609959274935955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16434th epoch : 0.4360688288673331  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16435th epoch : 0.4360381098043373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16436th epoch : 0.43600743546857773  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16437th epoch : 0.4359768057685079  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16438th epoch : 0.4359462206128284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16439th epoch : 0.43591567991048613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16440th epoch : 0.43588518357067335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16441th epoch : 0.43585473150282694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16442th epoch : 0.4358243236166273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16443th epoch : 0.43579395982199787  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16444th epoch : 0.43576364002910384  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16445th epoch : 0.4357333641483517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16446th epoch : 0.4357031320903882  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16447th epoch : 0.43567294376609955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16448th epoch : 0.4356427990866106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16449th epoch : 0.43561269796328395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16450th epoch : 0.43558264030771937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16451th epoch : 0.43555262603175254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16452th epoch : 0.4355226550474547  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16453th epoch : 0.43549272726713145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16454th epoch : 0.43546284260332224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16455th epoch : 0.4354330009687995  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16456th epoch : 0.4354032022765675  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16457th epoch : 0.43537344643986214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16458th epoch : 0.43534373337214965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16459th epoch : 0.4353140629871261  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16460th epoch : 0.4352844351987164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16461th epoch : 0.43525484992107366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16462th epoch : 0.4352253070685785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16463th epoch : 0.4351958065558379  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16464th epoch : 0.43516634829768486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16465th epoch : 0.4351369322091773  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16466th epoch : 0.4351075582055976  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16467th epoch : 0.43507822620245146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16468th epoch : 0.4350489361154674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16469th epoch : 0.43501968786059614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16470th epoch : 0.43499048135400936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16471th epoch : 0.4349613165120994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16472th epoch : 0.43493219325147836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16473th epoch : 0.4349031114889773  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16474th epoch : 0.4348740711416455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16475th epoch : 0.43484507212674994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16476th epoch : 0.43481611436177414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16477th epoch : 0.43478719776441793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16478th epoch : 0.4347583222525963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16479th epoch : 0.434729487744439  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16480th epoch : 0.4347006941582895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16481th epoch : 0.4346719414127045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16482th epoch : 0.4346432294264532  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16483th epoch : 0.43461455811851657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16484th epoch : 0.43458592740808644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16485th epoch : 0.4345573372145651  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16486th epoch : 0.4345287874575644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16487th epoch : 0.4345002780569052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16488th epoch : 0.43447180893261644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16489th epoch : 0.43444338000493465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16490th epoch : 0.43441499119430327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16491th epoch : 0.4343866424213717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16492th epoch : 0.43435833360699494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16493th epoch : 0.4343300646722328  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16494th epoch : 0.434301835538349  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16495th epoch : 0.43427364612681085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16496th epoch : 0.43424549635928833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16497th epoch : 0.43421738615765354  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16498th epoch : 0.4341893154439799  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16499th epoch : 0.4341612841405416  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16500th epoch : 0.434133292169813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16501th epoch : 0.4341053394544677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16502th epoch : 0.4340774259173782  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16503th epoch : 0.434049551481615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16504th epoch : 0.4340217160704461  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16505th epoch : 0.43399391960733635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16506th epoch : 0.4339661620159467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16507th epoch : 0.43393844322013353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16508th epoch : 0.4339107631439482  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16509th epoch : 0.4338831217116363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16510th epoch : 0.43385551884763696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16511th epoch : 0.43382795447658223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16512th epoch : 0.4338004285232967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16513th epoch : 0.4337729409127964  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16514th epoch : 0.4337454915702886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16515th epoch : 0.4337180804211709  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16516th epoch : 0.4336907073910309  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16517th epoch : 0.4336633724056453  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16518th epoch : 0.4336360753909794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16519th epoch : 0.43360881627318665  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16520th epoch : 0.4335815949786076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16521th epoch : 0.4335544114337698  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16522th epoch : 0.4335272655653869  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16523th epoch : 0.4335001573003581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16524th epoch : 0.43347308656576755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16525th epoch : 0.4334460532888838  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16526th epoch : 0.4334190573971592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16527th epoch : 0.43339209881822927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16528th epoch : 0.433365177479912  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16529th epoch : 0.4333382933102075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16530th epoch : 0.4333114462372974  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16531th epoch : 0.43328463618954394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16532th epoch : 0.43325786309548975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16533th epoch : 0.43323112688385707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16534th epoch : 0.4332044274835473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16535th epoch : 0.43317776482364034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16536th epoch : 0.43315113883339407  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16537th epoch : 0.4331245494422437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16538th epoch : 0.43309799657980136  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16539th epoch : 0.4330714801758553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16540th epoch : 0.43304500016036956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16541th epoch : 0.4330185564634833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16542th epoch : 0.43299214901551025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16543th epoch : 0.4329657777469382  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16544th epoch : 0.43293944258842826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16545th epoch : 0.4329131434708146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16546th epoch : 0.43288688032510386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16547th epoch : 0.43286065308247423  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16548th epoch : 0.43283446167427536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16549th epoch : 0.43280830603202763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16550th epoch : 0.4327821860874216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16551th epoch : 0.4327561017723174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16552th epoch : 0.4327300530187444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16553th epoch : 0.4327040397589006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16554th epoch : 0.4326780619251519  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16555th epoch : 0.43265211945003185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16556th epoch : 0.432626212266241  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16557th epoch : 0.4326003403066463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16558th epoch : 0.4325745035042807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16559th epoch : 0.43254870179234267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16560th epoch : 0.4325229351041955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16561th epoch : 0.4324972033733669  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16562th epoch : 0.4324715065335485  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16563th epoch : 0.4324458445185952  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16564th epoch : 0.4324202172625249  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16565th epoch : 0.4323946246995178  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16566th epoch : 0.4323690667639159  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16567th epoch : 0.4323435433902227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16568th epoch : 0.4323180545131023  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16569th epoch : 0.43229260006737935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16570th epoch : 0.43226717998803826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16571th epoch : 0.4322417942102228  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16572th epoch : 0.43221644266923553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16573th epoch : 0.4321911253005375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16574th epoch : 0.43216584203974756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16575th epoch : 0.43214059282264183  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16576th epoch : 0.43211537758515356  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16577th epoch : 0.43209019626337214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16578th epoch : 0.4320650487935431  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16579th epoch : 0.43203993511206734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16580th epoch : 0.4320148551555007  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16581th epoch : 0.4319898088605535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16582th epoch : 0.4319647961640901  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16583th epoch : 0.43193981700312845  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16584th epoch : 0.43191487131483935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16585th epoch : 0.43188995903654653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16586th epoch : 0.4318650801057255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16587th epoch : 0.43184023446000375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16588th epoch : 0.43181542203715967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16589th epoch : 0.43179064277512264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16590th epoch : 0.43176589661197207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16591th epoch : 0.4317411834859374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16592th epoch : 0.4317165033353973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16593th epoch : 0.43169185609887933  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16594th epoch : 0.43166724171505955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16595th epoch : 0.431642660122762  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16596th epoch : 0.4316181112609582  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16597th epoch : 0.4315935950687669  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16598th epoch : 0.43156911148545335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16599th epoch : 0.431544660450429  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16600th epoch : 0.4315202419032512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16601th epoch : 0.4314958557836225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16602th epoch : 0.43147150203139034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16603th epoch : 0.4314471805865465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16604th epoch : 0.431422891389227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16605th epoch : 0.4313986343797112  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16606th epoch : 0.4313744094984217  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16607th epoch : 0.4313502166859237  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16608th epoch : 0.4313260558829248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16609th epoch : 0.4313019270302742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16610th epoch : 0.43127783006896286  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16611th epoch : 0.4312537649401224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16612th epoch : 0.4312297315850252  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16613th epoch : 0.43120572994508366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16614th epoch : 0.43118175996184993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16615th epoch : 0.4311578215770155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16616th epoch : 0.43113391473241064  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16617th epoch : 0.43111003937000425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16618th epoch : 0.4310861954319031  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16619th epoch : 0.4310623828603516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16620th epoch : 0.43103860159773155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16621th epoch : 0.43101485158656144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16622th epoch : 0.4309911327694962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16623th epoch : 0.4309674450893267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16624th epoch : 0.4309437884889795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16625th epoch : 0.43092016291151625  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16626th epoch : 0.43089656830013345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16627th epoch : 0.43087300459816197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16628th epoch : 0.4308494717490666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16629th epoch : 0.4308259696964459  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16630th epoch : 0.4308024983840314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16631th epoch : 0.4307790577556876  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16632th epoch : 0.43075564775541125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16633th epoch : 0.4307322683273313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16634th epoch : 0.4307089194157081  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16635th epoch : 0.4306856009649334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16636th epoch : 0.4306623129195298  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16637th epoch : 0.43063905522415014  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16638th epoch : 0.4306158278235776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16639th epoch : 0.4305926306627249  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16640th epoch : 0.4305694636866341  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16641th epoch : 0.4305463268404763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16642th epoch : 0.43052322006955085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16643th epoch : 0.43050014331928554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16644th epoch : 0.4304770965352359  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16645th epoch : 0.43045407966308485  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16646th epoch : 0.4304310926486423  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16647th epoch : 0.4304081354378449  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16648th epoch : 0.4303852079767556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16649th epoch : 0.43036231021156324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16650th epoch : 0.4303394420885822  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16651th epoch : 0.4303166035542522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16652th epoch : 0.43029379455513767  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16653th epoch : 0.43027101503792753  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16654th epoch : 0.43024826494943474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16655th epoch : 0.4302255442365961  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16656th epoch : 0.43020285284647175  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16657th epoch : 0.43018019072624486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16658th epoch : 0.43015755782322124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16659th epoch : 0.43013495408482905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16660th epoch : 0.43011237945861835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16661th epoch : 0.4300898338922609  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16662th epoch : 0.4300673173335495  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16663th epoch : 0.43004482973039815  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16664th epoch : 0.4300223710308411  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16665th epoch : 0.4299999411830329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16666th epoch : 0.4299775401352481  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16667th epoch : 0.4299551678358805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16668th epoch : 0.4299328242334432  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16669th epoch : 0.4299105092765681  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16670th epoch : 0.4298882229140055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16671th epoch : 0.42986596509462405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16672th epoch : 0.42984373576740986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16673th epoch : 0.42982153488146674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16674th epoch : 0.4297993623860155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16675th epoch : 0.4297772182303937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16676th epoch : 0.42975510236405556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16677th epoch : 0.4297330147365711  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16678th epoch : 0.42971095529762626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16679th epoch : 0.42968892399702246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16680th epoch : 0.4296669207846762  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16681th epoch : 0.4296449456106187  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16682th epoch : 0.42962299842499574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16683th epoch : 0.42960107917806706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16684th epoch : 0.42957918782020643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16685th epoch : 0.4295573243019009  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16686th epoch : 0.4295354885737508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16687th epoch : 0.42951368058646916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16688th epoch : 0.4294919002908817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16689th epoch : 0.4294701476379261  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16690th epoch : 0.4294484225786521  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16691th epoch : 0.4294267250642209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16692th epoch : 0.429405055045905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16693th epoch : 0.42938341247508766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16694th epoch : 0.42936179730326296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16695th epoch : 0.42934020948203516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16696th epoch : 0.42931864896311844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16697th epoch : 0.42929711569833673  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16698th epoch : 0.4292756096396233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16699th epoch : 0.4292541307390205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16700th epoch : 0.42923267894867934  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16701th epoch : 0.4292112542208593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16702th epoch : 0.429189856507928  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16703th epoch : 0.42916848576236094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16704th epoch : 0.4291471419367409  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16705th epoch : 0.4291258249837582  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16706th epoch : 0.4291045348562098  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16707th epoch : 0.42908327150699943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16708th epoch : 0.42906203488913713  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16709th epoch : 0.4290408249557388  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16710th epoch : 0.4290196416600263  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16711th epoch : 0.4289984849553267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16712th epoch : 0.42897735479507226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16713th epoch : 0.4289562511328001  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16714th epoch : 0.4289351739221519  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16715th epoch : 0.4289141231168735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16716th epoch : 0.4288930986708147  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16717th epoch : 0.428872100537929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16718th epoch : 0.4288511286722734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16719th epoch : 0.4288301830280076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16720th epoch : 0.42880926355939464  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16721th epoch : 0.4287883702207995  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16722th epoch : 0.4287675029666899  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16723th epoch : 0.4287466617516351  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16724th epoch : 0.4287258465303063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16725th epoch : 0.4287050572574759  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16726th epoch : 0.4286842938880174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16727th epoch : 0.4286635563769052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16728th epoch : 0.42864284467921415  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16729th epoch : 0.4286221587501195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16730th epoch : 0.4286014985448963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16731th epoch : 0.42858086401891937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16732th epoch : 0.42856025512766294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16733th epoch : 0.42853967182670044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16734th epoch : 0.4285191140717041  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16735th epoch : 0.42849858181844486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16736th epoch : 0.4284780750227918  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16737th epoch : 0.42845759364071223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16738th epoch : 0.4284371376282712  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16739th epoch : 0.42841670694163125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16740th epoch : 0.4283963015370522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16741th epoch : 0.42837592137089087  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16742th epoch : 0.42835556639960065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16743th epoch : 0.42833523657973166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16744th epoch : 0.4283149318679299  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16745th epoch : 0.4282946522209375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16746th epoch : 0.42827439759559216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16747th epoch : 0.42825416794882704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16748th epoch : 0.4282339632376703  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16749th epoch : 0.42821378341924515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16750th epoch : 0.42819362845076925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16751th epoch : 0.4281734982895547  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16752th epoch : 0.42815339289300774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16753th epoch : 0.4281333122186284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16754th epoch : 0.4281132562240102  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16755th epoch : 0.42809322486684015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16756th epoch : 0.4280732181048983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16757th epoch : 0.4280532358960574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16758th epoch : 0.42803327819828296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16759th epoch : 0.4280133449696326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16760th epoch : 0.4279934361682562  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16761th epoch : 0.4279735517523953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16762th epoch : 0.42795369168038316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16763th epoch : 0.42793385591064415  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16764th epoch : 0.4279140444016939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16765th epoch : 0.4278942571121388  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16766th epoch : 0.42787449400067573  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16767th epoch : 0.4278547550260921  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16768th epoch : 0.4278350401472652  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16769th epoch : 0.42781534932316223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16770th epoch : 0.4277956825128401  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16771th epoch : 0.4277760396754449  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16772th epoch : 0.4277564207702121  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16773th epoch : 0.42773682575646566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16774th epoch : 0.4277172545936185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16775th epoch : 0.4276977072411718  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16776th epoch : 0.4276781836587149  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16777th epoch : 0.42765868380592525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16778th epoch : 0.4276392076425677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16779th epoch : 0.42761975512849465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16780th epoch : 0.42760032622364585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16781th epoch : 0.42758092088804794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16782th epoch : 0.4275615390818142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16783th epoch : 0.4275421807651446  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16784th epoch : 0.4275228458983253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16785th epoch : 0.42750353444172856  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 16786th epoch : 0.4274842463558124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16787th epoch : 0.42746498160112045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16788th epoch : 0.4274457401382818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16789th epoch : 0.42742652192801056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16790th epoch : 0.4274073269311057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16791th epoch : 0.4273881551084512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16792th epoch : 0.427369006421015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16793th epoch : 0.42734988082984965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16794th epoch : 0.42733077829609156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16795th epoch : 0.427311698780961  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16796th epoch : 0.4272926422457617  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16797th epoch : 0.42727360865188074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16798th epoch : 0.42725459796078835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16799th epoch : 0.42723561013403777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16800th epoch : 0.4272166451332647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16801th epoch : 0.42719770292018744  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16802th epoch : 0.4271787834566064  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16803th epoch : 0.42715988670440425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16804th epoch : 0.4271410126255452  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16805th epoch : 0.4271221611820752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16806th epoch : 0.4271033323361214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16807th epoch : 0.4270845260498924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16808th epoch : 0.42706574228567745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16809th epoch : 0.4270469810058467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16810th epoch : 0.4270282421728507  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16811th epoch : 0.4270095257492204  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16812th epoch : 0.4269908316975668  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16813th epoch : 0.4269721599805807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16814th epoch : 0.4269535105610327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16815th epoch : 0.42693488340177277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16816th epoch : 0.4269162784657302  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16817th epoch : 0.42689769571591324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16818th epoch : 0.426879135115409  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16819th epoch : 0.4268605966273832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16820th epoch : 0.4268420802150801  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16821th epoch : 0.42682358584182195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16822th epoch : 0.42680511347100925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16823th epoch : 0.42678666306612006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16824th epoch : 0.42676823459071034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16825th epoch : 0.4267498280084131  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16826th epoch : 0.4267314432829388  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16827th epoch : 0.42671308037807487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16828th epoch : 0.4266947392576854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16829th epoch : 0.42667641988571114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16830th epoch : 0.4266581222261693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16831th epoch : 0.4266398462431531  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16832th epoch : 0.426621591900832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16833th epoch : 0.426603359163451  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16834th epoch : 0.426585147995331  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16835th epoch : 0.42656695836086794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16836th epoch : 0.42654879022453324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16837th epoch : 0.4265306435508733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16838th epoch : 0.42651251830450915  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16839th epoch : 0.42649441445013664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16840th epoch : 0.42647633195252593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16841th epoch : 0.4264582707765215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16842th epoch : 0.4264402308870418  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16843th epoch : 0.42642221224907917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16844th epoch : 0.4264042148276996  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16845th epoch : 0.4263862385880424  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16846th epoch : 0.4263682834953205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16847th epoch : 0.42635034951481965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16848th epoch : 0.4263324366118985  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16849th epoch : 0.42631454475198854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16850th epoch : 0.42629667390059367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16851th epoch : 0.4262788240232902  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16852th epoch : 0.42626099508572657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16853th epoch : 0.42624318705362313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16854th epoch : 0.4262253998927721  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16855th epoch : 0.4262076335690372  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16856th epoch : 0.4261898880483536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16857th epoch : 0.42617216329672775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16858th epoch : 0.4261544592802371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16859th epoch : 0.42613677596502986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16860th epoch : 0.4261191133173251  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16861th epoch : 0.42610147130341225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16862th epoch : 0.42608384988965115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16863th epoch : 0.42606624904247165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16864th epoch : 0.42604866872837366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16865th epoch : 0.4260311089139268  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16866th epoch : 0.42601356956577047  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16867th epoch : 0.4259960506506132  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16868th epoch : 0.42597855213523295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16869th epoch : 0.42596107398647676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16870th epoch : 0.4259436161712604  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16871th epoch : 0.42592617865656857  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16872th epoch : 0.4259087614094543  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16873th epoch : 0.42589136439703906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16874th epoch : 0.4258739875865127  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16875th epoch : 0.4258566309451327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16876th epoch : 0.4258392944402247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16877th epoch : 0.4258219780391819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16878th epoch : 0.42580468170946506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16879th epoch : 0.42578740541860216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16880th epoch : 0.4257701491341883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16881th epoch : 0.4257529128238858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16882th epoch : 0.4257356964554235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16883th epoch : 0.4257184999965971  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16884th epoch : 0.42570132341526873  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16885th epoch : 0.42568416667936676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16886th epoch : 0.4256670297568858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16887th epoch : 0.4256499126158863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16888th epoch : 0.42563281522449464  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16889th epoch : 0.42561573755090276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16890th epoch : 0.42559867956336817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16891th epoch : 0.4255816412302135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16892th epoch : 0.42556462251982685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16893th epoch : 0.4255476234006609  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16894th epoch : 0.4255306438412334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16895th epoch : 0.4255136838101267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16896th epoch : 0.42549674327598763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16897th epoch : 0.4254798222075274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16898th epoch : 0.42546292057352125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16899th epoch : 0.4254460383428086  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16900th epoch : 0.42542917548429254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16901th epoch : 0.4254123319669399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16902th epoch : 0.42539550775978113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16903th epoch : 0.4253787028319099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16904th epoch : 0.4253619171524833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16905th epoch : 0.4253451506907211  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16906th epoch : 0.4253284034159063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16907th epoch : 0.42531167529738445  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16908th epoch : 0.42529496630456376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16909th epoch : 0.42527827640691485  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16910th epoch : 0.4252616055739705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16911th epoch : 0.42524495377532573  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16912th epoch : 0.4252283209806374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16913th epoch : 0.42521170715962425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16914th epoch : 0.4251951122820666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16915th epoch : 0.4251785363178062  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16916th epoch : 0.4251619792367464  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16917th epoch : 0.4251454410088514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16918th epoch : 0.42512892160414656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16919th epoch : 0.42511242099271823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16920th epoch : 0.4250959391447133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16921th epoch : 0.42507947603033935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16922th epoch : 0.4250630316198643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16923th epoch : 0.4250466058836165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16924th epoch : 0.42503019879198417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16925th epoch : 0.42501381031541574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16926th epoch : 0.4249974404244194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16927th epoch : 0.42498108908956295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16928th epoch : 0.42496475628147373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16929th epoch : 0.4249484419708386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16930th epoch : 0.4249321461284034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16931th epoch : 0.42491586872497333  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16932th epoch : 0.4248996097314124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16933th epoch : 0.4248833691186434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16934th epoch : 0.4248671468576477  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16935th epoch : 0.42485094291946546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16936th epoch : 0.4248347572751949  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16937th epoch : 0.4248185898959926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16938th epoch : 0.42480244075307316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16939th epoch : 0.42478630981770915  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16940th epoch : 0.424770197061231  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16941th epoch : 0.4247541024550266  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16942th epoch : 0.4247380259705415  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16943th epoch : 0.4247219675792786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16944th epoch : 0.4247059272527979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16945th epoch : 0.4246899049627166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16946th epoch : 0.4246739006807088  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16947th epoch : 0.4246579143785055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16948th epoch : 0.4246419460278941  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16949th epoch : 0.42462599560071884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16950th epoch : 0.42461006306888016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16951th epoch : 0.4245941484043348  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16952th epoch : 0.4245782515790955  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16953th epoch : 0.4245623725652312  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16954th epoch : 0.4245465113348664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16955th epoch : 0.4245306678601816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16956th epoch : 0.4245148421134126  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16957th epoch : 0.4244990340668508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16958th epoch : 0.4244832436928427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16959th epoch : 0.4244674709637901  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16960th epoch : 0.4244517158521499  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16961th epoch : 0.4244359783304337  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16962th epoch : 0.424420258371208  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16963th epoch : 0.4244045559470938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16964th epoch : 0.4243888710307666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16965th epoch : 0.4243732035949564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16966th epoch : 0.42435755361244726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16967th epoch : 0.42434192105607743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16968th epoch : 0.42432630589873904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16969th epoch : 0.4243107081133781  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16970th epoch : 0.4242951276729944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16971th epoch : 0.42427956455064103  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16972th epoch : 0.42426401871942476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16973th epoch : 0.42424849015250565  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16974th epoch : 0.4242329788230969  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16975th epoch : 0.4242174847044647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16976th epoch : 0.42420200776992817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16977th epoch : 0.4241865479928593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16978th epoch : 0.42417110534668273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16979th epoch : 0.4241556798048756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16980th epoch : 0.42414027134096755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16981th epoch : 0.4241248799285403  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16982th epoch : 0.42410950554122795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16983th epoch : 0.4240941481527165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16984th epoch : 0.42407880773674395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16985th epoch : 0.4240634842671  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16986th epoch : 0.4240481777176261  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16987th epoch : 0.42403288806221506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16988th epoch : 0.42401761527481135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16989th epoch : 0.42400235932941055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16990th epoch : 0.42398712020005935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16991th epoch : 0.4239718978608557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16992th epoch : 0.42395669228594834  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16993th epoch : 0.4239415034495367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16994th epoch : 0.42392633132587104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16995th epoch : 0.4239111758892522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16996th epoch : 0.42389603711403123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16997th epoch : 0.4238809149746097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16998th epoch : 0.42386580944543933  Training Accuracy:0.9642857142857143\n",
      "The training loss at 16999th epoch : 0.42385072050102185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17000th epoch : 0.4238356481159089  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17001th epoch : 0.42382059226470215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17002th epoch : 0.4238055529220527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17003th epoch : 0.42379053006266143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17004th epoch : 0.42377552366127874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17005th epoch : 0.42376053369270417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17006th epoch : 0.4237455601317867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17007th epoch : 0.42373060295342435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17008th epoch : 0.42371566213256406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17009th epoch : 0.4237007376442018  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17010th epoch : 0.4236858294633823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17011th epoch : 0.42367093756519875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17012th epoch : 0.42365606192479316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17013th epoch : 0.42364120251735576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17014th epoch : 0.4236263593181251  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17015th epoch : 0.42361153230238807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17016th epoch : 0.42359672144547944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17017th epoch : 0.4235819267227821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17018th epoch : 0.4235671481097267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17019th epoch : 0.42355238558179165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17020th epoch : 0.42353763911450304  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17021th epoch : 0.4235229086834344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17022th epoch : 0.4235081942642066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17023th epoch : 0.42349349583248797  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17024th epoch : 0.4234788133639939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17025th epoch : 0.4234641468344868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17026th epoch : 0.4234494962197761  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17027th epoch : 0.42343486149571813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17028th epoch : 0.4234202426382158  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17029th epoch : 0.42340563962321875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17030th epoch : 0.4233910524267231  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17031th epoch : 0.4233764810247713  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17032th epoch : 0.42336192539345224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17033th epoch : 0.4233473855089009  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17034th epoch : 0.42333286134729825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17035th epoch : 0.42331835288487135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17036th epoch : 0.4233038600978931  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17037th epoch : 0.4232893829626821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17038th epoch : 0.42327492145560264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17039th epoch : 0.42326047555306445  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17040th epoch : 0.42324604523152276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17041th epoch : 0.42323163046747814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17042th epoch : 0.42321723123747634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17043th epoch : 0.4232028475181082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17044th epoch : 0.4231884792860096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17045th epoch : 0.42317412651786124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17046th epoch : 0.4231597891903887  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17047th epoch : 0.42314546728036223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17048th epoch : 0.42313116076459656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17049th epoch : 0.42311686961995104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17050th epoch : 0.42310259382332926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17051th epoch : 0.4230883333516792  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17052th epoch : 0.42307408818199294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17053th epoch : 0.4230598582913066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17054th epoch : 0.42304564365670033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17055th epoch : 0.4230314442552981  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17056th epoch : 0.4230172600642676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17057th epoch : 0.4230030910608202  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17058th epoch : 0.42298893722221076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17059th epoch : 0.42297479852573777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17060th epoch : 0.4229606749487429  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17061th epoch : 0.42294656646861106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17062th epoch : 0.4229324730627705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17063th epoch : 0.42291839470869225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17064th epoch : 0.42290433138389044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17065th epoch : 0.422890283065922  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17066th epoch : 0.42287624973238674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17067th epoch : 0.4228622313609269  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17068th epoch : 0.4228482279292273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17069th epoch : 0.4228342394150155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17070th epoch : 0.4228202657960611  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17071th epoch : 0.4228063070501759  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17072th epoch : 0.4227923631552142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17073th epoch : 0.42277843408907206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17074th epoch : 0.42276451982968766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17075th epoch : 0.4227506203550409  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17076th epoch : 0.4227367356431536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17077th epoch : 0.4227228656720892  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17078th epoch : 0.4227090104199526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17079th epoch : 0.4226951698648904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17080th epoch : 0.42268134398509044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17081th epoch : 0.4226675327587817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17082th epoch : 0.42265373616423474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17083th epoch : 0.42263995417976086  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17084th epoch : 0.4226261867837125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17085th epoch : 0.422612433954483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17086th epoch : 0.4225986956705066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17087th epoch : 0.4225849719102581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17088th epoch : 0.42257126265225303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17089th epoch : 0.4225575678750474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17090th epoch : 0.4225438875572377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17091th epoch : 0.42253022167746074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17092th epoch : 0.42251657021439365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17093th epoch : 0.4225029331467536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17094th epoch : 0.4224893104532979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17095th epoch : 0.42247570211282387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17096th epoch : 0.4224621081041687  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17097th epoch : 0.4224485284062092  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17098th epoch : 0.42243496299786226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17099th epoch : 0.4224214118580841  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17100th epoch : 0.4224078749658704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17101th epoch : 0.42239435230025646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17102th epoch : 0.42238084384031693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17103th epoch : 0.4223673495651656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17104th epoch : 0.4223538694539554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17105th epoch : 0.4223404034858785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17106th epoch : 0.4223269516401658  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17107th epoch : 0.4223135138960874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17108th epoch : 0.422300090232952  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17109th epoch : 0.422286680630107  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17110th epoch : 0.42227328506693856  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17111th epoch : 0.4222599035228713  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17112th epoch : 0.42224653597736833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17113th epoch : 0.422233182409931  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17114th epoch : 0.4222198428000992  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17115th epoch : 0.42220651712745083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17116th epoch : 0.4221932053716019  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17117th epoch : 0.42217990751220635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17118th epoch : 0.4221666235289563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17119th epoch : 0.42215335340158155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17120th epoch : 0.42214009710984973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17121th epoch : 0.42212685463356603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17122th epoch : 0.4221136259525733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17123th epoch : 0.422100411046752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17124th epoch : 0.42208720989601983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17125th epoch : 0.42207402248033193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17126th epoch : 0.42206084877968064  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17127th epoch : 0.42204768877409554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17128th epoch : 0.4220345424436432  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17129th epoch : 0.4220214097684273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17130th epoch : 0.42200829072858825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17131th epoch : 0.4219951853043035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17132th epoch : 0.42198209347578713  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17133th epoch : 0.42196901522328994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17134th epoch : 0.4219559505270993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17135th epoch : 0.4219428993675389  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17136th epoch : 0.42192986172496927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17137th epoch : 0.4219168375797868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17138th epoch : 0.4219038269124245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17139th epoch : 0.42189082970335134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17140th epoch : 0.4218778459330725  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17141th epoch : 0.42186487558212904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17142th epoch : 0.42185191863109806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17143th epoch : 0.4218389750605925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17144th epoch : 0.421826044851261  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17145th epoch : 0.421813127983788  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17146th epoch : 0.4218002244388935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17147th epoch : 0.4217873341973329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17148th epoch : 0.42177445723989715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17149th epoch : 0.4217615935474127  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17150th epoch : 0.4217487431007411  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17151th epoch : 0.4217359058807792  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17152th epoch : 0.42172308186845897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17153th epoch : 0.42171027104474734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17154th epoch : 0.42169747339064634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17155th epoch : 0.4216846888871929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17156th epoch : 0.42167191751545874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17157th epoch : 0.4216591592565502  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17158th epoch : 0.4216464140916084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17159th epoch : 0.4216336820018092  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17160th epoch : 0.4216209629683626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17161th epoch : 0.4216082569725133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17162th epoch : 0.4215955639955404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17163th epoch : 0.42158288401875704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17164th epoch : 0.4215702170235107  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17165th epoch : 0.4215575629911831  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17166th epoch : 0.4215449219031897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17167th epoch : 0.42153229374098033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17168th epoch : 0.4215196784860384  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17169th epoch : 0.42150707611988125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17170th epoch : 0.42149448662406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17171th epoch : 0.4214819099801595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17172th epoch : 0.421469346169798  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17173th epoch : 0.4214567951746274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17174th epoch : 0.4214442569763332  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17175th epoch : 0.42143173155663394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17176th epoch : 0.42141921889728173  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17177th epoch : 0.4214067189800619  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17178th epoch : 0.4213942317867927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17179th epoch : 0.4213817572993257  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17180th epoch : 0.4213692954995454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17181th epoch : 0.42135684636936926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17182th epoch : 0.4213444098907475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17183th epoch : 0.4213319860456633  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17184th epoch : 0.4213195748161324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17185th epoch : 0.4213071761842033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17186th epoch : 0.42129479013195703  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17187th epoch : 0.42128241664150706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17188th epoch : 0.42127005569499937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17189th epoch : 0.42125770727461226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17190th epoch : 0.4212453713625564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17191th epoch : 0.4212330479410745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17192th epoch : 0.4212207369924416  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17193th epoch : 0.4212084384989648  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17194th epoch : 0.421196152442983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17195th epoch : 0.4211838788068672  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17196th epoch : 0.42117161757302035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17197th epoch : 0.421159368723877  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17198th epoch : 0.4211471322419035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17199th epoch : 0.42113490810959786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17200th epoch : 0.42112269630948973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17201th epoch : 0.42111049682414015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17202th epoch : 0.42109830963614175  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17203th epoch : 0.4210861347281184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17204th epoch : 0.4210739720827254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17205th epoch : 0.42106182168264916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17206th epoch : 0.4210496835106074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17207th epoch : 0.42103755754934885  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17208th epoch : 0.4210254437816533  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17209th epoch : 0.42101334219033154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17210th epoch : 0.4210012527582252  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17211th epoch : 0.42098917546820674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17212th epoch : 0.4209771103031795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17213th epoch : 0.4209650572460774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17214th epoch : 0.42095301627986503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17215th epoch : 0.4209409873875375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17216th epoch : 0.42092897055212053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17217th epoch : 0.42091696575667015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17218th epoch : 0.42090497298427276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17219th epoch : 0.42089299221804527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17220th epoch : 0.4208810234411345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17221th epoch : 0.42086906663671764  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17222th epoch : 0.42085712178800194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17223th epoch : 0.4208451888782247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17224th epoch : 0.4208332678906531  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17225th epoch : 0.4208213588085844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17226th epoch : 0.42080946161534555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17227th epoch : 0.42079757629429326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17228th epoch : 0.42078570282881417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17229th epoch : 0.42077384120232425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17230th epoch : 0.4207619913982693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17231th epoch : 0.42075015340012456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17232th epoch : 0.4207383271913947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17233th epoch : 0.4207265127556138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17234th epoch : 0.4207147100763452  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17235th epoch : 0.4207029191371817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17236th epoch : 0.42069113992174506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17237th epoch : 0.42067937241368636  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17238th epoch : 0.42066761659668567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17239th epoch : 0.420655872454452  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17240th epoch : 0.42064413997072353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17241th epoch : 0.4206324191292671  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17242th epoch : 0.42062070991387845  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17243th epoch : 0.4206090123083821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17244th epoch : 0.4205973262966314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17245th epoch : 0.420585651862508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17246th epoch : 0.42057398898992243  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17247th epoch : 0.4205623376628137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17248th epoch : 0.4205506978651491  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17249th epoch : 0.4205390695809244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17250th epoch : 0.42052745279416387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17251th epoch : 0.4205158474889198  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17252th epoch : 0.42050425364927274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17253th epoch : 0.42049267125933154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17254th epoch : 0.42048110030323305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17255th epoch : 0.42046954076514204  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17256th epoch : 0.42045799262925143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17257th epoch : 0.4204464558797819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17258th epoch : 0.4204349305009821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17259th epoch : 0.42042341647712833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17260th epoch : 0.4204119137925248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17261th epoch : 0.4204004224315033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17262th epoch : 0.42038894237842306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17263th epoch : 0.42037747361767114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17264th epoch : 0.42036601613366203  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17265th epoch : 0.4203545699108375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17266th epoch : 0.42034313493366676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17267th epoch : 0.4203317111866465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17268th epoch : 0.4203202986543004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17269th epoch : 0.42030889732117954  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17270th epoch : 0.4202975071718621  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17271th epoch : 0.42028612819095335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17272th epoch : 0.4202747603630855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17273th epoch : 0.42026340367291776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17274th epoch : 0.42025205810513633  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17275th epoch : 0.4202407236444542  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17276th epoch : 0.4202294002756112  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17277th epoch : 0.4202180879833738  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17278th epoch : 0.42020678675253526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17279th epoch : 0.4201954965679155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17280th epoch : 0.4201842174143608  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17281th epoch : 0.4201729492767442  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17282th epoch : 0.420161692139965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17283th epoch : 0.42015044598894913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17284th epoch : 0.4201392108086486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17285th epoch : 0.4201279865840418  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17286th epoch : 0.42011677330013353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17287th epoch : 0.4201055709419545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17288th epoch : 0.42009437949456174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17289th epoch : 0.4200831989430382  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17290th epoch : 0.42007202927249293  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17291th epoch : 0.42006087046806095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17292th epoch : 0.42004972251490313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17293th epoch : 0.4200385853982062  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17294th epoch : 0.4200274591031827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17295th epoch : 0.4200163436150709  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17296th epoch : 0.42000523891913466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17297th epoch : 0.4199941450006637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17298th epoch : 0.4199830618449731  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17299th epoch : 0.41997198943740344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17300th epoch : 0.419960927763321  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17301th epoch : 0.4199498768081173  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17302th epoch : 0.41993883655720915  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17303th epoch : 0.41992780699603893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17304th epoch : 0.41991678811007394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17305th epoch : 0.419905779884807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17306th epoch : 0.4198947823057558  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17307th epoch : 0.41988379535846326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17308th epoch : 0.41987281902849743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17309th epoch : 0.4198618533014512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17310th epoch : 0.41985089816294235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17311th epoch : 0.4198399535986138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17312th epoch : 0.419829019594133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17313th epoch : 0.4198180961351924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17314th epoch : 0.41980718320750904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17315th epoch : 0.4197962807968247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17316th epoch : 0.41978538888890576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17317th epoch : 0.41977450746954326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17318th epoch : 0.4197636365245526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17319th epoch : 0.41975277603977373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17320th epoch : 0.41974192600107113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17321th epoch : 0.4197310863943334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17322th epoch : 0.4197202572054736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17323th epoch : 0.4197094384204292  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17324th epoch : 0.41969863002516156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17325th epoch : 0.41968783200565646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17326th epoch : 0.4196770443479237  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17327th epoch : 0.4196662670379971  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17328th epoch : 0.4196555000619346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17329th epoch : 0.419644743405818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17330th epoch : 0.4196339970557531  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17331th epoch : 0.41962326099786945  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17332th epoch : 0.4196125352183206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17333th epoch : 0.41960181970328364  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17334th epoch : 0.41959111443895947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17335th epoch : 0.41958041941157276  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 17336th epoch : 0.4195697346073716  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17337th epoch : 0.4195590600126278  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17338th epoch : 0.41954839561363666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17339th epoch : 0.4195377413967168  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17340th epoch : 0.4195270973482105  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17341th epoch : 0.4195164634544832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17342th epoch : 0.4195058397019238  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17343th epoch : 0.4194952260769444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17344th epoch : 0.41948462256598035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17345th epoch : 0.4194740291554902  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17346th epoch : 0.41946344583195555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17347th epoch : 0.4194528725818812  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17348th epoch : 0.4194423093917949  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17349th epoch : 0.41943175624824736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17350th epoch : 0.41942121313781233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17351th epoch : 0.4194106800470863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17352th epoch : 0.41940015696268884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17353th epoch : 0.4193896438712621  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17354th epoch : 0.419379140759471  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17355th epoch : 0.41936864761400333  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17356th epoch : 0.41935816442156926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17357th epoch : 0.41934769116890186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17358th epoch : 0.4193372278427566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17359th epoch : 0.41932677442991145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17360th epoch : 0.4193163309171669  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17361th epoch : 0.4193058972913459  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17362th epoch : 0.41929547353929364  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17363th epoch : 0.4192850596478778  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17364th epoch : 0.4192746556039883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17365th epoch : 0.4192642613945372  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17366th epoch : 0.4192538770064589  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17367th epoch : 0.4192435024267097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17368th epoch : 0.4192331376422684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17369th epoch : 0.41922278264013546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17370th epoch : 0.41921243740733355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17371th epoch : 0.41920210193090734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17372th epoch : 0.4191917761979233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17373th epoch : 0.4191814601954698  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17374th epoch : 0.41917115391065707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17375th epoch : 0.4191608573306172  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17376th epoch : 0.41915057044250387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17377th epoch : 0.4191402932334925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17378th epoch : 0.4191300256907803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17379th epoch : 0.41911976780158583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17380th epoch : 0.4191095195531495  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17381th epoch : 0.419099280932733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17382th epoch : 0.4190890519276197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17383th epoch : 0.41907883252511413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17384th epoch : 0.4190686227125425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17385th epoch : 0.4190584224772522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17386th epoch : 0.419048231806612  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17387th epoch : 0.41903805068801175  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17388th epoch : 0.4190278791088628  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17389th epoch : 0.4190177170565974  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17390th epoch : 0.4190075645186691  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17391th epoch : 0.4189974214825524  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17392th epoch : 0.418987287935743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17393th epoch : 0.4189771638657575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17394th epoch : 0.41896704926013345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17395th epoch : 0.41895694410642925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17396th epoch : 0.41894684839222435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17397th epoch : 0.4189367621051189  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17398th epoch : 0.41892668523273385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17399th epoch : 0.4189166177627109  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17400th epoch : 0.4189065596827124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17401th epoch : 0.41889651098042147  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17402th epoch : 0.41888647164354176  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17403th epoch : 0.41887644165979754  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17404th epoch : 0.4188664210169336  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17405th epoch : 0.41885640970271515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17406th epoch : 0.418846407704928  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17407th epoch : 0.4188364150113782  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17408th epoch : 0.4188264316098923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17409th epoch : 0.4188164574883171  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17410th epoch : 0.4188064926345197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17411th epoch : 0.4187965370363874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17412th epoch : 0.4187865906818279  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17413th epoch : 0.41877665355876875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17414th epoch : 0.4187667256551579  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17415th epoch : 0.41875680695896317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17416th epoch : 0.41874689745817256  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17417th epoch : 0.418736997140794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17418th epoch : 0.4187271059948554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17419th epoch : 0.41871722400840466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17420th epoch : 0.41870735116950936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17421th epoch : 0.4186974874662571  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17422th epoch : 0.41868763288675526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17423th epoch : 0.4186777874191308  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17424th epoch : 0.4186679510515307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17425th epoch : 0.41865812377212136  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17426th epoch : 0.41864830556908894  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17427th epoch : 0.41863849643063916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17428th epoch : 0.41862869634499733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17429th epoch : 0.4186189053004082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17430th epoch : 0.4186091232851361  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17431th epoch : 0.4185993502874648  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17432th epoch : 0.41858958629569737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17433th epoch : 0.41857983129815635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17434th epoch : 0.41857008528318357  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17435th epoch : 0.4185603482391401  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17436th epoch : 0.41855062015440636  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17437th epoch : 0.41854090101738184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17438th epoch : 0.4185311908164853  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17439th epoch : 0.41852148954015467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17440th epoch : 0.41851179717684683  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17441th epoch : 0.41850211371503787  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17442th epoch : 0.41849243914322276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17443th epoch : 0.4184827734499156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17444th epoch : 0.4184731166236492  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17445th epoch : 0.41846346865297557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17446th epoch : 0.41845382952646537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17447th epoch : 0.41844419923270815  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17448th epoch : 0.41843457776031223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17449th epoch : 0.4184249650979047  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17450th epoch : 0.4184153612341315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17451th epoch : 0.41840576615765696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17452th epoch : 0.41839617985716426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17453th epoch : 0.4183866023213551  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17454th epoch : 0.4183770335389499  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17455th epoch : 0.4183674734986873  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17456th epoch : 0.41835792218932477  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17457th epoch : 0.41834837959963805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17458th epoch : 0.4183388457184213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17459th epoch : 0.41832932053448707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17460th epoch : 0.41831980403666635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17461th epoch : 0.4183102962138084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17462th epoch : 0.41830079705478057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17463th epoch : 0.41829130654846874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17464th epoch : 0.4182818246837768  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17465th epoch : 0.4182723514496268  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17466th epoch : 0.4182628868349591  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17467th epoch : 0.4182534308287319  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17468th epoch : 0.41824398341992164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17469th epoch : 0.4182345445975227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17470th epoch : 0.41822511435054743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17471th epoch : 0.4182156926680262  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17472th epoch : 0.41820627953900735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17473th epoch : 0.4181968749525568  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17474th epoch : 0.4181874788977587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17475th epoch : 0.4181780913637147  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17476th epoch : 0.4181687123395444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17477th epoch : 0.4181593418143851  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17478th epoch : 0.41814997977739166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17479th epoch : 0.4181406262177369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17480th epoch : 0.418131281124611  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17481th epoch : 0.41812194448722184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17482th epoch : 0.4181126162947949  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17483th epoch : 0.41810329653657313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17484th epoch : 0.418093985201817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17485th epoch : 0.41808468227980444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17486th epoch : 0.4180753877598307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17487th epoch : 0.41806610163120866  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17488th epoch : 0.41805682388326826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17489th epoch : 0.418047554505357  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17490th epoch : 0.41803829348683963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17491th epoch : 0.41802904081709796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17492th epoch : 0.4180197964855312  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17493th epoch : 0.4180105604815558  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17494th epoch : 0.41800133279460516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17495th epoch : 0.41799211341412995  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17496th epoch : 0.41798290232959784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17497th epoch : 0.4179736995304937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17498th epoch : 0.4179645050063191  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17499th epoch : 0.417955318746593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17500th epoch : 0.417946140740851  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17501th epoch : 0.41793697097864574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17502th epoch : 0.41792780944954677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17503th epoch : 0.41791865614314044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17504th epoch : 0.4179095110490299  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17505th epoch : 0.4179003741568352  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17506th epoch : 0.4178912454561929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17507th epoch : 0.4178821249367565  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17508th epoch : 0.4178730125881962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17509th epoch : 0.41786390840019877  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17510th epoch : 0.41785481236246746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17511th epoch : 0.41784572446472246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17512th epoch : 0.4178366446967001  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17513th epoch : 0.41782757304815366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17514th epoch : 0.4178185095088526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17515th epoch : 0.4178094540685829  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17516th epoch : 0.417800406717147  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17517th epoch : 0.41779136744436385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17518th epoch : 0.41778233624006855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17519th epoch : 0.4177733130941127  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17520th epoch : 0.4177642979963641  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17521th epoch : 0.41775529093670694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17522th epoch : 0.4177462919050414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17523th epoch : 0.4177373008912842  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17524th epoch : 0.41772831788536796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17525th epoch : 0.41771934287724155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17526th epoch : 0.41771037585686993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17527th epoch : 0.4177014168142342  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17528th epoch : 0.41769246573933144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17529th epoch : 0.4176835226221748  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17530th epoch : 0.4176745874527933  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17531th epoch : 0.417665660221232  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17532th epoch : 0.417656740917552  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17533th epoch : 0.41764782953183005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17534th epoch : 0.4176389260541589  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17535th epoch : 0.4176300304746472  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17536th epoch : 0.4176211427834193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17537th epoch : 0.4176122629706152  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17538th epoch : 0.41760339102639094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17539th epoch : 0.417594526940918  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17540th epoch : 0.4175856707043836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17541th epoch : 0.4175768223069909  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17542th epoch : 0.41756798173895815  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17543th epoch : 0.4175591489905196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17544th epoch : 0.4175503240519249  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17545th epoch : 0.4175415069134392  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17546th epoch : 0.41753269756534334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17547th epoch : 0.4175238959979333  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17548th epoch : 0.4175151022015209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17549th epoch : 0.4175063161664329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17550th epoch : 0.4174975378830119  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17551th epoch : 0.4174887673416156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17552th epoch : 0.41748000453261697  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17553th epoch : 0.4174712494464044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17554th epoch : 0.41746250207338154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17555th epoch : 0.4174537624039672  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17556th epoch : 0.4174450304285954  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17557th epoch : 0.4174363061377154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17558th epoch : 0.41742758952179143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17559th epoch : 0.4174188805713031  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17560th epoch : 0.41741017927674495  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17561th epoch : 0.41740148562862656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17562th epoch : 0.41739279961747255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17563th epoch : 0.4173841212338225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17564th epoch : 0.41737545046823116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17565th epoch : 0.417366787311268  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17566th epoch : 0.41735813175351744  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17567th epoch : 0.41734948378557885  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17568th epoch : 0.4173408433980664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17569th epoch : 0.41733221058160913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17570th epoch : 0.4173235853268509  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17571th epoch : 0.41731496762445025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17572th epoch : 0.4173063574650805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17573th epoch : 0.4172977548394297  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17574th epoch : 0.4172891597382006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17575th epoch : 0.41728057215211056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17576th epoch : 0.4172719920718916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17577th epoch : 0.4172634194882903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17578th epoch : 0.4172548543920679  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17579th epoch : 0.4172462967740001  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17580th epoch : 0.41723774662487717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17581th epoch : 0.41722920393550383  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17582th epoch : 0.41722066869669927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17583th epoch : 0.41721214089929715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17584th epoch : 0.4172036205341455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17585th epoch : 0.41719510759210676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17586th epoch : 0.4171866020640576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17587th epoch : 0.4171781039408893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17588th epoch : 0.41716961321350704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17589th epoch : 0.41716112987283066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17590th epoch : 0.417152653909794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17591th epoch : 0.41714418531534514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17592th epoch : 0.41713572408044647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17593th epoch : 0.41712727019607443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17594th epoch : 0.4171188236532196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17595th epoch : 0.4171103844428868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17596th epoch : 0.41710195255609467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17597th epoch : 0.4170935279838762  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17598th epoch : 0.4170851107172782  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17599th epoch : 0.4170767007473616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17600th epoch : 0.4170682980652012  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17601th epoch : 0.4170599026618858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17602th epoch : 0.4170515145285182  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17603th epoch : 0.417043133656215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17604th epoch : 0.4170347600361066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17605th epoch : 0.4170263936593375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17606th epoch : 0.4170180345170657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17607th epoch : 0.4170096826004632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17608th epoch : 0.41700133790071575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17609th epoch : 0.41699300040902276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17610th epoch : 0.41698467011659734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17611th epoch : 0.4169763470146664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17612th epoch : 0.41696803109447045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17613th epoch : 0.41695972234726353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17614th epoch : 0.41695142076431346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17615th epoch : 0.4169431263369016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17616th epoch : 0.41693483905632284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17617th epoch : 0.4169265589138855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17618th epoch : 0.4169182859009116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17619th epoch : 0.4169100200087366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17620th epoch : 0.41690176122870926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17621th epoch : 0.4168935095521919  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17622th epoch : 0.4168852649705602  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17623th epoch : 0.41687702747520333  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17624th epoch : 0.41686879705752367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17625th epoch : 0.4168605737089369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17626th epoch : 0.4168523574208723  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17627th epoch : 0.41684414818477206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17628th epoch : 0.41683594599209184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17629th epoch : 0.41682775083430046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17630th epoch : 0.41681956270287995  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17631th epoch : 0.41681138158932557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17632th epoch : 0.41680320748514565  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17633th epoch : 0.4167950403818617  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17634th epoch : 0.4167868802710084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17635th epoch : 0.4167787271441334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17636th epoch : 0.41677058099279746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17637th epoch : 0.4167624418085743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17638th epoch : 0.4167543095830508  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17639th epoch : 0.4167461843078267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17640th epoch : 0.41673806597451474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17641th epoch : 0.4167299545747406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17642th epoch : 0.41672185010014284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17643th epoch : 0.416713752542373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17644th epoch : 0.41670566189309527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17645th epoch : 0.41669757814398695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17646th epoch : 0.416689501286738  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17647th epoch : 0.41668143131305113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17648th epoch : 0.41667336821464196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17649th epoch : 0.41666531198323875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17650th epoch : 0.41665726261058256  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17651th epoch : 0.416649220088427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17652th epoch : 0.4166411844085385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17653th epoch : 0.41663315556269603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17654th epoch : 0.4166251335426913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17655th epoch : 0.41661711834032855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17656th epoch : 0.4166091099474246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17657th epoch : 0.4166011083558088  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17658th epoch : 0.41659311355732315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17659th epoch : 0.41658512554382193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17660th epoch : 0.4165771443071722  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17661th epoch : 0.4165691698392532  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17662th epoch : 0.4165612021319568  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17663th epoch : 0.4165532411771872  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17664th epoch : 0.416545286966861  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17665th epoch : 0.4165373394929072  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17666th epoch : 0.4165293987472672  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17667th epoch : 0.4165214647218945  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17668th epoch : 0.4165135374087552  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17669th epoch : 0.4165056167998274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17670th epoch : 0.41649770288710164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17671th epoch : 0.41648979566258065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17672th epoch : 0.4164818951182793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17673th epoch : 0.4164740012462248  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17674th epoch : 0.4164661140384563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17675th epoch : 0.4164582334870253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17676th epoch : 0.41645035958399534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17677th epoch : 0.41644249232144204  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17678th epoch : 0.41643463169145306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17679th epoch : 0.41642677768612824  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17680th epoch : 0.41641893029757926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17681th epoch : 0.41641108951793004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17682th epoch : 0.41640325533931627  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17683th epoch : 0.41639542775388577  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17684th epoch : 0.41638760675379816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17685th epoch : 0.41637979233122513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17686th epoch : 0.41637198447835005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17687th epoch : 0.41636418318736845  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17688th epoch : 0.41635638845048745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17689th epoch : 0.4163486002599262  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17690th epoch : 0.4163408186079155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17691th epoch : 0.41633304348669803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17692th epoch : 0.4163252748885283  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17693th epoch : 0.41631751280567236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17694th epoch : 0.4163097572304082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17695th epoch : 0.4163020081550254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17696th epoch : 0.41629426557182514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17697th epoch : 0.4162865294731205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17698th epoch : 0.416278799851236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17699th epoch : 0.4162710766985078  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17700th epoch : 0.41626336000728376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17701th epoch : 0.41625564976992313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17702th epoch : 0.41624794597879694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17703th epoch : 0.4162402486262875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17704th epoch : 0.4162325577047889  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17705th epoch : 0.4162248732067065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17706th epoch : 0.4162171951244572  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17707th epoch : 0.41620952345046935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17708th epoch : 0.4162018581771828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17709th epoch : 0.4161941992970487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17710th epoch : 0.4161865468025296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17711th epoch : 0.4161789006860994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17712th epoch : 0.4161712609402434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17713th epoch : 0.4161636275574583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17714th epoch : 0.4161560005302518  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17715th epoch : 0.4161483798511432  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17716th epoch : 0.416140765512663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17717th epoch : 0.4161331575073527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17718th epoch : 0.4161255558277653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17719th epoch : 0.4161179604664649  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17720th epoch : 0.4161103714160267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17721th epoch : 0.41610278866903716  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17722th epoch : 0.41609521221809387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17723th epoch : 0.4160876420558055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17724th epoch : 0.4160800781747918  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17725th epoch : 0.4160725205676837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17726th epoch : 0.41606496922712294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17727th epoch : 0.41605742414576263  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17728th epoch : 0.41604988531626663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17729th epoch : 0.41604235273130996  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17730th epoch : 0.4160348263835785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17731th epoch : 0.4160273062657692  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17732th epoch : 0.41601979237058984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17733th epoch : 0.4160122846907592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17734th epoch : 0.4160047832190068  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17735th epoch : 0.4159972879480733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17736th epoch : 0.4159897988707099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17737th epoch : 0.415982315979679  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17738th epoch : 0.41597483926775347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17739th epoch : 0.41596736872771717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17740th epoch : 0.41595990435236474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17741th epoch : 0.41595244613450155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17742th epoch : 0.41594499406694363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17743th epoch : 0.41593754814251777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17744th epoch : 0.4159301083540616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17745th epoch : 0.41592267469442323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17746th epoch : 0.41591524715646155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17747th epoch : 0.4159078257330461  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17748th epoch : 0.4159004104170569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17749th epoch : 0.4158930012013847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17750th epoch : 0.41588559807893094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17751th epoch : 0.4158782010426074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17752th epoch : 0.4158708100853365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17753th epoch : 0.4158634252000512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17754th epoch : 0.415856046379695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17755th epoch : 0.4158486736172218  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17756th epoch : 0.41584130690559595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17757th epoch : 0.4158339462377925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17758th epoch : 0.4158265916067967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17759th epoch : 0.4158192430056042  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17760th epoch : 0.4158119004272211  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17761th epoch : 0.415804563864664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17762th epoch : 0.4157972333109597  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17763th epoch : 0.4157899087591454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17764th epoch : 0.41578259020226854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17765th epoch : 0.41577527763338706  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17766th epoch : 0.41576797104556895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17767th epoch : 0.4157606704318926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17768th epoch : 0.41575337578544663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17769th epoch : 0.41574608709932986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17770th epoch : 0.41573880436665134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17771th epoch : 0.41573152758053034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17772th epoch : 0.4157242567340962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17773th epoch : 0.41571699182048855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17774th epoch : 0.4157097328328571  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17775th epoch : 0.41570247976436164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17776th epoch : 0.4156952326081721  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17777th epoch : 0.4156879913574685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17778th epoch : 0.41568075600544085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17779th epoch : 0.41567352654528933  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17780th epoch : 0.41566630297022406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17781th epoch : 0.41565908527346523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17782th epoch : 0.4156518734482429  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17783th epoch : 0.4156446674877973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17784th epoch : 0.41563746738537843  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17785th epoch : 0.4156302731342464  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17786th epoch : 0.415623084727671  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17787th epoch : 0.41561590215893224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17788th epoch : 0.4156087254213197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17789th epoch : 0.41560155450813313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17790th epoch : 0.41559438941268184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17791th epoch : 0.4155872301282852  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17792th epoch : 0.41558007664827223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17793th epoch : 0.4155729289659819  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17794th epoch : 0.4155657870747628  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17795th epoch : 0.4155586509679735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17796th epoch : 0.4155515206389821  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17797th epoch : 0.41554439608116656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17798th epoch : 0.4155372772879144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17799th epoch : 0.41553016425262307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17800th epoch : 0.41552305696869946  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17801th epoch : 0.41551595542956027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17802th epoch : 0.4155088596286318  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17803th epoch : 0.41550176955935  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17804th epoch : 0.4154946852151603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17805th epoch : 0.41548760658951794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17806th epoch : 0.41548053367588755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17807th epoch : 0.4154734664677434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17808th epoch : 0.4154664049585693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17809th epoch : 0.4154593491418585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17810th epoch : 0.41545229901111386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17811th epoch : 0.4154452545598477  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17812th epoch : 0.41543821578158185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17813th epoch : 0.41543118266984747  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17814th epoch : 0.4154241552181852  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17815th epoch : 0.4154171334201453  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17816th epoch : 0.4154101172692871  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17817th epoch : 0.41540310675917963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17818th epoch : 0.4153961018834011  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17819th epoch : 0.41538910263553913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17820th epoch : 0.41538210900919065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17821th epoch : 0.41537512099796203  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17822th epoch : 0.4153681385954688  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17823th epoch : 0.41536116179533583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17824th epoch : 0.4153541905911973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17825th epoch : 0.4153472249766967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17826th epoch : 0.41534026494548654  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17827th epoch : 0.41533331049122874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17828th epoch : 0.41532636160759445  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17829th epoch : 0.41531941828826385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17830th epoch : 0.4153124805269265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17831th epoch : 0.41530554831728095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17832th epoch : 0.41529862165303494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17833th epoch : 0.41529170052790537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17834th epoch : 0.41528478493561827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17835th epoch : 0.41527787486990864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17836th epoch : 0.41527097032452076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17837th epoch : 0.4152640712932078  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17838th epoch : 0.41525717776973203  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 17839th epoch : 0.41525028974786476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17840th epoch : 0.41524340722138636  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17841th epoch : 0.41523653018408613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17842th epoch : 0.4152296586297624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17843th epoch : 0.41522279255222244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17844th epoch : 0.41521593194528245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17845th epoch : 0.4152090768027676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17846th epoch : 0.415202227118512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17847th epoch : 0.41519538288635865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17848th epoch : 0.41518854410015943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17849th epoch : 0.4151817107537751  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17850th epoch : 0.41517488284107523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17851th epoch : 0.41516806035593834  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17852th epoch : 0.4151612432922517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17853th epoch : 0.41515443164391136  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17854th epoch : 0.4151476254048223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17855th epoch : 0.41514082456889817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17856th epoch : 0.41513402913006137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17857th epoch : 0.41512723908224314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17858th epoch : 0.4151204544193834  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17859th epoch : 0.4151136751354308  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17860th epoch : 0.41510690122434274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17861th epoch : 0.41510013268008517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17862th epoch : 0.41509336949663284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17863th epoch : 0.4150866116679692  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17864th epoch : 0.41507985918808615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17865th epoch : 0.41507311205098446  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17866th epoch : 0.4150663702506734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17867th epoch : 0.4150596337811707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17868th epoch : 0.41505290263650296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17869th epoch : 0.4150461768107051  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17870th epoch : 0.4150394562978208  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17871th epoch : 0.4150327410919021  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17872th epoch : 0.4150260311870096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17873th epoch : 0.41501932657721247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17874th epoch : 0.41501262725658844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17875th epoch : 0.4150059332192236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17876th epoch : 0.4149992444592125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17877th epoch : 0.4149925609706581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17878th epoch : 0.4149858827476721  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17879th epoch : 0.4149792097843742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17880th epoch : 0.4149725420748928  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17881th epoch : 0.4149658796133646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17882th epoch : 0.4149592223939346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17883th epoch : 0.41495257041075634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17884th epoch : 0.41494592365799154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17885th epoch : 0.4149392821298103  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17886th epoch : 0.41493264582039113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17887th epoch : 0.41492601472392077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17888th epoch : 0.41491938883459417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17889th epoch : 0.41491276814661476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17890th epoch : 0.414906152654194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17891th epoch : 0.41489954235155185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17892th epoch : 0.41489293723291626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17893th epoch : 0.41488633729252355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17894th epoch : 0.4148797425246182  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17895th epoch : 0.4148731529234529  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17896th epoch : 0.41486656848328846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17897th epoch : 0.41485998919839395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17898th epoch : 0.41485341506304646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17899th epoch : 0.4148468460715314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17900th epoch : 0.414840282218142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17901th epoch : 0.41483372349718  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17902th epoch : 0.41482716990295493  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17903th epoch : 0.4148206214297845  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17904th epoch : 0.4148140780719944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17905th epoch : 0.4148075398239185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17906th epoch : 0.41480100667989867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17907th epoch : 0.41479447863428476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17908th epoch : 0.4147879556814346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17909th epoch : 0.4147814378157142  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17910th epoch : 0.4147749250314973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17911th epoch : 0.41476841732316583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17912th epoch : 0.4147619146851094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17913th epoch : 0.414755417111726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17914th epoch : 0.414748924597421  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17915th epoch : 0.4147424371366082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17916th epoch : 0.4147359547237089  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17917th epoch : 0.4147294773531525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17918th epoch : 0.41472300501937626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17919th epoch : 0.41471653771682526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17920th epoch : 0.41471007543995236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17921th epoch : 0.4147036181832184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17922th epoch : 0.4146971659410919  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17923th epoch : 0.41469071870804936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17924th epoch : 0.4146842764785748  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17925th epoch : 0.4146778392471603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17926th epoch : 0.4146714070083055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17927th epoch : 0.41466497975651795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17928th epoch : 0.4146585574863128  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17929th epoch : 0.414652140192213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17930th epoch : 0.4146457278687493  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17931th epoch : 0.41463932051045993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17932th epoch : 0.41463291811189096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17933th epoch : 0.41462652066759614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17934th epoch : 0.41462012817213684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17935th epoch : 0.414613740620082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17936th epoch : 0.4146073580060084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17937th epoch : 0.4146009803245002  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17938th epoch : 0.4145946075701493  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17939th epoch : 0.41458823973755526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17940th epoch : 0.4145818768213251  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17941th epoch : 0.41457551881607335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17942th epoch : 0.4145691657164223  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17943th epoch : 0.4145628175170017  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17944th epoch : 0.4145564742124487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17945th epoch : 0.4145501357974081  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17946th epoch : 0.4145438022665323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17947th epoch : 0.41453747361448096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17948th epoch : 0.4145311498359213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17949th epoch : 0.41452483092552816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17950th epoch : 0.41451851687798363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17951th epoch : 0.41451220768797736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17952th epoch : 0.4145059033502063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17953th epoch : 0.414499603859375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17954th epoch : 0.41449330921019534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17955th epoch : 0.4144870193973865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17956th epoch : 0.4144807344156752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17957th epoch : 0.4144744542597953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17958th epoch : 0.41446817892448823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17959th epoch : 0.4144619084045027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17960th epoch : 0.4144556426945947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17961th epoch : 0.4144493817895275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17962th epoch : 0.4144431256840719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17963th epoch : 0.41443687437300564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17964th epoch : 0.4144306278511141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17965th epoch : 0.41442438611318966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17966th epoch : 0.414418149154032  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17967th epoch : 0.41441191696844826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17968th epoch : 0.41440568955125245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17969th epoch : 0.4143994668972661  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17970th epoch : 0.4143932490013178  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17971th epoch : 0.4143870358582434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17972th epoch : 0.4143808274628858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17973th epoch : 0.41437462381009527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17974th epoch : 0.41436842489472914  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17975th epoch : 0.4143622307116518  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17976th epoch : 0.41435604125573483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17977th epoch : 0.4143498565218571  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17978th epoch : 0.4143436765049043  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17979th epoch : 0.41433750119976936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17980th epoch : 0.41433133060135235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17981th epoch : 0.4143251647045604  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17982th epoch : 0.4143190035043075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17983th epoch : 0.41431284699551496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17984th epoch : 0.414306695173111  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17985th epoch : 0.41430054803203087  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17986th epoch : 0.4142944055672168  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17987th epoch : 0.41428826777361805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17988th epoch : 0.41428213464619096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17989th epoch : 0.41427600617989874  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17990th epoch : 0.4142698823697116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17991th epoch : 0.4142637632106066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17992th epoch : 0.414257648697568  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17993th epoch : 0.4142515388255867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17994th epoch : 0.4142454335896607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17995th epoch : 0.41423933298479493  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17996th epoch : 0.41423323700600106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17997th epoch : 0.41422714564829777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17998th epoch : 0.41422105890671057  Training Accuracy:0.9642857142857143\n",
      "The training loss at 17999th epoch : 0.41421497677627184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18000th epoch : 0.4142088992520208  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18001th epoch : 0.4142028263290035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18002th epoch : 0.41419675800227296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18003th epoch : 0.4141906942668887  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18004th epoch : 0.41418463511791737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18005th epoch : 0.4141785805504323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18006th epoch : 0.4141725305595134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18007th epoch : 0.41416648514024773  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18008th epoch : 0.4141604442877288  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18009th epoch : 0.41415440799705705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18010th epoch : 0.41414837626333956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18011th epoch : 0.4141423490816901  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18012th epoch : 0.41413632644722936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18013th epoch : 0.41413030835508446  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18014th epoch : 0.41412429480038937  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18015th epoch : 0.41411828577828474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18016th epoch : 0.41411228128391786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18017th epoch : 0.41410628131244265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18018th epoch : 0.4141002858590197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18019th epoch : 0.4140942949188163  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18020th epoch : 0.41408830848700623  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18021th epoch : 0.4140823265587701  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18022th epoch : 0.4140763491292948  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18023th epoch : 0.4140703761937741  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18024th epoch : 0.4140644077474083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18025th epoch : 0.4140584437854042  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18026th epoch : 0.41405248430297503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18027th epoch : 0.4140465292953409  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18028th epoch : 0.4140405787577282  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18029th epoch : 0.41403463268536994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18030th epoch : 0.4140286910735056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18031th epoch : 0.4140227539173812  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18032th epoch : 0.41401682121224925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18033th epoch : 0.4140108929533688  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18034th epoch : 0.4140049691360052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18035th epoch : 0.4139990497554305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18036th epoch : 0.413993134806923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18037th epoch : 0.41398722428576756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18038th epoch : 0.41398131818725536  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18039th epoch : 0.4139754165066841  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18040th epoch : 0.41396951923935793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18041th epoch : 0.41396362638058726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18042th epoch : 0.4139577379256889  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18043th epoch : 0.4139518538699862  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18044th epoch : 0.41394597420880863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18045th epoch : 0.4139400989374923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18046th epoch : 0.4139342280513794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18047th epoch : 0.41392836154581863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18048th epoch : 0.41392249941616494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18049th epoch : 0.4139166416577796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18050th epoch : 0.4139107882660302  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18051th epoch : 0.4139049392362906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18052th epoch : 0.4138990945639411  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18053th epoch : 0.4138932542443679  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18054th epoch : 0.4138874182729638  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18055th epoch : 0.41388158664512775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18056th epoch : 0.41387575935626497  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18057th epoch : 0.4138699364017868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18058th epoch : 0.413864117777111  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18059th epoch : 0.4138583034776613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18060th epoch : 0.41385249349886777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18061th epoch : 0.4138466878361667  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18062th epoch : 0.41384088648500045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18063th epoch : 0.41383508944081765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18064th epoch : 0.41382929669907303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18065th epoch : 0.4138235082552275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18066th epoch : 0.4138177241047481  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18067th epoch : 0.41381194424310797  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18068th epoch : 0.41380616866578646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18069th epoch : 0.4138003973682689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18070th epoch : 0.4137946303460468  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18071th epoch : 0.4137888675946178  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18072th epoch : 0.4137831091094855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18073th epoch : 0.41377735488615963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18074th epoch : 0.4137716049201561  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18075th epoch : 0.41376585920699654  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18076th epoch : 0.413760117742209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18077th epoch : 0.41375438052132735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18078th epoch : 0.41374864753989155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18079th epoch : 0.41374291879344743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18080th epoch : 0.41373719427754707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18081th epoch : 0.4137314739877483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18082th epoch : 0.4137257579196151  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18083th epoch : 0.41372004606871726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18084th epoch : 0.41371433843063077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18085th epoch : 0.41370863500093724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18086th epoch : 0.4137029357752246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18087th epoch : 0.41369724074908637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18088th epoch : 0.4136915499181222  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18089th epoch : 0.41368586327793755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18090th epoch : 0.4136801808241439  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18091th epoch : 0.4136745025523585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18092th epoch : 0.4136688284582045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18093th epoch : 0.413663158537311  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18094th epoch : 0.41365749278531294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18095th epoch : 0.41365183119785104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18096th epoch : 0.4136461737705719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18097th epoch : 0.4136405204991281  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18098th epoch : 0.41363487137917776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18099th epoch : 0.41362922640638505  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18100th epoch : 0.4136235855764199  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18101th epoch : 0.413617948884958  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18102th epoch : 0.4136123163276808  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18103th epoch : 0.41360668790027566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18104th epoch : 0.4136010635984355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18105th epoch : 0.4135954434178592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18106th epoch : 0.41358982735425126  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18107th epoch : 0.413584215403322  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18108th epoch : 0.41357860756078746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18109th epoch : 0.4135730038223694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18110th epoch : 0.4135674041837952  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18111th epoch : 0.41356180864079806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18112th epoch : 0.4135562171891169  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18113th epoch : 0.4135506298244962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18114th epoch : 0.41354504654268615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18115th epoch : 0.41353946733944275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18116th epoch : 0.41353389221052744  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18117th epoch : 0.41352832115170746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18118th epoch : 0.41352275415875567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18119th epoch : 0.41351719122745045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18120th epoch : 0.413511632353576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18121th epoch : 0.41350607753292196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18122th epoch : 0.4135005267612837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18123th epoch : 0.41349498003446195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18124th epoch : 0.4134894373482634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18125th epoch : 0.41348389869849994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18126th epoch : 0.4134783640809893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18127th epoch : 0.41347283349155467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18128th epoch : 0.4134673069260247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18129th epoch : 0.41346178438023373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18130th epoch : 0.4134562658500216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18131th epoch : 0.41345075133123355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18132th epoch : 0.41344524081972045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18133th epoch : 0.4134397343113387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18134th epoch : 0.4134342318019501  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18135th epoch : 0.41342873328742197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18136th epoch : 0.4134232387636272  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18137th epoch : 0.41341774822644395  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18138th epoch : 0.413412261671756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18139th epoch : 0.4134067790954526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18140th epoch : 0.4134013004934283  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18141th epoch : 0.41339582586158324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18142th epoch : 0.41339035519582285  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18143th epoch : 0.41338488849205807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18144th epoch : 0.4133794257462052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18145th epoch : 0.413373966954186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18146th epoch : 0.4133685121119275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18147th epoch : 0.41336306121536226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18148th epoch : 0.41335761426042816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18149th epoch : 0.41335217124306833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18150th epoch : 0.41334673215923146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18151th epoch : 0.41334129700487143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18152th epoch : 0.41333586577594744  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18153th epoch : 0.41333043846842427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18154th epoch : 0.4133250150782717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18155th epoch : 0.4133195956014649  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18156th epoch : 0.4133141800339846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18157th epoch : 0.41330876837181657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18158th epoch : 0.4133033606109519  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18159th epoch : 0.413297956747387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18160th epoch : 0.41329255677712357  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18161th epoch : 0.4132871606961685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18162th epoch : 0.413281768500534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18163th epoch : 0.4132763801862376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18164th epoch : 0.4132709957493018  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18165th epoch : 0.4132656151857546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18166th epoch : 0.4132602384916292  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18167th epoch : 0.41325486566296377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18168th epoch : 0.41324949669580197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18169th epoch : 0.41324413158619255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18170th epoch : 0.4132387703301893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18171th epoch : 0.41323341292385146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18172th epoch : 0.41322805936324325  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18173th epoch : 0.4132227096444341  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18174th epoch : 0.4132173637634986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18175th epoch : 0.4132120217165165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18176th epoch : 0.4132066834995727  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18177th epoch : 0.4132013491087571  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18178th epoch : 0.4131960185401649  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18179th epoch : 0.41319069178989637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18180th epoch : 0.41318536885405677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18181th epoch : 0.4131800497287566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18182th epoch : 0.4131747344101114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18183th epoch : 0.41316942289424174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18184th epoch : 0.4131641151772733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18185th epoch : 0.4131588112553369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18186th epoch : 0.4131535111245682  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18187th epoch : 0.4131482147811082  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18188th epoch : 0.4131429222211027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18189th epoch : 0.4131376334407027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18190th epoch : 0.4131323484360641  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18191th epoch : 0.4131270672033479  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18192th epoch : 0.41312178973872005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18193th epoch : 0.41311651603835153  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18194th epoch : 0.41311124609841837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18195th epoch : 0.41310597991510145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18196th epoch : 0.4131007174845867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18197th epoch : 0.41309545880306503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18198th epoch : 0.4130902038667324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18199th epoch : 0.41308495267178946  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18200th epoch : 0.41307970521444215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18201th epoch : 0.41307446149090105  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18202th epoch : 0.4130692214973818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18203th epoch : 0.41306398523010496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18204th epoch : 0.41305875268529607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18205th epoch : 0.41305352385918537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18206th epoch : 0.4130482987480083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18207th epoch : 0.4130430773480049  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18208th epoch : 0.41303785965542017  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18209th epoch : 0.41303264566650416  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18210th epoch : 0.41302743537751163  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18211th epoch : 0.41302222878470224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18212th epoch : 0.4130170258843404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18213th epoch : 0.41301182667269554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18214th epoch : 0.41300663114604186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18215th epoch : 0.41300143930065836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18216th epoch : 0.41299625113282884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18217th epoch : 0.41299106663884194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18218th epoch : 0.4129858858149912  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18219th epoch : 0.41298070865757486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18220th epoch : 0.41297553516289587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18221th epoch : 0.4129703653272622  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18222th epoch : 0.41296519914698643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18223th epoch : 0.4129600366183859  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18224th epoch : 0.4129548777377827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18225th epoch : 0.41294972250150386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18226th epoch : 0.41294457090588094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18227th epoch : 0.41293942294725033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18228th epoch : 0.4129342786219532  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18229th epoch : 0.41292913792633534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18230th epoch : 0.4129240008567473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18231th epoch : 0.41291886740954437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18232th epoch : 0.4129137375810865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18233th epoch : 0.41290861136773843  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18234th epoch : 0.4129034887658694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18235th epoch : 0.4128983697718535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18236th epoch : 0.4128932543820694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18237th epoch : 0.4128881425929006  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18238th epoch : 0.4128830344007349  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18239th epoch : 0.41287792980196514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18240th epoch : 0.41287282879298864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18241th epoch : 0.4128677313702073  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18242th epoch : 0.4128626375300277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18243th epoch : 0.41285754726886115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18244th epoch : 0.4128524605831234  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18245th epoch : 0.4128473774692349  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18246th epoch : 0.41284229792362065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18247th epoch : 0.41283722194271033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18248th epoch : 0.4128321495229381  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18249th epoch : 0.4128270806607428  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18250th epoch : 0.41282201535256774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18251th epoch : 0.4128169535948609  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18252th epoch : 0.41281189538407476  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18253th epoch : 0.4128068407166663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18254th epoch : 0.41280178958909713  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18255th epoch : 0.4127967419978334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18256th epoch : 0.41279169793934567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18257th epoch : 0.41278665741010917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18258th epoch : 0.4127816204066036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18259th epoch : 0.41277658692531305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18260th epoch : 0.4127715569627263  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18261th epoch : 0.4127665305153365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18262th epoch : 0.41276150757964136  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18263th epoch : 0.41275648815214294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18264th epoch : 0.4127514722293479  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18265th epoch : 0.41274645980776736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18266th epoch : 0.41274145088391684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18267th epoch : 0.4127364454543163  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18268th epoch : 0.4127314435154903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18269th epoch : 0.4127264450639676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18270th epoch : 0.4127214500962816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18271th epoch : 0.41271645860896994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18272th epoch : 0.4127114705985749  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18273th epoch : 0.4127064860616429  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18274th epoch : 0.412701504994725  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18275th epoch : 0.4126965273943766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18276th epoch : 0.41269155325715745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18277th epoch : 0.4126865825796316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18278th epoch : 0.41268161535836767  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18279th epoch : 0.41267665158993844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18280th epoch : 0.4126716912709213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18281th epoch : 0.4126667343978977  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18282th epoch : 0.4126617809674537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18283th epoch : 0.4126568309761796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18284th epoch : 0.41265188442067  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18285th epoch : 0.4126469412975239  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18286th epoch : 0.4126420016033445  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18287th epoch : 0.41263706533473954  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18288th epoch : 0.4126321324883208  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18289th epoch : 0.4126272030607046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18290th epoch : 0.4126222770485114  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18291th epoch : 0.41261735444836606  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18292th epoch : 0.41261243525689756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18293th epoch : 0.4126075194707393  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18294th epoch : 0.412602607086529  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18295th epoch : 0.41259769810090846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18296th epoch : 0.41259279251052383  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18297th epoch : 0.4125878903120256  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18298th epoch : 0.4125829915020683  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18299th epoch : 0.4125780960773109  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18300th epoch : 0.41257320403441644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18301th epoch : 0.4125683153700523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18302th epoch : 0.41256343008088997  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18303th epoch : 0.4125585481636053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18304th epoch : 0.41255366961487827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18305th epoch : 0.4125487944313929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18306th epoch : 0.41254392260983774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18307th epoch : 0.4125390541469052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18308th epoch : 0.41253418903929207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18309th epoch : 0.4125293272836991  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18310th epoch : 0.4125244688768316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18311th epoch : 0.41251961381539853  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18312th epoch : 0.41251476209611343  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18313th epoch : 0.4125099137156938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18314th epoch : 0.41250506867086123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18315th epoch : 0.41250022695834154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18316th epoch : 0.4124953885748646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18317th epoch : 0.41249055351716457  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18318th epoch : 0.4124857217819795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18319th epoch : 0.4124808933660517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18320th epoch : 0.4124760682661276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18321th epoch : 0.4124712464789575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18322th epoch : 0.41246642800129607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18323th epoch : 0.4124616128299019  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18324th epoch : 0.41245680096153775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18325th epoch : 0.41245199239297037  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18326th epoch : 0.41244718712097056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18327th epoch : 0.41244238514231335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18328th epoch : 0.4124375864537776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18329th epoch : 0.4124327910521463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18330th epoch : 0.4124279989342066  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18331th epoch : 0.4124232100967495  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18332th epoch : 0.4124184245365701  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18333th epoch : 0.41241364225046756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18334th epoch : 0.41240886323524506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18335th epoch : 0.4124040874877096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18336th epoch : 0.4123993150046726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18337th epoch : 0.41239454578294893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18338th epoch : 0.4123897798193579  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18339th epoch : 0.4123850171107226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18340th epoch : 0.41238025765387015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18341th epoch : 0.4123755014456316  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18342th epoch : 0.41237074848284205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18343th epoch : 0.4123659987623405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18344th epoch : 0.4123612522809698  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18345th epoch : 0.41235650903557697  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18346th epoch : 0.41235176902301285  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18347th epoch : 0.41234703224013225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18348th epoch : 0.4123422986837938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18349th epoch : 0.4123375683508602  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18350th epoch : 0.4123328412381981  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18351th epoch : 0.4123281173426778  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18352th epoch : 0.41232339666117385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18353th epoch : 0.4123186791905644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18354th epoch : 0.41231396492773176  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18355th epoch : 0.4123092538695619  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18356th epoch : 0.41230454601294475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18357th epoch : 0.41229984135477427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18358th epoch : 0.412295139891948  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 18359th epoch : 0.41229044162136763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18360th epoch : 0.4122857465399385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18361th epoch : 0.41228105464456993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18362th epoch : 0.4122763659321751  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18363th epoch : 0.4122716803996708  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18364th epoch : 0.41226699804397804  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18365th epoch : 0.41226231886202136  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18366th epoch : 0.4122576428507292  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18367th epoch : 0.41225297000703387  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18368th epoch : 0.41224830032787146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18369th epoch : 0.41224363381018186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18370th epoch : 0.4122389704509088  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18371th epoch : 0.41223431024699975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18372th epoch : 0.41222965319540594  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18373th epoch : 0.41222499929308254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18374th epoch : 0.41222034853698836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18375th epoch : 0.412215700924086  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18376th epoch : 0.4122110564513419  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18377th epoch : 0.41220641511572614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18378th epoch : 0.41220177691421267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18379th epoch : 0.4121971418437792  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18380th epoch : 0.412192509901407  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18381th epoch : 0.41218788108408133  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18382th epoch : 0.412183255388791  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18383th epoch : 0.41217863281252864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18384th epoch : 0.4121740133522906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18385th epoch : 0.4121693970050768  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18386th epoch : 0.4121647837678911  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18387th epoch : 0.412160173637741  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18388th epoch : 0.41215556661163755  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18389th epoch : 0.4121509626865956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18390th epoch : 0.41214636185963377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18391th epoch : 0.4121417641277742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18392th epoch : 0.41213716948804285  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18393th epoch : 0.41213257793746927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18394th epoch : 0.4121279894730867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18395th epoch : 0.41212340409193204  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18396th epoch : 0.4121188217910458  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18397th epoch : 0.41211424256747226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18398th epoch : 0.41210966641825925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18399th epoch : 0.4121050933404582  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18400th epoch : 0.4121005233311243  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18401th epoch : 0.4120959563873162  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18402th epoch : 0.4120913925060964  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18403th epoch : 0.4120868316845308  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18404th epoch : 0.41208227391968905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18405th epoch : 0.41207771920864433  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18406th epoch : 0.41207316754847345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18407th epoch : 0.41206861893625685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18408th epoch : 0.41206407336907847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18409th epoch : 0.4120595308440259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18410th epoch : 0.41205499135819035  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18411th epoch : 0.4120504549086665  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18412th epoch : 0.41204592149255265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18413th epoch : 0.4120413911069507  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18414th epoch : 0.41203686374896603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18415th epoch : 0.41203233941570766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18416th epoch : 0.41202781810428807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18417th epoch : 0.4120232998118234  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18418th epoch : 0.41201878453543317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18419th epoch : 0.4120142722722405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18420th epoch : 0.4120097630193722  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18421th epoch : 0.4120052567739583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18422th epoch : 0.41200075353313254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18423th epoch : 0.4119962532940321  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18424th epoch : 0.4119917560537978  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18425th epoch : 0.4119872618095738  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18426th epoch : 0.41198277055850774  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18427th epoch : 0.4119782822977509  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18428th epoch : 0.4119737970244579  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18429th epoch : 0.41196931473578696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18430th epoch : 0.4119648354288997  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18431th epoch : 0.4119603591009613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18432th epoch : 0.41195588574914016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18433th epoch : 0.4119514153706084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18434th epoch : 0.41194694796254155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18435th epoch : 0.4119424835221185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18436th epoch : 0.4119380220465216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18437th epoch : 0.4119335635329367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18438th epoch : 0.41192910797855303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18439th epoch : 0.4119246553805632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18440th epoch : 0.41192020573616345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18441th epoch : 0.41191575904255323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18442th epoch : 0.41191131529693537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18443th epoch : 0.41190687449651636  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18444th epoch : 0.41190243663850584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18445th epoch : 0.4118980017201169  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18446th epoch : 0.4118935697385662  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18447th epoch : 0.41188914069107363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18448th epoch : 0.4118847145748624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18449th epoch : 0.4118802913871593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18450th epoch : 0.41187587112519425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18451th epoch : 0.41187145378620077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18452th epoch : 0.4118670393674156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18453th epoch : 0.41186262786607886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18454th epoch : 0.41185821927943406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18455th epoch : 0.411853813604728  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18456th epoch : 0.41184941083921095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18457th epoch : 0.4118450109801363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18458th epoch : 0.411840614024761  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18459th epoch : 0.41183621997034525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18460th epoch : 0.4118318288141524  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18461th epoch : 0.41182744055344944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18462th epoch : 0.4118230551855064  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18463th epoch : 0.41181867270759676  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18464th epoch : 0.41181429311699724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18465th epoch : 0.41180991641098785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18466th epoch : 0.41180554258685204  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18467th epoch : 0.4118011716418763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18468th epoch : 0.41179680357335063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18469th epoch : 0.4117924383785682  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18470th epoch : 0.4117880760548255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18471th epoch : 0.41178371659942214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18472th epoch : 0.41177936000966125  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18473th epoch : 0.411775006282849  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18474th epoch : 0.411770655416295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18475th epoch : 0.4117663074073119  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18476th epoch : 0.4117619622532158  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18477th epoch : 0.4117576199513259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18478th epoch : 0.4117532804989647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18479th epoch : 0.4117489438934579  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18480th epoch : 0.4117446101321345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18481th epoch : 0.41174027921232653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18482th epoch : 0.4117359511313695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18483th epoch : 0.41173162588660195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18484th epoch : 0.41172730347536574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18485th epoch : 0.4117229838950058  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18486th epoch : 0.4117186671428703  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18487th epoch : 0.4117143532163107  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18488th epoch : 0.41171004211268164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18489th epoch : 0.41170573382934084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18490th epoch : 0.4117014283636492  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18491th epoch : 0.41169712571297085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18492th epoch : 0.41169282587467315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18493th epoch : 0.4116885288461265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18494th epoch : 0.4116842346247046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18495th epoch : 0.4116799432077841  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18496th epoch : 0.411675654592745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18497th epoch : 0.4116713687769704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18498th epoch : 0.4116670857578465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18499th epoch : 0.4116628055327626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18500th epoch : 0.41165852809911124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18501th epoch : 0.411654253454288  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18502th epoch : 0.4116499815956917  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18503th epoch : 0.4116457125207241  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18504th epoch : 0.4116414462267903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18505th epoch : 0.41163718271129823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18506th epoch : 0.41163292197165924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18507th epoch : 0.4116286640052875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18508th epoch : 0.41162440880960044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18509th epoch : 0.4116201563820186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18510th epoch : 0.41161590671996545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18511th epoch : 0.4116116598208677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18512th epoch : 0.41160741568215514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18513th epoch : 0.4116031743012605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18514th epoch : 0.4115989356756196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18515th epoch : 0.41159469980267155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18516th epoch : 0.4115904666798582  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18517th epoch : 0.4115862363046247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18518th epoch : 0.41158200867441913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18519th epoch : 0.4115777837866927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18520th epoch : 0.4115735616388995  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18521th epoch : 0.4115693422284969  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18522th epoch : 0.41156512555294505  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18523th epoch : 0.41156091160970737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18524th epoch : 0.41155670039625014  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18525th epoch : 0.4115524919100427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18526th epoch : 0.41154828614855743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18527th epoch : 0.41154408310926976  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18528th epoch : 0.41153988278965803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18529th epoch : 0.4115356851872036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18530th epoch : 0.41153149029939096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18531th epoch : 0.4115272981237074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18532th epoch : 0.4115231086576434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18533th epoch : 0.41151892189869227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18534th epoch : 0.41151473784435033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18535th epoch : 0.41151055649211693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18536th epoch : 0.41150637783949434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18537th epoch : 0.4115022018839879  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18538th epoch : 0.4114980286231058  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18539th epoch : 0.41149385805435923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18540th epoch : 0.4114896901752624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18541th epoch : 0.41148552498333224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18542th epoch : 0.41148136247608896  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18543th epoch : 0.41147720265105553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18544th epoch : 0.4114730455057578  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18545th epoch : 0.4114688910377247  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18546th epoch : 0.41146473924448806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18547th epoch : 0.4114605901235825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18548th epoch : 0.41145644367254575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18549th epoch : 0.41145229988891835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18550th epoch : 0.4114481587702437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18551th epoch : 0.41144402031406835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18552th epoch : 0.41143988451794145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18553th epoch : 0.41143575137941524  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18554th epoch : 0.4114316208960448  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18555th epoch : 0.4114274930653881  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18556th epoch : 0.41142336788500605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18557th epoch : 0.4114192453524624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18558th epoch : 0.41141512546532377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18559th epoch : 0.4114110082211596  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18560th epoch : 0.41140689361754246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18561th epoch : 0.4114027816520474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18562th epoch : 0.41139867232225263  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18563th epoch : 0.4113945656257392  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18564th epoch : 0.41139046156009074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18565th epoch : 0.4113863601228941  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18566th epoch : 0.4113822613117388  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18567th epoch : 0.4113781651242171  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18568th epoch : 0.41137407155792427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18569th epoch : 0.41136998061045843  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18570th epoch : 0.41136589227942033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18571th epoch : 0.4113618065624138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18572th epoch : 0.4113577234570453  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18573th epoch : 0.41135364296092414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18574th epoch : 0.41134956507166254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18575th epoch : 0.41134548978687546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18576th epoch : 0.4113414171041807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18577th epoch : 0.4113373470211988  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18578th epoch : 0.41133327953555315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18579th epoch : 0.41132921464486993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18580th epoch : 0.41132515234677813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18581th epoch : 0.4113210926389094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18582th epoch : 0.4113170355188984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18583th epoch : 0.41131298098438246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18584th epoch : 0.41130892903300154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18585th epoch : 0.41130487966239854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18586th epoch : 0.4113008328702192  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18587th epoch : 0.41129678865411173  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18588th epoch : 0.41129274701172736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18589th epoch : 0.41128870794072003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18590th epoch : 0.41128467143874636  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18591th epoch : 0.4112806375034657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18592th epoch : 0.41127660613254036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18593th epoch : 0.41127257732363504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18594th epoch : 0.4112685510744174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18595th epoch : 0.4112645273825578  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18596th epoch : 0.4112605062457294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18597th epoch : 0.4112564876616079  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18598th epoch : 0.4112524716278719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18599th epoch : 0.4112484581422025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18600th epoch : 0.4112444472022838  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18601th epoch : 0.4112404388058024  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18602th epoch : 0.41123643295044765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18603th epoch : 0.4112324296339116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18604th epoch : 0.41122842885388905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18605th epoch : 0.41122443060807745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18606th epoch : 0.41122043489417687  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18607th epoch : 0.41121644170989025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18608th epoch : 0.411212451052923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18609th epoch : 0.4112084629209833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18610th epoch : 0.41120447731178206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18611th epoch : 0.41120049422303284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18612th epoch : 0.41119651365245175  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18613th epoch : 0.41119253559775765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18614th epoch : 0.4111885600566721  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18615th epoch : 0.4111845870269193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18616th epoch : 0.41118061650622595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18617th epoch : 0.41117664849232166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18618th epoch : 0.41117268298293846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18619th epoch : 0.41116871997581106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18620th epoch : 0.411164759468677  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18621th epoch : 0.41116080145927614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18622th epoch : 0.4111568459453512  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18623th epoch : 0.4111528929246474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18624th epoch : 0.4111489423949127  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18625th epoch : 0.41114499435389756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18626th epoch : 0.41114104879935515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18627th epoch : 0.4111371057290412  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18628th epoch : 0.411133165140714  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18629th epoch : 0.41112922703213456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18630th epoch : 0.4111252914010664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18631th epoch : 0.4111213582452756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18632th epoch : 0.41111742756253095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18633th epoch : 0.41111349935060376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18634th epoch : 0.4111095736072679  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18635th epoch : 0.4111056503302999  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18636th epoch : 0.4111017295174788  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18637th epoch : 0.4110978111665862  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18638th epoch : 0.41109389527540635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18639th epoch : 0.41108998184172596  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18640th epoch : 0.41108607086333443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18641th epoch : 0.4110821623380236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18642th epoch : 0.4110782562635879  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18643th epoch : 0.4110743526378244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18644th epoch : 0.41107045145853255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18645th epoch : 0.4110665527235145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18646th epoch : 0.4110626564305749  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18647th epoch : 0.41105876257752083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18648th epoch : 0.41105487116216205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18649th epoch : 0.4110509821823108  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18650th epoch : 0.4110470956357818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18651th epoch : 0.41104321152039236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18652th epoch : 0.41103932983396224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18653th epoch : 0.4110354505743138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18654th epoch : 0.41103157373927185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18655th epoch : 0.4110276993266637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18656th epoch : 0.41102382733431925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18657th epoch : 0.4110199577600708  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18658th epoch : 0.41101609060175315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18659th epoch : 0.4110122258572037  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18660th epoch : 0.4110083635242623  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18661th epoch : 0.4110045036007712  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18662th epoch : 0.4110006460845752  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18663th epoch : 0.41099679097352165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18664th epoch : 0.4109929382654603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18665th epoch : 0.4109890879582433  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18666th epoch : 0.4109852400497254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18667th epoch : 0.4109813945377638  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18668th epoch : 0.410977551420218  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18669th epoch : 0.4109737106949503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18670th epoch : 0.41096987235982513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18671th epoch : 0.41096603641270946  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18672th epoch : 0.41096220285147284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18673th epoch : 0.4109583716739871  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18674th epoch : 0.41095454287812655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18675th epoch : 0.41095071646176806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18676th epoch : 0.4109468924227908  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18677th epoch : 0.4109430707590764  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18678th epoch : 0.41093925146850896  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18679th epoch : 0.410935434548975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18680th epoch : 0.4109316199983634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18681th epoch : 0.41092780781456556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18682th epoch : 0.41092399799547524  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18683th epoch : 0.41092019053898854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18684th epoch : 0.41091638544300413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18685th epoch : 0.41091258270542297  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18686th epoch : 0.4109087823241484  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18687th epoch : 0.4109049842970863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18688th epoch : 0.4109011886221447  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18689th epoch : 0.41089739529723435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18690th epoch : 0.41089360432026817  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18691th epoch : 0.41088981568916144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18692th epoch : 0.410886029401832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18693th epoch : 0.41088224545619983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18694th epoch : 0.41087846385018756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18695th epoch : 0.41087468458171994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18696th epoch : 0.41087090764872425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18697th epoch : 0.41086713304913003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18698th epoch : 0.4108633607808693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18699th epoch : 0.4108595908418764  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18700th epoch : 0.41085582323008796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18701th epoch : 0.410852057943443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18702th epoch : 0.41084829497988284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18703th epoch : 0.4108445343373513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18704th epoch : 0.41084077601379443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18705th epoch : 0.41083702000716055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18706th epoch : 0.41083326631540046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18707th epoch : 0.41082951493646724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18708th epoch : 0.41082576586831626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18709th epoch : 0.41082201910890526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18710th epoch : 0.4108182746561943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18711th epoch : 0.41081453250814576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18712th epoch : 0.41081079266272424  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18713th epoch : 0.4108070551178969  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18714th epoch : 0.4108033198716329  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18715th epoch : 0.41079958692190394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18716th epoch : 0.4107958562666839  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18717th epoch : 0.4107921279039491  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18718th epoch : 0.4107884018316779  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18719th epoch : 0.4107846780478513  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18720th epoch : 0.41078095655045227  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18721th epoch : 0.41077723733746624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18722th epoch : 0.4107735204068809  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18723th epoch : 0.41076980575668626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18724th epoch : 0.4107660933848745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18725th epoch : 0.41076238328944015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18726th epoch : 0.41075867546838  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18727th epoch : 0.4107549699196931  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18728th epoch : 0.41075126664138084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18729th epoch : 0.4107475656314467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18730th epoch : 0.4107438668878966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18731th epoch : 0.4107401704087386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18732th epoch : 0.4107364761919831  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18733th epoch : 0.41073278423564274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18734th epoch : 0.4107290945377323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18735th epoch : 0.4107254070962689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18736th epoch : 0.4107217219092719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18737th epoch : 0.4107180389747629  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18738th epoch : 0.41071435829076564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18739th epoch : 0.41071067985530624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18740th epoch : 0.41070700366641294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18741th epoch : 0.41070332972211626  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18742th epoch : 0.4106996580204489  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18743th epoch : 0.41069598855944583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18744th epoch : 0.41069232133714423  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18745th epoch : 0.4106886563515834  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18746th epoch : 0.410684993600805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18747th epoch : 0.4106813330828528  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18748th epoch : 0.4106776747957728  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18749th epoch : 0.41067401873761317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18750th epoch : 0.41067036490642433  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18751th epoch : 0.41066671330025883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18752th epoch : 0.41066306391717156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18753th epoch : 0.41065941675521944  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18754th epoch : 0.41065577181246155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18755th epoch : 0.41065212908695936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18756th epoch : 0.4106484885767763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18757th epoch : 0.4106448502799782  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18758th epoch : 0.4106412141946328  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18759th epoch : 0.4106375803188102  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18760th epoch : 0.4106339486505826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18761th epoch : 0.4106303191880244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18762th epoch : 0.41062669192921214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18763th epoch : 0.41062306687222455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18764th epoch : 0.4106194440151425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18765th epoch : 0.4106158233560489  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18766th epoch : 0.410612204893029  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18767th epoch : 0.41060858862417016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18768th epoch : 0.4106049745475618  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18769th epoch : 0.41060136266129543  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18770th epoch : 0.4105977529634649  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18771th epoch : 0.41059414545216605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18772th epoch : 0.41059054012549684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18773th epoch : 0.4105869369815575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18774th epoch : 0.41058333601845026  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18775th epoch : 0.4105797372342795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18776th epoch : 0.4105761406271517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18777th epoch : 0.4105725461951756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18778th epoch : 0.4105689539364618  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18779th epoch : 0.41056536384912323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18780th epoch : 0.4105617759312749  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18781th epoch : 0.41055819018103384  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18782th epoch : 0.41055460659651927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18783th epoch : 0.4105510251758524  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18784th epoch : 0.4105474459171567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18785th epoch : 0.4105438688185576  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18786th epoch : 0.41054029387818264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18787th epoch : 0.4105367210941615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18788th epoch : 0.41053315046462596  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18789th epoch : 0.41052958198770984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18790th epoch : 0.410526015661549  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18791th epoch : 0.4105224514842815  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18792th epoch : 0.4105188894540474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18793th epoch : 0.4105153295689888  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18794th epoch : 0.4105117718272499  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18795th epoch : 0.4105082162269771  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18796th epoch : 0.41050466276631853  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18797th epoch : 0.41050111144342477  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18798th epoch : 0.41049756225644823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18799th epoch : 0.41049401520354345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18800th epoch : 0.41049047028286695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18801th epoch : 0.41048692749257737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18802th epoch : 0.41048338683083535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18803th epoch : 0.4104798482958037  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18804th epoch : 0.41047631188564715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18805th epoch : 0.4104727775985324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18806th epoch : 0.4104692454326284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18807th epoch : 0.41046571538610593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18808th epoch : 0.410462187457138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18809th epoch : 0.4104586616438994  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18810th epoch : 0.41045513794456717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18811th epoch : 0.4104516163573203  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18812th epoch : 0.41044809688033973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18813th epoch : 0.41044457951180846  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18814th epoch : 0.4104410642499116  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18815th epoch : 0.4104375510928362  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18816th epoch : 0.41043404003877115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18817th epoch : 0.4104305310859077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18818th epoch : 0.41042702423243876  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18819th epoch : 0.41042351947655953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18820th epoch : 0.41042001681646695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18821th epoch : 0.41041651625036013  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18822th epoch : 0.41041301777644007  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18823th epoch : 0.4104095213929099  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18824th epoch : 0.41040602709797463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18825th epoch : 0.4104025348898412  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18826th epoch : 0.4103990447667186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18827th epoch : 0.41039555672681793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18828th epoch : 0.41039207076835205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18829th epoch : 0.4103885868895359  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18830th epoch : 0.41038510508858633  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18831th epoch : 0.41038162536372225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18832th epoch : 0.41037814771316455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18833th epoch : 0.4103746721351359  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18834th epoch : 0.4103711986278612  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18835th epoch : 0.41036772718956704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18836th epoch : 0.4103642578184822  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18837th epoch : 0.4103607905128372  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18838th epoch : 0.41035732527086466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18839th epoch : 0.41035386209079916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18840th epoch : 0.4103504009708771  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18841th epoch : 0.4103469419093369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18842th epoch : 0.4103434849044189  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18843th epoch : 0.41034002995436547  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18844th epoch : 0.4103365770574207  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18845th epoch : 0.4103331262118309  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18846th epoch : 0.41032967741584403  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18847th epoch : 0.4103262306677102  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18848th epoch : 0.4103227859656813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18849th epoch : 0.4103193433080111  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18850th epoch : 0.41031590269295554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18851th epoch : 0.41031246411877226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18852th epoch : 0.41030902758372084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18853th epoch : 0.4103055930860628  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18854th epoch : 0.4103021606240616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18855th epoch : 0.41029873019598256  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18856th epoch : 0.41029530180009294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18857th epoch : 0.41029187543466183  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18858th epoch : 0.41028845109796036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18859th epoch : 0.4102850287882614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18860th epoch : 0.4102816085038398  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18861th epoch : 0.4102781902429723  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18862th epoch : 0.4102747740039375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18863th epoch : 0.4102713597850159  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18864th epoch : 0.41026794758448987  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18865th epoch : 0.41026453740064367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18866th epoch : 0.41026112923176344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18867th epoch : 0.4102577230761373  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18868th epoch : 0.41025431893205494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18869th epoch : 0.4102509167978083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18870th epoch : 0.41024751667169096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18871th epoch : 0.4102441185519984  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18872th epoch : 0.4102407224370279  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18873th epoch : 0.41023732832507886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18874th epoch : 0.41023393621445225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18875th epoch : 0.41023054610345105  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18876th epoch : 0.41022715799038  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18877th epoch : 0.4102237718735458  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18878th epoch : 0.4102203877512569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18879th epoch : 0.41021700562182367  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18880th epoch : 0.4102136254835583  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18881th epoch : 0.41021024733477474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18882th epoch : 0.4102068711737889  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18883th epoch : 0.4102034969989185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18884th epoch : 0.41020012480848306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18885th epoch : 0.41019675460080396  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18886th epoch : 0.4101933863742043  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18887th epoch : 0.4101900201270093  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18888th epoch : 0.4101866558575456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18889th epoch : 0.4101832935641419  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18890th epoch : 0.4101799332451288  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18891th epoch : 0.4101765748988386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18892th epoch : 0.4101732185236052  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18893th epoch : 0.4101698641177648  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 18894th epoch : 0.410166511679655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18895th epoch : 0.4101631612076154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18896th epoch : 0.4101598126999873  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18897th epoch : 0.4101564661551139  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18898th epoch : 0.41015312157134015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18899th epoch : 0.4101497789470128  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18900th epoch : 0.4101464382804804  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18901th epoch : 0.41014309957009326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18902th epoch : 0.4101397628142036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18903th epoch : 0.4101364280111653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18904th epoch : 0.410133095159334  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18905th epoch : 0.41012976425706726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18906th epoch : 0.41012643530272436  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18907th epoch : 0.4101231082946663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18908th epoch : 0.41011978323125603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18909th epoch : 0.410116460110858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18910th epoch : 0.41011313893183865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18911th epoch : 0.41010981969256616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18912th epoch : 0.41010650239141044  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18913th epoch : 0.4101031870267431  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18914th epoch : 0.4100998735969376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18915th epoch : 0.4100965621003692  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18916th epoch : 0.4100932525354148  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18917th epoch : 0.41008994490045314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18918th epoch : 0.4100866391938647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18919th epoch : 0.41008333541403164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18920th epoch : 0.410080033559338  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18921th epoch : 0.41007673362816943  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18922th epoch : 0.4100734356189134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18923th epoch : 0.41007013952995913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18924th epoch : 0.41006684535969756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18925th epoch : 0.4100635531065214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18926th epoch : 0.41006026276882496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18927th epoch : 0.41005697434500443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18928th epoch : 0.4100536878334577  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18929th epoch : 0.4100504032325844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18930th epoch : 0.4100471205407858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18931th epoch : 0.41004383975646497  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18932th epoch : 0.4100405608780267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18933th epoch : 0.41003728390387745  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18934th epoch : 0.41003400883242547  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18935th epoch : 0.41003073566208065  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18936th epoch : 0.4100274643912546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18937th epoch : 0.4100241950183607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18938th epoch : 0.410020927541814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18939th epoch : 0.4100176619600313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18940th epoch : 0.41001439827143094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18941th epoch : 0.4100111364744332  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18942th epoch : 0.4100078765674599  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18943th epoch : 0.4100046185489346  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18944th epoch : 0.4100013624172825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18945th epoch : 0.4099981081709307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18946th epoch : 0.4099948558083076  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18947th epoch : 0.4099916053278437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18948th epoch : 0.40998835672797096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18949th epoch : 0.409985110007123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18950th epoch : 0.4099818651637353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18951th epoch : 0.40997862219624487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18952th epoch : 0.4099753811030904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18953th epoch : 0.4099721418827123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18954th epoch : 0.4099689045335527  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18955th epoch : 0.4099656690540553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18956th epoch : 0.40996243544266553  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18957th epoch : 0.4099592036978304  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18958th epoch : 0.40995597381799875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18959th epoch : 0.4099527458016209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18960th epoch : 0.40994951964714893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18961th epoch : 0.4099462953530366  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18962th epoch : 0.40994307291773924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18963th epoch : 0.40993985233971386  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18964th epoch : 0.4099366336174192  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18965th epoch : 0.40993341674931555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18966th epoch : 0.4099302017338649  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18967th epoch : 0.4099269885695308  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18968th epoch : 0.4099237772547786  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18969th epoch : 0.40992056778807506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18970th epoch : 0.4099173601678888  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18971th epoch : 0.4099141543926901  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18972th epoch : 0.40991095046095055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18973th epoch : 0.40990774837114374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18974th epoch : 0.40990454812174465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18975th epoch : 0.40990134971123  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18976th epoch : 0.4098981531380781  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18977th epoch : 0.40989495840076884  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18978th epoch : 0.4098917654977839  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18979th epoch : 0.40988857442760634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18980th epoch : 0.40988538518872103  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18981th epoch : 0.4098821977796143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18982th epoch : 0.40987901219877426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18983th epoch : 0.4098758284446905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18984th epoch : 0.4098726465158542  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18985th epoch : 0.40986946641075833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18986th epoch : 0.4098662881278972  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18987th epoch : 0.40986311166576694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18988th epoch : 0.4098599370228652  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18989th epoch : 0.40985676419769124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18990th epoch : 0.4098535931887458  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18991th epoch : 0.4098504239945314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18992th epoch : 0.40984725661355215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18993th epoch : 0.4098440910443135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18994th epoch : 0.40984092728532273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18995th epoch : 0.40983776533508864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18996th epoch : 0.4098346051921216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18997th epoch : 0.40983144685493356  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18998th epoch : 0.409828290322038  Training Accuracy:0.9642857142857143\n",
      "The training loss at 18999th epoch : 0.4098251355919501  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19000th epoch : 0.40982198266318653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19001th epoch : 0.40981883153426557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19002th epoch : 0.409815682203707  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19003th epoch : 0.4098125346700322  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19004th epoch : 0.4098093889317642  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19005th epoch : 0.40980624498742757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19006th epoch : 0.40980310283554827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19007th epoch : 0.409799962474654  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19008th epoch : 0.409796823903274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19009th epoch : 0.409793687119939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19010th epoch : 0.40979055212318144  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19011th epoch : 0.4097874189115351  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19012th epoch : 0.40978428748353535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19013th epoch : 0.40978115783771923  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19014th epoch : 0.4097780299726253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19015th epoch : 0.4097749038867936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19016th epoch : 0.4097717795787657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19017th epoch : 0.4097686570470848  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19018th epoch : 0.40976553629029555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19019th epoch : 0.40976241730694424  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19020th epoch : 0.40975930009557854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19021th epoch : 0.40975618465474783  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19022th epoch : 0.4097530709830029  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19023th epoch : 0.40974995907889605  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19024th epoch : 0.4097468489409813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19025th epoch : 0.4097437405678139  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19026th epoch : 0.40974063395795085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19027th epoch : 0.4097375291099506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19028th epoch : 0.40973442602237314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19029th epoch : 0.40973132469377993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19030th epoch : 0.40972822512273394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19031th epoch : 0.40972512730779975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19032th epoch : 0.40972203124754336  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19033th epoch : 0.40971893694053224  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19034th epoch : 0.40971584438533554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19035th epoch : 0.4097127535805237  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19036th epoch : 0.40970966452466895  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19037th epoch : 0.4097065772163446  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19038th epoch : 0.4097034916541259  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19039th epoch : 0.4097004078365893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19040th epoch : 0.4096973257623129  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19041th epoch : 0.40969424542987615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19042th epoch : 0.40969116683786017  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19043th epoch : 0.40968808998484746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19044th epoch : 0.40968501486942205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19045th epoch : 0.40968194149016934  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19046th epoch : 0.4096788698456765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19047th epoch : 0.40967579993453174  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19048th epoch : 0.40967273175532526  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19049th epoch : 0.4096696653066483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19050th epoch : 0.4096666005870938  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19051th epoch : 0.4096635375952562  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19052th epoch : 0.40966047632973135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19053th epoch : 0.40965741678911644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19054th epoch : 0.40965435897201036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19055th epoch : 0.4096513028770134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19056th epoch : 0.4096482485027272  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19057th epoch : 0.40964519584775494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19058th epoch : 0.4096421449107013  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19059th epoch : 0.4096390956901724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19060th epoch : 0.4096360481847758  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19061th epoch : 0.40963300239312045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19062th epoch : 0.40962995831381693  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19063th epoch : 0.4096269159454771  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19064th epoch : 0.40962387528671435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19065th epoch : 0.40962083633614355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19066th epoch : 0.4096177990923809  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19067th epoch : 0.40961476355404414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19068th epoch : 0.40961172971975246  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19069th epoch : 0.4096086975881264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19070th epoch : 0.40960566715778807  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19071th epoch : 0.40960263842736094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19072th epoch : 0.4095996113954699  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19073th epoch : 0.4095965860607413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19074th epoch : 0.40959356242180295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19075th epoch : 0.409590540477284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19076th epoch : 0.4095875202258151  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19077th epoch : 0.40958450166602844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19078th epoch : 0.40958148479655737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19079th epoch : 0.4095784696160369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19080th epoch : 0.4095754561231033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19081th epoch : 0.40957244431639434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19082th epoch : 0.40956943419454916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19083th epoch : 0.40956642575620844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19084th epoch : 0.40956341900001414  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19085th epoch : 0.4095604139246096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19086th epoch : 0.4095574105286398  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19087th epoch : 0.4095544088107509  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19088th epoch : 0.40955140876959045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19089th epoch : 0.40954841040380763  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19090th epoch : 0.40954541371205283  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19091th epoch : 0.4095424186929779  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19092th epoch : 0.40953942534523613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19093th epoch : 0.40953643366748216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19094th epoch : 0.40953344365837197  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19095th epoch : 0.40953045531656307  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19096th epoch : 0.40952746864071427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19097th epoch : 0.4095244836294858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19098th epoch : 0.4095215002815393  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19099th epoch : 0.4095185185955377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19100th epoch : 0.4095155385701454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19101th epoch : 0.4095125602040282  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19102th epoch : 0.4095095834958533  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19103th epoch : 0.40950660844428916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19104th epoch : 0.40950363504800574  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19105th epoch : 0.40950066330567425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19106th epoch : 0.40949769321596746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19107th epoch : 0.4094947247775593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19108th epoch : 0.4094917579891253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19109th epoch : 0.4094887928493421  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19110th epoch : 0.40948582935688793  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19111th epoch : 0.4094828675104423  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19112th epoch : 0.4094799073086861  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19113th epoch : 0.40947694875030155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19114th epoch : 0.4094739918339722  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19115th epoch : 0.40947103655838313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19116th epoch : 0.40946808292222053  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19117th epoch : 0.4094651309241722  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19118th epoch : 0.40946218056292705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19119th epoch : 0.4094592318371756  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19120th epoch : 0.40945628474560947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19121th epoch : 0.4094533392869218  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19122th epoch : 0.40945039545980694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19123th epoch : 0.40944745326296084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19124th epoch : 0.4094445126950804  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19125th epoch : 0.4094415737548643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19126th epoch : 0.4094386364410122  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19127th epoch : 0.4094357007522253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19128th epoch : 0.4094327666872061  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19129th epoch : 0.40942983424465834  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19130th epoch : 0.40942690342328725  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19131th epoch : 0.4094239742217993  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19132th epoch : 0.40942104663890233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19133th epoch : 0.4094181206733054  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19134th epoch : 0.40941519632371903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19135th epoch : 0.409412273588855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19136th epoch : 0.4094093524674265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19137th epoch : 0.40940643295814794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19138th epoch : 0.40940351505973505  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19139th epoch : 0.4094005987709049  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19140th epoch : 0.40939768409037597  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19141th epoch : 0.40939477101686794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19142th epoch : 0.40939185954910184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19143th epoch : 0.40938894968580003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19144th epoch : 0.40938604142568613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19145th epoch : 0.4093831347674851  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19146th epoch : 0.4093802297099233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19147th epoch : 0.40937732625172824  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19148th epoch : 0.4093744243916288  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19149th epoch : 0.40937152412835515  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19150th epoch : 0.40936862546063885  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19151th epoch : 0.40936572838721264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19152th epoch : 0.4093628329068106  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19153th epoch : 0.4093599390181681  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19154th epoch : 0.4093570467200218  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19155th epoch : 0.40935415601110975  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19156th epoch : 0.40935126689017115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19157th epoch : 0.40934837935594653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19158th epoch : 0.4093454934071778  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19159th epoch : 0.40934260904260805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19160th epoch : 0.40933972626098164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19161th epoch : 0.40933684506104434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19162th epoch : 0.40933396544154305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19163th epoch : 0.4093310874012261  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19164th epoch : 0.4093282109388429  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19165th epoch : 0.4093253360531444  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19166th epoch : 0.40932246274288264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19167th epoch : 0.409319591006811  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19168th epoch : 0.409316720843684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19169th epoch : 0.40931385225225764  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19170th epoch : 0.40931098523128906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19171th epoch : 0.40930811977953674  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19172th epoch : 0.40930525589576033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19173th epoch : 0.40930239357872084  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19174th epoch : 0.40929953282718046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19175th epoch : 0.4092966736399027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19176th epoch : 0.4092938160156523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19177th epoch : 0.40929095995319525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19178th epoch : 0.4092881054512989  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19179th epoch : 0.4092852525087317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19180th epoch : 0.40928240112426345  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19181th epoch : 0.40927955129666516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19182th epoch : 0.4092767030247091  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19183th epoch : 0.4092738563071688  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19184th epoch : 0.40927101114281905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19185th epoch : 0.4092681675304358  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19186th epoch : 0.40926532546879646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19187th epoch : 0.4092624849566794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19188th epoch : 0.40925964599286435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19189th epoch : 0.4092568085761324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19190th epoch : 0.4092539727052657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19191th epoch : 0.4092511383790477  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19192th epoch : 0.40924830559626313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19193th epoch : 0.4092454743556979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19194th epoch : 0.4092426446561392  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19195th epoch : 0.4092398164963753  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19196th epoch : 0.40923698987519597  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19197th epoch : 0.40923416479139196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19198th epoch : 0.4092313412437554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19199th epoch : 0.4092285192310795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19200th epoch : 0.40922569875215886  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19201th epoch : 0.40922287980578914  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19202th epoch : 0.40922006239076736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19203th epoch : 0.40921724650589164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19204th epoch : 0.4092144321499614  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19205th epoch : 0.40921161932177724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19206th epoch : 0.409208808020141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19207th epoch : 0.4092059982438557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19208th epoch : 0.4092031899917255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19209th epoch : 0.409200383262556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19210th epoch : 0.4091975780551537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19211th epoch : 0.40919477436832663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19212th epoch : 0.4091919722008837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19213th epoch : 0.4091891715516353  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19214th epoch : 0.4091863724193929  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19215th epoch : 0.409183574802969  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19216th epoch : 0.4091807787011777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19217th epoch : 0.40917798411283396  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19218th epoch : 0.40917519103675404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19219th epoch : 0.4091723994717554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19220th epoch : 0.4091696094166567  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19221th epoch : 0.40916682087027784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19222th epoch : 0.40916403383143973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19223th epoch : 0.4091612482989647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19224th epoch : 0.4091584642716761  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19225th epoch : 0.4091556817483986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19226th epoch : 0.40915290072795785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19227th epoch : 0.40915012120918093  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19228th epoch : 0.4091473431908959  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19229th epoch : 0.4091445666719321  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19230th epoch : 0.40914179165112  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19231th epoch : 0.40913901812729137  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19232th epoch : 0.409136246099279  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19233th epoch : 0.4091334755659169  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19234th epoch : 0.4091307065260403  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19235th epoch : 0.4091279389784855  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19236th epoch : 0.4091251729220901  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19237th epoch : 0.4091224083556928  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19238th epoch : 0.40911964527813344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19239th epoch : 0.40911688368825305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19240th epoch : 0.4091141235848939  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19241th epoch : 0.40911136496689926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19242th epoch : 0.40910860783311376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19243th epoch : 0.40910585218238293  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19244th epoch : 0.40910309801355377  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19245th epoch : 0.4091003453254742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19246th epoch : 0.40909759411699337  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19247th epoch : 0.4090948443869616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19248th epoch : 0.4090920961342303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19249th epoch : 0.4090893493576522  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19250th epoch : 0.40908660405608094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19251th epoch : 0.40908386022837145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19252th epoch : 0.4090811178733798  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19253th epoch : 0.4090783769899632  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19254th epoch : 0.40907563757698  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19255th epoch : 0.40907289963328963  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19256th epoch : 0.4090701631577528  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19257th epoch : 0.4090674281492312  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19258th epoch : 0.4090646946065878  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19259th epoch : 0.40906196252868654  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19260th epoch : 0.4090592319143927  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19261th epoch : 0.40905650276257255  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19262th epoch : 0.40905377507209356  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19263th epoch : 0.40905104884182425  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19264th epoch : 0.40904832407063435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19265th epoch : 0.4090456007573947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19266th epoch : 0.4090428789009773  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19267th epoch : 0.40904015850025516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19268th epoch : 0.40903743955410254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19269th epoch : 0.4090347220613948  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19270th epoch : 0.4090320060210083  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19271th epoch : 0.4090292914318207  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 19272th epoch : 0.4090265782927107  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19273th epoch : 0.4090238666025581  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19274th epoch : 0.4090211563602438  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19275th epoch : 0.40901844756464983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19276th epoch : 0.40901574021465936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19277th epoch : 0.40901303430915675  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19278th epoch : 0.4090103298470273  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19279th epoch : 0.40900762682715747  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19280th epoch : 0.4090049252484349  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19281th epoch : 0.4090022251097483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19282th epoch : 0.4089995264099875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19283th epoch : 0.4089968291480434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19284th epoch : 0.408994133322808  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19285th epoch : 0.40899143893317447  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19286th epoch : 0.4089887459780369  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19287th epoch : 0.40898605445629077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19288th epoch : 0.4089833643668324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19289th epoch : 0.4089806757085594  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19290th epoch : 0.4089779884803702  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19291th epoch : 0.40897530268116467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19292th epoch : 0.40897261830984355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19293th epoch : 0.4089699353653087  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19294th epoch : 0.4089672538464631  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19295th epoch : 0.4089645737522108  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19296th epoch : 0.40896189508145697  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19297th epoch : 0.40895921783310785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19298th epoch : 0.40895654200607073  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19299th epoch : 0.40895386759925406  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19300th epoch : 0.40895119461156726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19301th epoch : 0.4089485230419209  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19302th epoch : 0.4089458528892267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19303th epoch : 0.4089431841523973  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19304th epoch : 0.4089405168303465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19305th epoch : 0.4089378509219892  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19306th epoch : 0.4089351864262413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19307th epoch : 0.4089325233420199  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19308th epoch : 0.408929861668243  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19309th epoch : 0.4089272014038298  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19310th epoch : 0.40892454254770055  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19311th epoch : 0.40892188509877647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19312th epoch : 0.40891922905598  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19313th epoch : 0.40891657441823454  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19314th epoch : 0.4089139211844645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19315th epoch : 0.40891126935359556  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19316th epoch : 0.40890861892455427  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19317th epoch : 0.40890596989626826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19318th epoch : 0.4089033222676663  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19319th epoch : 0.40890067603767816  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19320th epoch : 0.4088980312052347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19321th epoch : 0.4088953877692678  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19322th epoch : 0.4088927457287105  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19323th epoch : 0.4088901050824966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19324th epoch : 0.4088874658295613  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19325th epoch : 0.40888482796884074  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19326th epoch : 0.4088821914992719  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19327th epoch : 0.4088795564197932  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19328th epoch : 0.4088769227293436  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19329th epoch : 0.40887429042686363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19330th epoch : 0.40887165951129456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19331th epoch : 0.4088690299815787  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19332th epoch : 0.40886640183665945  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19333th epoch : 0.4088637750754814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19334th epoch : 0.4088611496969899  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19335th epoch : 0.4088585257001315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19336th epoch : 0.4088559030838538  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19337th epoch : 0.40885328184710534  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19338th epoch : 0.4088506619888358  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19339th epoch : 0.4088480435079958  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19340th epoch : 0.4088454264035371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19341th epoch : 0.4088428106744124  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19342th epoch : 0.4088401963195754  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19343th epoch : 0.40883758333798087  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19344th epoch : 0.4088349717285847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19345th epoch : 0.40883236149034363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19346th epoch : 0.4088297526222155  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19347th epoch : 0.40882714512315926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19348th epoch : 0.4088245389921348  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19349th epoch : 0.4088219342281029  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19350th epoch : 0.40881933083002564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19351th epoch : 0.40881672879686587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19352th epoch : 0.40881412812758766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19353th epoch : 0.40881152882115585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19354th epoch : 0.4088089308765365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19355th epoch : 0.40880633429269664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19356th epoch : 0.4088037390686043  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19357th epoch : 0.4088011452032284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19358th epoch : 0.40879855269553905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19359th epoch : 0.40879596154450726  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19360th epoch : 0.40879337174910507  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19361th epoch : 0.4087907833083056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19362th epoch : 0.4087881962210828  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19363th epoch : 0.4087856104864118  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19364th epoch : 0.40878302610326867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19365th epoch : 0.4087804430706304  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19366th epoch : 0.4087778613874751  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19367th epoch : 0.4087752810527818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19368th epoch : 0.4087727020655306  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19369th epoch : 0.4087701244247025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19370th epoch : 0.40876754812927957  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19371th epoch : 0.40876497317824484  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19372th epoch : 0.4087623995705823  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19373th epoch : 0.408759827305277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19374th epoch : 0.40875725638131494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19375th epoch : 0.4087546867976831  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19376th epoch : 0.4087521185533695  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19377th epoch : 0.40874955164736315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19378th epoch : 0.4087469860786539  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19379th epoch : 0.4087444218462327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19380th epoch : 0.40874185894909154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19381th epoch : 0.4087392973862233  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19382th epoch : 0.4087367371566218  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19383th epoch : 0.40873417825928193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19384th epoch : 0.40873162069319957  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19385th epoch : 0.4087290644573715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19386th epoch : 0.40872650955079554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19387th epoch : 0.4087239559724704  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19388th epoch : 0.40872140372139587  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19389th epoch : 0.40871885279657266  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19390th epoch : 0.4087163031970024  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19391th epoch : 0.40871375492168777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19392th epoch : 0.4087112079696324  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19393th epoch : 0.4087086623398408  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19394th epoch : 0.4087061180313187  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19395th epoch : 0.4087035750430724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19396th epoch : 0.4087010333741095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19397th epoch : 0.40869849302343847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19398th epoch : 0.40869595399006864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19399th epoch : 0.4086934162730104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19400th epoch : 0.40869087987127517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19401th epoch : 0.40868834478387506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19402th epoch : 0.40868581100982343  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19403th epoch : 0.40868327854813447  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19404th epoch : 0.40868074739782323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19405th epoch : 0.40867821755790595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19406th epoch : 0.40867568902739965  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19407th epoch : 0.40867316180532226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19408th epoch : 0.40867063589069286  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19409th epoch : 0.4086681112825313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19410th epoch : 0.4086655879798584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19411th epoch : 0.408663065981696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19412th epoch : 0.40866054528706686  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19413th epoch : 0.40865802589499467  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19414th epoch : 0.40865550780450405  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19415th epoch : 0.4086529910146206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19416th epoch : 0.4086504755243709  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19417th epoch : 0.40864796133278225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19418th epoch : 0.40864544843888323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19419th epoch : 0.40864293684170305  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19420th epoch : 0.40864042654027205  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19421th epoch : 0.4086379175336214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19422th epoch : 0.4086354098207833  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19423th epoch : 0.4086329034007908  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19424th epoch : 0.40863039827267794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19425th epoch : 0.4086278944354796  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19426th epoch : 0.4086253918882317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19427th epoch : 0.4086228906299711  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19428th epoch : 0.40862039065973543  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19429th epoch : 0.4086178919765634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19430th epoch : 0.4086153945794946  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19431th epoch : 0.40861289846756954  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19432th epoch : 0.4086104036398296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19433th epoch : 0.4086079100953172  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19434th epoch : 0.40860541783307563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19435th epoch : 0.408602926852149  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19436th epoch : 0.4086004371515825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19437th epoch : 0.40859794873042216  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19438th epoch : 0.4085954615877149  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19439th epoch : 0.40859297572250863  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19440th epoch : 0.40859049113385215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19441th epoch : 0.4085880078207951  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19442th epoch : 0.4085855257823881  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19443th epoch : 0.4085830450176827  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19444th epoch : 0.40858056552573135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19445th epoch : 0.4085780873055873  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19446th epoch : 0.40857561035630496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19447th epoch : 0.4085731346769394  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19448th epoch : 0.40857066026654665  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19449th epoch : 0.40856818712418375  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19450th epoch : 0.4085657152489085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19451th epoch : 0.4085632446397798  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19452th epoch : 0.4085607752958572  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19453th epoch : 0.4085583072162014  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19454th epoch : 0.4085558403998738  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19455th epoch : 0.4085533748459368  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19456th epoch : 0.4085509105534537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19457th epoch : 0.4085484475214887  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19458th epoch : 0.4085459857491069  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19459th epoch : 0.4085435252353741  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19460th epoch : 0.40854106597935735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19461th epoch : 0.40853860798012437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19462th epoch : 0.4085361512367437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19463th epoch : 0.40853369574828496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19464th epoch : 0.4085312415138186  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19465th epoch : 0.4085287885324159  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19466th epoch : 0.4085263368031491  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19467th epoch : 0.4085238863250912  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19468th epoch : 0.40852143709731625  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19469th epoch : 0.4085189891188991  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19470th epoch : 0.40851654238891555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19471th epoch : 0.4085140969064421  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19472th epoch : 0.40851165267055634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19473th epoch : 0.40850920968033666  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19474th epoch : 0.40850676793486235  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19475th epoch : 0.40850432743321347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19476th epoch : 0.4085018881744711  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19477th epoch : 0.40849945015771716  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19478th epoch : 0.40849701338203437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19479th epoch : 0.40849457784650645  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19480th epoch : 0.40849214355021785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19481th epoch : 0.40848971049225397  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19482th epoch : 0.40848727867170115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19483th epoch : 0.40848484808764646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19484th epoch : 0.4084824187391779  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19485th epoch : 0.40847999062538437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19486th epoch : 0.40847756374535565  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19487th epoch : 0.40847513809818226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19488th epoch : 0.40847271368295573  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19489th epoch : 0.4084702904987684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19490th epoch : 0.4084678685447134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19491th epoch : 0.40846544781988486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19492th epoch : 0.4084630283233777  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19493th epoch : 0.4084606100542877  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19494th epoch : 0.40845819301171143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19495th epoch : 0.40845577719474646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19496th epoch : 0.40845336260249115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19497th epoch : 0.40845094923404474  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19498th epoch : 0.4084485370885072  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19499th epoch : 0.4084461261649795  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19500th epoch : 0.4084437164625634  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19501th epoch : 0.4084413079803616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19502th epoch : 0.40843890071747746  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19503th epoch : 0.4084364946730154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19504th epoch : 0.4084340898460806  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19505th epoch : 0.408431686235779  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19506th epoch : 0.40842928384121757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19507th epoch : 0.408426882661504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19508th epoch : 0.4084244826957468  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19509th epoch : 0.40842208394305546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19510th epoch : 0.40841968640254017  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19511th epoch : 0.408417290073312  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19512th epoch : 0.408414894954483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19513th epoch : 0.40841250104516585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19514th epoch : 0.40841010834447417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19515th epoch : 0.4084077168515225  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19516th epoch : 0.408405326565426  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19517th epoch : 0.4084029374853009  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19518th epoch : 0.4084005496102641  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19519th epoch : 0.40839816293943343  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19520th epoch : 0.40839577747192757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19521th epoch : 0.40839339320686585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19522th epoch : 0.4083910101433687  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19523th epoch : 0.40838862828055716  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19524th epoch : 0.4083862476175532  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19525th epoch : 0.40838386815347966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19526th epoch : 0.4083814898874601  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19527th epoch : 0.408379112818619  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19528th epoch : 0.40837673694608156  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19529th epoch : 0.4083743622689739  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19530th epoch : 0.40837198878642295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19531th epoch : 0.40836961649755643  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19532th epoch : 0.40836724540150293  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19533th epoch : 0.4083648754973918  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19534th epoch : 0.40836250678435326  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19535th epoch : 0.4083601392615183  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19536th epoch : 0.4083577729280188  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19537th epoch : 0.40835540778298735  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19538th epoch : 0.4083530438255575  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19539th epoch : 0.40835068105486344  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19540th epoch : 0.40834831947004036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19541th epoch : 0.4083459590702242  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19542th epoch : 0.40834359985455154  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19543th epoch : 0.4083412418221601  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19544th epoch : 0.4083388849721881  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19545th epoch : 0.40833652930377473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19546th epoch : 0.40833417481606005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19547th epoch : 0.4083318215081847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19548th epoch : 0.4083294693792903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19549th epoch : 0.4083271184285193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19550th epoch : 0.4083247686550149  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19551th epoch : 0.408322420057921  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19552th epoch : 0.40832007263638254  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19553th epoch : 0.408317726389545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19554th epoch : 0.40831538131655487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19555th epoch : 0.4083130374165593  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19556th epoch : 0.4083106946887063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19557th epoch : 0.40830835313214475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19558th epoch : 0.4083060127460242  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19559th epoch : 0.40830367352949504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19560th epoch : 0.4083013354817085  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19561th epoch : 0.4082989986018165  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19562th epoch : 0.408296662888972  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19563th epoch : 0.40829432834232837  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19564th epoch : 0.4082919949610401  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19565th epoch : 0.4082896627442623  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19566th epoch : 0.408287331691151  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19567th epoch : 0.4082850018008629  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19568th epoch : 0.4082826730725555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19569th epoch : 0.40828034550538717  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19570th epoch : 0.408278019098517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19571th epoch : 0.40827569385110485  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19572th epoch : 0.4082733697623115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19573th epoch : 0.4082710468312983  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19574th epoch : 0.4082687250572275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19575th epoch : 0.40826640443926226  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19576th epoch : 0.40826408497656624  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19577th epoch : 0.4082617666683041  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19578th epoch : 0.4082594495136412  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19579th epoch : 0.4082571335117437  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19580th epoch : 0.40825481866177854  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19581th epoch : 0.4082525049629134  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19582th epoch : 0.4082501924143167  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19583th epoch : 0.4082478810151578  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19584th epoch : 0.4082455707646067  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19585th epoch : 0.4082432616618342  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19586th epoch : 0.4082409537060119  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19587th epoch : 0.40823864689631206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19588th epoch : 0.4082363412319079  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19589th epoch : 0.4082340367119733  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19590th epoch : 0.40823173333568286  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19591th epoch : 0.408229431102212  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19592th epoch : 0.408227130010737  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19593th epoch : 0.40822483006043475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19594th epoch : 0.408222531250483  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19595th epoch : 0.4082202335800603  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19596th epoch : 0.40821793704834586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19597th epoch : 0.4082156416545196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19598th epoch : 0.40821334739776244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19599th epoch : 0.4082110542772559  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19600th epoch : 0.4082087622921822  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19601th epoch : 0.4082064714417245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19602th epoch : 0.40820418172506656  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19603th epoch : 0.40820189314139294  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19604th epoch : 0.40819960568988906  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19605th epoch : 0.40819731936974096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19606th epoch : 0.4081950341801355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19607th epoch : 0.40819275012026024  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19608th epoch : 0.40819046718930363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19609th epoch : 0.4081881853864547  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19610th epoch : 0.40818590471090327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19611th epoch : 0.40818362516184004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19612th epoch : 0.40818134673845635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19613th epoch : 0.4081790694399443  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19614th epoch : 0.4081767932654968  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19615th epoch : 0.40817451821430734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19616th epoch : 0.40817224428557036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19617th epoch : 0.40816997147848094  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19618th epoch : 0.4081676997922349  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19619th epoch : 0.4081654292260289  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19620th epoch : 0.40816315977906015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19621th epoch : 0.40816089145052686  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19622th epoch : 0.4081586242396278  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19623th epoch : 0.40815635814556245  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19624th epoch : 0.4081540931675312  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19625th epoch : 0.40815182930473504  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19626th epoch : 0.4081495665563758  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19627th epoch : 0.4081473049216559  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19628th epoch : 0.40814504439977867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19629th epoch : 0.40814278498994805  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19630th epoch : 0.4081405266913688  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19631th epoch : 0.4081382695032463  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19632th epoch : 0.4081360134247868  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19633th epoch : 0.4081337584551972  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19634th epoch : 0.4081315045936852  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19635th epoch : 0.4081292518394591  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19636th epoch : 0.40812700019172804  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19637th epoch : 0.4081247496497019  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19638th epoch : 0.4081225002125912  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19639th epoch : 0.40812025187960727  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19640th epoch : 0.4081180046499621  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19641th epoch : 0.4081157585228685  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19642th epoch : 0.4081135134975399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19643th epoch : 0.4081112695731905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19644th epoch : 0.4081090267490352  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19645th epoch : 0.4081067850242897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19646th epoch : 0.40810454439817034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19647th epoch : 0.40810230486989424  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19648th epoch : 0.4081000664386792  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19649th epoch : 0.40809782910374365  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19650th epoch : 0.40809559286430697  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19651th epoch : 0.40809335771958904  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19652th epoch : 0.40809112366881056  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19653th epoch : 0.408088890711193  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19654th epoch : 0.40808665884595835  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19655th epoch : 0.40808442807232953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19656th epoch : 0.40808219838953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19657th epoch : 0.4080799697967841  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19658th epoch : 0.40807774229331684  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19659th epoch : 0.4080755158783537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19660th epoch : 0.4080732905511213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19661th epoch : 0.40807106631084655  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19662th epoch : 0.40806884315675734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19663th epoch : 0.40806662108808217  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19664th epoch : 0.4080644001040503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19665th epoch : 0.4080621802038916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19666th epoch : 0.4080599613868368  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19667th epoch : 0.4080577436521171  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19668th epoch : 0.4080555269989647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19669th epoch : 0.4080533114266122  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19670th epoch : 0.40805109693429314  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19671th epoch : 0.4080488835212417  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19672th epoch : 0.4080466711866926  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19673th epoch : 0.40804445992988153  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19674th epoch : 0.40804224975004466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19675th epoch : 0.40804004064641897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19676th epoch : 0.40803783261824217  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19677th epoch : 0.4080356256647525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19678th epoch : 0.40803341978518903  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19679th epoch : 0.4080312149787915  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19680th epoch : 0.40802901124480045  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19681th epoch : 0.4080268085824569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19682th epoch : 0.4080246069910027  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19683th epoch : 0.4080224064696803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19684th epoch : 0.40802020701773295  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19685th epoch : 0.40801800863440457  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19686th epoch : 0.40801581131893977  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19687th epoch : 0.40801361507058376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19688th epoch : 0.4080114198885825  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19689th epoch : 0.40800922577218274  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19690th epoch : 0.4080070327206317  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19691th epoch : 0.4080048407331775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19692th epoch : 0.40800264980906875  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19693th epoch : 0.4080004599475549  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19694th epoch : 0.40799827114788606  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19695th epoch : 0.407996083409313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19696th epoch : 0.40799389673108705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19697th epoch : 0.40799171111246046  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19698th epoch : 0.407989526552686  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19699th epoch : 0.40798734305101714  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19700th epoch : 0.40798516060670803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19701th epoch : 0.40798297921901355  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19702th epoch : 0.40798079888718924  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19703th epoch : 0.40797861961049126  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19704th epoch : 0.4079764413881765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19705th epoch : 0.40797426421950256  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19706th epoch : 0.4079720881037276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19707th epoch : 0.4079699130401105  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19708th epoch : 0.40796773902791095  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19709th epoch : 0.4079655660663891  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19710th epoch : 0.4079633941548059  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19711th epoch : 0.40796122329242296  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19712th epoch : 0.40795905347850253  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19713th epoch : 0.40795688471230757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19714th epoch : 0.4079547169931016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19715th epoch : 0.40795255032014893  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19716th epoch : 0.4079503846927145  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19717th epoch : 0.40794822011006393  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19718th epoch : 0.4079460565714635  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19719th epoch : 0.4079438940761801  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19720th epoch : 0.4079417326234813  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19721th epoch : 0.40793957221263544  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19722th epoch : 0.40793741284291146  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19723th epoch : 0.4079352545135788  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19724th epoch : 0.4079330972239079  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19725th epoch : 0.40793094097316956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19726th epoch : 0.40792878576063535  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19727th epoch : 0.4079266315855775  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19728th epoch : 0.4079244784472689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19729th epoch : 0.4079223263449832  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19730th epoch : 0.40792017527799446  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19731th epoch : 0.4079180252455776  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19732th epoch : 0.4079158762470081  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19733th epoch : 0.40791372828156214  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19734th epoch : 0.4079115813485166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19735th epoch : 0.4079094354471489  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19736th epoch : 0.4079072905767372  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19737th epoch : 0.40790514673656025  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19738th epoch : 0.40790300392589757  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19739th epoch : 0.4079008621440291  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19740th epoch : 0.4078987213902357  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19741th epoch : 0.40789658166379866  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19742th epoch : 0.40789444296400007  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19743th epoch : 0.40789230529012266  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19744th epoch : 0.4078901686414496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19745th epoch : 0.407888033017265  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19746th epoch : 0.40788589841685347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19747th epoch : 0.4078837648395002  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19748th epoch : 0.40788163228449115  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19749th epoch : 0.40787950075111284  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19750th epoch : 0.4078773702386525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19751th epoch : 0.4078752407463979  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19752th epoch : 0.4078731122736376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19753th epoch : 0.4078709848196607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19754th epoch : 0.4078688583837569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19755th epoch : 0.4078667329652167  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19756th epoch : 0.407864608563331  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19757th epoch : 0.4078624851773916  Training Accuracy:0.9642857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 19758th epoch : 0.40786036280669075  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19759th epoch : 0.40785824145052135  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19760th epoch : 0.4078561211081771  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19761th epoch : 0.40785400177895215  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19762th epoch : 0.4078518834621413  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19763th epoch : 0.40784976615704016  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19764th epoch : 0.40784764986294475  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19765th epoch : 0.40784553457915185  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19766th epoch : 0.4078434203049588  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19767th epoch : 0.4078413070396637  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19768th epoch : 0.40783919478256514  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19769th epoch : 0.40783708353296244  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19770th epoch : 0.4078349732901554  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19771th epoch : 0.40783286405344465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19772th epoch : 0.4078307558221313  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19773th epoch : 0.40782864859551715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19774th epoch : 0.40782654237290455  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19775th epoch : 0.4078244371535967  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19776th epoch : 0.407822332936897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19777th epoch : 0.40782022972210996  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19778th epoch : 0.4078181275085404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19779th epoch : 0.40781602629549385  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19780th epoch : 0.4078139260822765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19781th epoch : 0.40781182686819506  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19782th epoch : 0.40780972865255694  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19783th epoch : 0.4078076314346702  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19784th epoch : 0.4078055352138434  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19785th epoch : 0.4078034399893858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19786th epoch : 0.40780134576060734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19787th epoch : 0.4077992525268184  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19788th epoch : 0.4077971602873302  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19789th epoch : 0.4077950690414544  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19790th epoch : 0.4077929787885033  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19791th epoch : 0.40779088952778986  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19792th epoch : 0.4077888012586277  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19793th epoch : 0.4077867139803309  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19794th epoch : 0.40778462769221435  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19795th epoch : 0.40778254239359335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19796th epoch : 0.407780458083784  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19797th epoch : 0.4077783747621028  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19798th epoch : 0.4077762924278671  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19799th epoch : 0.4077742110803947  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19800th epoch : 0.407772130719004  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19801th epoch : 0.4077700513430141  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19802th epoch : 0.40776797295174466  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19803th epoch : 0.4077658955445159  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19804th epoch : 0.4077638191206488  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19805th epoch : 0.4077617436794647  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19806th epoch : 0.4077596692202858  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19807th epoch : 0.4077575957424347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19808th epoch : 0.40775552324523473  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19809th epoch : 0.4077534517280098  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19810th epoch : 0.4077513811900844  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19811th epoch : 0.4077493116307836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19812th epoch : 0.4077472430494331  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19813th epoch : 0.4077451754453592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19814th epoch : 0.40774310881788883  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19815th epoch : 0.4077410431663494  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19816th epoch : 0.40773897849006907  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19817th epoch : 0.4077369147883765  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19818th epoch : 0.407734852060601  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19819th epoch : 0.4077327903060724  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19820th epoch : 0.4077307295241212  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19821th epoch : 0.4077286697140785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19822th epoch : 0.407726610875276  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19823th epoch : 0.40772455300704585  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19824th epoch : 0.40772249610872097  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19825th epoch : 0.4077204401796347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19826th epoch : 0.4077183852191213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19827th epoch : 0.4077163312265151  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19828th epoch : 0.4077142782011516  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19829th epoch : 0.4077122261423664  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19830th epoch : 0.407710175049496  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19831th epoch : 0.40770812492187736  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19832th epoch : 0.407706075758848  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19833th epoch : 0.4077040275597461  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19834th epoch : 0.4077019803239104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19835th epoch : 0.4076999340506803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19836th epoch : 0.4076978887393956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19837th epoch : 0.4076958443893969  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19838th epoch : 0.40769380100002517  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19839th epoch : 0.4076917585706222  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19840th epoch : 0.40768971710053015  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19841th epoch : 0.40768767658909183  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19842th epoch : 0.4076856370356507  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19843th epoch : 0.40768359843955077  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19844th epoch : 0.40768156080013657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19845th epoch : 0.40767952411675323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19846th epoch : 0.4076774883887465  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19847th epoch : 0.4076754536154627  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19848th epoch : 0.4076734197962487  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19849th epoch : 0.40767138693045196  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19850th epoch : 0.4076693550174206  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19851th epoch : 0.407667324056503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19852th epoch : 0.4076652940470486  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19853th epoch : 0.40766326498840705  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19854th epoch : 0.40766123687992867  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19855th epoch : 0.4076592097209644  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19856th epoch : 0.4076571835108657  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19857th epoch : 0.4076551582489847  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19858th epoch : 0.40765313393467384  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19859th epoch : 0.40765111056728653  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19860th epoch : 0.4076490881461764  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19861th epoch : 0.4076470666706978  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19862th epoch : 0.40764504614020564  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19863th epoch : 0.40764302655405543  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19864th epoch : 0.4076410079116032  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19865th epoch : 0.40763899021220545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19866th epoch : 0.4076369734552195  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19867th epoch : 0.407634957640003  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19868th epoch : 0.4076329427659143  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19869th epoch : 0.40763092883231217  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19870th epoch : 0.40762891583855615  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19871th epoch : 0.4076269037840062  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19872th epoch : 0.4076248926680229  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19873th epoch : 0.40762288248996725  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19874th epoch : 0.40762087324920104  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19875th epoch : 0.4076188649450865  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19876th epoch : 0.4076168575769864  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19877th epoch : 0.4076148511442641  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19878th epoch : 0.4076128456462836  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19879th epoch : 0.40761084108240925  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19880th epoch : 0.40760883745200616  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19881th epoch : 0.4076068347544399  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19882th epoch : 0.4076048329890766  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19883th epoch : 0.40760283215528303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19884th epoch : 0.4076008322524264  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19885th epoch : 0.40759883327987456  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19886th epoch : 0.40759683523699586  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19887th epoch : 0.40759483812315916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19888th epoch : 0.40759284193773404  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19889th epoch : 0.4075908466800905  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19890th epoch : 0.40758885234959913  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19891th epoch : 0.40758685894563096  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19892th epoch : 0.4075848664675578  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19893th epoch : 0.4075828749147518  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19894th epoch : 0.40758088428658584  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19895th epoch : 0.4075788945824331  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19896th epoch : 0.40757690580166767  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19897th epoch : 0.40757491794366374  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19898th epoch : 0.40757293100779646  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19899th epoch : 0.40757094499344126  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19900th epoch : 0.4075689598999742  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19901th epoch : 0.407566975726772  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19902th epoch : 0.4075649924732117  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19903th epoch : 0.407563010138671  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19904th epoch : 0.4075610287225283  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19905th epoch : 0.4075590482241622  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19906th epoch : 0.4075570686429521  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19907th epoch : 0.40755508997827794  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19908th epoch : 0.40755311222952  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19909th epoch : 0.40755113539605936  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19910th epoch : 0.40754915947727743  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19911th epoch : 0.4075471844725563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19912th epoch : 0.4075452103812785  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19913th epoch : 0.40754323720282715  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19914th epoch : 0.4075412649365859  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19915th epoch : 0.40753929358193897  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19916th epoch : 0.407537323138271  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19917th epoch : 0.40753535360496734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19918th epoch : 0.4075333849814138  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19919th epoch : 0.4075314172669966  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19920th epoch : 0.40752945046110267  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19921th epoch : 0.4075274845631194  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19922th epoch : 0.4075255195724347  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19923th epoch : 0.4075235554884371  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19924th epoch : 0.40752159231051555  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19925th epoch : 0.4075196300380595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19926th epoch : 0.4075176686704592  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19927th epoch : 0.40751570820710503  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19928th epoch : 0.40751374864738826  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19929th epoch : 0.4075117899907005  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19930th epoch : 0.40750983223643383  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19931th epoch : 0.4075078753839811  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19932th epoch : 0.40750591943273545  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19933th epoch : 0.40750396438209063  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19934th epoch : 0.407502010231441  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19935th epoch : 0.4075000569801814  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19936th epoch : 0.40749810462770697  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19937th epoch : 0.40749615317341376  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19938th epoch : 0.4074942026166981  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19939th epoch : 0.4074922529569569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19940th epoch : 0.4074903041935876  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19941th epoch : 0.4074883563259881  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19942th epoch : 0.40748640935355696  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19943th epoch : 0.40748446327569315  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19944th epoch : 0.4074825180917962  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19945th epoch : 0.40748057380126607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19946th epoch : 0.4074786304035034  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19947th epoch : 0.4074766878979093  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19948th epoch : 0.40747474628388525  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19949th epoch : 0.4074728055608335  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19950th epoch : 0.4074708657281566  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19951th epoch : 0.4074689267852577  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19952th epoch : 0.40746698873154047  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19953th epoch : 0.40746505156640916  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19954th epoch : 0.40746311528926843  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19955th epoch : 0.4074611798995234  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19956th epoch : 0.40745924539657996  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19957th epoch : 0.40745731177984423  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19958th epoch : 0.40745537904872303  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19959th epoch : 0.4074534472026236  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19960th epoch : 0.4074515162409537  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19961th epoch : 0.40744958616312166  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19962th epoch : 0.4074476569685363  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19963th epoch : 0.4074457286566069  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19964th epoch : 0.40744380122674323  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19965th epoch : 0.4074418746783557  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19966th epoch : 0.4074399490108551  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19967th epoch : 0.40743802422365283  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19968th epoch : 0.4074361003161607  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19969th epoch : 0.40743417728779113  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19970th epoch : 0.4074322551379569  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19971th epoch : 0.40743033386607147  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19972th epoch : 0.40742841347154873  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19973th epoch : 0.407426493953803  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19974th epoch : 0.4074245753122492  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19975th epoch : 0.40742265754630275  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19976th epoch : 0.40742074065537953  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19977th epoch : 0.40741882463889595  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19978th epoch : 0.4074169094962689  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19979th epoch : 0.4074149952269158  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19980th epoch : 0.4074130818302546  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19981th epoch : 0.4074111693057036  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19982th epoch : 0.4074092576526818  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19983th epoch : 0.4074073468706086  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19984th epoch : 0.4074054369589039  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19985th epoch : 0.4074035279169881  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19986th epoch : 0.40740161974428213  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19987th epoch : 0.40739971244020734  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19988th epoch : 0.4073978060041857  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19989th epoch : 0.40739590043563956  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19990th epoch : 0.4073939957339918  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19991th epoch : 0.4073920918986659  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19992th epoch : 0.40739018892908563  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19993th epoch : 0.4073882868246754  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19994th epoch : 0.4073863855848602  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19995th epoch : 0.40738448520906523  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19996th epoch : 0.4073825856967164  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19997th epoch : 0.4073806870472402  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19998th epoch : 0.40737878926006327  Training Accuracy:0.9642857142857143\n",
      "The training loss at 19999th epoch : 0.40737689233461305  Training Accuracy:0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "train_gradient_update(model , loss_m , X_train,Y_train , 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:0.9642857142857143\n",
      "Test accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:{}\".format(accuracy_neural_net(model,X_train, Y_train)))\n",
    "\n",
    "print(\"Test accuracy:{}\".format(accuracy_neural_net(model,X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4) (4,)\n",
      "(4, 2) (2,)\n",
      "(2, 1) (1,)\n",
      "The training loss at 0th epoch : 3.607285466475095  Training Accuracy:0.5\n",
      "The training loss at 1th epoch : 6.998835234621003  Training Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "layer_list = [n,4,2,1]\n",
    "model = Neural_Net(layer_list)\n",
    "loss_m = Loss()\n",
    "train_newton_update(model , loss_m , X_train,Y_train , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_neural_net(model,X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
